{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mod1 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0417'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "programtrend_df = pd.read_sql(\"select Date from programtrend order by Date desc limit 1\", engine)\n",
    "programtrend_df = str(programtrend_df['Date'])\n",
    "until_date = programtrend_df[5:15]\n",
    "\n",
    "start = datetime.strptime(until_date , \"%Y-%m-%d\")\n",
    "until_date= (start + timedelta(days=0)).strftime('%m%d')  ##  'yy-mm-dd' \n",
    "until_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('d:\\\\'+until_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2020-04-13', '2020-04-14'], dtype='datetime64[ns]', name='Date', freq=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_kospi.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mod1 import *\n",
    "df = get_index_ohlcv_by_date(\"20200219\", \"20200410\", \"코스닥\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_kospi  = get_index_ohlcv_by_date(\"20200219\", \"20200410\", \"코스피\")\n",
    "df_kospi.index.names = ['Date']\n",
    "df_kospi.columns  = ('Open','High','Low','Close','Volume')\n",
    "df_kospi['Market']='kospi'\n",
    "df_kospi.to_sql(name='kospi', con=engine, if_exists='append')\n",
    "\n",
    "df_kosdaq = get_index_ohlcv_by_date(\"20200219\", \"20200410\", \"코스닥\")\n",
    "df_kosdaq.index.names = ['Date']\n",
    "df_kosdaq.columns  = ('Open','High','Low','Close','Volume')\n",
    "df_kosdaq['Market']='kosdaq'\n",
    "df_kosdaq.to_sql(name='kosdaq', con=engine, if_exists='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kosdaq = get_index_ohlcv_by_date(\"2020311\", \"20200320\", \"코스닥\")\n",
    "df_kosdaq.index.names = ['Date']\n",
    "df_kosdaq.columns  = ('Open','High','Low','Close','Volume')\n",
    "df_kosdaq['Market']='kosdaq'\n",
    "df_kosdaq.to_sql(name='kosdaq', con=engine, if_exists='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kosdaq = get_index_ohlcv_by_date(\"202012\", \"20200320\", \"코스피\")\n",
    "df_kosdaq.index.names = ['Date']\n",
    "df_kosdaq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kosdaq = get_index_ohlcv_by_date(\"20200408\", \"20200410\", \"코스닥\")\n",
    "df_kosdaq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#df=df_kosdaq.loc[:'2020-04-09']\n",
    "#df_kosdaq = df\n",
    "\n",
    "df_kosdaq.index.names = ['Date']\n",
    "df_kosdaq.columns  = ('Open','High','Low','Close','Volume')\n",
    "df_kosdaq['Market']='kosdaq'\n",
    "df_kosdaq.to_sql(name='kosdaq', con=engine, if_exists='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_kosdaq.index.names = ['Date'] \n",
    "df_kosdaq.columns  = ('Open','High','Low','Close','Volume')\n",
    "df_kosdaq['Market']='kosdaq'\n",
    "df_kosdaq.to_sql(name='kosdaq', con=engine, if_exists='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kosdaq.index.names = ['Date']\n",
    "df_kosdaq.columns  = ('Open','High','Low','Close','Volume')\n",
    "df_kosdaq['Market']='kosdaq'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.loc[:'2020-03-25']\n",
    "df_kosdaq = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_kosdaq.to_sql(name='kosdaq', con=engine, if_exists='append')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mod1 import * \n",
    "data = select_stock('부광약품','2018-01-01')\n",
    "\n",
    "\n",
    "PP = pd.Series((data['High'] + data['Low'] + data['Close']) / 3)  \n",
    "R1 = pd.Series(2 * PP - data['Low'])  \n",
    "S1 = pd.Series(2 * PP - data['High'])  \n",
    "R2 = pd.Series(PP + data['High'] - data['Low'])  \n",
    "S2 = pd.Series(PP - data['High'] + data['Low'])  \n",
    "R3 = pd.Series(data['High'] + 2 * (PP - data['Low']))  \n",
    "S3 = pd.Series(data['Low'] - 2 * (data['High'] - PP))  \n",
    "psr = {'PP':PP, 'R1':R1, 'S1':S1, 'R2':R2, 'S2':S2, 'R3':R3, 'S3':S3}  \n",
    "PSR = pd.DataFrame(psr)  \n",
    "data= data.join(PSR)  \n",
    "\n",
    "# plot the data\n",
    "#pd.concat([data['Close'],PP,R1,S1,R2,S2,R3,S3],axis=1).plot(figsize=(12,9),grid=True)\n",
    "pd.concat([data['Close'],PP],axis=1).plot(figsize=(12,6),grid=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mod1 import * \n",
    "data = select_stock('hrs','2018-01-01')\n",
    "\n",
    "\n",
    "PP = pd.Series((data['High'] + data['Low'] + data['Close']) / 3)  \n",
    "R1 = pd.Series(2 * PP - data['Low'])  \n",
    "S1 = pd.Series(2 * PP - data['High'])  \n",
    "R2 = pd.Series(PP + data['High'] - data['Low'])  \n",
    "S2 = pd.Series(PP - data['High'] + data['Low'])  \n",
    "R3 = pd.Series(data['High'] + 2 * (PP - data['Low']))  \n",
    "S3 = pd.Series(data['Low'] - 2 * (data['High'] - PP))  \n",
    "psr = {'PP':PP, 'R1':R1, 'S1':S1, 'R2':R2, 'S2':S2, 'R3':R3, 'S3':S3}  \n",
    "PSR = pd.DataFrame(psr)  \n",
    "data= data.join(PSR)  \n",
    "\n",
    "# plot the data\n",
    "pd.concat([data['Close'],PP,R1,S1,R2,S2,R3,S3],axis=1).plot(figsize=(12,9),grid=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  기간동안 낙폭 과대종목 검색\n",
    "\n",
    "from mod1 import *\n",
    "\n",
    "df_from = all_stock('2020-04-3')\n",
    "df_to = all_stock('2020-04-06')\n",
    "df_first=df_from[['Name','Close']]\n",
    "df_last=df_to[['Name','Close']]\n",
    "df = pd.merge(df_first,df_last,on='Name')\n",
    "\n",
    "df['diff']=df['Close_y']/df['Close_x']\n",
    "df.head()\n",
    "\n",
    "close_diff_df =  df.sort_values([\"diff\"],ascending=True)\n",
    "close_diff_df.head()\n",
    "\n",
    "close_diff_df.to_excel(\"d:\\\\b_1.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from  mod1 import *\n",
    "\n",
    "start = time.time()  # 시작 시간 저장\n",
    "\n",
    "def all_stock_period(date1, date2='2021-01-01'):\n",
    "    select_query = \"select * from market_good where Date >=  \"\n",
    "    var = select_query +\"'\"+date1+\"'\"  +\" \"+ 'and Date <=' + \"'\"+date2+\"'\"\n",
    "    df = pd.read_sql(var, engine)\n",
    "    return df\n",
    "\n",
    "\n",
    "df = all_stock_period('2020-02-20','2020-03-25')\n",
    "df_uniq = df['Name'].unique()\n",
    "df_uniq_list=df_uniq.tolist()\n",
    "\n",
    "min_data = []\n",
    "for x in df_uniq_list:\n",
    "    min_value = min(df[df['Name']== x ].Close)\n",
    "    min_data.append(min_value)\n",
    "\n",
    "min_close = pd.DataFrame(min_data)\n",
    "\n",
    "df_a=pd.DataFrame(df_uniq)\n",
    "\n",
    "\n",
    "df_first=pd.DataFrame()\n",
    "df_first['Name']=df_a[0]\n",
    "df_first['Close']=min_close[0]\n",
    "df_to = all_stock('2020-04-08')\n",
    "df_last=df_to[['Name','Close']]\n",
    "df = pd.merge(df_first,df_last,on='Name')\n",
    "\n",
    "df['diff']=df['Close_y']/df['Close_x']\n",
    "df.head()\n",
    "\n",
    "close_diff_df =  df.sort_values([\"diff\"],ascending=True)\n",
    "close_diff_df.head()\n",
    "\n",
    "close_diff_df.to_excel(\"d:\\\\b_1.xlsx\")\n",
    "print(\"time :\", time.time() - start)  # 현재시각 - 시작시간 = 실행 시간"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  mod1 import *\n",
    "\n",
    "def all_stock_period(date1, date2='2021-01-01'):\n",
    "    select_query = \"select * from market_good where Date >=  \"\n",
    "    var = select_query +\"'\"+date1+\"'\"  +\" \"+ 'and Date <=' + \"'\"+date2+\"'\"\n",
    "    df = pd.read_sql(var, engine)\n",
    "    return df\n",
    "\n",
    "\n",
    "df = all_stock_period('2020-02-20','2020-03-25')\n",
    "df_uniq = df['Name'].unique()\n",
    "df_uniq_list=df_uniq.tolist()\n",
    "\n",
    "min_data = []\n",
    "for x in df_uniq_list:\n",
    "    min_value = min(df[df['Name']== x ].Close)\n",
    "    min_data.append(min_value)\n",
    "\n",
    "min_close = pd.DataFrame(min_data)\n",
    "\n",
    "df_a=pd.DataFrame(df_uniq)\n",
    "\n",
    "\n",
    "df_first=pd.DataFrame()\n",
    "df_first['Name']=df_a[0]\n",
    "df_first['Close']=min_close[0]\n",
    "df_to = all_stock('2020-04-16')\n",
    "df_last=df_to[['Name','Close']]\n",
    "df = pd.merge(df_first,df_last,on='Name')\n",
    "\n",
    "df['diff']=df['Close_y']/df['Close_x']\n",
    "df.head()\n",
    "\n",
    "close_diff_df =  df.sort_values([\"diff\"],ascending=True)\n",
    "close_diff_df.head()\n",
    "\n",
    "close_diff_df.to_excel(\"d:\\\\b_5.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_data = []\n",
    "for x in code:\n",
    "    min_value = min(df[df['Code']== x ].Close)\n",
    "    min_data.append(min_value)\n",
    "\n",
    "a['min'] = pd.DataFrame(min_data)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = df['Code'].unique()\n",
    "len(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['code'] = pd.DataFrame(data = code)\n",
    "df['code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df['code'].dropna()\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_data = []\n",
    "for x in code:\n",
    "    min_value = min(df[df['Code']== x ].Close)\n",
    "    min_data.append(min_value)\n",
    "\n",
    "min_close = pd.DataFrame(min_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['code']=a\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['min']=min_close\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(df[df['Code']=='000547'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in a:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in name:\n",
    "    df['min']  = min(df[df['Name']==i].Close)\n",
    "    print(df)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from mod1 import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "\n",
    "def close_ma(df,select1,select2):\n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close',select1,select2]].values)\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1.columns=['close',select1,select2]\n",
    "    df1 = df1.set_index(df['date'])\n",
    "    df1.plot(figsize=(16,4))\n",
    "    plt.title(df['name'][0])\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def close_ma_vol(df,select1,select2,select3):\n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close',select1,select2,select3]].values)\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1.columns=['close',select1,select2,select3]\n",
    "    df1 = df1.set_index(df['date'])\n",
    "    df1.plot(figsize=(16,4))\n",
    "    plt.title(df['name'][0])\n",
    "    plt.grid(True)\n",
    "    plt.show()    \n",
    "    \n",
    "def rsi(df):\n",
    "    talib_rsi = ta.RSI(df, timeperiod=14)\n",
    "    df['rsi_14'] = talib_rsi\n",
    "    df = df.set_index(df['date'])\n",
    "    \n",
    "    plt.figure(figsize=(16,4))\n",
    "    plt.plot(df['rsi_14'])\n",
    "    plt.fill_between(df.index,y1=30, y2=70, color='#adccff', alpha='0.3')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('RSI')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "name = ['hrs','한컴위드','손오공']    \n",
    "#name = ['hrs','이노인스트루먼트','한국자산신탁','한국화장품','코리아나','우림기계','아스트','디엔에프','푸드나무','상보','포스코인터내셔널','우주일렉트로','서원','인터파크홀딩스','대양금속','아난티','제룡전기']   \n",
    "for i in name:\n",
    "    df = select_stock(i,'2010-01-01')\n",
    "    close_ma(df,'ma60','ma120')\n",
    "    rsi(df)\n",
    "    close_ma_vol(df,'ma60','ma120','volume')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "df = select_stock('hrs','2010-01-01')\n",
    "\n",
    "close_ma(df,'ma60','ma120')\n",
    "close_ma_vol(df,'ma60','ma120','volume')\n",
    "\n",
    "talib_rsi = ta.RSI(df, timeperiod=14)\n",
    "df['rsi_14'] = talib_rsi\n",
    "display(talib_rsi.head(15))\n",
    "\n",
    "plt.figure(figsize=(16,4))\n",
    "plt.plot(df['rsi_14'])\n",
    "plt.fill_between(df.index,y1=30, y2=70, color='#adccff', alpha='0.3')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('RSI')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mod1 import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "\n",
    "def market_ma(df,select1,select2):\n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close',select1,select2]].values)\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1.columns=['close',select1,select2]\n",
    "    df1 = df1.set_index(df['date'])\n",
    "    df1.plot(figsize=(16,4))\n",
    "    plt.title(df['market'][0])\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def market_ma_vol(df,select1,select2,select3):\n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close',select1,select2,select3]].values)\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1.columns=['close',select1,select2,select3]\n",
    "    df1 = df1.set_index(df['date'])\n",
    "    df1.plot(figsize=(16,4))\n",
    "    plt.title(df['market'][0])\n",
    "    plt.grid(True)\n",
    "    plt.show()    \n",
    "    \n",
    "df = select_market('kospi','2010-01-01')\n",
    "    \n",
    "close_ma(df,'ma60','ma120')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_market(name,date):\n",
    "    select_query = \"select * from \"\n",
    "    date_query = \" where Date > \"    \n",
    "    var = select_query + name + date_query+\"'\"+date+\"'\" \n",
    "    df = pd.read_sql(var, engine)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from mod1 import *\n",
    "df = select_market('kospi','2015-01-01')\n",
    "market_ma(df,'ma60','ma120')\n",
    "df = select_market('kosdaq','2015-01-01')\n",
    "market_ma(df,'ma60','ma120')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mod1 import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "\n",
    "def close_ma(df,select1,select2):\n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close',select1,select2]].values)\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1.columns=['close',select1,select2]\n",
    "    df1 = df1.set_index(df['date'])\n",
    "    df1.plot(figsize=(16,4))\n",
    "    plt.title(df['name'][0])\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def close_ma_vol(df,select1,select2,select3):\n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close',select1,select2,select3]].values)\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1.columns=['close',select1,select2,select3]\n",
    "    df1 = df1.set_index(df['date'])\n",
    "    df1.plot(figsize=(16,4))\n",
    "    plt.title(df['name'][0])\n",
    "    plt.grid(True)\n",
    "    plt.show()    \n",
    "    \n",
    "query = \"select * from kospi where Date > '1995-01-01'\"\n",
    "df = pd.read_sql(query ,engine)\n",
    "\n",
    "close_ma(df,'ma60','ma120')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mod1 import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "\n",
    "def close_ma(df,select1,select2):\n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close',select1,select2]].values)\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1.columns=['close',select1,select2]\n",
    "    df1 = df1.set_index(df['date'])\n",
    "    df1.plot(figsize=(16,4))\n",
    "    plt.title(df['market'][0])\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def close_ma_vol(df,select1,select2,select3):\n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close',select1,select2,select3]].values)\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1.columns=['close',select1,select2,select3]\n",
    "    df1 = df1.set_index(df['date'])\n",
    "    df1.plot(figsize=(16,4))\n",
    "    #plt.title(df['Market'][0])\n",
    "    plt.grid(True)\n",
    "    plt.show()    \n",
    "    \n",
    "query = \"select * from kospi where Date > '2010-01-01'\"\n",
    "df = pd.read_sql(query ,engine)\n",
    "\n",
    "close_ma(df,'ma60','ma120')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mod1 import *\n",
    "from pykrx import stock,website\n",
    "\n",
    "df_kospi  = stock.api.get_index_kospi_ohlcv_by_date(\"19950101\", \"202001050228\", \"코스피\")\n",
    "df_kospi.index.names = ['Date']\n",
    "df_kospi.columns  = ('Open','High','Low','Close','Volume')\n",
    "df_kospi['Market']='kospi'\n",
    "df_kospi.to_sql(name='kospi', con=engine, if_exists='append')\n",
    "\n",
    "df_kosdaq = stock.api.get_index_kosdaq_ohlcv_by_date(\"19960101\", \"20200105\", \"코스닥\")\n",
    "df_kosdaq.index.names = ['Date']\n",
    "df_kosdaq.columns  = ('Open','High','Low','Close','Volume')\n",
    "df_kosdaq'Market']='kosdaq'\n",
    "df_kosdaq.to_sql(name='kosdaq', con=engine, if_exists='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mod1 import *\n",
    "from pykrx import stock,website\n",
    "\n",
    "df  = stock.api.get_index_kospi_ohlcv_by_date(\"19960101\", \"202001050228\", \"코스피\")\n",
    "df.index.names = ['Date']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Name']='kospi'\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df.to_excel('d:\\\\kospi.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mod1 import *\n",
    "\n",
    "\n",
    "df = select_stock('hrs','2019-01-01')\n",
    "df.columns=df.columns.str.lower()\n",
    "df[['volume','close']] = df[['volume','close']].astype(float) #  TA-Lib로 평균을 구하려면 실수로 만들어야 함\n",
    "volume = df['volume'].values.astype('float')\n",
    "sma_vol = talib.SMA(volume, timeperiod=10)\n",
    "df['vol_10'] = sma_vol\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mod1 import *\n",
    "\n",
    "df = select_stock('hrs','2019-01-01')\n",
    "df.columns=df.columns.str.lower()\n",
    "df[['volume','close']] = df[['volume','close']].astype(float) #  TA-Lib로 평균을 구하려면 실수로 만들어야 함\n",
    "sma_vol = ta.SMA(df, timeperiod=10,price='volume')\n",
    "df['vol_10'] = sma_vol\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mod1 import *\n",
    "\n",
    "df = select_stock('hrs','2019-01-01')\n",
    "df.columns=df.columns.str.lower()\n",
    "df[['volume','close']] = df[['volume','close']].astype(float) #  TA-Lib로 평균을 구하려면 실수로 만들어야 함\n",
    "\n",
    "close=ta.MA(df,timeperiod=10)\n",
    "sma = ta.SMA(df, timeperiod=10,price='volume')\n",
    "ema = ta.EMA(df, timeperiod=10,price='volume')\n",
    "plt.plot(close, 'r-')\n",
    "plt.plot(sma, 'b-')\n",
    "plt.plot(ema, 'g-')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for numeric_string in a:\n",
    "    print(numeric_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1,2,3,4,5,5,7,8,9,10,10,2,3,4])\n",
    "desired_array = [int(numeric_string) for numeric_string in row] for row in a]\n",
    "#a = a.astype(np.int64)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=np.random.random(15)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import talib\n",
    "a = a.astype(float)\n",
    "ama=talib.MA(a, timeperiod=5)\n",
    "ama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=a.shape[0]\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sma = ta.SMA(b, timeperiod=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mod1 import *\n",
    "\n",
    "\n",
    "df = select_stock('hrs','2010-01-01')\n",
    "df.columns=df.columns.str.lower()\n",
    "df[['volume','close']] = df[['volume','close']].astype(float) #  TA-Lib로 평균을 구하려면 실수로 만들어야 함\n",
    "\n",
    "close = df['close']\n",
    "\n",
    "sma = ta.SMA(df, timeperiod=120)\n",
    "ema = ta.EMA(df, timeperiod=120)\n",
    "plt.figure(figsize=(16,4))\n",
    "plt.plot(close, 'r-')\n",
    "plt.plot(sma, 'b-')\n",
    "plt.plot(ema, 'g-')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(sma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mod1 import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "import torch.utils.data\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "df = select_stock('hrs','2018-01-01')\n",
    "\n",
    "df['Direction'] = df['Close'].shift(-1)-df['Close']\n",
    "df['Direction'] = df['Direction'].shift(1)\n",
    "\n",
    "#df['shift'][df['shift'] <= 0 ] = 0\n",
    "#df['shift'][df['shift']  > 0 ] = 1\n",
    "# Change type to datetime\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Moving average indicators, short, medium and long term\n",
    "df['SMA10'] = df.Close.rolling(10).mean()\n",
    "df['SMA30'] = df.Close.rolling(30).mean()\n",
    "df['SMA90'] = df.Close.rolling(90).mean()\n",
    "\n",
    "# Exponential moving average \n",
    "df['EWA10'] = df['Close'].ewm(span=10, min_periods=10).mean()\n",
    "df['EWA30'] = df['Close'].ewm(span=30, min_periods=30).mean()\n",
    "df['EWA90'] = df['Close'].ewm(span=90, min_periods=90).mean()\n",
    "\n",
    "# Stochastic Osciallator\n",
    "df['SOI'] = (df['Close'] - df['Low']) / (df['High'] - df['Low'])\n",
    "\n",
    "# 10, 5 and 2 Day Momentum\n",
    "df['Momentum_10'] = df['Close'].diff(10)\n",
    "df['Momentum_5'] = df['Close'].diff(5)\n",
    "df['Momentum_2'] = df['Close'].diff(2)\n",
    "\n",
    "# Standard deviation\n",
    "df['Std_10'] = df['Close'].rolling(10, min_periods=10).std()\n",
    "\n",
    "\n",
    "# Daily variation (High - low)\n",
    "df['Daily_variation'] = (df['High'] - df['Low']) / df['Close']\n",
    "\n",
    "# Day of week\n",
    "df['Day'] = df.Date.dt.dayofweek\n",
    "\n",
    "# Month of year\n",
    "df['Month'] = df.Date.dt.month_name()\n",
    "\n",
    "# Replace day of week number with string in order to make categorical dummy variables\n",
    "df['Day'].replace({0: 'Monday', 1 : 'Tuesday', 2: 'Wednesday', 3 : 'Thursday', 4 : 'Friday'}, inplace=True);\n",
    "\n",
    "# Make dummy variables out of cateorical features \n",
    "df = pd.get_dummies(df);\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  전종목 검색하여  종가 > ma120  일일 비교  하여  관심 종목 추출_9  total_a(1년분) ,total_b(11년분) 추출 및  공통종목을 추출\n",
    "\n",
    "from mod1 import *\n",
    "#import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "#from pandas.core.common import SettingWithCopyWarning\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
    "\n",
    "path = 'd:\\\\stockdata\\\\close_ma120\\\\close_ma120_'\n",
    "path_total = 'd:\\\\stockdata\\\\close_ma120\\\\total_'\n",
    "path_total_f = 'd:\\\\stockdata\\\\close_ma120\\\\total_filter_'\n",
    "path_total_a = 'd:\\\\stockdata\\\\close_ma120\\\\total_a_'\n",
    "path_total_b = 'd:\\\\stockdata\\\\close_ma120\\\\total_b_'\n",
    "path_total_c = 'd:\\\\stockdata\\\\close_ma120\\\\total_c_'\n",
    "\n",
    "\n",
    "df = all_stock('2019-10-10')\n",
    "df = df['Name']\n",
    "name = df.to_list()\n",
    "    \n",
    "select_start_a = '2019-01-01'\n",
    "select_start_b = '2008-01-01'\n",
    "\n",
    "select_query = \"select * from market where Name='hrs' and Date >= '2019-10-01' \"\n",
    "df3 = pd.read_sql(select_query, engine)\n",
    "\n",
    "df3 = df3['Date']\n",
    "datelist = df3.to_list()\n",
    "    \n",
    "def search_stock(name,select_start):   \n",
    "    print(name)\n",
    "    print(select_start)\n",
    "    pure_df = pd.DataFrame()\n",
    "    df2 = pd.DataFrame() \n",
    "    for i in name:\n",
    "        #print(i)\n",
    "        df=select_stock(i,select_start)\n",
    "        #print(df)\n",
    "        pure_df = pure_df.append(df)\n",
    "        ma(df)\n",
    "\n",
    "        source = MinMaxScaler()\n",
    "        data = source.fit_transform(df[['close','ma60','ma120','volume']].values)\n",
    "        df1 = pd.DataFrame(data)\n",
    "        df1['name']=i\n",
    "        df1.columns=['close','ma60','ma120','volume','name']\n",
    "        df1[['date','code']] = df[['date','code']]\n",
    "        #print(df1)\n",
    "        df2 = df2.append(df1)\n",
    "\n",
    "    pure_df.columns = map(str.lower, pure_df.columns) ## \n",
    "\n",
    "    last_df = df2.loc[df2['date'] == datelist[-1]]\n",
    "    last_close_df = last_df[last_df['close'] < 0.1]\n",
    "    last_ma_df = last_df[last_df['ma120'] < 0.1]\n",
    "    a_df = last_ma_df[last_ma_df['close'] > last_ma_df['ma60']] \n",
    "    last_ma_df = a_df[a_df['ma60'] > a_df['ma120']]\n",
    "    last_price_df = pure_df.loc[pure_df['date'] == datelist[-1]]\n",
    "    \n",
    "    for i in datelist:\n",
    "        first_df = df2.loc[df2['date'] == i]\n",
    "        first_price_df = pure_df.loc[pure_df['date'] == i]\n",
    "        one_close_df = pd.merge(first_df,last_close_df,on='code')\n",
    "        one_df = pd.merge(first_df,last_ma_df,on='code')\n",
    "        reset_close_df = last_close_df.reset_index()\n",
    "        reset_ma_df = last_ma_df.reset_index()\n",
    "        one_close_df['code']= reset_close_df['code']\n",
    "        one_df['code']= reset_ma_df['code']\n",
    "        close_df = pd.merge(first_price_df[['close','code']],one_close_df,on='code')\n",
    "        ma_df = pd.merge(first_price_df[['close','code']],one_df,on='code')        \n",
    "        two_close_df = pd.merge(last_price_df[['close','code','volume']],close_df,on='code')\n",
    "        two_df = pd.merge(last_price_df[['close','code','volume']],ma_df,on='code')\n",
    "        two_close_df.columns= ['price_y','code', 'volume_z','price_x', 'close_x', 'ma60_x', 'ma120_x', 'volume_x','name_x', 'date_x', 'close_y', 'ma60_y', 'ma120_y', 'volume_y','name_y', 'date_y']\n",
    "        two_df.columns= ['price_y','code', 'volume_z','price_x', 'close_x', 'ma60_x', 'ma120_x', 'volume_x','name_x', 'date_x', 'close_y', 'ma60_y', 'ma120_y', 'volume_y','name_y', 'date_y']\n",
    "\n",
    "        price_df = two_close_df[['name_x','code','close_x','close_y','ma60_x','ma60_y','ma120_x','ma120_y','price_x','price_y','date_x','volume_z']]\n",
    "        ma120_df = two_df[['name_x','code','close_x','close_y','ma60_x','ma60_y','ma120_x','ma120_y','price_x','price_y','date_x','volume_z']]\n",
    "        price_df['price_diff']=price_df['price_y']/price_df['price_x']\n",
    "        ma120_df['price_diff']=ma120_df['price_y']/ma120_df['price_x']\n",
    "        price_df =  price_df.sort_values([\"price_diff\"],ascending=True)\n",
    "        ma120_df =  ma120_df.sort_values([\"price_diff\"],ascending=True)\n",
    "        second_df =  first_df.sort_values([\"ma120\"],ascending=True)\n",
    "        #ma120_df['price_x']=first_price_df['close'].values\n",
    "        #ma120_df['price_y']=last_price_df['close'].values\n",
    "        strdate = i.strftime('%Y-%m-%d')\n",
    "       \n",
    "        if select_start == select_start_a:\n",
    "            ma120_df.to_excel(path_total_a+strdate+'.xlsx')\n",
    "            price_df.to_excel(path_total_c+strdate+'.xlsx')\n",
    "        else:\n",
    "            ma120_df.to_excel(path_total_b+strdate+'.xlsx')\n",
    "            second_df.to_excel(path+strdate+'.xlsx')\n",
    "            \n",
    "def total_ab_intersection( ):\n",
    "    for i in datelist:\n",
    "        strdate = i.strftime('%Y-%m-%d')\n",
    "        df_a = pd.read_excel(path_total_a+strdate+'.xlsx')\n",
    "        filter_df_a = df_a[df_a['close_y'] < 0.2]\n",
    "        df_b = pd.read_excel(path_total_b+strdate+'.xlsx')\n",
    "        #df_ab = pd.DataFrame()\n",
    "        df_ab = pd.merge(df_a[['name_x']],df_b,on='name_x')\n",
    "        filter_df_ab = pd.merge(filter_df_a[['name_x']],df_b,on='name_x')\n",
    "\n",
    "        total_df = df_ab[['name_x', 'code', 'close_x', 'close_y', 'ma60_x', 'ma60_y', 'ma120_x', 'ma120_y', 'price_x', 'price_y', 'date_x','volume_z', 'price_diff']]\n",
    "        filter_total_df = filter_df_ab[['name_x', 'code', 'close_x', 'close_y', 'ma60_x', 'ma60_y', 'ma120_x', 'ma120_y', 'price_x', 'price_y', 'date_x','volume_z', 'price_diff']]\n",
    "        total_df.to_excel(path_total+strdate+'.xlsx')\n",
    "        filter_total_df.to_excel('filter_'+path_total+strdate+'.xlsx') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  전종목 검색하여  종가 > ma120  일일 비교  하여  관심 종목 추출_9  total_a(1년분) ,total_b(11년분) 추출 및  공통종목을 추출 another method\n",
    "\n",
    "from mod1 import *\n",
    "#import pandas as pd\n",
    "\n",
    "path = 'd:\\\\test\\\\close_ma120_'\n",
    "path_total = 'd:\\\\test\\\\total_'\n",
    "path_total_a = 'd:\\\\test\\\\total_a_'\n",
    "path_total_b = 'd:\\\\test\\\\total_b_'\n",
    "path_total_c = 'd:\\\\test\\\\total_c_'\n",
    "\n",
    "#df = all_stock('2019-10-10')\n",
    "#df = df['Name']\n",
    "#name = df.to_list()\n",
    "    \n",
    "name = ['HRS','디엔에프','푸드나무','에이프로젠제약','포스코엠텍','유니켐','DB','아난티','상보','이에스에이','아스트','모트렉스','이노인스트루먼트','피앤씨테크']\n",
    "\n",
    "select_start_a = '2019-01-01'\n",
    "select_start_b = '2008-01-01'\n",
    "\n",
    "select_query = \"select * from market where Name='hrs' and Date >= '2019-10-01' \"\n",
    "df3 = pd.read_sql(select_query, engine)\n",
    "\n",
    "df3 = df3['Date']\n",
    "datelist = df3.to_list()\n",
    "    \n",
    "def search_stock(name,select_start_a,select_start_b):   \n",
    "    #print(name)\n",
    "    #print(select_start)\n",
    "    pure_df_a = pd.DataFrame()\n",
    "    df2_a = pd.DataFrame() \n",
    "    pure_df_b = pd.DataFrame()\n",
    "    df2_b = pd.DataFrame() \n",
    "    for i in name:\n",
    "        #print(i)\n",
    "        df_a=select_stock(i,select_start_a)\n",
    "        df_b=select_stock(i,select_start_b)\n",
    "        #print(df)\n",
    "        pure_df_a = pure_df_a.append(df_a)\n",
    "        pure_df_b = pure_df_b.append(df_b)\n",
    "        ma(df_a)\n",
    "        ma(df_b)\n",
    "\n",
    "        source = MinMaxScaler()\n",
    "        data_a = source.fit_transform(df_a[['close','ma60','ma120','volume']].values)\n",
    "        data_b = source.fit_transform(df_b[['close','ma60','ma120','volume']].values)\n",
    "        df1_a = pd.DataFrame(data_a)\n",
    "        df1_b = pd.DataFrame(data_b)\n",
    "        df1_a['name']=i\n",
    "        df1_b['name']=i\n",
    "        df1_a.columns=['close','ma60','ma120','volume','name']\n",
    "        df1_b.columns=['close','ma60','ma120','volume','name']\n",
    "        df1_a[['date','code','price']] = df_a[['date','code','close']]\n",
    "        df1_b[['date','code','price']] = df_b[['date','code','close']]\n",
    "        df2_a = df2_a.append(df1_a)\n",
    "        df2_b = df2_b.append(df1_b)        \n",
    "        \n",
    "    pure_df_a.columns = map(str.lower, pure_df_a.columns) ## \n",
    "    pure_df_b.columns = map(str.lower, pure_df_a.columns) ##\n",
    "    \n",
    "    pure_df_a = pure_df_a[['name','close','volume','date']]\n",
    "    pure_df_b = pure_df_b[['name','close','volume','date']]\n",
    "        \n",
    "    choice_day = pd.Timestamp('2019-09-30 00:00:00')\n",
    "    c = df2_a[df2_a['date']>choice_day]\n",
    "    d = df2_b[df2_b['date']>choice_day]\n",
    "    e = pure_df_a[pure_df_a['date']>choice_day]\n",
    "    f = pure_df_b[pure_df_b['date']>choice_day]\n",
    "    \n",
    "    last_df_a = c.loc[c['date'] == datelist[-1]]\n",
    "    last_close_df_a = last_df_a[last_df_a['close'] < 0.1]\n",
    "    last_ma_df_a = last_df_a[last_df_a['ma120'] < 0.1]\n",
    "    a_df_a = last_ma_df_a[last_ma_df_a['close'] > last_ma_df_a['ma60']] \n",
    "    last_ma_df_a = a_df_a[a_df_a['ma60'] > a_df_a['ma120']]\n",
    "    last_price_df_a = e.loc[e['date'] == datelist[-1]]\n",
    "    last_price_df_a = last_price_df_a[['name','volume']]\n",
    "    last_ma_df_a  = pd.merge(last_ma_df_a,last_price_df_a,on='name')\n",
    "\n",
    "    last_df_b = d.loc[d['date'] == datelist[-1]]\n",
    "    last_close_df_b = last_df_b[last_df_b['close'] < 0.1]\n",
    "    last_ma_df_b = last_df_b[last_df_b['ma120'] < 0.1]\n",
    "    a_df_b = last_ma_df_b[last_ma_df_b['close'] > last_ma_df_b['ma60']] \n",
    "    last_ma_df_b = a_df_b[a_df_b['ma60'] > a_df_b['ma120']]\n",
    "    last_price_df_b = f.loc[f['date'] == datelist[-1]]\n",
    "    last_price_df_b = last_price_df_b[['name','volume']]\n",
    "    last_ma_df_b  = pd.merge(last_ma_df_b,last_price_df_b,on='name')\n",
    "    \n",
    "    g = last_ma_df_a\n",
    "    h = last_ma_df_b\n",
    "    \n",
    "    a = pd.merge(c,g, on='name')\n",
    "    b = pd.merge(d,h, on='name')\n",
    "    \n",
    "    a['price_diff']=a['price_y']/a['price_x']\n",
    "    b['price_diff']=b['price_y']/b['price_x']\n",
    "    #g['volume_z'] = last_price_df_a['volume']\n",
    "    a = a[['name','code_x','close_x','close_y','ma60_x','ma60_y','ma120_x','ma120_y','price_x','price_y','date_x','volume_y','price_diff']]\n",
    "    b = b[['name','code_x','close_x','close_y','ma60_x','ma60_y','ma120_x','ma120_y','price_x','price_y','date_x','volume_y','price_diff']]\n",
    "    \n",
    "    for i in datelist:\n",
    "        t = pd.Timestamp(i)\n",
    "        first_df = a.loc[a['date_x'] == t]             ##  표준화 dataframe \n",
    "        second_df = b.loc[b['date_x'] == t] \n",
    "        strdate = t.strftime('%Y-%m-%d')\n",
    "        first_df =  first_df.sort_values([\"price_diff\"],ascending=True)\n",
    "        second_df = second_df.sort_values([\"price_diff\"],ascending=True)\n",
    "        first_df.to_excel(path_total_a+strdate+'.xlsx')  ##  표준화 dataframe 중 ma120 < 0.1 and close > ma60 > ma120 (from 2019.01.01)\n",
    "        second_df.to_excel(path_total_b+strdate+'.xlsx')  ##  표준화 dataframe 중 ma120 < 0.1 and close > ma60 > ma120 (from 2008.01.01) \n",
    "        \n",
    "search_stock(name,select_start_a,select_start_b)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mod1 import *\n",
    "#import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "#from pandas.core.common import SettingWithCopyWarning\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
    "\n",
    "path = 'd:\\\\test\\\\close_ma120_'\n",
    "path_total = 'd:\\\\test\\\\total_'\n",
    "path_total_a = 'd:\\\\test\\\\total_a_'\n",
    "path_total_b = 'd:\\\\test\\\\total_b_'\n",
    "path_total_c = 'd:\\\\test\\\\total_c_'\n",
    "path_total_f = 'd:\\\\test\\\\total_filter_'\n",
    "\n",
    "#df = all_stock('2019-10-10')\n",
    "#df = df['Name']\n",
    "#name = df.to_list()\n",
    "    \n",
    "name = ['hrs','디엔에프','푸드나무','화성밸브','미래생명자원','웹케시']\n",
    "\n",
    "select_start_a = '2019-01-01'\n",
    "select_start_b = '2008-01-01'\n",
    "\n",
    "select_query = \"select * from market where Name='hrs' and Date >= '2019-10-01' \"\n",
    "df3 = pd.read_sql(select_query, engine)\n",
    "\n",
    "df3 = df3['Date']\n",
    "datelist = df3.to_list()\n",
    "    \n",
    "def search_stock(name,select_start):   \n",
    "    print(name)\n",
    "    print(select_start)\n",
    "    pure_df = pd.DataFrame()\n",
    "    df2 = pd.DataFrame() \n",
    "    for i in name:\n",
    "        #print(i)\n",
    "        df=select_stock(i,select_start)\n",
    "        #print(df)\n",
    "        pure_df = pure_df.append(df)\n",
    "        ma(df)\n",
    "\n",
    "        source = MinMaxScaler()\n",
    "        data = source.fit_transform(df[['close','ma60','ma120','volume']].values)\n",
    "        df1 = pd.DataFrame(data)\n",
    "        df1['name']=i\n",
    "        df1.columns=['close','ma60','ma120','volume','name']\n",
    "        df1[['date','code']] = df[['date','code']]\n",
    "        #print(df1)\n",
    "        df2 = df2.append(df1)\n",
    "\n",
    "    pure_df.columns = map(str.lower, pure_df.columns) ## \n",
    "\n",
    "    last_df = df2.loc[df2['date'] == datelist[-1]]\n",
    "    last_close_df = last_df[last_df['close'] < 0.1]\n",
    "    last_ma_df = last_df[last_df['ma120'] < 0.1]\n",
    "    a_df = last_ma_df[last_ma_df['close'] > last_ma_df['ma60']] \n",
    "    last_ma_df = a_df[a_df['ma60'] > a_df['ma120']]\n",
    "    last_price_df = pure_df.loc[pure_df['date'] == datelist[-1]]\n",
    "    \n",
    "    for i in datelist:\n",
    "        first_df = df2.loc[df2['date'] == i]\n",
    "        first_price_df = pure_df.loc[pure_df['date'] == i]\n",
    "        one_close_df = pd.merge(first_df,last_close_df,on='code')\n",
    "        one_df = pd.merge(first_df,last_ma_df,on='code')\n",
    "        reset_close_df = last_close_df.reset_index()\n",
    "        reset_ma_df = last_ma_df.reset_index()\n",
    "        one_close_df['code']= reset_close_df['code']\n",
    "        one_df['code']= reset_ma_df['code']\n",
    "        close_df = pd.merge(first_price_df[['close','code']],one_close_df,on='code')\n",
    "        ma_df = pd.merge(first_price_df[['close','code']],one_df,on='code')        \n",
    "        two_close_df = pd.merge(last_price_df[['close','code','volume']],close_df,on='code')\n",
    "        two_df = pd.merge(last_price_df[['close','code','volume']],ma_df,on='code')\n",
    "        two_close_df.columns= ['price_y','code', 'volume_z','price_x', 'close_x', 'ma60_x', 'ma120_x', 'volume_x','name_x', 'date_x', 'close_y', 'ma60_y', 'ma120_y', 'volume_y','name_y', 'date_y']\n",
    "        two_df.columns= ['price_y','code', 'volume_z','price_x', 'close_x', 'ma60_x', 'ma120_x', 'volume_x','name_x', 'date_x', 'close_y', 'ma60_y', 'ma120_y', 'volume_y','name_y', 'date_y']\n",
    "\n",
    "        price_df = two_close_df[['name_x','code','close_x','close_y','ma60_x','ma60_y','ma120_x','ma120_y','price_x','price_y','date_x','volume_z']]\n",
    "        ma120_df = two_df[['name_x','code','close_x','close_y','ma60_x','ma60_y','ma120_x','ma120_y','price_x','price_y','date_x','volume_z']]\n",
    "        price_df['price_diff']=price_df['price_y']/price_df['price_x']\n",
    "        ma120_df['price_diff']=ma120_df['price_y']/ma120_df['price_x']\n",
    "        price_df =  price_df.sort_values([\"price_diff\"],ascending=True)\n",
    "        ma120_df =  ma120_df.sort_values([\"price_diff\"],ascending=True)\n",
    "        second_df =  first_df.sort_values([\"ma120\"],ascending=True)\n",
    "        #ma120_df['price_x']=first_price_df['close'].values\n",
    "        #ma120_df['price_y']=last_price_df['close'].values\n",
    "        strdate = i.strftime('%Y-%m-%d')\n",
    "       \n",
    "        if select_start == select_start_a:\n",
    "            ma120_df.to_excel(path_total_a+strdate+'.xlsx')\n",
    "            price_df.to_excel(path_total_c+strdate+'.xlsx')\n",
    "        else:\n",
    "            ma120_df.to_excel(path_total_b+strdate+'.xlsx')\n",
    "            second_df.to_excel(path+strdate+'.xlsx')\n",
    "\n",
    "def total_ab_intersection( ):\n",
    "    for i in datelist:\n",
    "        strdate = i.strftime('%Y-%m-%d')\n",
    "        df_a = pd.read_excel(path_total_a+strdate+'.xlsx')\n",
    "        filter_df_a = df_a[df_a['close_y'] < 0.2]\n",
    "        df_b = pd.read_excel(path_total_b+strdate+'.xlsx')\n",
    "        #df_ab = pd.DataFrame()\n",
    "        df_ab = pd.merge(df_a[['name_x']],df_b,on='name_x')\n",
    "        filter_df_ab = pd.merge(filter_df_a[['name_x']],df_b,on='name_x')\n",
    "\n",
    "        total_df = df_ab[['name_x', 'code', 'close_x', 'close_y', 'ma60_x', 'ma60_y', 'ma120_x', 'ma120_y', 'price_x', 'price_y', 'date_x','volume_z', 'price_diff']]\n",
    "        filter_total_df = filter_df_ab[['name_x', 'code', 'close_x', 'close_y', 'ma60_x', 'ma60_y', 'ma120_x', 'ma120_y', 'price_x', 'price_y', 'date_x','volume_z', 'price_diff']]\n",
    "        total_df.to_excel(path_total+strdate+'.xlsx')\n",
    "        filter_total_df.to_excel(path_total_f+strdate+'.xlsx') \n",
    "            \n",
    "            \n",
    "#search_stock(name,select_start_b)\n",
    "total_ab_intersection( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vote_stock volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from mod1 import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "\n",
    "def close_ma(df,select1,select2):\n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close',select1,select2]].values)\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1.columns=['close',select1,select2]\n",
    "    df1 = df1.set_index(df['date'])\n",
    "    df1.plot(figsize=(16,4))\n",
    "    plt.title(df['name'][0])\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def close_ma_vol(df,select1,select2,select3):\n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close',select1,select2,select3]].values)\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1.columns=['close',select1,select2,select3]\n",
    "    df1 = df1.set_index(df['date'])\n",
    "    df1.plot(figsize=(16,4))\n",
    "    plt.title(df['name'][0])\n",
    "    plt.grid(True)\n",
    "    plt.show()    \n",
    "    \n",
    "    \n",
    "path = 'd:\\\\stockdata\\\\close_ma120\\\\close_ma120_'\n",
    "path_total_f = 'd:\\\\stockdata\\\\close_ma120\\\\total_filter_'\n",
    "path_price = 'd:\\\\stockdata\\\\vote_stock\\\\detect_stock_with_price_'\n",
    "path_volume = 'd:\\\\stockdata\\\\vote_stock\\\\detect_stock_with_volume_'\n",
    "\n",
    "choice_date='2020-01-02'\n",
    "df_volume = pd.read_excel(path_volume+choice_date+'.xlsx')\n",
    "name_volume = df_volume['Name']\n",
    "#name = name_volume.to_list()\n",
    "name = ['한국화장품','HRS','디엔에프','푸드나무','에이프로젠제약','포스코엠텍','유니켐','DB','아난티','상보','이에스에이','아스트','모트렉스','이노인스트루먼트','피앤씨테크']\n",
    "\n",
    "\n",
    "for i in name:\n",
    "#for i in name_volume:\n",
    "    #df = select_stock(i,choice_date)\n",
    "    df = select_stock(i, '2018-01-03')\n",
    "    close_ma_vol(df,'ma60','ma120','volume')\n",
    "    #close_ma(df,'ma5','ma20','volume')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykrx.stock.api import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_shorting_status_by_date('20191211','2019125','067390')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykrx.stock import api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vote_stock price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from mod1 import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "\n",
    "def close_ma(df,select1,select2):\n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close',select1,select2]].values)\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1.columns=['close',select1,select2]\n",
    "    df1 = df1.set_index(df['date'])\n",
    "    df1.plot(figsize=(16,4))\n",
    "    plt.title(df['name'][0])\n",
    "    plt.show()\n",
    "\n",
    "def close_ma_vol(df,select1,select2,select3):\n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close',select1,select2,select3]].values)\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1.columns=['close',select1,select2,select3]\n",
    "    df1 = df1.set_index(df['date'])\n",
    "    df1.plot(figsize=(16,4))\n",
    "    plt.title(df['name'][0])\n",
    "    plt.show()    \n",
    "    \n",
    "    \n",
    "path = 'd:\\\\stockdata\\\\close_ma120\\\\close_ma120_'\n",
    "path_total_f = 'd:\\\\stockdata\\\\close_ma120\\\\total_filter_'\n",
    "path_price = 'd:\\\\stockdata\\\\vote_stock\\\\detect_stock_with_price_'\n",
    "path_volume = 'd:\\\\stockdata\\\\vote_stock\\\\detect_stock_with_volume_'\n",
    "\n",
    "choice_date='2020-01-02'\n",
    "df_price = pd.read_excel(path_price+choice_date+'.xlsx')\n",
    "name_price = df_price['Name']\n",
    "#name = name_df.to_list()\n",
    "#name=['hrs','디엔에프','푸드나무','이에스브이']\n",
    "\n",
    "for i in name_price:\n",
    "    #df = select_stock(i,choice_date)\n",
    "    df = select_stock(i, '2010-01-03')\n",
    "    #close_ma_vol(df,'ma60','ma120','volume')\n",
    "    close_ma_vol(df,'ma60','ma120','volume')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# close_ma120 filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from mod1 import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "\n",
    "def close_ma(df,select1,select2):\n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close',select1,select2]].values)\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1.columns=['close',select1,select2]\n",
    "    df1 = df1.set_index(df['date'])\n",
    "    df1.plot(figsize=(16,4))\n",
    "    plt.grid(True)\n",
    "    plt.title(df['name'][0])\n",
    "    plt.show()\n",
    "\n",
    "def close_ma_vol(df,select1,select2,select3):\n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close',select1,select2,select3]].values)\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1.columns=['close',select1,select2,select3]\n",
    "    df1 = df1.set_index(df['date'])\n",
    "    df1.plot(figsize=(16,4))\n",
    "    plt.grid(True)\n",
    "    plt.title(df['name'][0])\n",
    "    plt.show()    \n",
    "    \n",
    "    \n",
    "path = 'd:\\\\stockdata\\\\close_ma120\\\\close_ma120_'\n",
    "path_total_f = 'd:\\\\stockdata\\\\close_ma120\\\\total_filter_'\n",
    "path_total_c = 'd:\\\\stockdata\\\\close_ma120\\\\total_c_'\n",
    "path_total_b = 'd:\\\\stockdata\\\\close_ma120\\\\total_b_'\n",
    "path_price = 'd:\\\\stockdata\\\\vote_stock\\\\detect_stock_with_price_'\n",
    "path_volume = 'd:\\\\stockdata\\\\vote_stock\\\\detect_stock_with_volume_'\n",
    "\n",
    "choice_date='2019-10-01'\n",
    "df = pd.read_excel(path_total_b+choice_date+'.xlsx')\n",
    "name = df['name_x']\n",
    "#name=['hrs','디엔에프','푸드나무','이에스브이']\n",
    "\n",
    "for i in name:\n",
    "    #df = select_stock(i,choice_date)\n",
    "    df = select_stock(i,'2010-01-01')\n",
    "    close_ma(df,'ma60','ma120')\n",
    "    #close_ma(df,'ma10','ma20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from mod1 import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "\n",
    "def close_ma(df,select1,select2):\n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close',select1,select2]].values)\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1.columns=['close',select1,select2]\n",
    "    df1 = df1.set_index(df['date'])\n",
    "    df1.plot(figsize=(16,4))\n",
    "    plt.grid(True)\n",
    "    plt.title(df['name'][0])\n",
    "    plt.show()\n",
    "\n",
    "def close_ma_vol(df,select1,select2,select3):\n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close',select1,select2,select3]].values)\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1.columns=['close',select1,select2,select3]\n",
    "    df1 = df1.set_index(df['date'])\n",
    "    df1.plot(figsize=(16,4))\n",
    "    plt.grid(True)\n",
    "    plt.title(df['name'][0])\n",
    "    plt.show()    \n",
    "    \n",
    "    \n",
    "path = 'd:\\\\stockdata\\\\close_ma120\\\\close_ma120_'\n",
    "path_total_f = 'd:\\\\stockdata\\\\close_ma120\\\\total_filter_'\n",
    "path_total_c = 'd:\\\\stockdata\\\\close_ma120\\\\total_c_'\n",
    "path_total_b = 'd:\\\\stockdata\\\\close_ma120\\\\total_b_'\n",
    "path_price = 'd:\\\\stockdata\\\\vote_stock\\\\detect_stock_with_price_'\n",
    "path_volume = 'd:\\\\stockdata\\\\vote_stock\\\\detect_stock_with_volume_'\n",
    "\n",
    "choice_date='2019-10-01'\n",
    "df = pd.read_excel(path_total_f+choice_date+'.xlsx')\n",
    "name = df['name_x']\n",
    "#name=['hrs','디엔에프','푸드나무','이에스브이']\n",
    "\n",
    "for i in name:\n",
    "    #df = select_stock(i,choice_date)\n",
    "    df = select_stock(i,'2012-12-30')\n",
    "    #close_ma(df,'ma60','ma120')\n",
    "    close_ma_vol(df,'ma60','ma120','volume')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from mod1 import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "\n",
    "def close_ma(df,select1,select2):\n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close',select1,select2]].values)\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1.columns=['close',select1,select2]\n",
    "    df1 = df1.set_index(df['date'])\n",
    "    df1.plot(figsize=(16,4))\n",
    "    plt.title(df['name'][0])\n",
    "    plt.show()\n",
    "\n",
    "path = 'd:\\\\stockdata\\\\close_ma120\\\\close_ma120_'\n",
    "path_total_f = 'd:\\\\stockdata\\\\close_ma120\\\\total_filter_'\n",
    "\n",
    "choice_date='2019-10-01'\n",
    "df = pd.read_excel(path_total_f +choice_date+'.xlsx')\n",
    "#df = df.sort_values([\"close_y\"],ascending=True)\n",
    "name_df = df['name_x']\n",
    "name = name_df.to_list()\n",
    "name.insert(0,'hrs')\n",
    "#name=['hrs','디엔에프','푸드나무','에스퓨얼셀']\n",
    "\n",
    "\n",
    "for i in name:\n",
    "    df = select_stock(i, '2010-01-01')\n",
    "    close_ma(df,'ma60','ma120')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "###  관심종목 ma60, ma120, cci 그래프 생성\n",
    "\n",
    "from mod1 import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "\n",
    "def close_ma(df,select1,select2,select3):\n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close',select1,select2,select3]].values)\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1.columns=['close',select1,select2,select3]\n",
    "    df1 = df1.set_index(df['date'])\n",
    "    df1.plot(figsize=(16,4))\n",
    "    plt.title(df['name'][0])\n",
    "    plt.show()\n",
    "\n",
    "path = 'd:\\\\stockdata\\\\close_ma120\\\\close_ma120_'\n",
    "path_total = 'd:\\\\stockdata\\\\close_ma120\\\\total_'\n",
    "path_total_f = 'd:\\\\stockdata\\\\close_ma120\\\\total_filter_'\n",
    "\n",
    "choice_date='2019-10-01'\n",
    "df = pd.read_excel(path_total_f+choice_date+'.xlsx')\n",
    "name_df = df['name_x']\n",
    "name = name_df.to_list()\n",
    "name.insert(0,'hrs')\n",
    "name=['hrs','디엔에프','푸드나무','에스퓨얼셀','에어부산','HDC아이콘트롤스','유니슨','엔시트론','데일리블록체인']\n",
    "\n",
    "pure_df = pd.DataFrame()\n",
    "df2 = pd.DataFrame()\n",
    "cci_df = pd.DataFrame()\n",
    "for i in name:\n",
    "    #print(i)\n",
    "    df=select_stock(i,'2010-01-01')\n",
    "    cci_df[['open','high','low','volume','close']] = df[['Open','High','Low','Volume','Close']].astype(float) #  TA-Lib로 평균을 구하려면 실수로 만들어야 함\n",
    "    period = 60\n",
    "    cci_df['cci'] = ta.CCI(cci_df, timeperiod=period)\n",
    "    df['cci'] = cci_df['cci']\n",
    "    close_ma(df,'cci','ma60','ma120')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###  관심종목 ma60, ma120, cci 그래프 생성\n",
    "\n",
    "from mod1 import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "\n",
    "def cci_ma2(df,select1,select2,select3):\n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close',select1,select2,select3]].values)\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1.columns=['close',select1,select2,select3]\n",
    "    df1 = df1.set_index(df['date'])\n",
    "    df1.plot(figsize=(16,4))\n",
    "    plt.title(df['name'][0])\n",
    "    plt.show()\n",
    "\n",
    "path = 'd:\\\\stockdata\\\\close_ma120\\\\close_ma120_'\n",
    "path_total = 'd:\\\\stockdata\\\\close_ma120\\\\total_'\n",
    "\n",
    "choice_date = '2019-10-01'\n",
    "df = pd.read_excel(path_total+choice_date+'.xlsx')\n",
    "df = df['name']\n",
    "name = df.to_list()\n",
    "\n",
    "#name=['hrs','손오공']\n",
    "\n",
    "pure_df = pd.DataFrame()\n",
    "df2 = pd.DataFrame()\n",
    "cci_df = pd.DataFrame()\n",
    "for i in name:\n",
    "    #print(i)\n",
    "    df=select_stock(i,'2010-01-01')\n",
    "    cci_df[['open','high','low','volume','close']] = df[['Open','High','Low','Volume','Close']].astype(float) #  TA-Lib로 평균을 구하려면 실수로 만들어야 함\n",
    "    period = 120\n",
    "    cci_df['cci'] = ta.CCI(cci_df, timeperiod=period)\n",
    "    df['cci'] = cci_df['cci']\n",
    "    cci_ma2(df,'cci','ma60','ma120')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ab.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from mod1 import * \n",
    "\n",
    "def close_ma(df,select1,select2):\n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close',select1,select2]].values)\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1.columns=['close',select1,select2]\n",
    "    df1 = df1.set_index(df['date'])\n",
    "    df1.plot(figsize=(16,4))\n",
    "    plt.title(df['name'][0])\n",
    "    plt.show()\n",
    "    \n",
    "#df = df_ab['name_x']\n",
    "#name = df.to_list()\n",
    "name=['hrs','디엔에프','푸드나무','에스퓨얼셀','에어부산','HDC아이콘트롤스','유니슨','엔시트론','데일리블록체인']\n",
    "\n",
    "for i in name:\n",
    "    df = select_stock(i, '2015-01-01')\n",
    "    close_ma(df,'ma60','ma120')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 일별 관리종목 추출\n",
    "\n",
    "from  datetime import datetime\n",
    "import pandas as pd\n",
    "import xlsxwriter\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "today = datetime.now()\n",
    "today = today.strftime(\"%Y-%m-%d\")\n",
    "#today=input('입력')\n",
    "#url = 'http://finance.naver.com/sise/investorDealTrendDay.nhn?bizdate=2020601&sosok=&page=1'\n",
    "url = 'https://finance.naver.com/sise/management.nhn'\n",
    "source = urlopen(url).read()   # 지정한 페이지에서 코드 읽기\n",
    "source = BeautifulSoup(source, 'lxml')   # 뷰티풀 스프로 태그별로 코드 분류\n",
    "data = []\n",
    "\n",
    "path = 'd:\\\\stockdata\\\\관리종목\\\\'+today+'.xlsx'\n",
    "body = source.find('body')\n",
    "trs = body.find_all('tr')\n",
    "name = []\n",
    "for tr in trs:\n",
    "    tds = tr.find_all('a',{'class':\"tltle\"})\n",
    "    for td in tds:\n",
    "        name.append(td.text.strip())\n",
    "\n",
    "df = pd.DataFrame(name)\n",
    "df['Date']=str(today)\n",
    "df = df.set_index('Date')\n",
    "df.columns=['Name']\n",
    "df.to_excel(path)\n",
    "df = pd.read_excel(path)\n",
    "\n",
    "df.to_sql(name='badstock', con=engine, if_exists='append', index = False)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mod1 import *\n",
    "\n",
    "df = select_stock('hrs','2017-10-01')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mod1 import *\n",
    "\n",
    "df = select_stock('hrs','2010-10-01')\n",
    "df.columns=df.columns.str.lower()\n",
    "df[['volume','close']] = df[['volume','close']].astype(float) #  TA-Lib로 평균을 구하려면 실수로 만들어야 함\n",
    "\n",
    "# ta-lib로 5기간 종가 이동평균 계산\n",
    "talib_ma120 = ta.MA(df, timeperiod=120)\n",
    "df['ma120'] = talib_ma120\n",
    "# pandas 기능을 이용하여 5기간 이동평균 계산\n",
    "pandas_ma120 = df.close.rolling(window=120).mean() \n",
    "\n",
    "talib_ma120.equals(pandas_ma120)\n",
    "# True / 결과는 같음  \n",
    "\n",
    "vol_ma120 = df.volume.rolling(window=120).mean() \n",
    "df['vol_ma120'] = vol_ma120\n",
    "\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.scatter(df['vol_ma120'],df['ma120'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "plt.scatter(df['Volume'],df['Close'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1e7*16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mod1 import *\n",
    "#import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "#from pandas.core.common import SettingWithCopyWarning\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
    "\n",
    "path = 'd:\\\\test\\\\close_ma120_'\n",
    "path_total = 'd:\\\\test\\\\total_'\n",
    "path_total_a = 'd:\\\\test\\\\total_a_'\n",
    "path_total_b = 'd:\\\\test\\\\total_b_'\n",
    "path_total_c = 'd:\\\\test\\\\total_c_'\n",
    "path_total_f = 'd:\\\\test\\\\total_filter_'\n",
    "\n",
    "#df = all_stock('2019-10-10')\n",
    "#df = df['Name']\n",
    "#name = df.to_list()\n",
    "    \n",
    "name = ['hrs','디엔에프','푸드나무','화성밸브','미래생명자원','웹케시']\n",
    "\n",
    "select_start_a = '2019-01-01'\n",
    "select_start_b = '2008-01-01'\n",
    "\n",
    "select_query = \"select distinct name from market \"\n",
    "df3 = pd.read_sql(select_query, engine)\n",
    "\n",
    "df3.to_excel('d:\\\\market_name.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 기존에 액면분할시 가격조정 안된 기존 data가 있을때\n",
    "## insert mysql 개별 주식\n",
    "\n",
    "Code = input('주식 Code를 입력하세요')\n",
    "Name = input('주식이름을 입력하세요')\n",
    "\n",
    "query = \"delete from  market where Code = \"+\"'\"+Code+\"'\"\n",
    "\n",
    "curs.execute(query)\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "df = fdr.DataReader(Code, '1995')\n",
    "df.to_excel('d:\\\\'+Code+'.xlsx', encoding='UTF-8')\n",
    "\n",
    "df = pd.read_excel('d:\\\\'+Code+'.xlsx')\n",
    "df['Code']= Code\n",
    "df['Name']= Name\n",
    "\n",
    "df = df[['Date','Code','Name','Open', 'High', 'Low', 'Volume','Close']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "###  선물크롤링하여 맨처음 DB에 future table생성할때\n",
    "\n",
    "# 2019-09-11 수정  mysql future table에서 최종 날짜를 확인해서 그뒤날부터 insert \n",
    "# 기존 daum 주식 사이트 : ajax 방식으로 변경으로 인해 이를 반영한 코드를 수정.\n",
    "# pip install fake-useragent 설치 후 실행 가능\n",
    "\n",
    "import io\n",
    "import json\n",
    "import sys\n",
    "import pandas as pd\n",
    "import sqlalchemy \n",
    "import urllib.request as req\n",
    "from datetime import datetime\n",
    "from fake_useragent import UserAgent\n",
    "\n",
    "engine = sqlalchemy.create_engine('mysql+pymysql://kkang:leaf2027@localhost/stock?charset=utf8',encoding='utf-8')\n",
    "\n",
    "\n",
    "# Fake Header 정보\n",
    "ua = UserAgent()\n",
    "\n",
    "# 헤더 선언\n",
    "headers = {\n",
    "    'User-Agent': ua.ie,\n",
    "    'referer': 'http://finance.daum.net/domestic/futures'\n",
    "}\n",
    "\n",
    "\n",
    "url = \"http://finance.daum.net/api/future/KR4101Q30005/days?pagination=true&page=1\"\n",
    "res = req.urlopen(req.Request(url, headers=headers)).read().decode('utf-8')\n",
    "\n",
    "df1 = pd.DataFrame()\n",
    "for i in range(1,7):\n",
    "    # 다음 주식 요청 URL\n",
    "    url = \"http://finance.daum.net/api/future/KR4101Q30005/days?pagination=true&page=\"+str(i)\n",
    "\n",
    "    res = req.urlopen(req.Request(url, headers=headers)).read().decode('utf-8')\n",
    "    \n",
    "    rank_json = json.loads(res)['data']\n",
    "    \n",
    "    df = pd.DataFrame(rank_json)\n",
    "    df1 = df1.append(df,ignore_index=True)\n",
    "    \n",
    "df2 = df1[['date','tradePrice','change', 'changePrice','changeRate','unsettledVolume','foreignSettlement', 'institutionSettlement', 'privateSettlement']]\n",
    "df2.columns=('Date','Future','change','가격변동','등락률','미결제약정','외국인','기관','개인')\n",
    "df2['Date'] = pd.to_datetime(df2['Date']).dt.date\n",
    "#df2['Date'] = pd.to_datetime(df2['Date']).apply(lambda x: x.date())\n",
    "#df2['Date'] = pd.to_datetime(df2['Date'], format = '%Y-%m-%d') # yyyy-mm-dd hh:mm:ss -> yyyy-mm-dd (속성은그대로 보여주는 형식만 변경)\n",
    "df2 =df2[['Date','Future','미결제약정','외국인','기관','개인']]\n",
    "#df2 = df2[df2.Date > until_date]\n",
    "df2.to_sql(name='future', con=engine, if_exists='append', index = False)\n",
    "df2 = df2.set_index('Date')\n",
    "df2.to_excel('d:\\\\future.xlsx',encoding='utf-8')\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mod1 import *\n",
    "\n",
    "## 선물  베이시스 graph ( One_graph)\n",
    "## def future_trend_graph():\n",
    "   \n",
    "\n",
    "#query = \"select * from future where Date > '2019-06-13'\"+\"'\"+date+\"'\"\n",
    "query = \"select * from basis where Date > '2019-12-11'\"\n",
    "\n",
    "\n",
    "name=['kpi200','Future']\n",
    "#name=['미결제약정']\n",
    "\n",
    "tuple_name=tuple(name)\n",
    "df1 = pd.DataFrame()\n",
    "    \n",
    "df = pd.read_sql(query ,engine)\n",
    "\n",
    "#df.columns=['Date','kpi200','Close']\n",
    "df = df.set_index('Date')\n",
    "df1=df[name]\n",
    "\n",
    "plt.figure(figsize=(16,4))    \n",
    "for i in range(len(name)):\n",
    "    plt.plot(df1[name[i]]/df1[name[i]].loc[df.index[0]]*100, label=name[i])\n",
    "        \n",
    "#plt.legend(loc=0)\n",
    "plt.legend(loc=0)\n",
    "plt.grid(True,color='0.7',linestyle=':',linewidth=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mod1 import *\n",
    "\n",
    "df = select_stock('hrs','2010-01-01')\n",
    "    \n",
    "df.to_csv('d:\\\\hrs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "37810821*1155"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fix_yahoo_finance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
