{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 월별 상장 종목수 갱신"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종일지 :  2021-01-29\n",
      "(2373, 3)\n",
      "(2395, 2)\n",
      "(2373, 8)\n",
      "time : 5.657953500747681\n"
     ]
    }
   ],
   "source": [
    "##  월별 상장주식종목 갱신\n",
    "\n",
    "from mod1 import *\n",
    "from pykrx.stock.api import *\n",
    "from pykrx import *\n",
    "\n",
    "start = time.time()  # 시작 시간 저장\n",
    "\n",
    "date_query = \"select Date from market where Name='hrs' order by Date desc limit 1\"\n",
    "\n",
    "df = pd.read_sql(date_query, engine)\n",
    "df = pd.to_datetime(df['Date'])\n",
    "df = str(df)\n",
    "last_date = df[4:14]\n",
    "last_day = last_date.replace('-','')   ## 20200713\n",
    "print(\"최종일자 : \", last_date)\n",
    "\n",
    "pre_query =\"select * from market where Date =\"\n",
    "query = pre_query+'\\''+last_date+'\\''\n",
    "\n",
    "#df = get_market_price_change_by_ticker(\"20200917\", \"20200918\")\n",
    "#df.to_excel('f:/kkang.xlsx')\n",
    "a = pd.read_excel('d:/market.xlsx')\n",
    "df = stock.get_market_ohlcv_by_ticker(last_day, \"KOSPI\")\n",
    "df = df.reset_index()\n",
    "df_kospi=df[['티커','종목명']]\n",
    "\n",
    "df = stock.get_market_ohlcv_by_ticker(last_day, \"KOSDAQ\")\n",
    "df = df.reset_index()\n",
    "df_kosdaq=df[['티커','종목명']]\n",
    "b=pd.concat([df_kospi, df_kosdaq])\n",
    "c = pd.read_sql(query, engine)\n",
    "\n",
    "a = a.rename(columns={'종목코드':'code','종목명':'name'})\n",
    "b = b.rename(columns={'티커':'code','종목명':'name'})\n",
    "c = c.rename(columns={'Code':'code','Name':'name'})\n",
    "#total_list = list(set(file_list) - set(filter_list))  ## total*.xlsx - total_filter*.xlsx\n",
    "print(a.shape)  ##  현재 기준이되는 종목수\n",
    "print(b.shape)  ##  거래소 상장 종목수     ( b - a = 10)   우선주 18, 외국상장종목 8   \n",
    "print(c.shape)  ##  현재 DB에 있는 종목수 \n",
    "print(\"time :\", time.time() - start)  # 현재시각 - 시작시간 = 실행 시간"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 하위 디렉토리 포함 file 병합, 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mod1 import *\n",
    "\n",
    "a = pd.read_excel('d:/kkk.xlsx',index_col=0)  ## 종목명, code 번호 (kospi, kosdaq 전체)\n",
    "a = a.reset_index(drop=True)\n",
    "code_list = a['code'].tolist()\n",
    "code_list = [str(item).zfill(6) for item in code_list]\n",
    "a['code_b'] = pd.DataFrame(code_list)\n",
    "a = a[['code_b','name']]\n",
    "path = 'd:/stockdata/close_ma120/2021/2021_01/0129/'\n",
    "dir_list=os.listdir(path)\n",
    "\n",
    "file_list = glob.glob(path+'total_*.xlsx')\n",
    "filter_list = glob.glob(path+'total_filter*.xlsx')\n",
    "total_list = list(set(file_list) - set(filter_list))  ## total*.xlsx - total_filter*.xlsx\n",
    "for j in total_list:\n",
    "    b = pd.read_excel(j,index_col=0)\n",
    "    b = b.reset_index(drop=True)\n",
    "    code_list = b['code'].tolist()\n",
    "    code_list = [str(item).zfill(6) for item in code_list]\n",
    "    b['code_b'] = pd.DataFrame(code_list)\n",
    "    c = pd.merge(b,a,on='code_b')\n",
    "    c = c.drop(['name_x','code'],axis=1)\n",
    "    d = c[['name','code_b','close_x', 'close_y', 'ma60_x', 'ma60_y', 'ma120_x', 'ma120_y','price_x', 'price_y', 'date_x', 'volume_z', 'price_diff']]\n",
    "    d = d.rename(columns = {'name':'name_x', 'code_b':'code'})\n",
    "    d.to_excel(j) \n",
    "for k in filter_list:\n",
    "    b = pd.read_excel(k,index_col=0)\n",
    "    b = b.reset_index(drop=True)\n",
    "    code_list = b['code'].tolist()\n",
    "    code_list = [str(item).zfill(6) for item in code_list]\n",
    "    b['code_b'] = pd.DataFrame(code_list)\n",
    "    c = pd.merge(b,a,on='code_b')\n",
    "    c = c.drop(['code'],axis=1)\n",
    "    d = c[['name','code_b','close_x', 'close_y', 'ma60_x', 'ma60_y', 'ma120_x', 'ma120_y','Closed', 'price_y', 'date_x', 'volume_z', 'price_diff']]\n",
    "    d = d.rename(columns = {'name':'Name', 'code_b':'code'})\n",
    "    d.to_excel(k)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mod1 import *\n",
    "\n",
    "a = pd.read_excel('f:/kk.xlsx')  ## 종목명, code 번호 (kospi, kosdaq 전체)\n",
    "a = a.reset_index(drop=True)\n",
    "code_list = a['code'].tolist()\n",
    "code_list = [str(item).zfill(6) for item in code_list]\n",
    "a['code_b'] = pd.DataFrame(code_list)\n",
    "a = a[['code_b','name']]\n",
    "path = 'f:/stockdata/close_ma120/2020/2020_11/'\n",
    "dir_list=os.listdir(path)\n",
    "\n",
    "for i in dir_list:\n",
    "    file_list = glob.glob(path+i+'/'+'total_*.xlsx')\n",
    "    filter_list = glob.glob(path+i+'/'+'total_filter*.xlsx')\n",
    "    total_list = list(set(file_list) - set(filter_list))  ## total*.xlsx - total_filter*.xlsx\n",
    "    for j in total_list:\n",
    "        b = pd.read_excel(j,index_col=0)\n",
    "        b = b.reset_index(drop=True)\n",
    "        code_list = b['code'].tolist()\n",
    "        code_list = [str(item).zfill(6) for item in code_list]\n",
    "        b['code_b'] = pd.DataFrame(code_list)\n",
    "        c = pd.merge(b,a,on='code_b')\n",
    "        c = c.drop(['name_x','code'],axis=1)\n",
    "        d = c[['name','code_b','close_x', 'close_y', 'ma60_x', 'ma60_y', 'ma120_x', 'ma120_y','price_x', 'price_y', 'date_x', 'volume_z', 'price_diff']]\n",
    "        d = d.rename(columns = {'name':'name_x', 'code_b':'code'})\n",
    "        d.to_excel(j)  \n",
    "\n",
    "    for k in filter_list:\n",
    "        b = pd.read_excel(k,index_col=0)\n",
    "        b = b.reset_index(drop=True)\n",
    "        code_list = b['code'].tolist()\n",
    "        code_list = [str(item).zfill(6) for item in code_list]\n",
    "        b['code_b'] = pd.DataFrame(code_list)\n",
    "        c = pd.merge(b,a,on='code_b')\n",
    "        c = c.drop(['Name','code'],axis=1)\n",
    "        d = c[['name','code_b','close_x', 'close_y', 'ma60_x', 'ma60_y', 'ma120_x', 'ma120_y','Closed', 'price_y', 'date_x', 'volume_z', 'price_diff']]\n",
    "        d = d.rename(columns = {'name':'Name', 'code_b':'code'})\n",
    "        d.to_excel(k)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 디렉토리내 화일별 기간 주가 추이변화 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## vote_stock 디렉토리 추이 분석 (함수로 변경_prioce, volume , 기간 선택 , 최종날짜를 DB에서 자동추출)_ 4\n",
    "\n",
    "from mod1 import *\n",
    "\n",
    "def vote_stock(select):\n",
    "    \n",
    "    date_query = \"select Date from market where Name='hrs' order by Date desc limit 1\"\n",
    "\n",
    "    df = pd.read_sql(date_query, engine)\n",
    "    df = pd.to_datetime(df['Date'])\n",
    "    df = str(df)\n",
    "    last_date = df[4:14]                ## table에서 최종 날짜 추줄\n",
    "    \n",
    "    if select == 'pprice':\n",
    "        file = glob.glob('f:\\\\stockdata\\\\vote_stock\\\\detect_stock_with_pprice_'+'*.xlsx')\n",
    "        \n",
    "    elif select == 'volume':\n",
    "        file = glob.glob('f:\\\\stockdata\\\\vote_stock\\\\detect_stock_with_volume_'+'*.xlsx')\n",
    "        \n",
    "    else:\n",
    "        print('select error')\n",
    "        exit()    \n",
    "    \n",
    "    \n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    file = glob.glob('f:\\\\stockdata\\\\vote_stock\\\\'+'*.xlsx')\n",
    "        \n",
    "     \n",
    "    for i in file:\n",
    "        df = pd.read_excel(i, index_col=0)\n",
    "        df = df[['Name','today_Close']]\n",
    "        df = df.rename(columns={'today_Close':'Closed'})\n",
    "        name = df['Name'].tolist()\n",
    "        select_query = \"select Name,Close from market where Name in (\"\n",
    "        var = \") and  Date = \"\n",
    "\n",
    "        query = select_query+str(name)[1:-1]+var+\"'\"+last_date+\"'\"\n",
    "        df2 = pd.read_sql(query, engine)\n",
    "\n",
    "        df1 = pd.merge(df, df2)\n",
    "        df1['diff']=df1['Close']/df1['Closed']\n",
    "        df1 = df1.sort_values(by=['diff'], ascending=False)\n",
    "        df1.to_excel('f:/stockdata/vote_stock/analysis/'+select+i[48:59]+'.xlsx')\n",
    "\n",
    "    print(\"time:\", time.time()-start)\n",
    "    \n",
    "vote_stock('pprice')\n",
    "vote_stock('volume')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## stockdata / close_ma120 디렉토리 추이 분선 _ 1\n",
    "\n",
    "from mod1 import *\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "path = 'f:\\\\stockdata\\\\close_ma120\\\\2020\\\\2020-07\\\\'\n",
    "file_list = os.listdir(path)\n",
    "for i in file_list:\n",
    "    file = glob.glob(path+i+'/'+'total_filter_2020-02-20.*')\n",
    "    df = pd.read_excel(file[0])\n",
    "    df = df[['name_x','price_y']]\n",
    "    df = df.rename(columns={'name_x':'Name','price_y':'Closed'}) \n",
    "    df.to_excel('f:/df_'+i+'.xlsx')\n",
    "df = pd.read_excel('f:/df_0702.xlsx',index_col=0)\n",
    "name = df['Name'].tolist()\n",
    "\n",
    "\n",
    "df2 = pd.DataFrame()\n",
    "for i in range(len(name)):\n",
    "    select_query = \"select Name,Close from market where Name in (\"\n",
    "    var = \") and  Date > '2020-08-13' \"\n",
    "    query = select_query+\"'\"+name[i]+\"'\"+ var\n",
    "    \n",
    "    df3 = pd.read_sql(query, engine)\n",
    "    df2 = df2.append(df3)\n",
    "    #df['Close'] = df3['Close']\n",
    "df1 = pd.merge(df, df2)\n",
    "df1['diff']=df1['Close']/df1['Closed']\n",
    "df1 = df1.sort_values(by=['diff'], ascending=False)\n",
    "df1.to_excel('f:/df1_0702.xlsx')\n",
    "print(\"time:\", time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## stockdata / close_ma120 디렉토리 추이 분선 _ 2\n",
    "\n",
    "from mod1 import *\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "path = 'f:\\\\stockdata\\\\close_ma120\\\\2020\\\\2020-07\\\\'\n",
    "file_list = os.listdir(path)\n",
    "for i in file_list:\n",
    "    file = glob.glob(path+i+'/'+'total_filter_2020-02-20.*')\n",
    "    df = pd.read_excel(file[0])\n",
    "    df = df[['name_x','price_y']]\n",
    "    df = df.rename(columns={'name_x':'Name','price_y':'Closed'}) \n",
    "    df.to_excel('f:/df_'+i+'.xlsx')\n",
    "df = pd.read_excel('f:/df_0702.xlsx',index_col=0)\n",
    "name = df['Name'].tolist()\n",
    "\n",
    "\n",
    "select_query = \"select Name,Close from market where Name in (\"\n",
    "var = \") and  Date > '2020-08-13' \"\n",
    "#query = select_query+str(name).strip('[]')+var  ##  list to str\n",
    "query = select_query+str(name)[1:-1]+var        ##  list to str\n",
    "df2 = pd.read_sql(query, engine)\n",
    "\n",
    "\n",
    "df1 = pd.merge(df, df2)\n",
    "df1['diff']=df1['Close']/df1['Closed']\n",
    "df1 = df1.sort_values(by=['diff'], ascending=False)\n",
    "df1.to_excel('f:/df1_0702.xlsx')\n",
    "print(\"time:\", time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## stockdata / close_ma120 디렉토리 추이 분선 _ 3\n",
    "\n",
    "from mod1 import *\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "file = glob.glob('f:/df_*.xlsx')\n",
    "\n",
    "path = 'f:\\\\stockdata\\\\close_ma120\\\\2020\\\\2020-07\\\\'\n",
    "file_list = os.listdir(path)\n",
    "for i in file_list:\n",
    "    file_name = glob.glob(path+i+'/'+'total_filter_2020-02-20.*')\n",
    "    df = pd.read_excel(file_name[0])\n",
    "    df = df[['name_x','price_y']]\n",
    "    df = df.rename(columns={'name_x':'Name','price_y':'Closed'}) \n",
    "    df.to_excel('f:/df_'+i+'.xlsx')\n",
    "\n",
    "\n",
    "\n",
    "for i in file:\n",
    "    df = pd.read_excel(i, index_col=0)\n",
    "    name = df['Name'].tolist()\n",
    "    select_query = \"select Name,Close from market where Name in (\"\n",
    "    var = \") and  Date > '2020-08-13' \"\n",
    "    #query = select_query+str(name).strip('[]')+var   ##  list to str\n",
    "    query = select_query+str(name)[1:-1]+var          ##  list to str\n",
    "    df2 = pd.read_sql(query, engine)\n",
    "    \n",
    "    df1 = pd.merge(df, df2)\n",
    "    df1['diff']=df1['Close']/df1['Closed']\n",
    "    df1 = df1.sort_values(by=['diff'], ascending=False)\n",
    "    df1.to_excel('f:/stockdata/close_ma120/'+i[6:10]+'.xlsx')\n",
    "print(\"time:\", time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  ##  일봉,주봉,월봉 데이터 생성\n",
    "\n",
    "from mod1 import *\n",
    "\n",
    "def day_week_month_data(market='hrs', start_day = '2020-01-01',period ='month'):\n",
    "    if market=='kospi' or market=='kosdaq':\n",
    "        df = select_market(market,start_day)\n",
    "    else :\n",
    "        df = select_stock(market,start_day)\n",
    "    df['Date']=pd.to_datetime(df['Date'])\n",
    "    months = [g for n, g in df.groupby(pd.Grouper(key='Date',freq='M'))]  ##   월별\n",
    "    weeks = [g for n, g in df.groupby(pd.Grouper(key='Date',freq='W'))]  ##   주별\n",
    "    columns = ['Date','Open', 'High', 'Low', 'Close', 'Volume']\n",
    "    rows = []    \n",
    "\n",
    "    if period == 'day':\n",
    "        \n",
    "        df=df[['Date','Open', 'High', 'Low','Close', 'Volume']]\n",
    "        df.columns=columns\n",
    "        #df = df.set_index(df['date'])\n",
    "        return df\n",
    "    \n",
    "    elif period == 'month':\n",
    "        period = months\n",
    "        \n",
    "    elif period == 'week':\n",
    "        period = weeks\n",
    "        \n",
    "    for i in range(len(period)):\n",
    "        rows.append(period[i].iloc[-1]['Date'])\n",
    "        rows.append(period[i].iloc[0][\"Open\"])\n",
    "        rows.append(max(period[i]['High']))\n",
    "        rows.append(min(period[i]['Low']))\n",
    "        rows.append(period[i].iloc[-1]['Close'])\n",
    "        rows.append(sum(period[i]['Volume']))\n",
    "        \n",
    "    arr = np.array(rows)\n",
    "    arr1 = arr.reshape(len(period),6)\n",
    "    df = pd.DataFrame(data=arr1, columns=columns)\n",
    "    df = df.set_index(df['Date'])\n",
    "    df.rename(columns = {'Date' : 'Date1'}, inplace = True)\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  일봉,주봉,월봉에서  연속으로 하락한 종목을 순서대로 정렬\n",
    "\n",
    "\n",
    "from mod1 import *\n",
    "\n",
    "def day_week_month_data(market='일야', start_day = '2020-01-01',period ='month'):\n",
    "    if market=='kospi' or market=='kosdaq':\n",
    "        df = select_market(market,start_day)\n",
    "    else :\n",
    "        df = select_stock(market,start_day)\n",
    "    df['Date']=pd.to_datetime(df['Date'])\n",
    "    months = [g for n, g in df.groupby(pd.Grouper(key='Date',freq='M'))]  ##   월별\n",
    "    weeks = [g for n, g in df.groupby(pd.Grouper(key='Date',freq='W'))]  ##   주별\n",
    "    columns = ['Date','Open', 'High', 'Low', 'Close', 'Volume']\n",
    "    rows = []    \n",
    "\n",
    "    if period == 'day':\n",
    "        \n",
    "        df=df[['Date','Open', 'High', 'Low','Close', 'Volume']]\n",
    "        df.columns=columns\n",
    "        #df = df.set_index(df['date'])\n",
    "        return df\n",
    "    \n",
    "    elif period == 'month':\n",
    "        period = months\n",
    "        \n",
    "    elif period == 'week':\n",
    "        period = weeks\n",
    "        \n",
    "    for i in range(len(period)):\n",
    "        rows.append(period[i].iloc[-1]['Date'])\n",
    "        rows.append(period[i].iloc[0][\"Open\"])\n",
    "        rows.append(max(period[i]['High']))\n",
    "        rows.append(min(period[i]['Low']))\n",
    "        rows.append(period[i].iloc[-1]['Close'])\n",
    "        rows.append(sum(period[i]['Volume']))\n",
    "        \n",
    "    arr = np.array(rows)\n",
    "    arr1 = arr.reshape(len(period),6)\n",
    "    df = pd.DataFrame(data=arr1, columns=columns)\n",
    "    df = df.set_index(df['Date'])\n",
    "    df.rename(columns = {'Date' : 'Date1'}, inplace = True)\n",
    "    return df \n",
    "\n",
    "def depress(period):\n",
    "    today = datetime.now().strftime('%Y-%m-%d')\n",
    "    path_depress = 'f:\\\\stockdata\\\\depress\\\\depress_'\n",
    "    if period=='month':\n",
    "        start_day='2019-01-01'\n",
    "        \n",
    "    elif period=='week' :\n",
    "        start_day='2020-01-01'\n",
    "        \n",
    "    else :\n",
    "        start_day='2020-05-01'\n",
    "        \n",
    "    df = all_stock('2020-06-15')\n",
    "    df = df['Name']\n",
    "    name = df.to_list()\n",
    "\n",
    "    #name=['일야','hrs','디지털대성']\n",
    "    count = 0\n",
    "    depress=[]\n",
    "    for i in name:\n",
    "        df = day_week_month_data(market=i,start_day=start_day,period=period)\n",
    "        df['yesterday']=df.Close.shift(1)\n",
    "        df['minus']=(df['Close']-df['yesterday']) < 0\n",
    "        df1 = df.sort_values(by=['Date'], axis=0, ascending=False,ignore_index=True )\n",
    "        minus = df1.minus.values\n",
    "\n",
    "        for i in minus:\n",
    "            if i == True:\n",
    "                count += 1\n",
    "\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        #print(count)\n",
    "        depress.append(count)\n",
    "        count=0\n",
    "\n",
    "\n",
    "    df2= pd.DataFrame()\n",
    "    df2['name']=name\n",
    "    df2['count']=depress\n",
    "    df3 = df2.sort_values(by=['count'], axis=0, ascending=False,ignore_index=True )\n",
    "    if period=='month':\n",
    "        df3 = df3.iloc[:100]\n",
    "    elif period=='week':\n",
    "        df3 = df3.iloc[:200]\n",
    "    elif period=='day':\n",
    "        df3 = df3.iloc[:300]\n",
    "    #else:\n",
    "       # break\n",
    "    #df3.to_excel(path_depress+today+'_'+period+'.xlsx')\n",
    "    df3.to_excel(path_depress+period+'_'+today+'.xlsx')\n",
    "    #return df3\n",
    "\n",
    "\n",
    "three_period=['day','week','month']\n",
    "for i in three_period:\n",
    "    depress(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  일봉상 연속으로 하락한 종목을 순서대로 정렬\n",
    "\n",
    "from mod1 import *\n",
    "\n",
    "df = all_stock('2020-06-12')\n",
    "df = df['Name']\n",
    "name = df.to_list()\n",
    "\n",
    "count = 0\n",
    "depress=[]\n",
    "for i in name:\n",
    "    df = select_stock(i,'2020-05-01')\n",
    "    df['yesterday']=df.Close.shift(1)\n",
    "    df['minus']=(df['Close']-df['yesterday']) < 0\n",
    "    df1 = df.sort_values(by=['Date'], axis=0, ascending=False,ignore_index=True )\n",
    "    minus = df1.minus.values\n",
    "\n",
    "    for i in minus:\n",
    "        \n",
    "\n",
    "        if i == True:\n",
    "            count += 1\n",
    "\n",
    "        else:\n",
    "            \n",
    "            break\n",
    "        \n",
    "    print(count)\n",
    "    depress.append(count)\n",
    "    count=0\n",
    "\n",
    "\n",
    "df2= pd.DataFrame()\n",
    "df2['name']=name\n",
    "df2['count']=depress\n",
    "df3 = df2.sort_values(by=['count'], axis=0, ascending=False,ignore_index=True )\n",
    "df3.to_excel('d:\\depress_day.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###  기간동안 종목별 종가중 최대값 \n",
    "\n",
    "from  mod1 import *\n",
    "\n",
    "def all_stock_period(date1, date2='2021-01-01'):\n",
    "    select_query = \"select * from market_good where Date >=  \"\n",
    "    var = select_query +\"'\"+date1+\"'\"  +\" \"+ 'and Date <=' + \"'\"+date2+\"'\"\n",
    "    df = pd.read_sql(var, engine)\n",
    "    return df\n",
    "\n",
    "df = all_stock_period('2020-03-05','2020-03-10')\n",
    "\n",
    "max(df[df['Code']=='000547'].Close) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  기간동안 낙폭 과대종목 검색 (기간동안 최저점에서 현재가 비교)_1\n",
    "\n",
    "import time\n",
    "from  mod1 import *\n",
    "\n",
    "def all_stock_period(date1, date2='2021-01-01'):\n",
    "    select_query = \"select * from market_good where Date >=  \"\n",
    "    var = select_query +\"'\"+date1+\"'\"  +\" \"+ 'and Date <=' + \"'\"+date2+\"'\"\n",
    "    df = pd.read_sql(var, engine)\n",
    "    return df\n",
    "\n",
    "def flow_close(method, standard_day='2020-12-11'):\n",
    "    start = time.time()  # 시작 시간 저장\n",
    "    df=method\n",
    "    df = method\n",
    "    df_uniq = df['Name'].unique()\n",
    "    df_uniq_list=df_uniq.tolist()\n",
    "\n",
    "    min_data = []\n",
    "    for x in df_uniq_list:\n",
    "        min_value = min(df[df['Name']== x ].Close)\n",
    "        min_data.append(min_value)\n",
    "\n",
    "    min_close = pd.DataFrame(min_data)\n",
    "\n",
    "    df_a=pd.DataFrame(df_uniq)\n",
    "\n",
    "\n",
    "    df_first=pd.DataFrame()\n",
    "    df_first['Name']=df_a[0]\n",
    "    df_first['Close']=min_close[0]\n",
    "    df_to = all_stock(standard_day)\n",
    "    df_last=df_to[['Name','Close']]\n",
    "    df = pd.merge(df_first,df_last,on='Name')\n",
    "\n",
    "    df['diff']=df['Close_y']/df['Close_x']\n",
    "    df.head()\n",
    "\n",
    "    close_diff_df =  df.sort_values([\"diff\"],ascending=True)\n",
    "    close_diff_df.head()\n",
    "\n",
    "    close_diff_df.to_excel(\"d:\\\\b_2.xlsx\")\n",
    "    print(\"time :\", time.time() - start)  # 현재시각 - 시작시간 = 실행 시간\n",
    "flow_close(all_stock_period('2020-02-19','2020-03-25'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  기간동안 낙폭 과대종목 검색 (기간동안 최저점에서 현재가 비교)_2\n",
    "\n",
    "import time\n",
    "from  mod1 import *\n",
    "\n",
    "df = pd.read_sql(\"select Date from market where Name='hrs' order by Date desc limit 1\",engine)\n",
    "df = pd.to_datetime(df['Date'])\n",
    "#df = df + timedelta(1)          ##  최종날짜 다음날짜\n",
    "df = str(df)\n",
    "today = df[4:14]                ## 2020-07-13\n",
    "standard=today\n",
    "\n",
    "\n",
    "def all_stock_period(date1, date2='2021-01-01'):\n",
    "    select_query = \"select * from market_good where Date >=  \"\n",
    "    var = select_query +\"'\"+date1+\"'\"  +\" \"+ 'and Date <=' + \"'\"+date2+\"'\"\n",
    "    df = pd.read_sql(var, engine)\n",
    "    return df\n",
    "\n",
    "def flow_close(method, standard_day = standard):\n",
    "    start = time.time()  # 시작 시간 저장\n",
    "    df = method\n",
    "    df = all_stock_period('2020-02-19','2020-03-25')\n",
    "    df_start=pd.DataFrame()\n",
    "    name = df['Name'].unique()\n",
    "\n",
    "    df = df.set_index('Name')\n",
    "\n",
    "    min_list=[ ]\n",
    "    for i in name:\n",
    "        min_close  = min(df.loc[i].Close)\n",
    "        min_list.append(min_close)\n",
    "\n",
    "    df_start=pd.DataFrame(name)\n",
    "    df_start['Name']=pd.DataFrame(name)\n",
    "    df_start['Close']=pd.DataFrame(min_list)\n",
    "    df_start=df_start[['Name','Close']]\n",
    "    df1 = all_stock(standard_day)\n",
    "    df1_last = df1[['Name','Close']]\n",
    "\n",
    "    df2 = pd.merge(df_start, df1_last, on=\"Name\")\n",
    "    df2['diff']=df2['Close_y']/df2['Close_x']\n",
    "    df2 = df2.sort_values(by=['diff'], ascending='True')\n",
    "\n",
    "    df2.to_excel('d:\\\\down_'+standard+'.xlsx')\n",
    "    #df2.to_excel(\"d:\\\\b_2.xlsx\")\n",
    "    print(\"time :\", time.time() - start)  # 현재시각 - 시작시간 = 실행 시간\n",
    "flow_close(all_stock_period('2020-02-19','2020-03-25'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## _1 기간동안 낙폭 과대종목 검색 (기간동안 최저점에서 현재가 비교)_2\n",
    "\n",
    "import time\n",
    "from  mod1 import *\n",
    "\n",
    "start = time.time()  # 시작 시간 저장\n",
    "today = datetime.now().strftime('%Y-%m-%d')\n",
    "df = select_stock('아스트','2019-01-01')\n",
    "how = {'Open': 'first', 'High': 'max', 'Low': 'min', 'Close': 'last', 'Volume': 'sum'}\n",
    "def resample_df(df, freq, how):\n",
    "    df['Date'] = df['Date'].astype('datetime64[ns]')\n",
    "    df = df.set_index('Date')\n",
    "    df = df[['Open','High','Low','Close','Volume']]\n",
    "    #how = {'Open': 'first', 'High': 'max', 'Low': 'min', 'Close': 'last', 'Volume': 'sum'}\n",
    "    if freq != 'd' and len(df) > 0:\n",
    "        if freq == 'm':\n",
    "            df = df.resample('M').apply(how)\n",
    "            #df.index = df.index.strftime('%Y%m')\n",
    "        elif freq == 'y':\n",
    "            df = df.resample('Y').apply(how)\n",
    "            #df.index = df.index.strftime('%Y')\n",
    "        else:\n",
    "            print(\"choose a freq parameter in ('m', 'y', 'd')\")\n",
    "            raise RuntimeError\n",
    "    return df\n",
    "\n",
    "df = resample_df(df,'m',how)    \n",
    "print(df.head())\n",
    "print(\"time :\", time.time() - start)  # 현재시각 - 시작시간 = 실행 시간"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## _2기간동안 낙폭 과대종목 검색 (기간동안 최저점에서 현재가 비교)_2\n",
    "\n",
    "import time\n",
    "from  mod1 import *\n",
    "\n",
    "start = time.time()  # 시작 시간 저장\n",
    "today = datetime.now().strftime('%Y-%m-%d')\n",
    "df = select_stock('아스트','2019-01-01')\n",
    "\n",
    "df1=pd.DataFrame()\n",
    "\n",
    "df1[['Date','Close']] = df[['Date','Close']]\n",
    "\n",
    "df1['Date'] = df1['Date'].astype('datetime64[ns]')\n",
    "\n",
    " \n",
    "\n",
    "df1 = df1.set_index('Date')\n",
    "\n",
    "df_week = df1.resample('W').mean()\n",
    "\n",
    "df_month = df1.resample('M').mean()\n",
    "\n",
    "print(df_month.head())\n",
    "\n",
    "print(\"time :\", time.time() - start)  # 현재시각 - 시작시간 = 실행 시간"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  기간동안 낙폭 과대종목 검색\n",
    "\n",
    "from mod1 import *\n",
    "today = datetime.now().strftime('%Y-%m-%d')\n",
    "current=today\n",
    "\n",
    "df_from = all_stock('2020-03-05')\n",
    "df_to = all_stock(current)\n",
    "df_first=df_from[['Name','Close']]\n",
    "df_last=df_to[['Name','Close']]\n",
    "df = pd.merge(df_first,df_last,on='Name')\n",
    "\n",
    "df['diff']=df['Close_y']/df['Close_x']\n",
    "df.head()\n",
    "\n",
    "close_diff_df =  df.sort_values([\"diff\"],ascending=True)\n",
    "close_diff_df.head()\n",
    "\n",
    "close_diff_df.to_excel('d:\\\\down_'+current+'.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 월봉 만들기\n",
    "\n",
    "df = select_stock('아스트','2019-01-01')\n",
    "how = {'Open': 'first', 'High': 'max', 'Low': 'min', 'Close': 'last', 'Volume': 'sum'}\n",
    "def resample_df(df, freq, how):\n",
    "    df['Date'] = df['Date'].astype('datetime64[ns]')\n",
    "    df = df.set_index('Date')\n",
    "    df = df[['Open','High','Low','Close','Volume']]\n",
    "    #how = {'Open': 'first', 'High': 'max', 'Low': 'min', 'Close': 'last', 'Volume': 'sum'}\n",
    "    if freq != 'd' and len(df) > 0:\n",
    "        if freq == 'm':\n",
    "            df = df.resample('M').apply(how)\n",
    "            #df.index = df.index.strftime('%Y%m')\n",
    "        elif freq == 'y':\n",
    "            df = df.resample('Y').apply(how)\n",
    "            #df.index = df.index.strftime('%Y')\n",
    "        else:\n",
    "            print(\"choose a freq parameter in ('m', 'y', 'd')\")\n",
    "            raise RuntimeError\n",
    "    return df\n",
    "\n",
    "df = resample_df(df,'m',how)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  기간동안 종목 가격 변화 \n",
    "\n",
    "from  mod1 import *\n",
    "\n",
    "price_path = 'f:/stockdata/vote_stock/detect_stock_with_price_'\n",
    "volume_path = 'f:/stockdata/vote_stock/detect_stock_with_volume_'\n",
    "\n",
    "df = pd.read_excel(volume_path+'2019-01-03.xlsx', index_col=0)\n",
    "\n",
    "data = pd.DataFrame()\n",
    "for x in df['Name']:\n",
    "    current = select_stock(x,'2020-07-20')\n",
    "    data = data.append(current['Close'])\n",
    "\n",
    "data = data.reset_index(drop=True)\n",
    "data.columns=['current_Close']\n",
    "\n",
    "df['current_Close']=data['current_Close']\n",
    "df['diff']=df['current_Close'] / df['today_Close']\n",
    "\n",
    "df = df.sort_values(['diff'], ascending=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## datetime.date  -> pd.to_datetime \n",
    "\n",
    "#!/usr/bin/env python3\n",
    "# coding: utf-8\n",
    "\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "# create a datetime data object\n",
    "d_time = datetime.date(2010, 11, 12)\n",
    "\n",
    "# create a pandas Timestamp object\n",
    "t_stamp = pd.to_datetime('2010/11/12')\n",
    "\n",
    "# cast `datetime_timestamp` as Timestamp object and compare\n",
    "d_time2t_stamp = pd.to_datetime(d_time)\n",
    "\n",
    "# print to double check\n",
    "print(d_time)\n",
    "print(t_stamp)\n",
    "print(d_time2t_stamp)\n",
    "\n",
    "# since the conversion succeds this prints `True`\n",
    "print(d_time2t_stamp == t_stamp)\n",
    "\n",
    "\n",
    "## sample \n",
    "t = pd.Timestamp('2013-12-25 00:00:00')\n",
    "\n",
    "t.date()\n",
    "#datetime.date(2013, 12, 25)\n",
    "\n",
    "t.date() == datetime.date(2013, 12, 25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import FinanceDataReader as fdr\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime as dt\n",
    "from datetime import datetime,timedelta\n",
    "from urllib.request import urlopen\n",
    "import sqlalchemy \n",
    "import pymysql\n",
    "import talib.abstract as ta\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "from matplotlib import font_manager, rc\n",
    "font_name = font_manager.FontProperties(fname=\"c:/Windows/Fonts/malgun.ttf\").get_name()\n",
    "rc('font', family=font_name)\n",
    "\n",
    "now = dt.datetime.today().strftime('%Y-%m-%d')\n",
    "engine = sqlalchemy.create_engine('mysql+pymysql://kkang:leaf2027@localhost/stock?charset=utf8',encoding='utf-8')\n",
    "conn = pymysql.connect(host = 'localhost', user = 'kkang', password = 'leaf2027' ,db = 'stock')\n",
    "curs = conn.cursor()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataBase 입출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  코스피, 코드닥 지수 Database에 입력\n",
    "\n",
    "from mod1 import *\n",
    "def market_index_to_database(startday, lastday='20251231', market='코스피'):\n",
    "\n",
    "    df = get_index_ohlcv_by_date(startday, lastday, market)\n",
    "\n",
    "    df.index.names = ['Date']\n",
    "    df.columns  = ('Open','High','Low','Close','Volume')\n",
    "    if market == '코스피':\n",
    "        df['Market']='kospi'\n",
    "        df.to_sql(name='kospi', con=engine, if_exists='append')\n",
    "    elif market == '코스닥':\n",
    "        df['Market']='kosdaq'\n",
    "        df.to_sql(name='kosdaq', con=engine, if_exists='append')\n",
    "    #df.to_excel('d:\\\\kospi.xlsx')\n",
    "#market_index_to_database(\"20200811\",'20251231','코스피')\n",
    "market_index_to_database(\"20201103\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "파일이름을 입력하세요:input.xlsx\n",
      "저장 방식을 입력하세요 : sample: excel, sql sql\n",
      "시작날자를 입려하세요 : sample: '2015-01-01'2021-02-01\n",
      "table명을 입력하세요 : sample: marketmarket\n",
      "164060 이루다\n",
      "166090 하나머티리얼즈\n",
      "166480 코아스템\n",
      "168330 내츄럴엔도텍\n",
      "168490 한국패러랠\n",
      "169330 엠브레인\n",
      "170030 현대공업\n",
      "170790 파이오링크\n",
      "170900 동아에스티\n",
      "170920 엘티씨\n",
      "171010 램테크놀러지\n",
      "171090 선익시스템\n",
      "171120 라이온켐텍\n",
      "172580 하이골드12호\n",
      "173130 오파스넷\n",
      "173940 에프엔씨엔터\n",
      "174880 장원테크\n",
      "174900 앱클론\n",
      "175140 인포마크\n",
      "175250 아이큐어\n",
      "175330 JB금융지주\n",
      "176440 에이치엔티\n",
      "177350 베셀\n",
      "177830 파버나인\n",
      "178320 서진시스템\n",
      "178780 유테크\n",
      "178920 PI첨단소재\n",
      "179290 엠아이텍\n",
      "179900 유티아이\n",
      "180400 캔서롭\n",
      "180640 한진칼\n",
      "181340 이즈미디어\n",
      "181710 NHN\n",
      "182360 큐브엔터\n",
      "182400 엔케이맥스\n",
      "182690 테라셈\n",
      "183190 아세아시멘트\n",
      "183300 코미코\n",
      "183490 엔지켐생명과학\n",
      "184230 SGA솔루션즈\n",
      "185490 아이진\n",
      "185750 종근당\n",
      "186230 그린플러스\n",
      "187220 디티앤씨\n",
      "187270 신화콘텍\n",
      "187420 제노포커스\n",
      "187790 나노\n",
      "187870 디바이스이엔지\n",
      "189300 인텔리안테크\n",
      "189690 포시에스\n",
      "189860 서전기전\n",
      "189980 흥국에프엔비\n",
      "190510 나무가\n",
      "190650 코리아에셋투자증권\n",
      "191410 육일씨엔에쓰\n",
      "191420 테고사이언스\n",
      "192080 더블유게임즈\n",
      "192250 케이사인\n",
      "192390 윈하이텍\n",
      "192400 쿠쿠홀딩스\n",
      "192410 감마누\n",
      "192440 슈피겐코리아\n",
      "192650 드림텍\n",
      "192820 코스맥스\n",
      "193250 와이제이엠게임즈\n",
      "194370 제이에스코퍼레이션\n",
      "194480 데브시스터즈\n",
      "194700 노바렉스\n",
      "195440 퓨전\n",
      "195500 마니커에프앤지\n",
      "195870 해성디에스\n",
      "195990 에이비프로바이오\n",
      "196170 알테오젠\n",
      "196300 애니젠\n",
      "196450 디오스텍\n",
      "196490 디에이테크놀로지\n",
      "196700 웹스\n",
      "197140 디지캡\n",
      "198080 엔피디\n",
      "198440 고려시멘트\n",
      "199820 제일전기공업\n",
      "200130 콜마비앤에이치\n",
      "200230 텔콘RF제약\n",
      "200470 에이팩트\n",
      "200670 휴메딕스\n",
      "200710 에이디테크놀로지\n",
      "200780 비씨월드제약\n",
      "200880 서연이화\n",
      "201490 미투온\n",
      "203450 유니온커뮤니티\n",
      "203650 드림시큐리티\n",
      "203690 프로스테믹스\n",
      "204020 그리티\n",
      "204210 모두투어리츠\n",
      "204270 제이앤티씨\n",
      "204320 만도\n",
      "204620 글로벌텍스프리\n",
      "204630 스튜디오산타클로스\n",
      "204840 지엘팜텍\n",
      "205100 엑셈\n",
      "205470 휴마시스\n",
      "205500 액션스퀘어\n",
      "206400 베노홀딩스\n",
      "206560 덱스터\n",
      "206640 바디텍메드\n",
      "206650 유바이오로직스\n",
      "207760 미스터블루\n",
      "207940 삼성바이오로직스\n",
      "208140 정다운\n",
      "208340 파멥신\n",
      "208350 지란지교시큐리티\n",
      "208370 셀바스헬스케어\n",
      "208640 썸에이지\n",
      "208710 바이오로그디바이스\n",
      "208860 엔지스테크널러지\n",
      "210540 디와이파워\n",
      "210980 SK디앤디\n",
      "211270 AP위성\n",
      "212560 네오오토\n",
      "213090 미래테크놀로지\n",
      "213420 덕산네오룩스\n",
      "213500 한솔제지\n",
      "214150 클래시스\n",
      "214180 민앤지\n",
      "214260 라파스\n",
      "214270 퓨쳐스트림네트웍스\n",
      "214310 세미콘라이트\n",
      "214320 이노션\n",
      "214330 금호에이치티\n",
      "214370 케어젠\n",
      "214390 경보제약\n",
      "214420 토니모리\n",
      "214430 아이쓰리시스템\n",
      "214450 파마리서치프로덕트\n",
      "214610 미코바이오메드\n",
      "214680 디알텍\n",
      "214870 뉴지랩\n",
      "215000 골프존\n",
      "215090 이디티\n",
      "215100 로보로보\n",
      "215200 메가스터디교육\n",
      "215360 우리산업\n",
      "215380 우정바이오\n",
      "215480 토박스코리아\n",
      "215600 신라젠\n",
      "215790 이노인스트루먼트\n",
      "216050 인크로스\n",
      "216080 제테마\n",
      "217190 제너셈\n",
      "217270 넵튠\n",
      "217330 싸이토젠\n",
      "217480 에스디생명공학\n",
      "217500 러셀\n",
      "217600 켐온\n",
      "217620 디딤\n",
      "217730 강스템바이오텍\n",
      "217820 엔에스\n",
      "218150 미래생명자원\n",
      "218410 RFHIC\n",
      "219130 타이거일렉\n",
      "219420 링크제니시스\n",
      "219550 MP한강\n",
      "219750 지티지웰니스\n",
      "220100 퓨쳐켐\n",
      "220180 핸디소프트\n",
      "220260 켐트로스\n",
      "220630 해마로푸드서비스\n",
      "221610 자안\n",
      "221840 하이즈항공\n",
      "221980 케이디켐\n",
      "222040 코스맥스엔비티\n",
      "222080 씨아이에스\n",
      "222110 팬젠\n",
      "222420 쎄노텍\n",
      "222800 심텍\n",
      "222810 마이더스AI\n",
      "222980 한국맥널티\n",
      "223250 드림씨아이에스\n",
      "223310 경남제약헬스케어\n",
      "224060 코디엠\n",
      "224110 에이텍티앤\n",
      "225190 삼양옵틱스\n",
      "225220 제놀루션\n",
      "225330 씨엠에스에듀\n",
      "225430 케이엠제약\n",
      "225530 보광산업\n",
      "225570 넷게임즈\n",
      "225590 패션플랫폼\n",
      "226320 잇츠한불\n",
      "226330 신테카바이오\n",
      "226340 본느\n",
      "226350 아이엠텍\n",
      "226360 이엑스티\n",
      "226400 오스테오닉\n",
      "226440 한송네오텍\n",
      "226950 올릭스\n",
      "227100 디자인\n",
      "227610 아우딘퓨쳐스\n",
      "227840 현대코퍼레이션홀딩스\n",
      "227950 엔투텍\n",
      "228340 동양파일\n",
      "228670 레이\n",
      "228760 지노믹트리\n",
      "228850 레이언스\n",
      "229000 젠큐릭스\n",
      "229640 LS전선아시아\n",
      "230240 에치에프알\n",
      "230360 에코마케팅\n",
      "230980 솔트웍스\n",
      "232140 와이아이케이\n",
      "234080 JW생명과학\n",
      "234100 세원\n",
      "234300 에스트래픽\n",
      "234340 세틀뱅크\n",
      "234690 녹십자웰빙\n",
      "234920 자이글\n",
      "235980 메드팩토\n",
      "236200 슈프리마\n",
      "236810 엔비티\n",
      "237690 에스티팜\n",
      "237750 피앤씨테크\n",
      "237820 플레이디\n",
      "237880 클리오\n",
      "238090 앤디포스\n",
      "238120 얼라인드\n",
      "238200 비피도\n",
      "238490 힘스\n",
      "239340 줌인터넷\n",
      "239610 에이치엘사이언스\n",
      "240810 원익IPS\n",
      "241520 DSC인베스트먼트\n",
      "241560 두산밥캣\n",
      "241590 화승엔터프라이즈\n",
      "241690 유니테크노\n",
      "241710 코스메카코리아\n",
      "241770 메카로\n",
      "241790 오션브릿지\n",
      "241820 피씨엘\n",
      "241840 에이스토리\n",
      "242040 나무기술\n",
      "243070 휴온스\n",
      "243840 신흥에스이씨\n",
      "244460 올리패스\n",
      "244920 에이플러스에셋\n",
      "245620 EDGC\n",
      "246690 TS인베스트먼트\n",
      "246710 티앤알바이오팹\n",
      "246720 아스타\n",
      "246960 이노테라피\n",
      "247540 에코프로비엠\n",
      "248170 샘표식품\n",
      "249420 일동제약\n",
      "250000 보라티알\n",
      "250060 모비스\n",
      "250930 예선테크\n",
      "251270 넷마블\n",
      "251370 와이엠티\n",
      "251630 브이원텍\n",
      "251970 펌텍코리아\n",
      "252500 세화피앤씨\n",
      "253450 스튜디오드래곤\n",
      "253590 네오셈\n",
      "253840 수젠텍\n",
      "254120 자비스\n",
      "255220 SG\n",
      "255440 야스\n",
      "256150 한독크린텍\n",
      "256630 포인트엔지니어링\n",
      "256840 한국비엔씨\n",
      "256940 케이피에스\n",
      "257370 명성티엔에스\n",
      "258610 이더블유케이\n",
      "258790 소프트캠프\n",
      "258830 세종메디칼\n",
      "259630 엠플러스\n",
      "260660 알리코제약\n",
      "260930 씨티케이코스메틱스\n",
      "261200 덴티스\n",
      "262260 에이프로\n",
      "263020 디케이앤디\n",
      "263050 유틸렉스\n",
      "263540 샘코\n",
      "263600 덕우전자\n",
      "263690 디알젬\n",
      "263700 케어랩스\n",
      "263720 디앤씨미디어\n",
      "263750 펄어비스\n",
      "263770 유에스티\n",
      "263800 데이타솔루션\n",
      "263810 상신전자\n",
      "263860 지니언스\n",
      "263920 블러썸엠앤씨\n",
      "264450 유비쿼스\n",
      "264660 씨앤지하이테크\n",
      "264850 이랜시스\n",
      "264900 크라운제과\n",
      "265520 AP시스템\n",
      "265560 영화테크\n",
      "265740 엔에프씨\n",
      "267250 현대중공업지주\n",
      "267260 현대일렉트릭\n",
      "267270 현대건설기계\n",
      "267290 경동도시가스\n",
      "267320 나인테크\n",
      "267790 배럴\n",
      "267850 아시아나IDT\n",
      "267980 매일유업\n",
      "268280 미원에스씨\n",
      "268600 셀리버리\n",
      "269620 시스웍\n",
      "270520 지엔원에너지\n",
      "270870 뉴트리\n",
      "271560 오리온\n",
      "271980 제일약품\n",
      "272110 케이엔제이\n",
      "272210 한화시스템\n",
      "272290 이녹스첨단소재\n",
      "272450 진에어\n",
      "272550 삼양패키징\n",
      "273060 와이즈버즈\n",
      "274090 켄코아에어로스페이스\n",
      "275630 에스에스알\n",
      "277070 린드먼아시아\n",
      "277410 인산가\n",
      "277880 티에스아이\n",
      "278280 천보\n",
      "278650 노터스\n",
      "279600 미디어젠\n",
      "280360 롯데제과\n",
      "281740 레이크머티리얼즈\n",
      "281820 케이씨텍\n",
      "282330 BGF리테일\n",
      "282690 동아타이어\n",
      "282880 코윈테크\n",
      "284620 카이노스메드\n",
      "284740 쿠쿠홈시스\n",
      "285130 SK케미칼\n",
      "285490 노바텍\n",
      "286750 나노브릭\n",
      "286940 롯데정보통신\n",
      "287410 유안타제3호스팩\n",
      "288330 브릿지바이오테라퓨틱스\n",
      "288620 에스퓨얼셀\n",
      "289010 아이스크림에듀\n",
      "289080 sv인베스트먼트\n",
      "290120 대유에이피\n",
      "290270 휴네시온\n",
      "290380 대유\n",
      "290510 코리아센터\n",
      "290520 신도기연\n",
      "290550 디케이티\n",
      "290650 엘앤씨바이오\n",
      "290660 네오펙트\n",
      "290670 대보마그네틱\n",
      "290690 소룩스\n",
      "290720 푸드나무\n",
      "290740 액트로\n",
      "291230 삼성스팩2호\n",
      "291650 압타머사이언스\n",
      "293480 하나제약\n",
      "293490 카카오게임즈\n",
      "293580 나우IB\n",
      "293780 압타바이오\n",
      "293940 신한알파리츠\n",
      "294090 이오플로우\n",
      "294140 레몬\n",
      "294630 서남\n",
      "294870 HDC현대산업개발\n",
      "297090 씨에스베어링\n",
      "297570 알로이스\n",
      "297890 엘이티\n",
      "298000 효성화학\n",
      "298020 효성티앤씨\n",
      "298040 효성중공업\n",
      "298050 효성첨단소재\n",
      "298060 에스씨엠생명과학\n",
      "298380 에이비엘바이오\n",
      "298540 더네이쳐홀딩스\n",
      "298690 에어부산\n",
      "299030 하나기술\n",
      "299170 더블유에스아이\n",
      "299660 셀리드\n",
      "299900 위지윅스튜디오\n",
      "299910 베스파\n",
      "300080 플리토\n",
      "300120 라온피플\n",
      "300720 한일시멘트\n",
      "301300 바이브컴퍼니\n",
      "302430 이노메트리\n",
      "302550 리메드\n",
      "303030 지니틱스\n",
      "304100 솔트룩스\n",
      "304840 피플바이오\n",
      "305090 마이크로디지탈\n",
      "306040 에스제이그룹\n",
      "306200 세아제강\n",
      "306620 네온테크\n",
      "307070 SK4호스팩\n",
      "307160 하나머스트제6호스팩\n",
      "307180 아이엘사이언스\n",
      "307280 교보8호스팩\n",
      "307750 대신밸런스제6호스팩\n",
      "307870 상상인이안1호스팩\n",
      "307930 컴퍼니케이\n",
      "307950 현대오토에버\n",
      "308100 까스텔바작\n",
      "308170 센트랄모텍\n",
      "309930 오하임아이엔티\n",
      "310200 애니플러스\n",
      "310840 엔에이치스팩13호\n",
      "310870 한국제8호스팩\n",
      "311270 키움제5호스팩\n",
      "311390 네오크레마\n",
      "311690 천랩\n",
      "312610 에이에프더블류\n",
      "313750 유안타제4호스팩\n",
      "313760 윌링스\n",
      "314130 지놈앤컴퍼니\n",
      "316140 우리금융지주\n",
      "317030 케이비17호스팩\n",
      "317120 라닉스\n",
      "317240 TS트릴리온\n",
      "317320 한화에스비아이스팩\n",
      "317330 덕산테코피아\n",
      "317400 자이에스앤디\n",
      "317530 캐리소프트\n",
      "317690 퀀타매트릭스\n",
      "317770 슈프리마아이디\n",
      "317830 에스피시스템스\n",
      "317850 대모\n",
      "317870 엔바이오니아\n",
      "318000 한국바이오젠\n",
      "318010 팜스빌\n",
      "318020 포인트모바일\n",
      "318410 비비씨\n",
      "319400 엔에이치스팩14호\n",
      "319660 피에스케이\n",
      "320000 윈텍\n",
      "321260 유진스팩4호\n",
      "321550 티움바이오\n",
      "322000 현대에너지솔루션\n",
      "322180 티라유텍\n",
      "322510 제이엘케이\n",
      "322780 코퍼스코리아\n",
      "323210 이베스트이안스팩1호\n",
      "323230 엠에프코리아\n",
      "323280 신영스팩5호\n",
      "323940 케이비제18호스팩\n",
      "323990 박셀바이오\n",
      "326030 SK바이오팜\n",
      "327260 메탈라이프\n",
      "328380 미래에셋대우스팩3호\n",
      "329560 상상인이안제2호스팩\n",
      "330350 위더스제약\n",
      "330590 롯데리츠\n",
      "330860 네패스아크\n",
      "330990 케이비제19호스팩\n",
      "331380 유진스팩5호\n",
      "331520 교보9호스팩\n",
      "331920 셀레믹스\n",
      "332290 대신밸런스제7호스팩\n",
      "332370 아이디피\n",
      "332570 와이팜\n",
      "332710 하나금융14호스팩\n",
      "333050 신한제6호스팩\n",
      "333430 미래에셋대우스팩4호\n",
      "334890 이지스밸류리츠\n",
      "335810 프리시젼바이오\n",
      "335870 IBKS제12호스팩\n",
      "335890 비올\n",
      "336060 유안타제5호스팩\n",
      "336260 두산퓨얼셀\n",
      "336370 두산솔루스\n",
      "336570 대신밸런스제8호스팩\n",
      "337450 SK5호스팩\n",
      "337930 브랜드에스코퍼레이션\n",
      "338100 NH프라임리츠\n",
      "339770 교촌에프앤비\n",
      "339950 아이비김영\n",
      "340120 하이제5호스팩\n",
      "340350 SK6호스팩\n",
      "340360 유안타제6호스팩\n",
      "340440 한화플러스제1호스팩\n",
      "340570 티앤엘\n",
      "341160 하나금융15호스팩\n",
      "342550 케이비제20호스팩\n",
      "343510 하나금융16호스팩\n",
      "344050 신영스팩6호\n",
      "344820 케이씨씨글라스\n",
      "347000 센코\n",
      "347140 케이프이에스제4호\n",
      "347740 피엔케이피부임상연구센타\n",
      "347770 핌스\n",
      "347860 알체라\n",
      "347890 엠투아이\n",
      "348030 모비릭스\n",
      "348150 고바이오랩\n",
      "348210 넥스틴\n",
      "348350 위드텍\n",
      "348950 제이알글로벌리츠\n",
      "349720 이베스트스팩5호\n",
      "350520 이지스레지던스리츠\n",
      "351320 IBKS제14호스팩\n",
      "351340 IBKS제13호스팩\n",
      "352700 씨앤투스성진\n",
      "352770 클리노믹스\n",
      "352820 빅히트\n",
      "352940 인바이오\n",
      "353060 에이치엠씨제5호스팩\n",
      "353070 에이치엠씨제4호스팩\n",
      "353190 엔에이치스팩16호\n",
      "353200 대덕전자\n",
      "353490 미래에셋대우스팩5호\n",
      "353810 이지바이오\n",
      "354200 엔젠바이오\n",
      "355150 교보10호스팩\n",
      "356860 티엘비\n",
      "357120 코람코에너지리츠\n",
      "357250 미래에셋맵스리츠\n",
      "357550 석경에이티\n",
      "357780 솔브레인\n",
      "359090 엔에이치스팩17호\n",
      "363280 티와이홀딩스\n",
      "365550 ESR켄달스퀘어리츠\n",
      "365590 엔에이치스팩18호\n",
      "367340 DB금융스팩8호\n",
      "367460 유안타제7호스팩\n",
      "368770 한국9호스팩\n",
      "369370 대신밸런스제9호스팩\n",
      "375500 DL이앤씨\n",
      "900070 글로벌에스엠\n",
      "900080 에스앤씨엔진그룹\n",
      "900100 뉴프라이드\n",
      "900110 이스트아시아홀딩스\n",
      "900120 씨케이에이치\n",
      "900140 엘브이엠씨홀딩스\n",
      "900250 크리스탈신소재\n",
      "900260 로스웰\n",
      "900270 헝셩그룹\n",
      "900280 골든센츄리\n",
      "900290 GRT\n",
      "900300 오가닉티코스메틱\n",
      "900310 컬러레이\n",
      "900340 윙입푸드\n",
      "950110 SBI핀테크솔루션즈\n",
      "950130 엑세스바이오\n",
      "950140 잉글우드랩\n",
      "950160 코오롱티슈진\n",
      "950170 JTC\n",
      "950180 SNK\n",
      "950190 미투젠\n",
      "950200 소마젠(Reg.S)\n"
     ]
    }
   ],
   "source": [
    "## def get_stock_price_from_fdr(end_date=now):  코스피,코스닥 전체종목 입력\n",
    "        \n",
    "file_name = input('파일이름을 입력하세요:')\n",
    "toward = input('저장 방식을 입력하세요 : sample: excel, sql ')\n",
    "start_date = input(\"시작날자를 입려하세요 : sample: '2015-01-01'\")\n",
    "table_name = input(\"table명을 입력하세요 : sample: market\")\n",
    "data=pd.read_excel('d:\\\\'+ file_name)\n",
    "   \n",
    "code_list = data['종목코드'].tolist()\n",
    "code_list = [str(item).zfill(6) for item in code_list]\n",
    "name_list = data['종목명'].tolist()\n",
    "\n",
    "# 코스피 상장종목 전체\n",
    "stock_dic = dict(list(zip(code_list,name_list)))\n",
    "\n",
    "for code in sorted(stock_dic.keys()):\n",
    "    df  = fdr.DataReader(code,start_date,now)\n",
    "    print(code,stock_dic[code])\n",
    "    df['Code'],df['Name'] = code,stock_dic[code]\n",
    "    df = df[['Code','Name','Open','High','Low','Volume','Close']]\n",
    "    if toward == 'excel':\n",
    "        df.to_excel('d:\\\\data_set\\\\kospi\\\\'+ stock_dic[code] +'.xlsx',engine = 'xlsxwriter')\n",
    "    elif toward == 'sql':\n",
    "        df.to_sql(name=table_name, con=engine, if_exists='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#### 신규종목 \n",
    "## insert mysql 개별 주식\n",
    "\n",
    "Code = input('주식 Code를 입력하세요')\n",
    "Name = input('주식이름을 입력하세요')\n",
    "\n",
    "df = fdr.DataReader(Code, '1995')\n",
    "#df.to_excel('d:\\\\'+Code+'.xlsx', encoding='UTF-8')\n",
    "\n",
    "#df = pd.read_excel('d:\\\\'+Code+'.xlsx')\n",
    "df['Code']= Code\n",
    "df['Name']= Name\n",
    "\n",
    "df = df[['Code','Name','Open', 'High', 'Low', 'Volume','Close']]\n",
    "df = df.reset_index().rename(columns={'index':'Date'})\n",
    "\n",
    "df.to_sql(name='market', con=engine, if_exists='append', index = False)\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "주식 Code를 입력하세요163730\n",
      "주식이름을 입력하세요핑거\n"
     ]
    }
   ],
   "source": [
    "#### 기존에 액면분할시 가격조정 안된 기존 data가 있을때\n",
    "## insert mysql 개별 주식\n",
    "\n",
    "\n",
    "Code = input('주식 Code를 입력하세요')\n",
    "Name = input('주식이름을 입력하세요')\n",
    "\n",
    "query = \"delete from  market where Code = \"+\"'\"+Code+\"'\"\n",
    "\n",
    "curs.execute(query)\n",
    "conn.commit()\n",
    "\n",
    "df = fdr.DataReader(Code, '1995')\n",
    "#df.to_excel('d:\\\\'+Code+'.xlsx', encoding='UTF-8')\n",
    "\n",
    "#df = pd.read_excel('d:\\\\'+Code+'.xlsx')\n",
    "df['Code']= Code\n",
    "df['Name']= Name\n",
    "\n",
    "df = df[['Code','Name','Open', 'High', 'Low', 'Volume','Close']]\n",
    "df = df.reset_index().rename(columns={'index':'Date'})\n",
    "\n",
    "df.to_sql(name='market', con=engine, if_exists='append', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "query = \"select distinct Name from market\"\n",
    "\n",
    "df = pd.read_sql(query,con=engine)\n",
    "df.to_excel('f:\\\\aa.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## def excel_to_mysql():\n",
    "\n",
    "file_name = input('파일이름을 입력하세요:')\n",
    "        \n",
    "df=pd.read_excel('d:\\\\'+ file_name)\n",
    "if file_name=='kpi200.xlsx':\n",
    "    df.columns=['Date','kpi200','거래량']\n",
    "    table_name = 'kpi200'\n",
    "    #df = df.set_index('Date')\n",
    "elif file_name=='moneytrend.xlsx':\n",
    "    table_name = 'moneytrend'\n",
    "    df.columns=['Date', '고객예탁금', '신용잔고','주식형펀드','혼합형펀드','채권형펀드']\n",
    "    #df = df.set_index('Date')\n",
    "elif file_name=='kospi_sector.xlsx':\n",
    "    table_name = 'kospi_sector'\n",
    "    df.columns=['Date', 'sectorName', 'changeRate', 'first', 'second']\n",
    "elif file_name=='kosdaq_sector.xlsx':\n",
    "    table_name = 'kosdaq_sector'\n",
    "    df.columns=['Date', 'sectorName', 'changeRate', 'first', 'second']\n",
    "else:\n",
    "    print('\\n file_name error\\n')\n",
    "    \n",
    "df.to_sql(name=table_name, con=engine, if_exists='append', index = False)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  코스피 , 코스닥 누락데이터 입력\n",
    "\n",
    "from mod1 import *\n",
    "\n",
    "kospi_df = pd.read_sql(\"select Date from kospi order by Date desc limit 1\", engine)\n",
    "kospi_df = str(kospi_df['Date'])\n",
    "kospi_date = kospi_df[5:15]\n",
    "\n",
    "kosdaq_df = pd.read_sql(\"select Date from kosdaq order by Date desc limit 1\", engine)\n",
    "kosdaq_df = str(kosdaq_df['Date'])\n",
    "kosdaq_date = kosdaq_df[5:15]\n",
    "\n",
    "\n",
    "start_kospi = datetime.strptime(kospi_date , \"%Y-%m-%d\")\n",
    "kospi_date= (start_kospi + timedelta(days=1)).strftime('%Y%m%d')\n",
    "\n",
    "start_kosdaq = datetime.strptime(kosdaq_date , \"%Y-%m-%d\")\n",
    "kosdaq_date= (start_kosdaq + timedelta(days=1)).strftime('%Y%m%d')\n",
    "\n",
    "\n",
    "df_kospi = get_index_ohlcv_by_date(kospi_date, \"20250228\", \"코스피\")\n",
    "df_kospi.index.names = ['Date']\n",
    "df_kospi.columns  = ['Open','High','Low','Close','Volume']\n",
    "df_kospi['Market']='kospi'\n",
    "df_kospi.to_sql(name='kospi', con=engine, if_exists='append')\n",
    "\n",
    "\n",
    "df_kosdaq = get_index_ohlcv_by_date(kosdaq_date, \"20250228\", \"코스닥\")\n",
    "df_kosdaq.index.names = ['Date']\n",
    "df_kosdaq.columns  = ('Open','High','Low','Close','Volume')\n",
    "df_kosdaq['Market']='kosdaq'\n",
    "df_kosdaq.to_sql(name='kosdaq', con=engine, if_exists='append')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Excel to mysql\n",
    "\n",
    "import FinanceDataReader as fdr\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "from  datetime import datetime\n",
    "\n",
    "engine = sqlalchemy.create_engine('mysql+pymysql://kkang:leaf2027@localhost/stock?charset=utf8',encoding='utf-8')\n",
    "\n",
    "date = input('원하는 날짜를 입력하세요 ')\n",
    "path = 'd:\\\\stockdata\\\\관리종목\\\\'+date+'.xlsx'\n",
    "\n",
    "df = pd.read_excel(path)\n",
    "\n",
    "df.to_sql(name='badstock', con=engine, if_exists='append', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Mysql to Excel\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "connect = create_engine('mysql+pymysql://kkang:leaf2027@localhost/stock?charset=utf8',encoding='utf-8')\n",
    "df = pd.read_sql(\"SELECT distinct Name,Code from market where date = '2019-09-05'\", connect)\n",
    "\n",
    "df.to_excel('d:\\\\sql_market.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### kospi, kosdaq  지수 DB 입력  version_1\n",
    "\n",
    "from mod1 import *\n",
    "\n",
    "df_kospi  = get_index_kospi_ohlcv_by_date(\"20200113\",\"20200120\", \"코스피\")\n",
    "df_kospi.index.names = ['Date']\n",
    "df_kospi.columns  = ('Open','High','Low','Close','Volume')\n",
    "df_kospi['Market']='kospi'\n",
    "df_kospi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### kospi, kosdaq  지수 DB 입력  version_2\n",
    "\n",
    "from mod1 import *\n",
    "\n",
    "df_kospi  = get_index_ohlcv_by_date(\"20200410\",\"20210410\", \"코스피\")\n",
    "df_kospi.index.names = ['Date']\n",
    "df_kospi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### kospi, kosdaq  지수 DB 입력  version_2\n",
    "\n",
    "from mod1 import *\n",
    "\n",
    "df_kospi  = get_index_ohlcv_by_date(\"20200413\",\"20210410\", \"코스피\")\n",
    "df_kospi.index.names = ['Date']\n",
    "df_kospi.columns  = ('Open','High','Low','Close','Volume')\n",
    "df_kospi['Market']='kospi'\n",
    "df_kospi.to_sql(name='kospi', con=engine, if_exists='append')\n",
    "\n",
    "df_kosdaq = get_index_ohlcv_by_date(\"20200413\",\"20210410\", \"코스닥\")\n",
    "df_kosdaq.index.names = ['Date']\n",
    "df_kosdaq.columns  = ('Open','High','Low','Close','Volume')\n",
    "df_kosdaq['Market']='kosdaq'\n",
    "df_kosdaq.to_sql(name='kosdaq', con=engine, if_exists='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### kospi, kosdaq  지수 DB 입력 version_3\n",
    "\n",
    "from mod1 import *\n",
    "\n",
    "kospi_df = pd.read_sql(\"select Date from kospi order by Date desc limit 1\", engine)\n",
    "kospi_df = str(kospi_df['Date'])\n",
    "kospi_date = kospi_df[5:15]\n",
    "\n",
    "kosdaq_df = pd.read_sql(\"select Date from kosdaq order by Date desc limit 1\", engine)\n",
    "kosdaq_df = str(kosdaq_df['Date'])\n",
    "kosdaq_date = kosdaq_df[5:15]\n",
    "\n",
    "\n",
    "start_kospi = datetime.strptime(kospi_date , \"%Y-%m-%d\")\n",
    "kospi_date= (start_kospi + timedelta(days=1)).strftime('%Y%m%d')\n",
    "\n",
    "start_kosdaq = datetime.strptime(kosdaq_date , \"%Y-%m-%d\")\n",
    "kosdaq_date= (start_kosdaq + timedelta(days=1)).strftime('%Y%m%d')\n",
    "\n",
    "\n",
    "df_kospi = get_index_ohlcv_by_date(kospi_date, \"20250228\", \"코스피\")\n",
    "df_kospi.index.names = ['Date']\n",
    "df_kospi.columns  = ('Open','High','Low','Close','Volume')\n",
    "df_kospi['Market']='kospi'\n",
    "df_kospi.to_sql(name='kospi', con=engine, if_exists='append')\n",
    "\n",
    "df_kosdaq = get_index_ohlcv_by_date(kosdaq_date, \"20250228\", \"코스피\")\n",
    "df_kosdaq.index.names = ['Date']\n",
    "df_kosdaq.columns  = ('Open','High','Low','Close','Volume')\n",
    "df_kosdaq['Market']='kosdaq'\n",
    "df_kosdaq.to_sql(name='kosdaq', con=engine, if_exists='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "###  선물크롤링하여 맨처음 DB에 future table생성할때\n",
    "\n",
    "# 2019-09-11 수정  mysql future table에서 최종 날짜를 확인해서 그뒤날부터 insert \n",
    "# 기존 daum 주식 사이트 : ajax 방식으로 변경으로 인해 이를 반영한 코드를 수정.\n",
    "# pip install fake-useragent 설치 후 실행 가능\n",
    "\n",
    "import io\n",
    "import json\n",
    "import sys\n",
    "import pandas as pd\n",
    "import sqlalchemy \n",
    "import urllib.request as req\n",
    "from datetime import datetime\n",
    "from fake_useragent import UserAgent\n",
    "\n",
    "engine = sqlalchemy.create_engine('mysql+pymysql://kkang:leaf2027@localhost/stock?charset=utf8',encoding='utf-8')\n",
    "\n",
    "\n",
    "# Fake Header 정보\n",
    "ua = UserAgent()\n",
    "\n",
    "# 헤더 선언\n",
    "headers = {\n",
    "    'User-Agent': ua.ie,\n",
    "    'referer': 'http://finance.daum.net/domestic/futures'\n",
    "}\n",
    "\n",
    "\n",
    "url = \"http://finance.daum.net/api/future/KR4101Q30005/days?pagination=true&page=1\"\n",
    "res = req.urlopen(req.Request(url, headers=headers)).read().decode('utf-8')\n",
    "\n",
    "df1 = pd.DataFrame()\n",
    "for i in range(1,7):\n",
    "    # 다음 주식 요청 URL\n",
    "    url = \"http://finance.daum.net/api/future/KR4101Q30005/days?pagination=true&page=\"+str(i)\n",
    "\n",
    "    res = req.urlopen(req.Request(url, headers=headers)).read().decode('utf-8')\n",
    "    \n",
    "    rank_json = json.loads(res)['data']\n",
    "    \n",
    "    df = pd.DataFrame(rank_json)\n",
    "    df1 = df1.append(df,ignore_index=True)\n",
    "    \n",
    "df2 = df1[['date','tradePrice','change', 'changePrice','changeRate','unsettledVolume','foreignSettlement', 'institutionSettlement', 'privateSettlement']]\n",
    "df2.columns=('Date','Future','change','가격변동','등락률','미결제약정','외국인','기관','개인')\n",
    "df2['Date'] = pd.to_datetime(df2['Date']).dt.date\n",
    "#df2['Date'] = pd.to_datetime(df2['Date']).apply(lambda x: x.date())\n",
    "#df2['Date'] = pd.to_datetime(df2['Date'], format = '%Y-%m-%d') # yyyy-mm-dd hh:mm:ss -> yyyy-mm-dd (속성은그대로 보여주는 형식만 변경)\n",
    "df2 =df2[['Date','Future','미결제약정','외국인','기관','개인']]\n",
    "#df2 = df2[df2.Date > until_date]\n",
    "df2.to_sql(name='future', con=engine, if_exists='append', index = False)\n",
    "df2 = df2.set_index('Date')\n",
    "df2.to_excel('d:\\\\future.xlsx',encoding='utf-8')\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2019-01-28 수정\n",
    "# 기존 daum 주식 사이트 : ajax 방식으로 변경으로 인해 이를 반영한 코드를 수정.\n",
    "# pip install fake-useragent 설치 후 실행 가능\n",
    "import time\n",
    "import io\n",
    "import json\n",
    "import sys\n",
    "import pandas as pd\n",
    "import urllib.request as req\n",
    "\n",
    "from fake_useragent import UserAgent\n",
    "\n",
    "start = time.time()  # 시작 시간 저장\n",
    "\n",
    "#sys.stdout = io.TextIOWrapper(sys.stdout.detach(), encoding='utf-8')\n",
    "#sys.stderr = io.TextIOWrapper(sys.stderr.detach(), encoding='utf-8')\n",
    "\n",
    "# Fake Header 정보\n",
    "ua = UserAgent()\n",
    "\n",
    "# 헤더 선언\n",
    "headers = {\n",
    "    'User-Agent': ua.ie,\n",
    "    'referer': 'http://finance.daum.net/domestic/all_stocks'\n",
    "}\n",
    "\n",
    "# 다음 주식 요청 URL\n",
    "kospi_sector_url = \"http://finance.daum.net/api/quotes/sectors?fieldName=&order=&perPage=&market=KOSPI&page=&changes=UPPER_LIMIT%2CRISE%2CEVEN%2CFALL%2CLOWER_LIMIT\"\n",
    "kosdaq_sector_url = \"http://finance.daum.net/api/quotes/sectors?fieldName=&order=&perPage=&market=KOSDAQ&page=&changes=UPPER_LIMIT%2CRISE%2CEVEN%2CFALL%2CLOWER_LIMI\"\n",
    "\n",
    "# 요청\n",
    "kospi_sector_res = req.urlopen(req.Request(kospi_sector_url, headers=headers)).read().decode('utf-8')\n",
    "kosdaq_sector_res = req.urlopen(req.Request(kosdaq_sector_url, headers=headers)).read().decode('utf-8')\n",
    "# 응답 데이터 확인(Json Data)\n",
    "# print('res', res)\n",
    "\n",
    "# 응답 데이터 str -> json 변환 및 data 값 저장\n",
    "kospi_sector = json.loads(kospi_sector_res)['data']\n",
    "kosdaq_sector = json.loads(kosdaq_sector_res)['data']\n",
    "# 중간 확인\n",
    "#print('중간 확인 : ', rank_json, '\\n')\n",
    "\n",
    "#for elm in rank_json:\n",
    "    # print(type(elm)) #Type 확인\n",
    "    #print('순위 : {}, 금액 : {}, 회사명 : {}'.format(elm['rank'], elm['tradePrice'], elm['name']), )\n",
    "\n",
    "kospi_sector_df = pd.DataFrame(kospi_sector)\n",
    "kosdaq_sector_df = pd.DataFrame(kosdaq_sector)\n",
    "\n",
    "kospi_name=[]\n",
    "kosdaq_name=[]\n",
    "\n",
    "for i in range(len(kospi_sector_df.index)):\n",
    "    stock_name = [kospi_sector_df['includedStocks'][i][0]['name'],kospi_sector_df['includedStocks'][i][1]['name']]\n",
    "    kospi_name.append(stock_name)\n",
    "kospi_name_df=pd.DataFrame(kospi_name)\n",
    "\n",
    "kospi_sector_df = kospi_sector_df[['date','sectorName','change','changeRate']]\n",
    "kospi_sector_df['changeRate'] = kospi_sector_df['changeRate']*100\n",
    "\n",
    "kospi_sector_df = kospi_sector_df.sort_values(['change','changeRate'], ascending=[False,False])\n",
    "\n",
    "for i in range(len(kosdaq_sector_df.index)):\n",
    "    stock_name = [kosdaq_sector_df['includedStocks'][i][0]['name'],kosdaq_sector_df['includedStocks'][i][1]['name']]\n",
    "    kosdaq_name.append(stock_name)\n",
    "kosdaq_name_df=pd.DataFrame(kosdaq_name)\n",
    "\n",
    "kosdaq_sector_df = kosdaq_sector_df[['date','sectorName','change','changeRate']]\n",
    "kosdaq_sector_df['changeRate'] = kosdaq_sector_df['changeRate']*100\n",
    "\n",
    "\n",
    "kospi_sector_df = kospi_sector_df.join(kospi_name_df)\n",
    "kosdaq_sector_df = kosdaq_sector_df.join(kosdaq_name_df)\n",
    "\n",
    "kospi_sector_df.columns=('date', 'sectorName', 'change', 'changeRate', 'first', 'second')\n",
    "kosdaq_sector_df.columns=('date', 'sectorName', 'change', 'changeRate', 'first', 'second')\n",
    "\n",
    "kosdaq_sector_df = kosdaq_sector_df.sort_values(['change','changeRate'], ascending=[False,False])\n",
    "\n",
    "#display(kospi_sector_df.set_index('date')) \n",
    "#display(kosdaq_sector_df.set_index('date')) \n",
    "\n",
    "\n",
    "##########  업종별시세 column중에 changeRate 'FALL' data를 일관되게 -수치로 바꾸는 code\n",
    " \n",
    "kospi = kospi_sector_df.set_index('change')  ##  index롤 분류하기위한 indeㅌing\n",
    "kosdaq = kosdaq_sector_df.set_index('change')  ##  index롤 분류하기위한 indeㅌing\n",
    "\n",
    "for i in [kospi,kosdaq]:\n",
    "    cols = i.index.difference(['RISE'])      ## cols는 DateFrame이 아닌 change값이 FALL을 가리키는 객체\n",
    "    b = i.loc[cols]\n",
    "    b['changeRate']=i.loc[cols]['changeRate'].mul(-1)\n",
    "    i.loc[cols]=b        ## a change 값이 FALL인 행을 chageRate값을 -로 바꾼 b로 치환   \n",
    "\n",
    "kospi_sector = kospi.set_index('date')\n",
    "kosdaq_sector = kosdaq.set_index('date')\n",
    "kospi_df =  kospi_sector.sort_values([\"changeRate\"],ascending=False)\n",
    "kosdaq_df =  kosdaq_sector.sort_values([\"changeRate\"],ascending=False)\n",
    "\n",
    "\n",
    "kospi_df.to_sql(name='kospi_sector', con=engine, if_exists='append')\n",
    "kosdaq_df.to_sql(name='kosdaq_seotor', con=engine, if_exists='append')\n",
    "print(\"time :\", time.time() - start)  # 현재시각 - 시작시간 = 실행 시간"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kosdaq_sector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###  선물 DB Update할때\n",
    "\n",
    "# 2019-09-11 수정  mysql future table에서 최종 날짜를 확인해서 그뒤날부터 insert \n",
    "# 기존 daum 주식 사이트 : ajax 방식으로 변경으로 인해 이를 반영한 코드를 수정.\n",
    "# pip ainstall fake-useragent 설치 후 실행 가능\n",
    "\n",
    "import io\n",
    "import json\n",
    "import sys\n",
    "import pandas as pd\n",
    "import sqlalchemy \n",
    "import urllib.request as req\n",
    "from datetime import datetime\n",
    "from fake_useragent import UserAgent\n",
    "\n",
    "from datetime import datetime\n",
    "from fake_useragent import UserAgent\n",
    "\n",
    "engine = sqlalchemy.create_engine('mysql+pymysql://kkang:leaf2027@localhost/stock?charset=utf8',encoding='utf-8')\n",
    "future_df = pd.read_sql(\"select Date from future order by Date desc limit 1\", engine)\n",
    "future_df = str(future_df['Date'])\n",
    "until_date = future_df[5:15]\n",
    "\n",
    "year = until_date.split('-')[0]\n",
    "mm = until_date.split('-')[1]\n",
    "dd = until_date.split('-')[2]\n",
    "#year=year[2:]\n",
    "until_date = year+'-'+mm+'-'+dd\n",
    "until_date = datetime.strptime(until_date, '%Y-%m-%d').date() ## str 을  datetime.date로 type 변경\n",
    "\n",
    "# Fake Header 정보\n",
    "ua = UserAgent()\n",
    "\n",
    "# 헤더 선언\n",
    "headers = {\n",
    "    'User-Agent': ua.ie,\n",
    "    'referer': 'http://finance.daum.net/domestic/futures'\n",
    "}\n",
    "\n",
    "\n",
    "url = \"http://finance.daum.net/api/future/KR4101Q60002/days?pagination=true&page=1\"  #KR4011PC002 \"선물 코스피 200지수 12월물\" 코드는 구글검색이용\n",
    "res = req.urlopen(req.Request(url, headers=headers)).read().decode('utf-8')\n",
    "\n",
    "df1 = pd.DataFrame()\n",
    "for i in range(1,3):\n",
    "    # 다음 주식 요청 URL\n",
    "    url = \"http://finance.daum.net/api/future/KR4101Q60002/days?pagination=true&page=\"+str(i)\n",
    "\n",
    "    res = req.urlopen(req.Request(url, headers=headers)).read().decode('utf-8')\n",
    "    \n",
    "    rank_json = json.loads(res)['data']\n",
    "    \n",
    "    df = pd.DataFrame(rank_json)\n",
    "    df1 = df1.append(df,ignore_index=True)\n",
    "df2 = df1[['date','tradePrice','change', 'changePrice','changeRate','unsettledVolume','foreignSettlement', 'institutionSettlement', 'privateSettlement']]\n",
    "df2.columns=('Date','Future','change','가격변동','등락률','미결제약정','외국인','기관','개인')\n",
    "df2['Date'] = pd.to_datetime(df2['Date']).dt.date\n",
    "#df2['Date'] = pd.to_datetime(df2['Date']).apply(lambda x: x.date())\n",
    "#df2['Date'] = pd.to_datetime(df2['Date'], format = '%Y-%m-%d') # yyyy-mm-dd hh:mm:ss -> yyyy-mm-dd (속성은그대로 보여주는 형식만 변경)\n",
    "df2 =df2[['Date','Future','미결제약정','외국인','기관','개인']]\n",
    "df2 = df2[df2.Date > until_date]\n",
    "df2.to_sql(name='future', con=engine, if_exists='append', index = False)\n",
    "df2 = df2.set_index('Date')\n",
    "df2.to_excel('d:\\\\future.xlsx',encoding='utf-8')\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matplotlib를 사용한 Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def option(path=path_volume, day=real_today, graph_start_date='2020-01-01',count=5):\n",
    "    name = pd.read_excel(path_volume+day+'.xlsx')\n",
    "    name = name[:count]\n",
    "    name = name['Name']\n",
    "    #name = name.to_list()\n",
    "    return name,graph_start_date\n",
    "\n",
    "\n",
    "def compare_graph(method):\n",
    "    name, graph_start_date = method\n",
    "    #name = ['hrs','오공','모트렉스']\n",
    "    #name = input('주식이름을 입력하세요:').split()\n",
    "    #date = input(\"날짜를 입력하세요 sample: '2019-01-10': \")\n",
    "\n",
    "    select_query = \"select Date,Close from market where Name= \"\n",
    "    date_query =  \"Date >\"\n",
    "\n",
    "    tuple_name=tuple(name)\n",
    "    df1 = pd.DataFrame()\n",
    "\n",
    "    for x in tuple_name:\n",
    "        var = select_query +\"'\"+x+\"'\"+\" \"+\"&&\"+\" \"+date_query+\"'\"+graph_start_date+\"'\"\n",
    "        df = pd.read_sql(var ,engine) \n",
    "        df.columns=['Date',x]\n",
    "        if df1.empty:\n",
    "            df1 = df\n",
    "        else:\n",
    "            df1 = pd.merge (df,df1,on='Date')\n",
    "    df1=df1.set_index('Date')\n",
    "\n",
    "    plt.figure(figsize=(12,5))\n",
    "\n",
    "    for i in range(len(name)):\n",
    "        plt.plot(df1[name[i]]/df1[name[i]].loc[df['Date'][0]]*100)\n",
    "        plt.legend(name,loc=0)\n",
    "        #plt.legend(loc=0,['hrs','오공','모트렉스'])\n",
    "        plt.grid(True,color='0.7',linestyle=':',linewidth=2)\n",
    "        \n",
    "compare_graph(option(day='2020-10-23'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## 선물  베이시스 graph ( One_graph)\n",
    "## def future_trend_graph():\n",
    "   \n",
    "\n",
    "#query = \"select * from future where Date > '2019-06-13'\"+\"'\"+date+\"'\"\n",
    "query = \"select * from basis where Date > '2019-06-13'\"\n",
    "\n",
    "\n",
    "name=['kpi200','Future']\n",
    "#name=['미결제약정']\n",
    "\n",
    "tuple_name=tuple(name)\n",
    "df1 = pd.DataFrame()\n",
    "    \n",
    "df = pd.read_sql(query ,engine)\n",
    "\n",
    "#df.columns=['Date','kpi200','Close']\n",
    "df = df.set_index('Date')\n",
    "df1=df[name]\n",
    "\n",
    "plt.figure(figsize=(16,4))    \n",
    "for i in range(len(name)):\n",
    "    plt.plot(df1[name[i]]/df1[name[i]].loc[df.index[0]]*100, label=name[i])\n",
    "        \n",
    "#plt.legend(loc=0)\n",
    "plt.legend(loc=0)\n",
    "plt.grid(True,color='0.7',linestyle=':',linewidth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## 선물  베이시스 graph ( One_graph)\n",
    "## def future_trend_graph():\n",
    "   \n",
    "\n",
    "#query = \"select * from future where Date > '2019-06-13'\"+\"'\"+date+\"'\"\n",
    "query = \"select * from future where Date > '2019-06-13'\"\n",
    "\n",
    "\n",
    "name=['Close', '미결제약정', '외국인', '기관', '개인']\n",
    "#name=['미결제약정']\n",
    "\n",
    "tuple_name=tuple(name)\n",
    "df1 = pd.DataFrame()\n",
    "    \n",
    "df = pd.read_sql(query ,engine)\n",
    "\n",
    "df.columns=['Date', 'Close', '미결제약정', '외국인', '기관', '개인']\n",
    "df = df.set_index('Date')\n",
    "df1=df[name]\n",
    "\n",
    "plt.figure(figsize=(16,4))    \n",
    "for i in range(len(name)):\n",
    "    plt.plot(df1[name[i]]/df1[name[i]].loc[df.index[0]]*100)\n",
    "        \n",
    "#plt.legend(loc=0)\n",
    "plt.legend(name)\n",
    "plt.grid(True,color='0.7',linestyle=':',linewidth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## 선물 graph ( One_graph)\n",
    "## def future_trend_graph():\n",
    "    \n",
    "#name = input(\"항목을 입력하세요: 선택항목: 'kpi200', '거래량', '고객예탁금', '신용잔고', '주식형펀드', '혼합형펀드', '채권형펀드'\").split()\n",
    "#date = input(\"날짜를 입력하세요 sample: '2019-01-10':\")\n",
    "    \n",
    "    \n",
    "#query = \"select * from future where Date > '2019-06-13'\"+\"'\"+date+\"'\"\n",
    "query = \"select * from future where Date > '2019-06-13'\"\n",
    "\n",
    "\n",
    "name=['Close', '미결제약정', '외국인', '기관', '개인']\n",
    "#name=['미결제약정']\n",
    "\n",
    "tuple_name=tuple(name)\n",
    "df1 = pd.DataFrame()\n",
    "    \n",
    "df = pd.read_sql(query ,engine)\n",
    "\n",
    "df.columns=['Date', 'Close', '미결제약정', '외국인', '기관', '개인']\n",
    "df = df.set_index('Date')\n",
    "df1=df[name]\n",
    "\n",
    "plt.figure(figsize=(16,4))    \n",
    "for i in range(len(name)):\n",
    "    plt.plot(df1[name[i]]/df1[name[i]].loc[df.index[0]]*100)\n",
    "        \n",
    "plt.legend(name,loc=0)\n",
    "plt.grid(True,color='0.7',linestyle=':',linewidth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## 선물 graph ( Multi_graph)\n",
    "## def future_trend_graph():\n",
    " \n",
    "#name = input(\"항목을 입력하세요: 선택항목: 'kpi200', '거래량', '고객예탁금', '신용잔고', '주식형펀드', '혼합형펀드', '채권형펀드'\").split()\n",
    "#date = input(\"날짜를 입력하세요 sample: '2019-01-10':\")\n",
    "    \n",
    "#query = \"select * from future where Date > '2019-06-13'\"+\"'\"+date+\"'\"\n",
    "query = \"select * from future where Date > '2019-06-11'\"\n",
    "\n",
    "\n",
    "name=['Close', '미결제약정', '외국인', '기관', '개인']\n",
    "name1=['Close','미결제약정']\n",
    "name2=['외국인', '기관', '개인']\n",
    "\n",
    "#tuple_name=tuple(name)\n",
    "df1 = pd.DataFrame()\n",
    "    \n",
    "df = pd.read_sql(query ,engine)\n",
    "\n",
    "df.columns=['Date', 'Close', '미결제약정', '외국인', '기관', '개인']\n",
    "df = df.set_index('Date')\n",
    "df1=df[name]\n",
    "\n",
    "plt.figure(figsize=(16,4))    \n",
    "for i in range(len(name1)):\n",
    "    #plt.subplot(2,2,i+1)\n",
    "    plt.plot(df1[name1[i]]/df1[name1[i]].loc[df.index[0]]*100,color=colors[i])\n",
    "    \n",
    "plt.legend(loc=0)\n",
    "plt.grid(True,color='0.7',linestyle=':',linewidth=1)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(16,4)) \n",
    "for i in range(len(name2)):\n",
    "    plt.subplot(2,2,i+1)\n",
    "    plt.plot(df1[name2[i]]/df1[name2[i]].loc[df.index[0]]*100,color=colors[i])\n",
    "    \n",
    "    plt.legend(loc=0)\n",
    "    plt.grid(True,color='0.7',linestyle=':',linewidth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Close and Volume graph 표준화\n",
    "\n",
    "import FinanceDataReader as fdr\n",
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "engine = sqlalchemy.create_engine('mysql+pymysql://kkang:leaf2027@localhost/stock?charset=utf8',encoding='utf-8')\n",
    "\n",
    "select_query = \"select Date,Volume,Close from market where Name= \"\n",
    "date_query = \"Date > \"\n",
    "\n",
    "def choice(select):\n",
    "    name = '화천기계'\n",
    "    date = '2019-01-01'\n",
    "    if select == 1:\n",
    "        name = input('주식이름을 입력하세요 : ')\n",
    "        date = input('날짜를 입력하세요: ')\n",
    "        var = select_query +\"'\"+name+\"'\"+\" \"+\"&&\"+\" \"+date_query+\"'\"+date+\"'\" \n",
    "        return var\n",
    "    elif select == 2:\n",
    "        var = select_query +\"'\"+name+\"'\"+\" \"+\"&&\"+\" \"+date_query+\"'\"+date+\"'\" \n",
    "        return var\n",
    "\n",
    "select = input('select 1 or 2: ')\n",
    "select = int(select)\n",
    "\n",
    "df = pd.read_sql(choice(select), engine)\n",
    "\n",
    "source = MinMaxScaler()\n",
    "data = source.fit_transform(df[['Close','Volume']].values.astype(float))\n",
    "df1 = pd.DataFrame(data)\n",
    "df1.columns=['Close','Volume']\n",
    "df1 = df1.set_index(df['Date'])\n",
    "df1.plot(figsize=(16,4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Close and Volume graph 표준화 _ 2  종목을 list로 설정\n",
    "\n",
    "import FinanceDataReader as fdr\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "engine = sqlalchemy.create_engine('mysql+pymysql://kkang:leaf2027@localhost/stock?charset=utf8',encoding='utf-8')\n",
    "\n",
    "select_query = \"select Date,Volume,Close from market where Name= \"\n",
    "date_query = \"Date > \"\n",
    "\n",
    "df = pd.read_excel('d:\\\\detect_stock_with_volume.xlsx')\n",
    "df=df['Name']\n",
    "#name = df.values.tolist() ## numpy to list\n",
    "name = df.to_list()              ## DataFrame to list\n",
    "date = '2019-01-01'\n",
    "for i in name:\n",
    "    var = select_query +\"'\"+i+\"'\"+\" \"+\"&&\"+\" \"+date_query+\"'\"+date+\"'\" \n",
    "    df = pd.read_sql(var, engine)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['Close','Volume']].values.astype(float))\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1.columns=['Close','Volume']\n",
    "    df1 = df1.set_index(df['Date'])\n",
    "    df1.plot(figsize=(16,2))\n",
    "    plt.title(i)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Close and Volume graph 표준화-3  이동평균선 포함\n",
    "\n",
    "import talib.abstract as ta\n",
    "import FinanceDataReader as fdr\n",
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "engine = sqlalchemy.create_engine('mysql+pymysql://kkang:leaf2027@localhost/stock?charset=utf8',encoding='utf-8')\n",
    "\n",
    "select_query = \"select * from market where Name= \"\n",
    "date_query = \"Date > \"\n",
    "\n",
    "def choice(select):\n",
    "    name = 'hrs'\n",
    "    date = '2010-01-01'\n",
    "    if select == 1:\n",
    "        name = input('주식이름을 입력하세요 : ')\n",
    "        date = input('날짜를 입력하세요: ')\n",
    "        var = select_query +\"'\"+name+\"'\"+\" \"+\"&&\"+\" \"+date_query+\"'\"+date+\"'\" \n",
    "        return var\n",
    "    elif select == 2:\n",
    "        var = select_query +\"'\"+name+\"'\"+\" \"+\"&&\"+\" \"+date_query+\"'\"+date+\"'\" \n",
    "        return var\n",
    "\n",
    "select = input('select 1 or 2: ')\n",
    "select = int(select)\n",
    "\n",
    "df = pd.read_sql(choice(select), engine)\n",
    "df[['Open','High','Low','Volume','Close']] = df[['Open','High','Low','Volume','Close']].astype(float) #  TA-Lib로 평균을 구하려면 실수로 만들어야 함\n",
    "df.columns=df.columns.str.lower()\n",
    "\n",
    "talib_ma5 = ta.MA(df, timeperiod=5)\n",
    "df['ma5'] = talib_ma5\n",
    "\n",
    "talib_ma120 = ta.MA(df, timeperiod=120)\n",
    "df['ma120'] = talib_ma120\n",
    "\n",
    "source = MinMaxScaler()\n",
    "data = source.fit_transform(df[['close','volume','ma120']].values)\n",
    "df1 = pd.DataFrame(data)\n",
    "df1.columns=['close','ma120','volume']\n",
    "df1 = df1.set_index(df['date'])\n",
    "df1.plot(figsize=(16,4))\n",
    "\n",
    "choice(select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Close and Volume and MA graph 표준화-3  주식 DataFrame에서   종가, 거래걍, 이동평균선을 graph로 그리는 함수 \n",
    "\n",
    "def close_vol_ma(DataFrame,select):\n",
    "\n",
    "    df = DataFrame\n",
    "    df.columns=df.columns.str.lower()\n",
    "    df[['volume','close']] = df[['volume','close']].astype(float) #  TA-Lib로 평균을 구하려면 실수로 만들어야 함\n",
    "\n",
    "    talib_ma5 = ta.MA(df, timeperiod=5)\n",
    "    df['ma5'] = talib_ma5\n",
    "    \n",
    "    talib_ma10 = ta.MA(df, timeperiod=10)\n",
    "    df['ma10'] = talib_ma10    \n",
    "\n",
    "    talib_ma15 = ta.MA(df, timeperiod=15)\n",
    "    df['ma15'] = talib_ma15\n",
    "\n",
    "    talib_ma20 = ta.MA(df, timeperiod=20)\n",
    "    df['ma20'] = talib_ma20\n",
    "    \n",
    "    talib_ma30 = ta.MA(df, timeperiod=30)\n",
    "    df['ma30'] = talib_ma30    \n",
    "    \n",
    "    talib_ma60 = ta.MA(df, timeperiod=60)\n",
    "    df['ma60'] = talib_ma60    \n",
    "    \n",
    "    talib_ma120 = ta.MA(df, timeperiod=120)\n",
    "    df['ma120'] = talib_ma120    \n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close',select,'volume']].values)\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1.columns=['close',select,'volume']\n",
    "    df1 = df1.set_index(df['date'])\n",
    "    df1.plot(figsize=(16,4))\n",
    "close_vol_ma(df,select='ma20')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## def stock_select_with_Volume_Close():\n",
    "    \n",
    "yesterday = input(\"어제날짜를 입력하세요 : sample: '2019-02-07 00:00:00'  \") \n",
    "today = input(\"오늘날짜를 입력하세요 : sample: '2019-02-07 00:00:00'  \")\n",
    "    \n",
    "select_query = \"select * from market where Date >=\"\n",
    "volume_query = \"&& Volume >  500000\"\n",
    "    \n",
    "var = select_query +\"'\"+yesterday+\"'\"+ volume_query\n",
    "df = pd.read_sql(var ,engine)\n",
    "\n",
    "df1 = df[df['Date'].astype(str) == yesterday]\n",
    "df1 = df1[['Name','Volume','Close']]\n",
    "df1.columns = ['Name','yester_Volume','yester_Close']\n",
    "#display(df1)\n",
    "\n",
    "df2 = df[df['Date'].astype(str) == today]\n",
    "df2 = df2[['Name','Volume','Close']]\n",
    "df2.columns = ['Name','today_Volume','today_Close']\n",
    "#display(df2)\n",
    "\n",
    "df3 = pd.merge(df1,df2,on='Name')\n",
    "df3['Close']=df3['today_Close']/df3['yester_Close']\n",
    "df3['Volume']=df3['today_Volume']/df3['yester_Volume']\n",
    "df3 = df3.sort_values(by=['Volume','Close'],ascending=False)\n",
    "df3 = df3.reset_index(drop=True)\n",
    "df3 = df3[:10]\n",
    "df4 = df3.sort_values(by=['Close','Volume'],ascending=False)\n",
    "df4 = df4.reset_index(drop=True)\n",
    "df4 = df4[:10]\n",
    "display(df3)\n",
    "display(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## def stock_price_graph():\n",
    "    \n",
    "name = input('주식이름을 입력하세요:').split()\n",
    "date = input(\"날짜를 입력하세요 sample: '2019-01-10': \")\n",
    "\n",
    "select_query = \"select Date,Close from market where Name= \"\n",
    "date_query =  \"Date >\"\n",
    "\n",
    "tuple_name=tuple(name)\n",
    "df1 = pd.DataFrame()\n",
    "\n",
    "for x in tuple_name:\n",
    "    var = select_query +\"'\"+x+\"'\"+\" \"+\"&&\"+\" \"+date_query+\"'\"+date+\"'\"\n",
    "    df = pd.read_sql(var ,engine) \n",
    "    df.columns=['Date',x]\n",
    "    if df1.empty:\n",
    "        df1 = df\n",
    "    else:\n",
    "        df1 = pd.merge (df,df1,on='Date')\n",
    "df1=df1.set_index('Date')\n",
    "    \n",
    "plt.figure(figsize=(12,5))\n",
    "    \n",
    "for i in range(len(name)):\n",
    "    plt.plot(df1[name[i]]/df1[name[i]].loc[df['Date'][0]]*100)\n",
    "        \n",
    "plt.legend(loc=0)\n",
    "plt.grid(True,color='0.7',linestyle=':',linewidth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def stock_price_graph():  여러개 입력가능\n",
    "    \n",
    "## def stock_price_graph():\n",
    "    \n",
    "name = input('주식이름을 입력하세요:').split(',')\n",
    "date = input(\"날짜를 입력하세요 sample: '2019-01-10':\")\n",
    "        \n",
    "select_query = \"select Date,Close from market where Name= \"\n",
    "date_query = \"Date > \"\n",
    "    \n",
    "\n",
    "tuple_name=tuple(name)\n",
    "df1 = pd.DataFrame()\n",
    "    \n",
    "for x in tuple_name:\n",
    "    var = select_query +\"'\"+x+\"'\"+\" \"+\"&&\"+\" \"+date_query+\"'\"+date+\"'\"\n",
    "    df = pd.read_sql(var ,engine)\n",
    "    df.columns=['Date',x]\n",
    "    if df1.empty:\n",
    "        df1 = df\n",
    "    else:\n",
    "        df1 = pd.merge (df,df1,on='Date')\n",
    "df1=df1.set_index('Date')\n",
    "    \n",
    "plt.figure(figsize=(12,5))\n",
    "    \n",
    "for i in range(len(name)):\n",
    "    plt.plot(df1[name[i]]/df1[name[i]].loc[df['Date'][0]]*100)\n",
    "        \n",
    "plt.legend(name,loc=0)\n",
    "plt.grid(True,color='0.7',linestyle=':',linewidth=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def stock_price_graph():  여러개 입력가능\n",
    "    \n",
    "## def stock_price_graph():\n",
    "    \n",
    "name = input('주식이름을 입력하세요:').split(',')\n",
    "date = input(\"날짜를 입력하세요 sample: '2019-01-10':\")\n",
    "        \n",
    "select_query = \"select Date,Close from market where Name= \"\n",
    "date_query = \"Date > \"\n",
    "    \n",
    "\n",
    "tuple_name=tuple(name)\n",
    "df1 = pd.DataFrame()\n",
    "    \n",
    "for x in tuple_name:\n",
    "    var = select_query +\"'\"+x+\"'\"+\" \"+\"&&\"+\" \"+date_query+\"'\"+date+\"'\"\n",
    "    df = pd.read_sql(var ,engine)\n",
    "    df.columns=['Date',x]\n",
    "    if df1.empty:\n",
    "        df1 = df\n",
    "    else:\n",
    "        df1 = pd.merge (df,df1,on='Date')\n",
    "df1=df1.set_index('Date')\n",
    "    \n",
    "plt.figure(figsize=(12,5))\n",
    "    \n",
    "for i in range(len(name)):\n",
    "    plt.plot(df1[name[i]]/df1[name[i]].loc[df['Date'][0]]*100)\n",
    "        \n",
    "plt.legend(name,loc=0)\n",
    "plt.grid(True,color='0.7',linestyle=':',linewidth=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def stock_volume and price_graph():  여러개 입력가능\n",
    "\n",
    "import io\n",
    "import json\n",
    "import sys\n",
    "from fake_useragent import UserAgent\n",
    "import FinanceDataReader as fdr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime as dt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from datetime import datetime,timedelta\n",
    "from urllib.request import urlopen\n",
    "import urllib.request as req\n",
    "import sqlalchemy \n",
    "import pymysql\n",
    "import talib.abstract as ta\n",
    "from talib import RSI, BBANDS\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "from matplotlib import font_manager, rc\n",
    "plt.rcParams.update({'figure.max_open_warning': 0})\n",
    "font_name = font_manager.FontProperties(fname=\"c:/Windows/Fonts/malgun.ttf\").get_name()\n",
    "rc('font', family=font_name)\n",
    "\n",
    "today = datetime.now()\n",
    "real_yesterday = (today-timedelta(1)).strftime('%Y-%m-%d')\n",
    "real_today = today.strftime('%Y-%m-%d')\n",
    "date_list = ['2008-01-01','2013-01-01','2018-01-01','2019-01-01']\n",
    "\n",
    "now = dt.datetime.today().strftime('%Y-%m-%d')\n",
    "engine = sqlalchemy.create_engine('mysql+pymysql://kkang:leaf2027@localhost/stock?charset=utf8',encoding='utf-8')\n",
    "conn = pymysql.connect(host = 'localhost', user = 'kkang', password = 'leaf2027' ,db = 'stock')\n",
    "curs = conn.cursor()\n",
    "\n",
    "path_price = 'd:\\\\stockdata\\\\vote_stock\\\\detect_stock_with_price_'\n",
    "path_volume = 'd:\\\\stockdata\\\\vote_stock\\\\detect_stock_with_volume_'\n",
    "path = 'd:\\\\stockdata\\\\close_ma120\\\\close_ma120_'\n",
    "path_total = 'd:\\\\stockdata\\\\close_ma120\\\\total_'\n",
    "path_total_f = 'd:\\\\stockdata\\\\close_ma120\\\\total_filter_'\n",
    "path_total_a = 'd:\\\\stockdata\\\\close_ma120\\\\total_a_'\n",
    "path_total_b = 'd:\\\\stockdata\\\\close_ma120\\\\total_b_'\n",
    "path_total_c = 'd:\\\\stockdata\\\\close_ma120\\\\total_c_'\n",
    "\n",
    "def select_market(name,date):\n",
    "    select_query = \"select * from \"\n",
    "    date_query = \" where Date > \"    \n",
    "    var = select_query + name + date_query+\"'\"+date+\"'\" \n",
    "    df = pd.read_sql(var, engine)\n",
    "    return df\n",
    "\n",
    "def min_max(df,select):\n",
    "    ma(df)\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close',select,'volume']].values)\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1.columns=['close',select,'volume']\n",
    "    df1 = df1.set_index(df['date'])\n",
    "    return df1\n",
    "\n",
    "def ma(DataFrame):\n",
    "    df = DataFrame\n",
    "    df.columns=df.columns.str.lower()\n",
    "    df[['volume','close']] = df[['volume','close']].astype(float) #  TA-Lib로 평균을 구하려면 실수로 만들어야 함\n",
    "\n",
    "    talib_ma5 = ta.MA(df, timeperiod=5)\n",
    "    df['ma5'] = talib_ma5\n",
    "    \n",
    "    talib_ma10 = ta.MA(df, timeperiod=10)\n",
    "    df['ma10'] = talib_ma10    \n",
    "\n",
    "    talib_ma15 = ta.MA(df, timeperiod=15)\n",
    "    df['ma15'] = talib_ma15\n",
    "\n",
    "    talib_ma20 = ta.MA(df, timeperiod=20)\n",
    "    df['ma20'] = talib_ma20\n",
    "    \n",
    "    talib_ma30 = ta.MA(df, timeperiod=30)\n",
    "    df['ma30'] = talib_ma30    \n",
    "    \n",
    "    talib_ma60 = ta.MA(df, timeperiod=60)\n",
    "    df['ma60'] = talib_ma60    \n",
    "    \n",
    "    talib_ma120 = ta.MA(df, timeperiod=120)\n",
    "    df['ma120'] = talib_ma120  \n",
    "\n",
    "    \n",
    "def market_ma(df,select1,select2):\n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close',select1,select2]].values)\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1.columns=['close',select1,select2]\n",
    "    df1 = df1.set_index(df['date'])\n",
    "    df1.plot(figsize=(16,4))\n",
    "    plt.title(df['market'][0])\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def get_graph(choice=1):\n",
    "    graph_name_list=['stock','money', 'program','future']\n",
    "    date='2018-01-01'\n",
    "    future_date='2019-12-11'  ##  선물마감 하루전\n",
    "    if choice == 1:\n",
    "        df = select_market('kospi','2015-01-01')\n",
    "        market_ma(df,'ma60','ma120')\n",
    "        df = select_market('kosdaq','2015-01-01')\n",
    "        market_ma(df,'ma60','ma120')\n",
    "      \n",
    "        kpi200_df = pd.read_sql(\"select Date from kpi200 order by Date desc limit 2\", engine)\n",
    "        yesterday = str(kpi200_df['Date'][1])\n",
    "        today = str(kpi200_df['Date'][0])\n",
    "        \n",
    "      \n",
    "        for i in graph_name_list:\n",
    "            if i == 'stock' :\n",
    "                name = pd.read_excel(path_volume+today+'.xlsx', encoding='utf-8')\n",
    "                name_all = name['Name']\n",
    "                name_all = name_all.to_list()\n",
    "                \n",
    "                name = name['Name']\n",
    "                name = name[0:2]\n",
    "                name = name.to_list()\n",
    "                print(name)\n",
    "\n",
    "                select_query = \"select Date,Volume,Close from market where Name= \"\n",
    "                date_query = \"Date > \"\n",
    "\n",
    "\n",
    "                tuple_name=tuple(name)\n",
    "                df1 = pd.DataFrame()\n",
    "\n",
    "                for x in tuple_name:\n",
    "                    var = select_query +\"'\"+x+\"'\"+\" \"+\"&&\"+\" \"+date_query+\"'\"+date+\"'\"\n",
    "                    df = pd.read_sql(var ,engine)\n",
    "                    df.columns=['Date',x+'거래량',x]\n",
    "                    if df1.empty:\n",
    "                        df1 = df\n",
    "                    else:\n",
    "                        df1 = pd.merge (df,df1,on='Date')\n",
    "                df1=df1.set_index('Date')\n",
    "                size = len(df1.index)\n",
    "\n",
    "\n",
    "                plt.figure(figsize=(16,4)) \n",
    "                for i in range(len(name)):\n",
    "                    plt.plot(df1[name[i]]/df1[name[i]].loc[df['Date'][0]]*100,label=name[i])\n",
    "                    plt.legend(loc=0)\n",
    "                    plt.grid(True,color='0.7',linestyle=':',linewidth=1)\n",
    "\n",
    "                plt.figure(figsize=(16,4))\n",
    "                for i in range(len(name)):\n",
    "                    volume_average = df1[name[i]+'거래량'].sum(axis=0)/size\n",
    "                    plt.plot(df1[name[i]+'거래량']/volume_average, label=name[i])\n",
    "                    #plt.plot(df1[name[i]+'거래량']/df1[name[i]+'거래량'].loc[df['Date'][0]]*100, label =[name[i]+'거래량'] )\n",
    "                    plt.legend(loc=0)\n",
    "                    plt.grid(True,color='0.7',linestyle=':',linewidth=1)  \n",
    "\n",
    "get_graph(choice=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## def money_trend_graph():\n",
    "    \n",
    "name = input(\"항목을 입력하세요: 선택항목: 'kpi200', '거래량', '고객예탁금', '신용잔고', '주식형펀드', '혼합형펀드', '채권형펀드'\").split()\n",
    "date = input(\"날짜를 입력하세요 sample: '2019-01-10':\")\n",
    "    \n",
    "query = \"select * from kpi_with_money where Date >\"+\"'\"+date+\"'\"\n",
    "    \n",
    "tuple_name=tuple(name)\n",
    "df1 = pd.DataFrame()\n",
    "    \n",
    "df = pd.read_sql(query ,engine)\n",
    "\n",
    "df.columns=['Date','kpi200', '거래량', '고객예탁금', '신용잔고', '주식형펀드', '혼합형펀드', '채권형펀드']\n",
    "df = df.set_index('Date')\n",
    "df1=df[name]\n",
    "\n",
    "\n",
    "for i in range(len(name)):\n",
    "    plt.plot(df1[name[i]]/df1[name[i]].loc[df.index[0]]*100)\n",
    "        \n",
    "plt.legend(loc=0)\n",
    "plt.grid(True,color='0.7',linestyle=':',linewidth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## def money_trend_graph():\n",
    "    \n",
    "name = input(\"항목을 입력하세요: 선택항목: 'kpi200', '거래량', '고객예탁금', '신용잔고', '주식형펀드', '혼합형펀드', '채권형펀드'\").split()\n",
    "date = input(\"날짜를 입력하세요 sample: '2019-01-10':\")\n",
    "    \n",
    "query = \"select * from kpi_with_money where Date >\"+\"'\"+date+\"'\"\n",
    "    \n",
    "tuple_name=tuple(name)\n",
    "df1 = pd.DataFrame()\n",
    "    \n",
    "df = pd.read_sql(query ,engine)\n",
    "\n",
    "df.columns=['Date','kpi200', '거래량', '고객예탁금', '신용잔고', '주식형펀드', '혼합형펀드', '채권형펀드']\n",
    "df = df.set_index('Date')\n",
    "df1=df[name]\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "for i in range(len(name)):\n",
    "    plt.plot(df1[name[i]]/df1[name[i]].loc[df.index[0]]*100)\n",
    "        \n",
    "plt.legend(loc=0)\n",
    "plt.grid(True,color='0.7',linestyle=':',linewidth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## def money_trend_graph():  integrate graph\n",
    "    \n",
    "name = input(\"항목을 입력하세요: 선택항목: 'kpi200', '거래량', '고객예탁금', '신용잔고', '주식형펀드', '혼합형펀드', '채권형펀드'\").split()\n",
    "date = input(\"날짜를 입력하세요 sample: '2019-01-10':\")\n",
    "    \n",
    "query = \"select * from kpi_with_money where Date >\"+\"'\"+date+\"'\"\n",
    "    \n",
    "tuple_name=tuple(name)\n",
    "df1 = pd.DataFrame()\n",
    "    \n",
    "df = pd.read_sql(query ,engine)\n",
    "\n",
    "df.columns=['Date','kpi200', '거래량', '고객예탁금', '신용잔고', '주식형펀드', '혼합형펀드', '채권형펀드']\n",
    "df = df.set_index('Date')\n",
    "df1=df[name]\n",
    "\n",
    "plt.figure(figsize=(16,4))\n",
    "colors = ['red','green','blue','pink','gray']\n",
    "for i in range(len(name)):\n",
    "    plt.subplot(2,2,i+1)\n",
    "    plt.plot(df1[name[i]]/df1[name[i]].loc[df.index[0]]*100,color=colors[i])\n",
    "    \n",
    "    plt.legend(loc=0)\n",
    "    plt.grid(True,color='0.7',linestyle=':',linewidth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 엑셀에서 종목별로 다양한 graph 출력\n",
    "\n",
    "from mod1 import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "\n",
    "def close_ma(df,select1,select2):\n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close',select1,select2]].values)\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1.columns=['close',select1,select2]\n",
    "    df1 = df1.set_index(df['date'])\n",
    "    df1.plot(figsize=(16,4))\n",
    "    plt.title(df['name'][0])\n",
    "    plt.show()\n",
    "\n",
    "def close_ma_vol(df,select1,select2,select3):\n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close',select1,select2,select3]].values)\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1.columns=['close',select1,select2,select3]\n",
    "    df1 = df1.set_index(df['date'])\n",
    "    df1.plot(figsize=(16,4))\n",
    "    plt.title(df['name'][0])\n",
    "    plt.show()    \n",
    "    \n",
    "    \n",
    "path = 'd:\\\\stockdata\\\\close_ma120\\\\close_ma120_'\n",
    "path_total_f = 'd:\\\\stockdata\\\\close_ma120\\\\total_filter_'\n",
    "\n",
    "choice_date='2019-10-01'\n",
    "#df = pd.read_excel(path_total_f+choice_date+'.xlsx')\n",
    "df = pd.read_excel('d:\\\\stockdata\\\\close_ma120\\\\2019_10\\\\total_2019-10-01.xlsx')\n",
    "name_df = df['name']\n",
    "name = name_df.to_list()\n",
    "#name=['hrs','디엔에프','푸드나무','에스퓨얼셀']\n",
    "\n",
    "for i in name:\n",
    "    df = select_stock(i, '2019-10-01')\n",
    "    #close_ma_vol(df,'ma60','ma120','volume')\n",
    "    close_ma(df,'ma5','ma10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## analysis graph (rsi, obv, ma60, ma120, volume)\n",
    "\n",
    "from mod1 import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "\n",
    "def close_ma(df,select1,select2):\n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close',select1,select2]].values)\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1.columns=['close',select1,select2]\n",
    "    df1 = df1.set_index(df['date'])\n",
    "    df1.iloc[14:].plot(grid=True,figsize=(16,4));\n",
    "    plt.title(df['name'][0])\n",
    "    plt.show()\n",
    "\n",
    "def close_ma_vol(df,select1,select2,select3):\n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close',select1,select2,select3]].values)\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1.columns=['close',select1,select2,select3]\n",
    "    df1 = df1.set_index(df['date'])\n",
    "    df1.iloc[14:].plot(grid=True,figsize=(16,4));\n",
    "    plt.title(df['name'][0])\n",
    "    plt.show()    \n",
    "    \n",
    "def rsi(df):\n",
    "    df = df.set_index('date')\n",
    "    talib_rsi = ta.RSI(df, timeperiod=14)\n",
    "    talib_rsi.iloc[14:].plot( grid=True,figsize=(16,4))\n",
    "    plt.fill_between(df.index,y1=30, y2=70, color='#adccff', alpha='0.3')\n",
    "    plt.show()\n",
    "    \n",
    "def obv(df):\n",
    "    df = df.set_index('date')\n",
    "    real = ta.OBV(df)\n",
    "    real.iloc[14:].plot( y=['volume'], grid=True,figsize=(16,4));\n",
    "    plt.show()\n",
    "    \n",
    "name = ['서원','hrs']   \n",
    "for i in name:\n",
    "    df = select_stock(i,'2016-04-01')\n",
    "    close_ma(df,'ma60','ma120')\n",
    "    rsi(df)\n",
    "    obv(df)\n",
    "    close_ma_vol(df,'ma60','ma120','volume')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Crawling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 상장회사 종가확인\n",
    "# 브라우저 실행\n",
    "from selenium import webdriver\n",
    "driver = webdriver.Chrome('C:/Users/kkang/selenium/chromedriver.exe')\n",
    "\n",
    "# 상장회사검색\n",
    "driver.get('http://marketdata.krx.co.kr/mdi#document=040602')\n",
    "\n",
    "# 다운로드 버튼을 클릭\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "button = driver.find_element(By.XPATH, '//button[text()=\"Excel\"]')\n",
    "button.click()\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "# 다운로드 폴더로 이동\n",
    "folder = 'c:\\\\Users\\\\kkang\\\\Downloads'\n",
    "os.chdir(folder)\n",
    "\n",
    "# 파일 다운로드까지 대기 (1초씩 최대 30회)\n",
    "fname = 'data.xls'\n",
    "for _ in range(30):\n",
    "    if os.path.exists(fname):\n",
    "        break\n",
    "    time.sleep(1)\n",
    "\n",
    "# 파일명 바꾸기\n",
    "os.rename('data.xls', 'price.xls')\n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 일별 관리종목 추출\n",
    "\n",
    "from mod1 import *\n",
    "\n",
    "today = datetime.now()\n",
    "today = today.strftime(\"%Y-%m-%d\")\n",
    "#today=input('입력')\n",
    "#url = 'http://finance.naver.com/sise/investorDealTrendDay.nhn?bizdate=2020601&sosok=&page=1'\n",
    "url = 'https://finance.naver.com/sise/management.nhn'\n",
    "source = urlopen(url).read()   # 지정한 페이지에서 코드 읽기\n",
    "source = BeautifulSoup(source, 'lxml')   # 뷰티풀 스프로 태그별로 코드 분류\n",
    "data = []\n",
    "\n",
    "path = 'f:\\\\stockdata\\\\관리종목\\\\'+today+'.xlsx'\n",
    "body = source.find('body')\n",
    "trs = body.find_all('tr')\n",
    "name = []\n",
    "for tr in trs:\n",
    "    tds = tr.find_all('a',{'class':\"tltle\"})\n",
    "    for td in tds:\n",
    "        name.append(td.text.strip())\n",
    "\n",
    "df = pd.DataFrame(name)\n",
    "df['Date']=str(today)\n",
    "df = df.set_index('Date')\n",
    "df.columns=['Name']\n",
    "df.to_excel(path)\n",
    "df = pd.read_excel(path)\n",
    "df.to_sql(name='badstock', con=engine, if_exists='append', index = False)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### pykrx 모듈을 통한 krx 웹 crawling\n",
    "\n",
    "from pykrx.comm.util import dataframe_empty_handler, singleton\n",
    "from pykrx.comm.http import KrxHttp\n",
    "from pandas import DataFrame\n",
    "import pandas as pd\n",
    "from pykrx import stock\n",
    "\n",
    "a = stock.market.ticker._StockFinder()\n",
    "b = stock.market.ticker._StockTicker()\n",
    "df_a = a.read()\n",
    "df_b = b._get_stock_info_listed()\n",
    "df_finder_kosdaq = df_a[df_a['marketName']=='KOSDAQ']\n",
    "df_finder_kospi = df_a[df_a['marketName']=='KOSPI']\n",
    "#display(df_kosdaq.reset_index(drop=True))\n",
    "#display(df_kospi.reset_index(drop=True))\n",
    "\n",
    "df_ticker_kosdaq = df_b[df_b['시장']=='KOSDAQ']\n",
    "df_ticker_kospi = df_b[df_b['시장']=='KOSPI']\n",
    "\n",
    "df_finder_kosdaq.to_excel('f:\\\\find_kosdaq.xlsx')\n",
    "df_finder_kospi.to_excel('f:\\\\find_kospi.xlsx')\n",
    "df_ticker_kosdaq.to_excel('f:\\\\tick_kosdaq.xlsx')\n",
    "df_ticker_kospi.to_excel('f:\\\\tick_kospi.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock Prediction 관련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  상승추세 종목 발굴 _1\n",
    "\n",
    "## market_good table에서 모든 colume 추출\n",
    "def market_stock(date):\n",
    "    select_query = \"select * from market_good where Date >  \"\n",
    "    var = select_query +\"'\"+date+\"'\" \n",
    "    df = pd.read_sql(var, engine)\n",
    "    return df\n",
    "\n",
    "from mod1 import *\n",
    "\n",
    "## 개별종목이름 리스트 생성\n",
    "df = market_stock('2019-01-01')\n",
    "stock_name=df['Name'].drop_duplicates()\n",
    "stock_name = stock_name.tolist()\n",
    "\n",
    "## 종목별로 이동평균선(ma5 ~ ma120)생성\n",
    "ma_df = pd.DataFrame()\n",
    "for name in stock_name:\n",
    "    print(name)\n",
    "    df1 = df[(df['Name'] == name)]\n",
    "    ma(df1)\n",
    "    ma_df=ma_df.append(df1)\n",
    "    \n",
    "#df3.to_excel('d:\\\\good_stock.xlsx')\n",
    "\n",
    "##  현재 today 종가가 ma120일선 위에있는 (상승추세에있는) 종목 추출\n",
    "df1 = ma_df[['date','code','name','close','volume','ma120']]\n",
    "df2 = df1[(df1['date'].astype(str) == '2019-09-30')]\n",
    "df3 = df2[(df2['close'] >= df2['ma120'])]\n",
    "df3\n",
    "\n",
    "## 상승추세종목 리스트 생성\n",
    "good_name=df3['name']\n",
    "good_name = good_name.tolist()\n",
    "\n",
    "## 상승추세 종목 그래프 생성 \n",
    "for i in good_name:\n",
    "    df=select_stock(i,'17-01-01')\n",
    "    df1 = close_vol_ma(df,'ma120')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  상승추세 종목 발굴 _2\n",
    "##  상승추세종목을 표준화하여 세부적으로 추출\n",
    "\n",
    "from mod1 import *\n",
    "\n",
    "## 개별종목이름 리스트 생성\n",
    "all_df = market_stock('2019-01-01')\n",
    "stock_name=all_df['Name'].drop_duplicates()\n",
    "stock_name = stock_name.tolist()\n",
    "\n",
    "## 종목별로 이동평균선(ma5 ~ ma120)생성\n",
    "ma_df = pd.DataFrame()\n",
    "min_max_df = pd.DataFrame()\n",
    "for name in stock_name:\n",
    "    print(name)\n",
    "    all_df1 = all_df[(all_df['Name'] == name)]\n",
    "    ma(all_df1)\n",
    "    ma_df=ma_df.append(all_df1)\n",
    "    \n",
    "#df3.to_excel('d:\\\\good_stock.xlsx')\n",
    "\n",
    "##  현재 today 종가가 ma120일선 위에있는 (상승추세에있는) 종목 추출\n",
    "first_df1 = ma_df[['date','code','name','close','volume','ma120']]\n",
    "first_df2 = first_df1[(first_df1['date'].astype(str) == '2019-09-30')]\n",
    "first_df3 = first_df2[(first_df2['close'] >= first_df2['ma120'])]\n",
    "first_df3\n",
    "\n",
    "## 상승추세종목 리스트 생성\n",
    "good_name=first_df3['name']\n",
    "good_name = good_name.tolist()\n",
    "\n",
    "## 상승추세종목별로 표준화 (MinMaxSchalr)생성\n",
    "good_stock_df = pd.DataFrame()\n",
    "min_max_df = pd.DataFrame()\n",
    "for name in good_name:\n",
    "    print(name)\n",
    "    good_df1 = select_stock(name,'2019-01-01')\n",
    "    good_stock_df=good_stock_df.append(good_df1)\n",
    "    min_max_df1 = min_max(good_df1,'ma120')\n",
    "    min_max_df=min_max_df.append(min_max_df1)\n",
    "\n",
    "good_stock_df1 = good_stock_df.set_index('Date')\n",
    "min_max_df[['code','name']]=good_stock_df1[['Code','Name']]\n",
    "\n",
    "second_df1 = min_max_df\n",
    "second_df2 = second_df1[(second_df1.index.astype(str) == real_yesterday)]\n",
    "second_df3 = second_df2[(second_df2['close'] <= 0.3) & (second_df2['ma120'] <=0.3)]\n",
    "second_df3\n",
    "\n",
    "## 표준화로 선별한 상승추세종목 리스트 생성\n",
    "min_max_name=second_df3['name']\n",
    "min_max_name = min_max_name.tolist()\n",
    "\n",
    "## 표준화로 선별한 추세 종목 그래프 생성 \n",
    "for i in min_max_name:\n",
    "    all_df=select_stock(i,'17-01-01')\n",
    "    all_df1 = close_vol_ma(all_df,'ma120')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  상승추세 종목 발굴 _3\n",
    "##  상승추세종목을 표준화 함수를 통합하여  속도 향상\n",
    "\n",
    "from mod1 import *\n",
    "\n",
    "all_df = market_stock('2019-10-01')\n",
    "stock_name=all_df['Name'].drop_duplicates()\n",
    "stock_name = stock_name.tolist()\n",
    "\n",
    "## 상승추세종목별로 표준화 (MinMaxSchalr)생성\n",
    "good_stock_df = pd.DataFrame()\n",
    "min_max_df = pd.DataFrame()\n",
    "\n",
    "for name in stock_name:\n",
    "    print(name)\n",
    "    good_df1 = select_stock(name,'2017-01-01')\n",
    "    min_max_df1 = min_max(good_df1,'ma120')\n",
    "    good_stock_df=good_stock_df.append(good_df1)\n",
    "    min_max_df=min_max_df.append(min_max_df1)\n",
    "\n",
    " \n",
    "good_stock_df1 = good_stock_df.set_index('date')\n",
    "min_max_df[['code','name']]=good_stock_df1[['code','name']]\n",
    " \n",
    "second_df1 = min_max_df\n",
    "second_df2 = second_df1[(second_df1.index.astype(str) == '2019-10-02')]\n",
    "second_df3 = second_df2[(second_df2['close'] <= 0.05)]\n",
    "second_df3\n",
    "\n",
    "## 표준화로 선별한 상승추세종목 리스트 생성\n",
    "min_max_name=second_df3['name']\n",
    "min_max_name = min_max_name.tolist()\n",
    "\n",
    "## 표준화로 선별한 추세 종목 그래프 생성 \n",
    "for i in min_max_name:\n",
    "    all_df=select_stock(i,'17-01-01')\n",
    "    all_df1 = close_vol_ma(all_df,'ma120')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Stock Prediction 30 days\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from tqdm import tqdm\n",
    "sns.set()\n",
    "tf.set_random_seed(777)  # reproducibility\n",
    "tf.reset_default_graph()\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter('ignore')\n",
    "\n",
    "import sqlalchemy\n",
    "\n",
    "engine = sqlalchemy.create_engine('mysql+pymysql://kkang:leaf2027@localhost/stock?charset=utf8',encoding='utf-8')\n",
    "var =\"select * from market where Name='HRS' and  Date > '2019-01-01'\" \n",
    "df = pd.read_sql(var ,engine)\n",
    "df.head()\n",
    "\n",
    "minmax = MinMaxScaler().fit(df.iloc[:, 7:].astype('float32')) # Close index\n",
    "df_log = minmax.transform(df.iloc[:, 7:].astype('float32')) # Close index\n",
    "df_log = pd.DataFrame(df_log)\n",
    "df_log.head()\n",
    "\n",
    "simulation_size = 10\n",
    "num_layers = 1\n",
    "size_layer = 128\n",
    "timestamp = 5\n",
    "epoch = 300\n",
    "dropout_rate = 0.8\n",
    "test_size = 30\n",
    "learning_rate = 0.01\n",
    "\n",
    "df_train = df_log\n",
    "df.shape, df_train.shape\n",
    "\n",
    "class Model:\n",
    "    def __init__(\n",
    "        self,\n",
    "        learning_rate,\n",
    "        num_layers,\n",
    "        size,\n",
    "        size_layer,\n",
    "        output_size,\n",
    "        forget_bias = 0.1,\n",
    "    ):\n",
    "        def lstm_cell(size_layer):\n",
    "            return tf.nn.rnn_cell.LSTMCell(size_layer, state_is_tuple = False)\n",
    "\n",
    "        rnn_cells = tf.nn.rnn_cell.MultiRNNCell(\n",
    "            [lstm_cell(size_layer) for _ in range(num_layers)],\n",
    "            state_is_tuple = False,\n",
    "        )\n",
    "        self.X = tf.placeholder(tf.float32, (None, None, size))\n",
    "        self.Y = tf.placeholder(tf.float32, (None, output_size))\n",
    "        drop = tf.contrib.rnn.DropoutWrapper(\n",
    "            rnn_cells, output_keep_prob = forget_bias\n",
    "        )\n",
    "        self.hidden_layer = tf.placeholder(\n",
    "            tf.float32, (None, num_layers * 2 * size_layer)\n",
    "        )\n",
    "        self.outputs, self.last_state = tf.nn.dynamic_rnn(\n",
    "            drop, self.X, initial_state = self.hidden_layer, dtype = tf.float32\n",
    "        )\n",
    "        self.logits = tf.layers.dense(self.outputs[-1], output_size)\n",
    "        self.cost = tf.reduce_mean(tf.square(self.Y - self.logits))\n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate).minimize(\n",
    "            self.cost\n",
    "        )\n",
    "        \n",
    "def calculate_accuracy(real, predict):\n",
    "    real = np.array(real) + 1\n",
    "    predict = np.array(predict) + 1\n",
    "    percentage = 1 - np.sqrt(np.mean(np.square((real - predict) / real)))\n",
    "    return percentage * 100\n",
    "\n",
    "def anchor(signal, weight):\n",
    "    buffer = []\n",
    "    last = signal[0]\n",
    "    for i in signal:\n",
    "        smoothed_val = last * weight + (1 - weight) * i\n",
    "        buffer.append(smoothed_val)\n",
    "        last = smoothed_val\n",
    "    return buffer\n",
    "\n",
    "def forecast():\n",
    "    tf.reset_default_graph()\n",
    "    modelnn = Model(\n",
    "        learning_rate, num_layers, df_log.shape[1], size_layer, df_log.shape[1], dropout_rate\n",
    "    )\n",
    "    sess = tf.InteractiveSession()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    date_ori = pd.to_datetime(df.iloc[:, 0]).tolist()\n",
    "\n",
    "    pbar = tqdm(range(epoch), desc = 'train loop')\n",
    "    for i in pbar:\n",
    "        init_value = np.zeros((1, num_layers * 2 * size_layer))\n",
    "        total_loss, total_acc = [], []\n",
    "        for k in range(0, df_train.shape[0] - 1, timestamp):\n",
    "            index = min(k + timestamp, df_train.shape[0] - 1)\n",
    "            batch_x = np.expand_dims(\n",
    "                df_train.iloc[k : index, :].values, axis = 0\n",
    "            )\n",
    "            batch_y = df_train.iloc[k + 1 : index + 1, :].values\n",
    "            logits, last_state, _, loss = sess.run(\n",
    "                [modelnn.logits, modelnn.last_state, modelnn.optimizer, modelnn.cost],\n",
    "                feed_dict = {\n",
    "                    modelnn.X: batch_x,\n",
    "                    modelnn.Y: batch_y,\n",
    "                    modelnn.hidden_layer: init_value,\n",
    "                },\n",
    "            )        \n",
    "            init_value = last_state\n",
    "            total_loss.append(loss)\n",
    "            total_acc.append(calculate_accuracy(batch_y[:, 0], logits[:, 0]))\n",
    "        pbar.set_postfix(cost = np.mean(total_loss), acc = np.mean(total_acc))\n",
    "    \n",
    "    future_day = test_size\n",
    "\n",
    "    output_predict = np.zeros((df_train.shape[0] + future_day, df_train.shape[1]))\n",
    "    output_predict[0] = df_train.iloc[0]\n",
    "    upper_b = (df_train.shape[0] // timestamp) * timestamp\n",
    "    init_value = np.zeros((1, num_layers * 2 * size_layer))\n",
    "\n",
    "    for k in range(0, (df_train.shape[0] // timestamp) * timestamp, timestamp):\n",
    "        out_logits, last_state = sess.run(\n",
    "            [modelnn.logits, modelnn.last_state],\n",
    "            feed_dict = {\n",
    "                modelnn.X: np.expand_dims(\n",
    "                    df_train.iloc[k : k + timestamp], axis = 0\n",
    "                ),\n",
    "                modelnn.hidden_layer: init_value,\n",
    "            },\n",
    "        )\n",
    "        init_value = last_state\n",
    "        output_predict[k + 1 : k + timestamp + 1] = out_logits\n",
    "\n",
    "    if upper_b != df_train.shape[0]:\n",
    "        out_logits, last_state = sess.run(\n",
    "            [modelnn.logits, modelnn.last_state],\n",
    "            feed_dict = {\n",
    "                modelnn.X: np.expand_dims(df_train.iloc[upper_b:], axis = 0),\n",
    "                modelnn.hidden_layer: init_value,\n",
    "            },\n",
    "        )\n",
    "        output_predict[upper_b + 1 : df_train.shape[0] + 1] = out_logits\n",
    "        future_day -= 1\n",
    "        date_ori.append(date_ori[-1] + timedelta(days = 1))\n",
    "\n",
    "    init_value = last_state\n",
    "    \n",
    "    for i in range(future_day):\n",
    "        o = output_predict[-future_day - timestamp + i:-future_day + i]\n",
    "        out_logits, last_state = sess.run(\n",
    "            [modelnn.logits, modelnn.last_state],\n",
    "            feed_dict = {\n",
    "                modelnn.X: np.expand_dims(o, axis = 0),\n",
    "                modelnn.hidden_layer: init_value,\n",
    "            },\n",
    "        )\n",
    "        init_value = last_state\n",
    "        output_predict[-future_day + i] = out_logits[-1]\n",
    "        date_ori.append(date_ori[-1] + timedelta(days = 1))\n",
    "    \n",
    "    output_predict = minmax.inverse_transform(output_predict)\n",
    "    deep_future = anchor(output_predict[:, 0], 0.4)\n",
    "    \n",
    "    return deep_future\n",
    "\n",
    "results = []\n",
    "for i in range(simulation_size):\n",
    "    print('simulation %d'%(i + 1))\n",
    "    results.append(forecast())\n",
    "    \n",
    "date_ori = pd.to_datetime(df.iloc[:, 0]).tolist()\n",
    "for i in range(test_size):\n",
    "    date_ori.append(date_ori[-1] + timedelta(days = 1))\n",
    "date_ori = pd.Series(date_ori).dt.strftime(date_format = '%Y-%m-%d').tolist()\n",
    "date_ori[-5:]\n",
    "\n",
    "accepted_results = []\n",
    "for r in results:\n",
    "    if (np.array(r[-test_size:]) < np.min(df['Close'])).sum() == 0 and \\\n",
    "    (np.array(r[-test_size:]) > np.max(df['Close']) * 2).sum() == 0:\n",
    "        accepted_results.append(r)\n",
    "len(accepted_results)\n",
    "\n",
    "accuracies = [calculate_accuracy(df['Close'].values, r[:-test_size]) for r in accepted_results]\n",
    "\n",
    "plt.figure(figsize = (15, 5))\n",
    "for no, r in enumerate(accepted_results):\n",
    "    plt.plot(r, label = 'forecast %d'%(no + 1))\n",
    "plt.plot(df['Close'], label = 'true trend', c = 'black')\n",
    "plt.legend()\n",
    "plt.title('average accuracy: %.4f'%(np.mean(accuracies)))\n",
    "\n",
    "x_range_future = np.arange(len(results[0]))\n",
    "plt.xticks(x_range_future[::30], date_ori[::30])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## MinMaxScaller() 변조및 복조\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "connect = create_engine('mysql+pymysql://kkang:leaf2027@localhost/stock?charset=utf8',encoding='utf-8')\n",
    "df = pd.read_sql(\"SELECT * from market where Code = '036640' and date > '2019-08-05'\", connect)\n",
    "\n",
    "df = df[['Open', 'High', 'Low', 'Volume', 'Close']]\n",
    "\n",
    "dataset = df.values\n",
    "\n",
    "source = MinMaxScaler() # default is 0,1\n",
    "dataset = source.fit_transform(dataset) ### MinMaxScaler 변조\n",
    "\n",
    "display(dataset)\n",
    "print('='*100)\n",
    "\n",
    "source.inverse_transform(dataset) ### MinMaxScaler 복조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## 이동 평균선\n",
    "\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "file = 'd:\\\\hrs.xlsx'\n",
    "\n",
    "connect = create_engine('mysql+pymysql://kkang:leaf2027@localhost/stock?charset=utf8',encoding='utf-8')\n",
    "df = pd.read_sql(\"SELECT * from market where Name = 'hrs' && Date > '2019-01-05'\", connect)\n",
    "\n",
    "volume_average_5 = df['Volume'].rolling(window=5,min_periods=1).mean()\n",
    "volume_average_10 = df['Volume'].rolling(window=10,min_periods=1).mean()\n",
    "volume_average_20 = df['Volume'].rolling(window=20,min_periods=1).mean()\n",
    "volume_average_60 = df['Volume'].rolling(window=60,min_periods=1).mean()\n",
    "volume_average_120 = df['Volume'].rolling(window=120,min_periods=1).mean()\n",
    "\n",
    "close_average_5 = df['Close'].rolling(window=5,min_periods=1).mean()\n",
    "close_average_10 = df['Close'].rolling(window=10,min_periods=1).mean()\n",
    "close_average_20 = df['Close'].rolling(window=20,min_periods=1).mean()\n",
    "close_average_60 = df['Close'].rolling(window=60,min_periods=1).mean()\n",
    "close_average_120 = df['Close'].rolling(window=120,min_periods=1).mean()\n",
    "\n",
    "df.insert(len(df.columns), \"Vol_MA5\", volume_average_5)\n",
    "df.insert(len(df.columns), \"Vol_MA10\", volume_average_10)\n",
    "df.insert(len(df.columns), \"Vol_MA20\", volume_average_20)\n",
    "df.insert(len(df.columns), \"Vol_MA60\", volume_average_60)\n",
    "df.insert(len(df.columns), \"Vol_MA120\", volume_average_120)\n",
    "\n",
    "df.insert(len(df.columns), \"Close_MA5\", close_average_5)\n",
    "df.insert(len(df.columns), \"Close_MA10\", close_average_10)\n",
    "df.insert(len(df.columns), \"Close_MA20\", close_average_20)\n",
    "df.insert(len(df.columns), \"Close_MA60\", close_average_60)\n",
    "df.insert(len(df.columns), \"Close_MA120\", close_average_120)\n",
    "\n",
    "df1 = df[['Date','Name','Close','Volume','Vol_MA5','Vol_MA10','Vol_MA20','Vol_MA60','Vol_MA120']]\n",
    "#df1.to_excel(file)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###  RSI\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "import talib.abstract as ta # talib.abstract는 Series나 numpy가 아닌 DataFrame도 대입가능\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import pandas_datareader.data as web\n",
    "import numpy as np\n",
    "from talib import RSI, BBANDS\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "file = 'd:\\\\hrs.xlsx'\n",
    "connect = create_engine('mysql+pymysql://kkang:leaf2027@localhost/stock?charset=utf8',encoding='utf-8')\n",
    "df = pd.read_sql(\"SELECT * from market where Name = 'hrs' && Date > '2019-01-05'\", connect)\n",
    "display(df.head())\n",
    "\n",
    "df = df.set_index('Date')\n",
    "df.columns = df.columns.str.lower()\n",
    "df[['open','high','low','volume','close']] = df[['open','high','low','volume','close']].astype(float)\n",
    "#df = df[['open','high','low','volume','close']]\n",
    "display(df.head())\n",
    "\n",
    "ta_ma5 = ta.MA(df,timeperiod=5 )\n",
    "display(ta_ma5.head())\n",
    "\n",
    "close = df['close'].values\n",
    "up, mid, low = BBANDS(close, timeperiod=20, nbdevup=2, nbdevdn=2, matype=0)\n",
    "df['BB_up']=up\n",
    "df['BB_mid']=mid\n",
    "df['BB_low']=low\n",
    "\n",
    "rsi = RSI(close, timeperiod=14)\n",
    "print(\"RSI (first 10 elements)\\n\", rsi[14:24])\n",
    "df['RSI']=rsi\n",
    "display(df['RSI'].head())\n",
    "\n",
    "up, mid, low = BBANDS(close, timeperiod=20, nbdevup=2, nbdevdn=2, matype=0)\n",
    "bbp = (df['close'] - low) / (up - low)\n",
    "df['BBP']=bbp\n",
    "display(bbp.head())\n",
    "\n",
    "index=df.index\n",
    "max_holding = 100\n",
    "\n",
    "holdings = pd.DataFrame(index=df.index, data={'Holdings': np.array([np.nan] * index.shape[0])})\n",
    "holdings.loc[((df['RSI'] < 30) & (df['BBP'] < 0)), 'Holdings'] = max_holding\n",
    "holdings.loc[((df['RSI'] > 70) & (df['BBP'] > 1)), 'Holdings'] = 0\n",
    "holdings.ffill(inplace=True)\n",
    "holdings.fillna(0, inplace=True)\n",
    "\n",
    "holdings['Order'] = holdings.diff()\n",
    "holdings.dropna(inplace=True)\n",
    "\n",
    "fig, (ax0, ax1, ax2) = plt.subplots(3, 1, sharex=True, figsize=(12, 8))\n",
    "ax0.plot(index, df['close'], label='Close')\n",
    "ax0.set_xlabel('Date')\n",
    "ax0.set_ylabel('close')\n",
    "ax0.grid()\n",
    "\n",
    "for day, holding in holdings.iterrows():\n",
    "    order = holding['Order']\n",
    "    if order > 0:\n",
    "        ax0.scatter(x=day, y=df.loc[day, 'close'], color='green')\n",
    "    elif order < 0:\n",
    "        ax0.scatter(x=day, y=df.loc[day, 'close'], color='red')\n",
    "\n",
    "ax1.plot(index, df['RSI'], label='RSI')\n",
    "ax1.fill_between(index, y1=30, y2=70, color='#adccff', alpha='0.3')\n",
    "ax1.set_xlabel('Date')\n",
    "ax1.set_ylabel('RSI')\n",
    "ax1.grid()\n",
    "\n",
    "ax2.plot(index, df['BB_up'], label='BB_up')\n",
    "ax2.plot(index, df['close'], label='AdjClose')\n",
    "ax2.plot(index, df['BB_low'], label='BB_low')\n",
    "ax2.fill_between(index, y1=df['BB_low'], y2=df['BB_up'], color='#adccff', alpha='0.3')\n",
    "ax2.set_xlabel('Date')\n",
    "ax2.set_ylabel('Bollinger Bands')\n",
    "ax2.grid()\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  ta-lib 이동평균선 그래프 출력\n",
    "\n",
    "import talib.abstract as ta\n",
    "import FinanceDataReader as fdr\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime as dt\n",
    "from datetime import datetime,timedelta\n",
    "from urllib.request import urlopen\n",
    "import sqlalchemy \n",
    "import pymysql\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "from matplotlib import font_manager, rc\n",
    "font_name = font_manager.FontProperties(fname=\"c:/Windows/Fonts/malgun.ttf\").get_name()\n",
    "rc('font', family=font_name)\n",
    "\n",
    "now = dt.datetime.today().strftime('%Y-%m-%d')\n",
    "engine = sqlalchemy.create_engine('mysql+pymysql://kkang:leaf2027@localhost/stock?charset=utf8',encoding='utf-8')\n",
    "\n",
    "\n",
    "df = pd.read_sql(\"SELECT * from market where Code = '036640' and date > '2019-01-05'\", engine)\n",
    "df = df.set_index('Date')\n",
    "df[['Open','High','Low','Volume','Close']] = df[['Open','High','Low','Volume','Close']].astype(float) #  TA-Lib로 평균을 구하려면 실수로 만들어야 함\n",
    "df.columns=df.columns.str.lower()\n",
    "\n",
    "talib_ma5 = ta.MA(df, timeperiod=5)\n",
    "df['ma5'] = talib_ma5\n",
    "\n",
    "talib_ma10 = ta.MA(df, timeperiod=10)\n",
    "df['ma10'] = talib_ma10\n",
    "\n",
    "talib_ma20 = ta.MA(df, timeperiod=20)\n",
    "df['ma20'] = talib_ma20\n",
    "\n",
    "talib_ma60 = ta.MA(df, timeperiod=60)\n",
    "df['ma60'] = talib_ma60\n",
    "\n",
    "talib_ma120 = ta.MA(df, timeperiod=120)\n",
    "df['ma120'] = talib_ma120\n",
    "\n",
    "display(df.iloc[120:].head())\n",
    "\n",
    "plt.figure(figsize=(16,4))\n",
    "plt.plot(df['ma5'],label='ma5')\n",
    "plt.plot(df['ma10'],label='ma10')\n",
    "plt.plot(df['ma20'],label='ma20')\n",
    "plt.plot(df['ma60'],label='ma60')\n",
    "plt.plot(df['ma120'],label='ma120')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  이동평균선  데이타베이스  일괄입력\n",
    "import time\n",
    "import talib.abstract as ta\n",
    "import FinanceDataReader as fdr\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime as dt\n",
    "from datetime import datetime,timedelta\n",
    "from urllib.request import urlopen\n",
    "import sqlalchemy \n",
    "import pymysql\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "from matplotlib import font_manager, rc\n",
    "font_name = font_manager.FontProperties(fname=\"c:/Windows/Fonts/malgun.ttf\").get_name()\n",
    "rc('font', family=font_name)\n",
    "\n",
    "now = dt.datetime.today().strftime('%Y-%m-%d')\n",
    "engine = sqlalchemy.create_engine('mysql+pymysql://kkang:leaf2027@localhost/stock?charset=utf8',encoding='utf-8')\n",
    "\n",
    "df = pd.read_sql(\"SELECT distinct Name from market \", engine)\n",
    "df = df.set_index('Name')\n",
    "name = df.index\n",
    "for i in range(len(name)):\n",
    "    df = pd.read_sql(\"SELECT * from market where Name =\"+\"'\"+name[i]+\"'\", engine)\n",
    "    line = df.shape[0]   \n",
    "    \n",
    "    df[['Open','High','Low','Volume','Close']] = df[['Open','High','Low','Volume','Close']].astype(float) #  TA-Lib로 평균을 구하려면 실수로 만들어야 함\n",
    "    df.columns=df.columns.str.lower()\n",
    "    #df = df.set_index('date')\n",
    "            \n",
    "    if line >= 120:\n",
    "        talib_ma5 = ta.MA(df, timeperiod=5)\n",
    "        df['ma5'] = talib_ma5\n",
    "\n",
    "        talib_ma10 = ta.MA(df, timeperiod=10)\n",
    "        df['ma10'] = talib_ma10\n",
    "\n",
    "        talib_ma20 = ta.MA(df, timeperiod=20)\n",
    "        df['ma20'] = talib_ma20\n",
    "\n",
    "        talib_ma60 = ta.MA(df, timeperiod=60)\n",
    "        df['ma60'] = talib_ma60\n",
    "\n",
    "        talib_ma120 = ta.MA(df, timeperiod=120)\n",
    "        df['ma120'] = talib_ma120\n",
    "\n",
    "        df_ma = df[['date','code','name','ma5','ma10','ma20','ma60','ma120']].round(2)\n",
    "        df_ma.iloc[:4,3]=df_ma.iloc[4,3]\n",
    "        df_ma.iloc[:9,4]=df_ma.iloc[9,4]\n",
    "        df_ma.iloc[:19,5]=df_ma.iloc[19,5]\n",
    "        df_ma.iloc[:59,6]=df_ma.iloc[59,6]\n",
    "        df_ma.iloc[:119,7]=df_ma.iloc[119,7]        \n",
    "        df_ma.columns=['Date','Code','Name','ma5','ma10','ma20','ma60','ma120']\n",
    "        df_ma.to_sql(name='ma', con=engine, if_exists='append', index = False)  \n",
    "        \n",
    "    elif line >= 60 and line < 120:\n",
    "        talib_ma5 = ta.MA(df, timeperiod=5)\n",
    "        df['ma5'] = talib_ma5\n",
    "        \n",
    "        talib_ma10 = ta.MA(df, timeperiod=10)\n",
    "        df['ma10'] = talib_ma10\n",
    "        \n",
    "        talib_ma20 = ta.MA(df, timeperiod=20)\n",
    "        df['ma20'] = talib_ma20\n",
    "        \n",
    "        talib_ma60 = ta.MA(df, timeperiod=60)\n",
    "        df['ma60'] = talib_ma60\n",
    "        \n",
    "        df_ma = df[['date','code','name','ma5','ma10','ma20','ma60']].round(2)\n",
    "        df_ma.iloc[:4,3]=df_ma.iloc[4,3]\n",
    "        df_ma.iloc[:9,4]=df_ma.iloc[9,4]\n",
    "        df_ma.iloc[:19,5]=df_ma.iloc[19,5]\n",
    "        df_ma.iloc[:59,6]=df_ma.iloc[59,6]        \n",
    "        df_ma.columns=['Date','Code','Name','ma5','ma10','ma20','ma60']\n",
    "        df_ma.to_sql(name='ma', con=engine, if_exists='append', index = False) \n",
    "        \n",
    "    elif line >= 20 and line <60:\n",
    "        talib_ma5 = ta.MA(df, timeperiod=5)\n",
    "        df['ma5'] = talib_ma5\n",
    "        \n",
    "        talib_ma10 = ta.MA(df, timeperiod=10)\n",
    "        df['ma10'] = talib_ma10\n",
    "        \n",
    "        talib_ma20 = ta.MA(df, timeperiod=20)\n",
    "        df['ma20'] = talib_ma20\n",
    "        \n",
    "        df_ma = df[['date','code','name','ma5','ma10','ma20']].round(2)\n",
    "        df_ma.iloc[:4,3]=df_ma.iloc[4,3]\n",
    "        df_ma.iloc[:9,4]=df_ma.iloc[9,4]\n",
    "        df_ma.iloc[:19,5]=df_ma.iloc[19,5]\n",
    "        df_ma.columns=['Date','Code','Name','ma5','ma10','ma20']\n",
    "        df_ma.to_sql(name='ma', con=engine, if_exists='append', index = False)\n",
    "        \n",
    "    elif line >= 10 and line <20:\n",
    "        talib_ma5 = ta.MA(df, timeperiod=5)\n",
    "        df['ma5'] = talib_ma5\n",
    "        \n",
    "        talib_ma10 = ta.MA(df, timeperiod=10)\n",
    "        df['ma10'] = talib_ma10\n",
    "        \n",
    "        df_ma = df[['date','code','name','ma5','ma10']].round(2)\n",
    "        df_ma.iloc[:4,3]=df_ma.iloc[4,3]\n",
    "        df_ma.iloc[:9,4]=df_ma.iloc[9,4] \n",
    "        df_ma.columns=['Date','Code','Name','ma5','ma10']\n",
    "        df_ma.to_sql(name='ma', con=engine, if_exists='append', index = False) \n",
    "        \n",
    "    elif line >= 5 and line <10:\n",
    "        talib_ma5 = ta.MA(df, timeperiod=5)\n",
    "        df['ma5'] = talib_ma5 \n",
    "        \n",
    "        df_ma = df[['date','code','name','ma5']].round(2)\n",
    "        df_ma.iloc[:4,3]=df_ma.iloc[4,3]\n",
    "        df_ma.columns=['Date','Code','Name','ma5']\n",
    "        df_ma.to_sql(name='ma', con=engine, if_exists='append', index = False)\n",
    "        \n",
    "    elif line > 5:\n",
    "        pass\n",
    "  \n",
    "    #df_ma.to_excel('d:\\ma_line.xlsx')\n",
    "    #df_ma.columns=['Date','Code','Name','ma5','ma10','ma20','ma60','ma120']\n",
    "    #df_ma.to_sql(name='ma', con=engine, if_exists='append', index = False)\n",
    "    print(df_ma.head(1))\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 일일 종목선정 project 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## 일일 거래량 50만주이상 주식중 전일 거래량 보다 많은 거래량 top15 종목 \n",
    "\n",
    "import FinanceDataReader as fdr\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime as dt\n",
    "from datetime import datetime,timedelta\n",
    "from urllib.request import urlopen\n",
    "import sqlalchemy \n",
    "import pymysql\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "from matplotlib import font_manager, rc\n",
    "font_name = font_manager.FontProperties(fname=\"c:/Windows/Fonts/malgun.ttf\").get_name()\n",
    "rc('font', family=font_name)\n",
    "\n",
    "today = datetime.now()\n",
    "real_yesterday = (today-timedelta(1)).strftime('%Y-%m-%d')\n",
    "real_today = today.strftime('%Y-%m-%d')\n",
    "\n",
    "now = dt.datetime.today().strftime('%Y-%m-%d')\n",
    "engine = sqlalchemy.create_engine('mysql+pymysql://kkang:leaf2027@localhost/stock?charset=utf8',encoding='utf-8')\n",
    "\n",
    "market_df = pd.read_sql(\"select * from market where Date > '2019-01-01'\", engine)\n",
    "#market_df\n",
    "\n",
    "is_hrs=market_df['Name']=='HRS'\n",
    "hrs_df = market_df[is_hrs]\n",
    "yesterday = str(hrs_df['Date'].iloc[0])\n",
    "today = str(hrs_df['Date'].iloc[1])\n",
    "#print(yesterday)\n",
    "#print(today)\n",
    "\n",
    "#var = \"select * from market where (Date = '2019-01-02' OR Date = '2019-01-03')  and Volume >  500000\"\n",
    "#df = pd.read_sql(var ,engine)\n",
    "#df\n",
    "\n",
    "select_query = \"select * from market where (Date = \"\n",
    "volume_query = \"&& Volume >  500000\"\n",
    "    \n",
    "var = select_query +\"'\"+yesterday+\"'\"+'or Date ='+\"'\"+today+\"'\"+')' + volume_query\n",
    "df = pd.read_sql(var ,engine)\n",
    "\n",
    "#df\n",
    "\n",
    "\n",
    "df1 = df[df['Date'].astype(str) == yesterday]\n",
    "df1 = df1[['Name','Volume','Close']]\n",
    "df1.columns = ['Name','yester_Volume','yester_Close']\n",
    "#display(df1)\n",
    "\n",
    "\n",
    "df2 = df[df['Date'].astype(str) == today]\n",
    "df2 = df2[['Name','Volume','Close']]\n",
    "df2.columns = ['Name','today_Volume','today_Close']\n",
    "#display(df2)\n",
    "\n",
    "df3 = pd.merge(df1,df2,on='Name')\n",
    "df3['Close']=df3['today_Close']/df3['yester_Close']\n",
    "df3['Volume']=df3['today_Volume']/df3['yester_Volume']\n",
    "df3 = df3.sort_values(by=['Volume','Close'],ascending=False)\n",
    "df4 = df3.sort_values(by=['Close','Volume'],ascending=False)\n",
    "df3 = df3.reset_index(drop=True)\n",
    "\n",
    "df3 = df3[:19]\n",
    "df4 = df4.reset_index(drop=True)\n",
    "df4 = df4[:19]\n",
    "df3.to_excel('d:\\\\stockdata\\\\vote_stock\\\\detect_stock_with_volume_'+today+'.xlsx', encoding='utf-8')\n",
    "df4.to_excel('d:\\\\stockdata\\\\vote_stock\\\\detect_stock_with_price_'+today+'.xlsx', encoding='utf-8')        \n",
    "display(df3)\n",
    "display(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## 일일 거래량 50만주이상 주식중 전일 거래량 보다 많은 거래량 top19 종목  for loop 추가 및 화일로 저장\n",
    "\n",
    "import FinanceDataReader as fdr\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime as dt\n",
    "from datetime import datetime,timedelta\n",
    "from urllib.request import urlopen\n",
    "import sqlalchemy \n",
    "import pymysql\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "from matplotlib import font_manager, rc\n",
    "font_name = font_manager.FontProperties(fname=\"c:/Windows/Fonts/malgun.ttf\").get_name()\n",
    "rc('font', family=font_name)\n",
    "\n",
    "today = datetime.now()\n",
    "real_yesterday = (today-timedelta(1)).strftime('%Y-%m-%d')\n",
    "real_today = today.strftime('%Y-%m-%d')\n",
    "\n",
    "now = dt.datetime.today().strftime('%Y-%m-%d')\n",
    "engine = sqlalchemy.create_engine('mysql+pymysql://kkang:leaf2027@localhost/stock?charset=utf8',encoding='utf-8')\n",
    "\n",
    "market_df = pd.read_sql(\"select * from market where Date > '2019-05-01'\", engine)\n",
    "#market_df\n",
    "\n",
    "is_hrs=market_df['Name']=='HRS'\n",
    "hrs_df = market_df[is_hrs]\n",
    "yesterday = str(hrs_df['Date'].iloc[0])\n",
    "today = str(hrs_df['Date'].iloc[1])\n",
    "count = hrs_df.shape[0]\n",
    "#for i in range(hrs_df['Date'].shape[0]):\n",
    "for i in range(count):\n",
    "    yesterday = str(hrs_df['Date'].iloc[i])\n",
    "    today = str(hrs_df['Date'].iloc[i+1])\n",
    "    print('y:{}'.format(yesterday))\n",
    "    print('t:{}'.format(today))\n",
    "    select_query = \"select * from market where (Date = \"\n",
    "    volume_query = \"&& Volume >  500000\"\n",
    "    \n",
    "    var = select_query +\"'\"+yesterday+\"'\"+'or Date ='+\"'\"+today+\"'\"+')' + volume_query\n",
    "    df = pd.read_sql(var ,engine)\n",
    "\n",
    "    #df\n",
    "\n",
    "\n",
    "    df1 = df[df['Date'].astype(str) == yesterday]\n",
    "    df1 = df1[['Name','Volume','Close']]\n",
    "    df1.columns = ['Name','yester_Volume','yester_Close']\n",
    "    #display(df1)\n",
    "\n",
    "\n",
    "    df2 = df[df['Date'].astype(str) == today]\n",
    "    df2 = df2[['Name','Volume','Close']]\n",
    "    df2.columns = ['Name','today_Volume','today_Close']\n",
    "    #display(df2)\n",
    "\n",
    "    df3 = pd.merge(df1,df2,on='Name')\n",
    "    df3['Close']=df3['today_Close']/df3['yester_Close']\n",
    "    df3['Volume']=df3['today_Volume']/df3['yester_Volume']\n",
    "    df3 = df3.sort_values(by=['Volume','Close'],ascending=False)\n",
    "    df4 = df3.sort_values(by=['Close','Volume'],ascending=False)\n",
    "    df3 = df3.reset_index(drop=True)\n",
    "\n",
    "    df3 = df3[:19]\n",
    "    df4 = df4.reset_index(drop=True)\n",
    "    df4 = df4[:19]\n",
    "    df3.to_excel('d:\\\\stockdata\\\\vote_stock\\\\detect_stock_with_volume_'+today+'.xlsx', encoding='utf-8')\n",
    "    df4.to_excel('d:\\\\stockdata\\\\vote_stock\\\\detect_stock_with_price_'+today+'.xlsx', encoding='utf-8')        \n",
    "    display(df3)\n",
    "    display(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  전종목 검색하여  종가 > ma120  일일 비교  하여  관심 종목 추출_1\n",
    "\n",
    "from mod1 import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "\n",
    "\n",
    "path = 'd:\\\\stockdata\\\\close_ma120\\\\close_ma120_'\n",
    "\n",
    "df = all_stock('2019-10-10')\n",
    "df = df['Name']\n",
    "\n",
    "name = df.to_list()\n",
    "\n",
    "df2 = pd.DataFrame()\n",
    "for i in name:\n",
    "    #print(i)\n",
    "    df=select_stock(i,'2010-01-01')\n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close','ma120','volume']].values)\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1['Name']=i\n",
    "    df1.columns=['close','ma120','volume','name',]\n",
    "    df1['date'] = df['date']\n",
    "    #print(df1)\n",
    "    df2 = df2.append(df1)\n",
    "    \n",
    "\n",
    "last = len(df2[df2['name'] == name[0]])-1\n",
    "today_df = df2[df2.index == last]\n",
    "\n",
    "ma120_df = today_df[today_df['close'] > today_df['ma120']]\n",
    "ma120_df = ma120_df.sort_values(['ma120'])\n",
    "\n",
    "today = str(ma120_df.iloc[0,4])\n",
    "ma120_df.to_excel(path+today+'.xlsx', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  전종목 검색하여  종가 > ma120  일일 비교  하여  관심 종목 추출_2  날짜를 지정하여 검색 가능\n",
    "\n",
    "from mod1 import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "\n",
    "choice_date='2019-10-22'\n",
    "path = 'd:\\\\stockdata\\\\close_ma120\\\\close_ma120_'\n",
    "\n",
    "df = all_stock('2019-10-10')\n",
    "df = df['Name']\n",
    "\n",
    "name = df.to_list()\n",
    "\n",
    "df2 = pd.DataFrame()\n",
    "for i in name:\n",
    "    #print(i)\n",
    "    df=select_stock(i,'2010-01-01')\n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close','ma120','volume']].values)\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1['Name']=i\n",
    "    df1.columns=['close','ma120','volume','name',]\n",
    "    df1['date'] = df['date']\n",
    "    #print(df1)\n",
    "    df2 = df2.append(df1)\n",
    "    \n",
    "\n",
    "select_query = \"select count(*) from market_good where Name='hrs' and Date > \"\n",
    "var = select_query +\"'\"+choice_date+\"'\" \n",
    "sql_df = pd.read_sql(var, engine)\n",
    "count = sql_df.values.tolist()\n",
    "back_date = count[0][0]\n",
    "back_date\n",
    "today_df = df2.loc[df2['date'] == (today_df['date'].values[0]-timedelta(back_date))]\n",
    "\n",
    "ma120_df = today_df[today_df['close'] > today_df['ma120']]\n",
    "ma120_df = ma120_df.sort_values(['ma120'])\n",
    "\n",
    "ma120_df.to_excel(path+choice_date+'.xlsx', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  전종목 검색하여  종가 > ma120  일일 비교  하여  관심 종목 추출_3  한달단위로 추출\n",
    "\n",
    "from mod1 import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "\n",
    "path = 'd:\\\\stockdata\\\\close_ma120\\\\close_ma120_'\n",
    "\n",
    "df = all_stock('2019-10-10')\n",
    "df = df['Name']\n",
    "\n",
    "name = df.to_list()\n",
    "\n",
    "df2 = pd.DataFrame()\n",
    "for i in name:\n",
    "    #print(i)\n",
    "    df=select_stock(i,'2010-01-01')\n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close','ma60','ma120','volume']].values)\n",
    "    df1 = pd.DataFrame(data)\n",
    "\n",
    "    df1['Name']=i\n",
    "    df1.columns=['close','ma60','ma120','volume','name',]\n",
    "    df1['date'] = df['date']\n",
    "\n",
    "    #print(df1)\n",
    "    df2 = df2.append(df1)\n",
    "\n",
    "select_query = \"select * from market where Name='hrs' and Date >= '2019-10-01' and Date < '2019-11-01' \"\n",
    "df3 = pd.read_sql(select_query, engine)\n",
    "\n",
    "df3 = df3['Date']\n",
    "datelist = df3.to_list()\n",
    "\n",
    "for i in datelist:\n",
    "    choice_df = df2.loc[df2['date'] == i]\n",
    "    strdate = i.strftime('%Y-%m-%d')\n",
    "    ma120_df = choice_df[choice_df['close'] > choice_df['ma120']]\n",
    "    ma120_df = ma120_df.sort_values(['ma120'])\n",
    "    ma120_df.to_excel(path+strdate+'.xlsx')\n",
    "    #print(today_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  전종목 검색하여  종가 > ma120  일일 비교  하여  관심 종목 추출_4  한달단위로  close_ma120, total 동시 추출\n",
    "\n",
    "from mod1 import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "\n",
    "path = 'd:\\\\stockdata\\\\close_ma120\\\\close_ma120_'\n",
    "path_total = 'd:\\\\stockdata\\\\close_ma120\\\\total_'\n",
    "\n",
    "df = all_stock('2019-10-10')\n",
    "df = df['Name']\n",
    "name = df.to_list()\n",
    "\n",
    "pure_df = pd.DataFrame()\n",
    "df2 = pd.DataFrame()\n",
    "\n",
    "for i in name:\n",
    "    #print(i)\n",
    "    df=select_stock(i,'2008-01-01')\n",
    "    pure_df = pure_df.append(df)\n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close','ma60','ma120','volume']].values)\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1['name']=i\n",
    "    df1.columns=['close','ma60','ma120','volume','name']\n",
    "    df1['date'] = df['date']\n",
    "    #print(df1)\n",
    "    df2 = df2.append(df1)\n",
    "\n",
    "pure_df.columns = map(str.lower, pure_df.columns) ## \n",
    "\n",
    "select_query = \"select * from market where Name='hrs' and Date >= '2019-10-01' \"\n",
    "df3 = pd.read_sql(select_query, engine)\n",
    "\n",
    "df3 = df3['Date']\n",
    "datelist = df3.to_list()\n",
    "\n",
    "last_df = df2.loc[df2['date'] == datelist[-1]]\n",
    "last_df = last_df[last_df['ma120'] < 0.1]\n",
    "last_price_df = pure_df.loc[pure_df['date'] == datelist[-1]]\n",
    "\n",
    "for i in datelist:\n",
    "    first_df = df2.loc[df2['date'] == i]\n",
    "    first_price_df = pure_df.loc[pure_df['date'] == i]\n",
    "    ma120_df = pd.merge(first_df,last_df,on='name')\n",
    "    ma_df = pd.merge(first_price_df[['close','name']],ma120_df,on='name')\n",
    "    ma120_df = pd.merge(last_price_df[['close','volume','name']],ma_df,on='name')\n",
    "    ma120_df.columns= ['price_y','volume_z', 'name', 'price_x', 'close_x', 'ma60_x', 'ma120_x','volume_x', 'date_x', 'close_y', 'ma60_y', 'ma120_y', 'volume_y', 'date_y']\n",
    "    ma120_df = ma120_df[['name','close_x','close_y','ma60_x','ma60_y','ma120_x','ma120_y','price_x','price_y','volume_z','date_x']]\n",
    "    ma120_df['price_diff']=ma120_df['price_y']/ma120_df['price_x']\n",
    "    ma120_df =  ma120_df.sort_values([\"price_diff\"],ascending=False)\n",
    "    second_df =  first_df.sort_values([\"ma120\"],ascending=False)\n",
    "    #ma120_df['price_x']=first_price_df['close'].values\n",
    "    #ma120_df['price_y']=last_price_df['close'].values\n",
    "    strdate = i.strftime('%Y-%m-%d')\n",
    "    second_df.to_excel(path+strdate+'.xlsx')\n",
    "    ma120_df.to_excel(path_total+strdate+'.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  전종목 검색하여  종가 > ma120  일일 비교  하여  관심 종목 추출_5  한달단위로  close_ma120, total 동시 추출(1년분)\n",
    "\n",
    "from mod1 import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
    "\n",
    "path = 'd:\\\\stockdata\\\\close_ma120\\\\close_ma120_'\n",
    "path_total = 'd:\\\\stockdata\\\\close_ma120\\\\total_'\n",
    "path_total_a = 'd:\\\\stockdata\\\\close_ma120\\\\total_a_'\n",
    "path_total_b = 'd:\\\\stockdata\\\\close_ma120\\\\total_b_'\n",
    "\n",
    "df = all_stock('2019-10-10')\n",
    "df = df['Name']\n",
    "name = df.to_list()\n",
    "\n",
    "pure_df = pd.DataFrame()\n",
    "df2 = pd.DataFrame()\n",
    "\n",
    "for i in name:\n",
    "    #print(i)\n",
    "    df=select_stock(i,'2019-01-01')\n",
    "    pure_df = pure_df.append(df)\n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close','ma60','ma120','volume']].values)\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1['name']=i\n",
    "    df1.columns=['close','ma60','ma120','volume','name']\n",
    "    df1[['date','code']] = df[['date','code']]\n",
    "\n",
    "    #print(df1)\n",
    "    df2 = df2.append(df1)\n",
    "\n",
    "pure_df.columns = map(str.lower, pure_df.columns) ## \n",
    "\n",
    "select_query = \"select * from market where Name='hrs' and Date >= '2019-10-01' \"\n",
    "df3 = pd.read_sql(select_query, engine)\n",
    "\n",
    "df3 = df3['Date']\n",
    "datelist = df3.to_list()\n",
    "\n",
    "last_df = df2.loc[df2['date'] == datelist[-1]]\n",
    "last_df = last_df[last_df['ma120'] < 0.1]\n",
    "a_df = last_df[last_df['close'] > last_df['ma60']] \n",
    "last_df = a_df[a_df['ma60'] > a_df['ma120']]\n",
    "last_price_df = pure_df.loc[pure_df['date'] == datelist[-1]]\n",
    "\n",
    "for i in datelist:\n",
    "    first_df = df2.loc[df2['date'] == i]\n",
    "    first_price_df = pure_df.loc[pure_df['date'] == i]\n",
    "    one_df = pd.merge(first_df,last_df,on='code')\n",
    "    reset_index_df = last_df.reset_index()\n",
    "    one_df['code']= reset_index_df['code']\n",
    "    ma_df = pd.merge(first_price_df[['close','code']],one_df,on='code')\n",
    "    two_df = pd.merge(last_price_df[['close','code','volume']],ma_df,on='code')\n",
    "    two_df.columns= ['price_y','code', 'volume_z','price_x', 'close_x', 'ma60_x', 'ma120_x', 'volume_x','name_x', 'date_x', 'close_y', 'ma60_y', 'ma120_y', 'volume_y','name_y', 'date_y']\n",
    "\n",
    "    ma120_df = two_df[['name_x','code','close_x','close_y','ma60_x','ma60_y','ma120_x','ma120_y','price_x','price_y','date_x','volume_z']]\n",
    "    ma120_df['price_diff']=ma120_df['price_y']/ma120_df['price_x']\n",
    "    ma120_df =  ma120_df.sort_values([\"price_diff\"],ascending=False)\n",
    "    #second_df =  first_df.sort_values([\"ma120\"],ascending=False)\n",
    "\n",
    "    strdate = i.strftime('%Y-%m-%d')\n",
    "    #second_df.to_excel(path+strdate+'.xlsx')\n",
    "    ma120_df.to_excel(path_total_a+strdate+'.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  전종목 검색하여  종가 > ma120  일일 비교  하여  관심 종목 추출_6  한달단위로  close_ma120, total 동시 추출(11년분)\n",
    "\n",
    "from mod1 import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
    "\n",
    "path = 'd:\\\\stockdata\\\\close_ma120\\\\close_ma120_'\n",
    "path_total = 'd:\\\\stockdata\\\\close_ma120\\\\total_'\n",
    "path_total_a = 'd:\\\\stockdata\\\\close_ma120\\\\total_a_'\n",
    "path_total_b = 'd:\\\\stockdata\\\\close_ma120\\\\total_b_'\n",
    "\n",
    "df = all_stock('2019-10-10')\n",
    "df = df['Name']\n",
    "name = df.to_list()\n",
    "\n",
    "pure_df = pd.DataFrame()\n",
    "df2 = pd.DataFrame()\n",
    "\n",
    "for i in name:\n",
    "    #print(i)\n",
    "    df=select_stock(i,'2008-01-01')\n",
    "    pure_df = pure_df.append(df)\n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close','ma60','ma120','volume']].values)\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1['name']=i\n",
    "    df1.columns=['close','ma60','ma120','volume','name']\n",
    "    df1[['date','code']] = df[['date','code']]\n",
    "\n",
    "    #print(df1)\n",
    "    df2 = df2.append(df1)\n",
    "\n",
    "pure_df.columns = map(str.lower, pure_df.columns) ## \n",
    "\n",
    "select_query = \"select * from market where Name='hrs' and Date >= '2019-10-01' \"\n",
    "df3 = pd.read_sql(select_query, engine)\n",
    "\n",
    "df3 = df3['Date']\n",
    "datelist = df3.to_list()\n",
    "\n",
    "last_df = df2.loc[df2['date'] == datelist[-1]]\n",
    "last_df = last_df[last_df['ma120'] < 0.1]\n",
    "a_df = last_df[last_df['close'] > last_df['ma60']] \n",
    "last_df = a_df[a_df['ma60'] > a_df['ma120']]\n",
    "last_price_df = pure_df.loc[pure_df['date'] == datelist[-1]]\n",
    "\n",
    "for i in datelist:\n",
    "    first_df = df2.loc[df2['date'] == i]\n",
    "    first_price_df = pure_df.loc[pure_df['date'] == i]\n",
    "    one_df = pd.merge(first_df,last_df,on='code')\n",
    "    reset_index_df = last_df.reset_index()\n",
    "    one_df['code']= reset_index_df['code']\n",
    "    ma_df = pd.merge(first_price_df[['close','code']],one_df,on='code')\n",
    "    two_df = pd.merge(last_price_df[['close','code','volume']],ma_df,on='code')\n",
    "    two_df.columns= ['price_y','code', 'volume_z','price_x', 'close_x', 'ma60_x', 'ma120_x', 'volume_x','name_x', 'date_x', 'close_y', 'ma60_y', 'ma120_y', 'volume_y','name_y', 'date_y']\n",
    "\n",
    "    ma120_df = two_df[['name_x','code','close_x','close_y','ma60_x','ma60_y','ma120_x','ma120_y','price_x','price_y','date_x','volume_z']]\n",
    "    ma120_df['price_diff']=ma120_df['price_y']/ma120_df['price_x']\n",
    "    ma120_df =  ma120_df.sort_values([\"price_diff\"],ascending=False)\n",
    "    second_df =  first_df.sort_values([\"ma120\"],ascending=False)\n",
    "\n",
    "    strdate = i.strftime('%Y-%m-%d')\n",
    "    second_df.to_excel(path+strdate+'.xlsx')\n",
    "    ma120_df.to_excel(path_total_b+strdate+'.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  전종목 검색하여  종가 > ma120  일일 비교  하여  관심 종목 추출_7  한달단위로  close_ma120, total (1년분),close_ma120, total (11년분) 동시 추출\n",
    "\n",
    "from mod1 import *\n",
    "#import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "#from pandas.core.common import SettingWithCopyWarning\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
    "\n",
    "path = 'd:\\\\stockdata\\\\close_ma120\\\\close_ma120_'\n",
    "path_total = 'd:\\\\test\\\\total_'\n",
    "path_total_a = 'd:\\\\test\\\\total_a_'\n",
    "path_total_b = 'd:\\\\test\\\\total_b_'\n",
    "\n",
    "#df = all_stock('2019-10-10')\n",
    "#df = df['Name']\n",
    "#name = df.to_list()\n",
    "    \n",
    "name = ['필룩스','MP한강','금호전기','나이벡']\n",
    "\n",
    "select_start_a = '2019-01-01'\n",
    "select_start_b = '2008-01-01'\n",
    "    \n",
    "def search_stock(name,select_start):   \n",
    "    print(name)\n",
    "    print(select_start)\n",
    "    pure_df = pd.DataFrame()\n",
    "    df2 = pd.DataFrame() \n",
    "    for i in name:\n",
    "        #print(i)\n",
    "        df=select_stock(i,select_start)\n",
    "        #print(df)\n",
    "        pure_df = pure_df.append(df)\n",
    "        ma(df)\n",
    "\n",
    "        source = MinMaxScaler()\n",
    "        data = source.fit_transform(df[['close','ma60','ma120','volume']].values)\n",
    "        df1 = pd.DataFrame(data)\n",
    "        df1['name']=i\n",
    "        df1.columns=['close','ma60','ma120','volume','name']\n",
    "        df1[['date','code']] = df[['date','code']]\n",
    "        #print(df1)\n",
    "        df2 = df2.append(df1)\n",
    "\n",
    "    pure_df.columns = map(str.lower, pure_df.columns) ## \n",
    "\n",
    "    select_query = \"select * from market where Name='hrs' and Date >= '2019-10-01' \"\n",
    "    df3 = pd.read_sql(select_query, engine)\n",
    "\n",
    "    df3 = df3['Date']\n",
    "    datelist = df3.to_list()\n",
    "\n",
    "    last_df = df2.loc[df2['date'] == datelist[-1]]\n",
    "    last_df = last_df[last_df['ma120'] < 0.1]\n",
    "    a_df = last_df[last_df['close'] > last_df['ma60']] \n",
    "    last_df = a_df[a_df['ma60'] > a_df['ma120']]\n",
    "    last_price_df = pure_df.loc[pure_df['date'] == datelist[-1]]\n",
    "\n",
    "    for i in datelist:\n",
    "        first_df = df2.loc[df2['date'] == i]\n",
    "        first_price_df = pure_df.loc[pure_df['date'] == i]\n",
    "        one_df = pd.merge(first_df,last_df,on='code')\n",
    "        reset_index_df = last_df.reset_index()\n",
    "        one_df['code']= reset_index_df['code']\n",
    "        ma_df = pd.merge(first_price_df[['close','code']],one_df,on='code')\n",
    "        two_df = pd.merge(last_price_df[['close','code']],ma_df,on='code')\n",
    "        two_df.columns= ['price_y','code', 'price_x', 'close_x', 'ma60_x', 'ma120_x', 'volume_x','name_x', 'date_x', 'close_y', 'ma60_y', 'ma120_y', 'volume_y','name_y', 'date_y']\n",
    "        ma120_df = two_df[['name_x','code','close_x','close_y','ma60_x','ma60_y','ma120_x','ma120_y','price_x','price_y','date_x']]\n",
    "        ma120_df['price_diff']=ma120_df['price_y']/ma120_df['price_x']\n",
    "        ma120_df =  ma120_df.sort_values([\"price_diff\"],ascending=False)\n",
    "        second_df =  first_df.sort_values([\"ma120\"],ascending=False)\n",
    "        #ma120_df['price_x']=first_price_df['close'].values\n",
    "        #ma120_df['price_y']=last_price_df['close'].values\n",
    "        strdate = i.strftime('%Y-%m-%d')\n",
    "        #second_df.to_excel(path+strdate+'.xlsx')\n",
    "        if select_start == select_start_a:\n",
    "            ma120_df.to_excel(path_total_a+strdate+'.xlsx')\n",
    "        else:\n",
    "            ma120_df.to_excel(path_total_b+strdate+'.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  전종목 검색하여  종가 > ma120  일일 비교  하여  관심 종목 추출_8  total_a(1년분) ,total_b(11년분) 의 공통종목을 추출\n",
    "\n",
    "from mod1 import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
    "\n",
    "path = 'd:\\\\stockdata\\\\close_ma120\\\\close_ma120_'\n",
    "path_total = 'd:\\\\stockdata\\\\close_ma120\\\\total_'\n",
    "path_total_a = 'd:\\\\stockdata\\\\close_ma120\\\\total_a_'\n",
    "path_total_b = 'd:\\\\stockdata\\\\close_ma120\\\\total_b_'\n",
    "\n",
    "select_query = \"select * from market where Name='hrs' and Date >= '2019-10-01' \"\n",
    "df3 = pd.read_sql(select_query, engine)\n",
    "\n",
    "df3 = df3['Date']\n",
    "datelist = df3.to_list()\n",
    "\n",
    "for i in datelist:\n",
    "    strdate = i.strftime('%Y-%m-%d')\n",
    "    df_a = pd.read_excel(path_total_a+strdate+'.xlsx')\n",
    "    df_b = pd.read_excel(path_total_b+strdate+'.xlsx')\n",
    "    #df_ab = pd.DataFrame()\n",
    "    df_ab = pd.merge(df_a[['name_x']],df_b,on='name_x')\n",
    "    \n",
    "    total_df = df_ab[['name_x', 'code', 'close_x', 'close_y', 'ma60_x', 'ma60_y', 'ma120_x', 'ma120_y', 'price_x', 'price_y', 'date_x','volume_z', 'price_diff']]\n",
    "    total_df.to_excel(path_total+strdate+'.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  전종목 검색하여  종가 > ma120  일일 비교  하여  관심 종목 추출_9  total_a(1년분) ,total_b(11년분) 추출 및  공통종목을 추출\n",
    "\n",
    "from mod1 import *\n",
    "#import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "#from pandas.core.common import SettingWithCopyWarning\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
    "\n",
    "path = 'd:\\\\stockdata\\\\close_ma120\\\\close_ma120_'\n",
    "path_total = 'd:\\\\stockdata\\\\close_ma120\\\\total_'\n",
    "path_total_f = 'd:\\\\stockdata\\\\close_ma120\\\\total_filter_'\n",
    "path_total_a = 'd:\\\\stockdata\\\\close_ma120\\\\total_a_'\n",
    "path_total_b = 'd:\\\\stockdata\\\\close_ma120\\\\total_b_'\n",
    "path_total_c = 'd:\\\\stockdata\\\\close_ma120\\\\total_c_'\n",
    "\n",
    "\n",
    "df = all_stock('2019-10-10')\n",
    "df = df['Name']\n",
    "name = df.to_list()\n",
    "    \n",
    "select_start_a = '2019-01-01'\n",
    "select_start_b = '2008-01-01'\n",
    "\n",
    "select_query = \"select * from market where Name='hrs' and Date >= '2019-10-01' \"\n",
    "df3 = pd.read_sql(select_query, engine)\n",
    "\n",
    "df3 = df3['Date']\n",
    "datelist = df3.to_list()\n",
    "    \n",
    "def search_stock(name,select_start):   \n",
    "    print(name)\n",
    "    print(select_start)\n",
    "    pure_df = pd.DataFrame()\n",
    "    df2 = pd.DataFrame() \n",
    "    for i in name:\n",
    "        #print(i)\n",
    "        df=select_stock(i,select_start)\n",
    "        #print(df)\n",
    "        pure_df = pure_df.append(df)\n",
    "        ma(df)\n",
    "\n",
    "        source = MinMaxScaler()\n",
    "        data = source.fit_transform(df[['close','ma60','ma120','volume']].values)\n",
    "        df1 = pd.DataFrame(data)\n",
    "        df1['name']=i\n",
    "        df1.columns=['close','ma60','ma120','volume','name']\n",
    "        df1[['date','code']] = df[['date','code']]\n",
    "        #print(df1)\n",
    "        df2 = df2.append(df1)\n",
    "\n",
    "    pure_df.columns = map(str.lower, pure_df.columns) ## \n",
    "\n",
    "    last_df = df2.loc[df2['date'] == datelist[-1]]\n",
    "    last_close_df = last_df[last_df['close'] < 0.1]\n",
    "    last_ma_df = last_df[last_df['ma120'] < 0.1]\n",
    "    a_df = last_ma_df[last_ma_df['close'] > last_ma_df['ma60']] \n",
    "    last_ma_df = a_df[a_df['ma60'] > a_df['ma120']]\n",
    "    last_price_df = pure_df.loc[pure_df['date'] == datelist[-1]]\n",
    "    \n",
    "    for i in datelist:\n",
    "        first_df = df2.loc[df2['date'] == i]\n",
    "        first_price_df = pure_df.loc[pure_df['date'] == i]\n",
    "        one_close_df = pd.merge(first_df,last_close_df,on='code')\n",
    "        one_df = pd.merge(first_df,last_ma_df,on='code')\n",
    "        reset_close_df = last_close_df.reset_index()\n",
    "        reset_ma_df = last_ma_df.reset_index()\n",
    "        one_close_df['code']= reset_close_df['code']\n",
    "        one_df['code']= reset_ma_df['code']\n",
    "        close_df = pd.merge(first_price_df[['close','code']],one_close_df,on='code')\n",
    "        ma_df = pd.merge(first_price_df[['close','code']],one_df,on='code')        \n",
    "        two_close_df = pd.merge(last_price_df[['close','code','volume']],close_df,on='code')\n",
    "        two_df = pd.merge(last_price_df[['close','code','volume']],ma_df,on='code')\n",
    "        two_close_df.columns= ['price_y','code', 'volume_z','price_x', 'close_x', 'ma60_x', 'ma120_x', 'volume_x','name_x', 'date_x', 'close_y', 'ma60_y', 'ma120_y', 'volume_y','name_y', 'date_y']\n",
    "        two_df.columns= ['price_y','code', 'volume_z','price_x', 'close_x', 'ma60_x', 'ma120_x', 'volume_x','name_x', 'date_x', 'close_y', 'ma60_y', 'ma120_y', 'volume_y','name_y', 'date_y']\n",
    "\n",
    "        price_df = two_close_df[['name_x','code','close_x','close_y','ma60_x','ma60_y','ma120_x','ma120_y','price_x','price_y','date_x','volume_z']]\n",
    "        ma120_df = two_df[['name_x','code','close_x','close_y','ma60_x','ma60_y','ma120_x','ma120_y','price_x','price_y','date_x','volume_z']]\n",
    "        price_df['price_diff']=price_df['price_y']/price_df['price_x']\n",
    "        ma120_df['price_diff']=ma120_df['price_y']/ma120_df['price_x']\n",
    "        price_df =  price_df.sort_values([\"price_diff\"],ascending=True)\n",
    "        ma120_df =  ma120_df.sort_values([\"price_diff\"],ascending=True)\n",
    "        second_df =  first_df.sort_values([\"ma120\"],ascending=True)\n",
    "        #ma120_df['price_x']=first_price_df['close'].values\n",
    "        #ma120_df['price_y']=last_price_df['close'].values\n",
    "        strdate = i.strftime('%Y-%m-%d')\n",
    "       \n",
    "        if select_start == select_start_a:\n",
    "            ma120_df.to_excel(path_total_a+strdate+'.xlsx')\n",
    "            price_df.to_excel(path_total_c+strdate+'.xlsx')\n",
    "        else:\n",
    "            ma120_df.to_excel(path_total_b+strdate+'.xlsx')\n",
    "            second_df.to_excel(path+strdate+'.xlsx')\n",
    "            \n",
    "def total_ab_intersection( ):\n",
    "    for i in datelist:\n",
    "        strdate = i.strftime('%Y-%m-%d')\n",
    "        df_a = pd.read_excel(path_total_a+strdate+'.xlsx')\n",
    "        filter_df_a = df_a[df_a['close_y'] < 0.2]\n",
    "        df_b = pd.read_excel(path_total_b+strdate+'.xlsx')\n",
    "        #df_ab = pd.DataFrame()\n",
    "        df_ab = pd.merge(df_a[['name_x']],df_b,on='name_x')\n",
    "        filter_df_ab = pd.merge(filter_df_a[['name_x']],df_b,on='name_x')\n",
    "\n",
    "        total_df = df_ab[['name_x', 'code', 'close_x', 'close_y', 'ma60_x', 'ma60_y', 'ma120_x', 'ma120_y', 'price_x', 'price_y', 'date_x','volume_z', 'price_diff']]\n",
    "        filter_total_df = filter_df_ab[['name_x', 'code', 'close_x', 'close_y', 'ma60_x', 'ma60_y', 'ma120_x', 'ma120_y', 'price_x', 'price_y', 'date_x','volume_z', 'price_diff']]\n",
    "        total_df.to_excel(path_total+strdate+'.xlsx')\n",
    "        filter_total_df.to_excel(path_total_f+strdate+'.xlsx') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  전종목 검색하여  종가 > ma120  일일 비교  하여  관심 종목 추출_9  total_a(1년분) ,total_b(11년분) 추출 및  공통종목을 추출 another method\n",
    "\n",
    "from mod1 import *\n",
    "#import pandas as pd\n",
    "\n",
    "path = 'd:\\\\test\\\\close_ma120_'\n",
    "path_total = 'd:\\\\test\\\\total_'\n",
    "path_total_a = 'd:\\\\test\\\\total_a_'\n",
    "path_total_b = 'd:\\\\test\\\\total_b_'\n",
    "path_total_c = 'd:\\\\test\\\\total_c_'\n",
    "\n",
    "#df = all_stock('2019-10-10')\n",
    "#df = df['Name']\n",
    "#name = df.to_list()\n",
    "    \n",
    "name = ['HRS','디엔에프','푸드나무','화성밸브','미래생명자원','웹케시']\n",
    "\n",
    "select_start_a = '2019-01-01'\n",
    "select_start_b = '2008-01-01'\n",
    "\n",
    "select_query = \"select * from market where Name='hrs' and Date >= '2019-10-01' \"\n",
    "df3 = pd.read_sql(select_query, engine)\n",
    "\n",
    "df3 = df3['Date']\n",
    "datelist = df3.to_list()\n",
    "    \n",
    "def search_stock(name,select_start_a,select_start_b):   \n",
    "    #print(name)\n",
    "    #print(select_start)\n",
    "    pure_df_a = pd.DataFrame()\n",
    "    df2_a = pd.DataFrame() \n",
    "    pure_df_b = pd.DataFrame()\n",
    "    df2_b = pd.DataFrame() \n",
    "    for i in name:\n",
    "        #print(i)\n",
    "        df_a=select_stock(i,select_start_a)\n",
    "        df_b=select_stock(i,select_start_b)\n",
    "        #print(df)\n",
    "        pure_df_a = pure_df_a.append(df_a)\n",
    "        pure_df_b = pure_df_b.append(df_b)\n",
    "        ma(df_a)\n",
    "        ma(df_b)\n",
    "\n",
    "        source = MinMaxScaler()\n",
    "        data_a = source.fit_transform(df_a[['close','ma60','ma120','volume']].values)\n",
    "        data_b = source.fit_transform(df_b[['close','ma60','ma120','volume']].values)\n",
    "        df1_a = pd.DataFrame(data_a)\n",
    "        df1_b = pd.DataFrame(data_b)\n",
    "        df1_a['name']=i\n",
    "        df1_b['name']=i\n",
    "        df1_a.columns=['close','ma60','ma120','volume','name']\n",
    "        df1_b.columns=['close','ma60','ma120','volume','name']\n",
    "        df1_a[['date','code','price']] = df_a[['date','code','close']]\n",
    "        df1_b[['date','code','price']] = df_b[['date','code','close']]\n",
    "        df2_a = df2_a.append(df1_a)\n",
    "        df2_b = df2_b.append(df1_b)        \n",
    "        \n",
    "    pure_df_a.columns = map(str.lower, pure_df_a.columns) ## \n",
    "    pure_df_b.columns = map(str.lower, pure_df_a.columns) ##\n",
    "    \n",
    "    pure_df_a = pure_df_a[['name','close','volume','date']]\n",
    "    pure_df_b = pure_df_b[['name','close','volume','date']]\n",
    "        \n",
    "    choice_day = pd.Timestamp('2019-09-30 00:00:00')\n",
    "    c = df2_a[df2_a['date']>choice_day]\n",
    "    d = df2_b[df2_b['date']>choice_day]\n",
    "    e = pure_df_a[pure_df_a['date']>choice_day]\n",
    "    f = pure_df_b[pure_df_b['date']>choice_day]\n",
    "    \n",
    "    last_df_a = c.loc[c['date'] == datelist[-1]]\n",
    "    last_close_df_a = last_df_a[last_df_a['close'] < 0.1]\n",
    "    last_ma_df_a = last_df_a[last_df_a['ma120'] < 0.1]\n",
    "    a_df_a = last_ma_df_a[last_ma_df_a['close'] > last_ma_df_a['ma60']] \n",
    "    last_ma_df_a = a_df_a[a_df_a['ma60'] > a_df_a['ma120']]\n",
    "    last_price_df_a = e.loc[e['date'] == datelist[-1]]\n",
    "    last_price_df_a = last_price_df_a[['name','volume']]\n",
    "    last_ma_df_a  = pd.merge(last_ma_df_a,last_price_df_a,on='name')\n",
    "\n",
    "    last_df_b = d.loc[d['date'] == datelist[-1]]\n",
    "    last_close_df_b = last_df_b[last_df_b['close'] < 0.1]\n",
    "    last_ma_df_b = last_df_b[last_df_b['ma120'] < 0.1]\n",
    "    a_df_b = last_ma_df_b[last_ma_df_b['close'] > last_ma_df_b['ma60']] \n",
    "    last_ma_df_b = a_df_b[a_df_b['ma60'] > a_df_b['ma120']]\n",
    "    last_price_df_b = f.loc[f['date'] == datelist[-1]]\n",
    "    last_price_df_b = last_price_df_b[['name','volume']]\n",
    "    last_ma_df_b  = pd.merge(last_ma_df_b,last_price_df_b,on='name')\n",
    "    \n",
    "    g = last_ma_df_a\n",
    "    h = last_ma_df_b\n",
    "    \n",
    "    a = pd.merge(c,g, on='name')\n",
    "    b = pd.merge(d,h, on='name')\n",
    "    \n",
    "    a['price_diff']=a['price_y']/a['price_x']\n",
    "    b['price_diff']=b['price_y']/b['price_x']\n",
    "    #g['volume_z'] = last_price_df_a['volume']\n",
    "    a = a[['name','code_x','close_x','close_y','ma60_x','ma60_y','ma120_x','ma120_y','price_x','price_y','date_x','volume_y','price_diff']]\n",
    "    b = b[['name','code_x','close_x','close_y','ma60_x','ma60_y','ma120_x','ma120_y','price_x','price_y','date_x','volume_y','price_diff']]\n",
    "    \n",
    "    for i in datelist:\n",
    "        t = pd.Timestamp(i)\n",
    "        first_df = a.loc[a['date_x'] == t]             ##  표준화 dataframe \n",
    "        second_df = b.loc[b['date_x'] == t] \n",
    "        strdate = t.strftime('%Y-%m-%d')\n",
    "        first_df =  first_df.sort_values([\"price_diff\"],ascending=True)\n",
    "        second_df = second_df.sort_values([\"price_diff\"],ascending=True)\n",
    "        first_df.to_excel(path_total_a+strdate+'.xlsx')  ##  표준화 dataframe 중 ma120 < 0.1 and close > ma60 > ma120 (from 2019.01.01)\n",
    "        second_df.to_excel(path_total_b+strdate+'.xlsx')  ##  표준화 dataframe 중 ma120 < 0.1 and close > ma60 > ma120 (from 2008.01.01) \n",
    "        \n",
    "search_stock(name,select_start_a,select_start_b)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  샘플로 간략하게  검색하여  종가 > ma120  일일 비교  하여  관심 종목 추출_9  total_a(1년분) ,total_b(11년분) 추출 및  공통종목을 추출\n",
    "\n",
    "\n",
    "from mod1 import *\n",
    "#import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "#from pandas.core.common import SettingWithCopyWarning\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
    "\n",
    "path = 'd:\\\\test\\\\close_ma120_'\n",
    "path_total = 'd:\\\\test\\\\total_'\n",
    "path_total_a = 'd:\\\\test\\\\total_a_'\n",
    "path_total_b = 'd:\\\\test\\\\total_b_'\n",
    "path_total_c = 'd:\\\\test\\\\total_c_'\n",
    "path_total_f = 'd:\\\\test\\\\total_filter_'\n",
    "\n",
    "#df = all_stock('2019-10-10')\n",
    "#df = df['Name']\n",
    "#name = df.to_list()\n",
    "    \n",
    "name = ['hrs','디엔에프','푸드나무','화성밸브','미래생명자원','웹케시']\n",
    "\n",
    "select_start_a = '2019-01-01'\n",
    "select_start_b = '2008-01-01'\n",
    "\n",
    "select_query = \"select * from market where Name='hrs' and Date >= '2019-10-01' \"\n",
    "df3 = pd.read_sql(select_query, engine)\n",
    "\n",
    "df3 = df3['Date']\n",
    "datelist = df3.to_list()\n",
    "    \n",
    "def search_stock(name,select_start):   \n",
    "    print(name)\n",
    "    print(select_start)\n",
    "    pure_df = pd.DataFrame()\n",
    "    df2 = pd.DataFrame() \n",
    "    for i in name:\n",
    "        #print(i)\n",
    "        df=select_stock(i,select_start)\n",
    "        #print(df)\n",
    "        pure_df = pure_df.append(df)\n",
    "        ma(df)\n",
    "\n",
    "        source = MinMaxScaler()\n",
    "        data = source.fit_transform(df[['close','ma60','ma120','volume']].values)\n",
    "        df1 = pd.DataFrame(data)\n",
    "        df1['name']=i\n",
    "        df1.columns=['close','ma60','ma120','volume','name']\n",
    "        df1[['date','code']] = df[['date','code']]\n",
    "        #print(df1)\n",
    "        df2 = df2.append(df1)\n",
    "\n",
    "    pure_df.columns = map(str.lower, pure_df.columns) ## \n",
    "\n",
    "    last_df = df2.loc[df2['date'] == datelist[-1]]\n",
    "    last_close_df = last_df[last_df['close'] < 0.1]\n",
    "    last_ma_df = last_df[last_df['ma120'] < 0.1]\n",
    "    a_df = last_ma_df[last_ma_df['close'] > last_ma_df['ma60']] \n",
    "    last_ma_df = a_df[a_df['ma60'] > a_df['ma120']]\n",
    "    last_price_df = pure_df.loc[pure_df['date'] == datelist[-1]]\n",
    "    \n",
    "    for i in datelist:\n",
    "        first_df = df2.loc[df2['date'] == i]\n",
    "        first_price_df = pure_df.loc[pure_df['date'] == i]\n",
    "        one_close_df = pd.merge(first_df,last_close_df,on='code')\n",
    "        one_df = pd.merge(first_df,last_ma_df,on='code')\n",
    "        reset_close_df = last_close_df.reset_index()\n",
    "        reset_ma_df = last_ma_df.reset_index()\n",
    "        one_close_df['code']= reset_close_df['code']\n",
    "        one_df['code']= reset_ma_df['code']\n",
    "        close_df = pd.merge(first_price_df[['close','code']],one_close_df,on='code')\n",
    "        ma_df = pd.merge(first_price_df[['close','code']],one_df,on='code')        \n",
    "        two_close_df = pd.merge(last_price_df[['close','code','volume']],close_df,on='code')\n",
    "        two_df = pd.merge(last_price_df[['close','code','volume']],ma_df,on='code')\n",
    "        two_close_df.columns= ['price_y','code', 'volume_z','price_x', 'close_x', 'ma60_x', 'ma120_x', 'volume_x','name_x', 'date_x', 'close_y', 'ma60_y', 'ma120_y', 'volume_y','name_y', 'date_y']\n",
    "        two_df.columns= ['price_y','code', 'volume_z','price_x', 'close_x', 'ma60_x', 'ma120_x', 'volume_x','name_x', 'date_x', 'close_y', 'ma60_y', 'ma120_y', 'volume_y','name_y', 'date_y']\n",
    "\n",
    "        price_df = two_close_df[['name_x','code','close_x','close_y','ma60_x','ma60_y','ma120_x','ma120_y','price_x','price_y','date_x','volume_z']]\n",
    "        ma120_df = two_df[['name_x','code','close_x','close_y','ma60_x','ma60_y','ma120_x','ma120_y','price_x','price_y','date_x','volume_z']]\n",
    "        price_df['price_diff']=price_df['price_y']/price_df['price_x']\n",
    "        ma120_df['price_diff']=ma120_df['price_y']/ma120_df['price_x']\n",
    "        price_df =  price_df.sort_values([\"price_diff\"],ascending=True)\n",
    "        ma120_df =  ma120_df.sort_values([\"price_diff\"],ascending=True)\n",
    "        second_df =  first_df.sort_values([\"ma120\"],ascending=True)\n",
    "        #ma120_df['price_x']=first_price_df['close'].values\n",
    "        #ma120_df['price_y']=last_price_df['close'].values\n",
    "        strdate = i.strftime('%Y-%m-%d')\n",
    "       \n",
    "        if select_start == select_start_a:\n",
    "            ma120_df.to_excel(path_total_a+strdate+'.xlsx')\n",
    "            price_df.to_excel(path_total_c+strdate+'.xlsx')\n",
    "        else:\n",
    "            ma120_df.to_excel(path_total_b+strdate+'.xlsx')\n",
    "            second_df.to_excel(path+strdate+'.xlsx')\n",
    "\n",
    "def total_ab_intersection( ):\n",
    "    for i in datelist:\n",
    "        strdate = i.strftime('%Y-%m-%d')\n",
    "        df_a = pd.read_excel(path_total_a+strdate+'.xlsx')\n",
    "        filter_df_a = df_a[df_a['close_y'] < 0.2]\n",
    "        df_b = pd.read_excel(path_total_b+strdate+'.xlsx')\n",
    "        #df_ab = pd.DataFrame()\n",
    "        df_ab = pd.merge(df_a[['name_x']],df_b,on='name_x')\n",
    "        filter_df_ab = pd.merge(filter_df_a[['name_x']],df_b,on='name_x')\n",
    "\n",
    "        total_df = df_ab[['name_x', 'code', 'close_x', 'close_y', 'ma60_x', 'ma60_y', 'ma120_x', 'ma120_y', 'price_x', 'price_y', 'date_x','volume_z', 'price_diff']]\n",
    "        filter_total_df = filter_df_ab[['name_x', 'code', 'close_x', 'close_y', 'ma60_x', 'ma60_y', 'ma120_x', 'ma120_y', 'price_x', 'price_y', 'date_x','volume_z', 'price_diff']]\n",
    "        total_df.to_excel(path_total+strdate+'.xlsx')\n",
    "        filter_total_df.to_excel(path_total_f+strdate+'.xlsx') \n",
    "            \n",
    "            \n",
    "#search_stock(name,select_start_b)\n",
    "total_ab_intersection( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##  관심종목에서 종가 비교하기\n",
    "\n",
    "from mod1 import *\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "\n",
    "path = 'd:\\\\stockdata\\\\close_ma120\\\\close_ma120_'\n",
    "\n",
    "back_date=1\n",
    "choice_date='2019-10-18'\n",
    "\n",
    "df = pd.read_excel(path+choice_date+'.xlsx')\n",
    "df = df['name']\n",
    "name = df.to_list()\n",
    "\n",
    "df1 = pd.DataFrame()\n",
    "diff_df = pd.DataFrame()\n",
    "for i in name:\n",
    "    #print(i)\n",
    "    df=select_stock(i,'2019-01-01')\n",
    "    df1 = df1.append(df)\n",
    "\n",
    "last = len(df1[df1['Name'] == name[0]])-1\n",
    "price_startday_df = df1[df1.index == (last-back_date)]\n",
    "price_today_df = df1[df1.index == last]\n",
    "\n",
    "diff_df = pd.merge(price_startday_df[['Name','Close']],price_today_df[['Name','Close']],on='Name')\n",
    "diff_df.columns=['name','price_startday','price_today']\n",
    "diff_df['diff']=diff_df['price_today']/diff_df['price_startday']\n",
    "\n",
    "price_up = diff_df[diff_df['diff'] > 1]\n",
    "price_down = diff_df[diff_df['diff'] < 1]\n",
    "price_sum=len(price_up)+len(price_down)\n",
    "print('price_up = {}'.format(len(price_up)))\n",
    "print('price_down = {}'.format(len(price_down)))\n",
    "    \n",
    "print('win_rate={}%'.format((len(price_up)/price_sum)*100))\n",
    "\n",
    "display((price_up.sort_values([\"diff\"],ascending=False).head(10)))\n",
    "display(price_down.sort_values(['diff']).head(10))\n",
    "display(diff_df.describe())\n",
    "\n",
    "#sort_df = diff_df.sort_values([\"diff\"],ascending=False)  ##  상승, 하락 을  순서별로 정렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mod1 import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "\n",
    "path = 'd:\\\\stockdata\\\\close_ma120\\\\close_ma120_'\n",
    "path_total = 'd:\\\\stockdata\\\\close_ma120\\\\total_'\n",
    "\n",
    "df = all_stock('2019-10-10')\n",
    "df = df['Name']\n",
    "name = df.to_list()\n",
    "\n",
    "pure_df = pd.DataFrame()\n",
    "df2 = pd.DataFrame()\n",
    "for i in name:\n",
    "    #print(i)\n",
    "    df=select_stock(i,'2008-01-01')\n",
    "    pure_df = pure_df.append(df)\n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close','ma60','ma120','volume']].values)\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1['name']=i\n",
    "    df1.columns=['close','ma60','ma120','volume','name']\n",
    "    df1[['date','code']] = df[['date','code']]\n",
    "    #print(df1)\n",
    "    df2 = df2.append(df1)\n",
    "\n",
    "pure_df.columns = map(str.lower, pure_df.columns) ## \n",
    " \n",
    "select_query = \"select * from market where Name='hrs' and Date >= '2019-10-01' and Date < '2019-11-01' \"\n",
    "df3 = pd.read_sql(select_query, engine)\n",
    "\n",
    "df3 = df3['Date']\n",
    "datelist = df3.to_list()\n",
    "\n",
    "last_df = df2.loc[df2['date'] == datelist[-1]]\n",
    "last_df = last_df[last_df['ma120'] < 0.1]\n",
    "last_price_df = pure_df.loc[pure_df['date'] == datelist[-1]]\n",
    "\n",
    "for i in datelist:\n",
    "    first_df = df2.loc[df2['date'] == i]\n",
    "    first_price_df = pure_df.loc[pure_df['date'] == i]\n",
    "    one_df = pd.merge(first_df,last_df,on='code')\n",
    "    reset_index_df = last_df.reset_index()\n",
    "    one_df['code']= reset_index_df['code']\n",
    "    ma_df = pd.merge(first_price_df[['close','code']],one_df,on='code')\n",
    "    two_df = pd.merge(last_price_df[['close','code']],ma_df,on='code')\n",
    "    two_df.columns= ['price_y','code', 'price_x', 'close_x', 'ma60_x', 'ma120_x', 'volume_x','name_x', 'date_x', 'close_y', 'ma60_y', 'ma120_y', 'volume_y','name_y', 'date_y']\n",
    "    ma120_df = two_df[['name_x','code','close_x','close_y','ma60_x','ma60_y','ma120_x','ma120_y','price_x','price_y','date_x']]\n",
    "    ma120_df['price_diff']=ma120_df['price_y']/ma120_df['price_x']\n",
    "    ma120_df =  ma120_df.sort_values([\"price_diff\"],ascending=False)\n",
    "    second_df =  first_df.sort_values([\"ma120\"],ascending=False)\n",
    "    #ma120_df['price_x']=first_price_df['close'].values\n",
    "    #ma120_df['price_y']=last_price_df['close'].values\n",
    "    strdate = i.strftime('%Y-%m-%d')\n",
    "    second_df.to_excel(path+strdate+'.xlsx')\n",
    "    ma120_df.to_excel(path_total+strdate+'.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  관심종목  ma120 일선 비교하기\n",
    "\n",
    "from mod1 import *\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "\n",
    "path = 'd:\\\\stockdata\\\\close_ma120\\\\close_ma120_'\n",
    "\n",
    "back_date=1\n",
    "choice_date='2019-10-25'\n",
    "\n",
    "df = pd.read_excel(path+choice_date+'.xlsx')\n",
    "df = df['name']\n",
    "name = df.to_list()\n",
    "\n",
    "df1 = pd.DataFrame()\n",
    "diff_df = pd.DataFrame()\n",
    "ma120_df2 = pd.DataFrame()\n",
    "for i in name:\n",
    "    #print(i)\n",
    "    df=select_stock(i,'2010-01-01')\n",
    "    df1 = df1.append(df)    \n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close','ma120','volume']].values)\n",
    "    ma120_df1 = pd.DataFrame(data)\n",
    "    ma120_df1['Name']=i\n",
    "    ma120_df1.columns=['close','ma120','volume','name',]\n",
    "    ma120_df1['date'] = df['date']\n",
    "    #print(df1)\n",
    "    ma120_df2 = ma120_df2.append(ma120_df1)\n",
    "    \n",
    "\n",
    "last = len(ma120_df2[ma120_df2['name'] == name[0]])-1\n",
    "startday_df = ma120_df2[ma120_df2.index == (last-back_date)]\n",
    "#yesterday_df = df2[df2.index == (last-1)]\n",
    "today_df = ma120_df2[ma120_df2.index == last]\n",
    "\n",
    "ma120_diff_df = pd.merge(startday_df[['name','ma120']],today_df[['name','ma120']],on='name')\n",
    "ma120_diff_df.columns=['name','startday','today']\n",
    "ma120_diff_df['diff']=ma120_diff_df['today']/ma120_diff_df['startday']\n",
    "\n",
    "ma120_up = ma120_diff_df[ma120_diff_df['diff'] > 1]\n",
    "ma120_down = ma120_diff_df[ma120_diff_df['diff'] < 1]\n",
    "ma120_sum=len(ma120_up)+len(ma120_down)\n",
    "print('ma120_up = {}'.format(len(ma120_up)))\n",
    "print('ma120_down = {}'.format(len(ma120_down)))\n",
    "    \n",
    "print('win_rate={}%'.format((len(ma120_up)/ma120_sum)*100))\n",
    "\n",
    "display((ma120_up.sort_values([\"diff\"],ascending=False).head(10)))\n",
    "display(ma120_down.sort_values(['diff']).head(10))\n",
    "display(ma120_diff_df.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  관심종목  종가, ma120 일선별로   상세히 비교 하기\n",
    "\n",
    "from mod1 import *\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "\n",
    "path = 'd:\\\\stockdata\\\\close_ma120\\\\close_ma120_'\n",
    "path_total = 'd:\\\\stockdata\\\\close_ma120\\\\total_'\n",
    "\n",
    "back_date=1\n",
    "choice_date='2019-10-25'\n",
    "\n",
    "df = pd.read_excel(path+choice_date+'.xlsx')\n",
    "df = df['name']\n",
    "name = df.to_list()\n",
    "\n",
    "df1 = pd.DataFrame()\n",
    "diff_df = pd.DataFrame()\n",
    "ma120_df2 = pd.DataFrame()\n",
    "for i in name:\n",
    "    #print(i)\n",
    "    df=select_stock(i,'2010-01-01')\n",
    "    df1 = df1.append(df)    \n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close','ma120','volume']].values)\n",
    "    ma120_df1 = pd.DataFrame(data)\n",
    "    ma120_df1['Name']=i\n",
    "    ma120_df1.columns=['close','ma120','volume','name',]\n",
    "    ma120_df1['date'] = df['date']\n",
    "    #print(df1)\n",
    "    ma120_df2 = ma120_df2.append(ma120_df1)\n",
    "    \n",
    "\n",
    "last = len(ma120_df2[ma120_df2['name'] == name[0]])-1\n",
    "ma120_startday_df = ma120_df2[ma120_df2.index == (last-back_date)]\n",
    "ma120_today_df = ma120_df2[ma120_df2.index == last]\n",
    "price_startday_df = df1[df1.index == (last-back_date)]\n",
    "price_today_df = df1[df1.index == last]\n",
    "\n",
    "ma120_diff_df = pd.merge(ma120_startday_df[['name','ma120']],ma120_today_df[['name','ma120']],on='name')\n",
    "ma120_diff_df.columns=['name','ma120_startday','ma120_today']\n",
    "ma120_diff_df['ma120_diff']=ma120_diff_df['ma120_today']/ma120_diff_df['ma120_startday']\n",
    "\n",
    "diff_df = pd.merge(price_startday_df[['Name','Close']],price_today_df[['Name','Close']],on='Name')\n",
    "diff_df.columns=['name','price_startday','price_today']\n",
    "diff_df['price_diff']=diff_df['price_today']/diff_df['price_startday']\n",
    "\n",
    "ma120_up = ma120_diff_df[ma120_diff_df['ma120_diff'] > 1]\n",
    "ma120_down = ma120_diff_df[ma120_diff_df['ma120_diff'] < 1]\n",
    "ma120_sum=len(ma120_up)+len(ma120_down)\n",
    "\n",
    "price_up = diff_df[diff_df['price_diff'] > 1]\n",
    "price_down = diff_df[diff_df['price_diff'] < 1]\n",
    "price_sum=len(price_up)+len(price_down)\n",
    "\n",
    "print('ma120_up = {}'.format(len(ma120_up)))\n",
    "print('ma120_down = {}'.format(len(ma120_down)))\n",
    "    \n",
    "print('win_rate={}%'.format((len(ma120_up)/ma120_sum)*100))\n",
    "\n",
    "display((ma120_up.sort_values([\"ma120_diff\"],ascending=False).head(10)))\n",
    "display(ma120_down.sort_values(['ma120_diff']).head(10))\n",
    "display(ma120_diff_df.describe())\n",
    "\n",
    "print('price_up = {}'.format(len(price_up)))\n",
    "print('price_down = {}'.format(len(price_down)))\n",
    "    \n",
    "print('win_rate={}%'.format((len(price_up)/price_sum)*100))\n",
    "\n",
    "display((price_up.sort_values([\"price_diff\"],ascending=False).head(10)))\n",
    "display(price_down.sort_values(['price_diff']).head(10))\n",
    "display(diff_df.describe())\n",
    "\n",
    "total_df = pd.merge(ma120_diff_df,diff_df,on='name')\n",
    "total_df = total_df.sort_values([\"price_diff\"],ascending=False)\n",
    "total_df.to_excel(path_total+choice_date+'.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  관심종목  종가, ma120 일선별로 상세히 비교 하기 _ back_date 자동계산 및 Volume 추가\n",
    "\n",
    "from mod1 import *\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "\n",
    "path = 'd:\\\\stockdata\\\\close_ma120\\\\close_ma120_'\n",
    "path_total = 'd:\\\\stockdata\\\\close_ma120\\\\total_'\n",
    "\n",
    "choice_date='2019-10-11'\n",
    "select_query = \"select count(*) from market_good where Name='hrs' and Date > \"\n",
    "var = select_query +\"'\"+choice_date+\"'\" \n",
    "df = pd.read_sql(var, engine)\n",
    "count = df.values.tolist()\n",
    "back_date = count[0][0]\n",
    "\n",
    "df = pd.read_excel(path+choice_date+'.xlsx')\n",
    "df = df['name']\n",
    "name = df.to_list()\n",
    "\n",
    "df1 = pd.DataFrame()\n",
    "diff_df = pd.DataFrame()\n",
    "ma120_df2 = pd.DataFrame()\n",
    "for i in name:\n",
    "    #print(i)\n",
    "    df=select_stock(i,'2010-01-01')\n",
    "    df1 = df1.append(df)    \n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close','ma120','volume']].values)\n",
    "    ma120_df1 = pd.DataFrame(data)\n",
    "    ma120_df1['Name']=i\n",
    "    ma120_df1.columns=['close','ma120','volume','name',]\n",
    "    ma120_df1['date'] = df['date']\n",
    "    #print(df1)\n",
    "    ma120_df2 = ma120_df2.append(ma120_df1)\n",
    "    \n",
    "\n",
    "last = len(ma120_df2[ma120_df2['name'] == name[0]])-1\n",
    "ma120_startday_df = ma120_df2[ma120_df2.index == (last-back_date)]\n",
    "ma120_today_df = ma120_df2[ma120_df2.index == last]\n",
    "price_startday_df = df1[df1.index == (last-back_date)]\n",
    "price_today_df = df1[df1.index == last]\n",
    "\n",
    "ma120_diff_df = pd.merge(ma120_startday_df[['name','ma120']],ma120_today_df[['name','ma120']],on='name')\n",
    "ma120_diff_df.columns=['name','ma120_startday','ma120_today']\n",
    "ma120_diff_df['ma120_diff']=ma120_diff_df['ma120_today']/ma120_diff_df['ma120_startday']\n",
    "\n",
    "diff_df = pd.merge(price_startday_df[['Name','Close','Volume']],price_today_df[['Name','Close','Volume']],on='Name')\n",
    "diff_df.columns=['name','price_startday','volume_startday','price_today','volume_today']\n",
    "diff_df['price_diff']=diff_df['price_today']/diff_df['price_startday']\n",
    "\n",
    "ma120_up = ma120_diff_df[ma120_diff_df['ma120_diff'] > 1]\n",
    "ma120_down = ma120_diff_df[ma120_diff_df['ma120_diff'] < 1]\n",
    "ma120_sum=len(ma120_up)+len(ma120_down)\n",
    "\n",
    "price_up = diff_df[diff_df['price_diff'] > 1]\n",
    "price_down = diff_df[diff_df['price_diff'] < 1]\n",
    "price_sum=len(price_up)+len(price_down)\n",
    "\n",
    "print('ma120_up = {}'.format(len(ma120_up)))\n",
    "print('ma120_down = {}'.format(len(ma120_down)))\n",
    "    \n",
    "print('win_rate={}%'.format((len(ma120_up)/ma120_sum)*100))\n",
    "\n",
    "display((ma120_up.sort_values([\"ma120_diff\"],ascending=False).head(10)))\n",
    "display(ma120_down.sort_values(['ma120_diff']).head(10))\n",
    "display(ma120_diff_df.describe())\n",
    "\n",
    "print('price_up = {}'.format(len(price_up)))\n",
    "print('price_down = {}'.format(len(price_down)))\n",
    "    \n",
    "print('win_rate={}%'.format((len(price_up)/price_sum)*100))\n",
    "\n",
    "display((price_up.sort_values([\"price_diff\"],ascending=False).head(10)))\n",
    "display(price_down.sort_values(['price_diff']).head(10))\n",
    "display(diff_df.describe())\n",
    "\n",
    "total_df = pd.merge(ma120_diff_df,diff_df,on='name')\n",
    "total_df  = total_df[['name','ma120_startday','ma120_today','ma120_diff','price_startday','price_today','volume_startday','volume_today','price_diff']]\n",
    "total_df = total_df.sort_values([\"price_diff\"],ascending=False)\n",
    "total_df.to_excel(path_total+choice_date+'.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##  전종목  종가 > ma120  일일 비교 하여  종목 pick 하고 pick한 종목의  종가를  비교분석\n",
    "\n",
    "from mod1 import *\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "\n",
    "\n",
    "path = 'd:\\\\stockdata\\\\close_ma120\\\\close_ma120_'\n",
    "back_date=1\n",
    "choice_date='2019-10-11'\n",
    "\n",
    "all_df = all_stock(choice_date)\n",
    "all_name_df = all_df['Name']\n",
    "\n",
    "all_name = all_name_df.to_list()\n",
    "\n",
    "all_df2 = pd.DataFrame()\n",
    "for i in all_name:\n",
    "    #print(i)\n",
    "    all_df=select_stock(i,'2010-01-01')\n",
    "    ma(all_df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(all_df[['close','ma120','volume']].values)\n",
    "    all_df1 = pd.DataFrame(data)\n",
    "    all_df1['Name']=i\n",
    "    all_df1.columns=['close','ma120','volume','name',]\n",
    "    all_df1['date'] = all_df['date']\n",
    "    #print(df1)\n",
    "    all_df2 = all_df2.append(all_df1)\n",
    "    \n",
    "\n",
    "last = len(all_df2[all_df2['name'] == all_name[0]])-1\n",
    "all_today_df = all_df2[all_df2.index == last]\n",
    "\n",
    "ma120_df = all_today_df[all_today_df['close'] > all_today_df['ma120']]\n",
    "\n",
    "today = str(ma120_df.iloc[0,4])\n",
    "ma120_df.to_excel(path+today+'.xlsx', encoding='utf-8')\n",
    "\n",
    "pick_df = pd.read_excel(path+choice_date+'.xlsx')\n",
    "pick_df = pick_df['name']\n",
    "pick_name = pick_df.to_list()\n",
    "\n",
    "pick_df1 = pd.DataFrame()\n",
    "diff_df = pd.DataFrame()\n",
    "for i in pick_name:\n",
    "    #print(i)\n",
    "    pick_df=select_stock(i,'2019-01-01')\n",
    "    pick_df1 = pick_df1.append(pick_df)\n",
    "\n",
    "last = len(pick_df1[pick_df1['Name'] == pick_name[0]])-1\n",
    "startday_df = pick_df1[pick_df1.index == (last-back_date)]\n",
    "today_df = pick_df1[pick_df1.index == last]\n",
    "\n",
    "diff_df = pd.merge(startday_df[['Name','Close']],today_df[['Name','Close']],on='Name')\n",
    "diff_df.columns=['name','startday','today']\n",
    "diff_df['diff']=diff_df['today']/diff_df['startday']\n",
    "\n",
    "up = diff_df[diff_df['diff'] > 1]\n",
    "down = diff_df[diff_df['diff'] < 1]\n",
    "sum=len(up)+len(down)\n",
    "print('up = {}'.format(len(up)))\n",
    "print('down = {}'.format(len(down)))\n",
    "    \n",
    "print('win_rate={}%'.format((len(up)/sum)*100))\n",
    "\n",
    "display((up.sort_values([\"diff\"],ascending=False).head(10)))\n",
    "display(down.sort_values(['diff']).head(10))\n",
    "display(diff_df.describe())\n",
    "\n",
    "#kk = datetime.now()-datetime(2019,10,13)\n",
    "#print(kk.days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##  전종목  종가, ma120 일선 비교하기\n",
    "\n",
    "from mod1 import *\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "\n",
    "path = 'd:\\\\stockdata\\\\close_ma120\\\\close_ma120_'\n",
    "path_total = 'd:\\\\stockdata\\\\close_ma120\\\\all_'\n",
    "\n",
    "back_date=5\n",
    "choice_date='2019-10-11'\n",
    "\n",
    "df = all_stock(choice_date)\n",
    "#df.columns=['date', 'code', 'name', 'open', 'high', 'low', 'volume', 'close']\n",
    "df.columns = map(str.lower, df.columns)\n",
    "df = df['name']\n",
    "name = df.to_list()\n",
    "\n",
    "df1 = pd.DataFrame()\n",
    "diff_df = pd.DataFrame()\n",
    "ma120_df2 = pd.DataFrame()\n",
    "for i in name:\n",
    "    #print(i)\n",
    "    df=select_stock(i,'2010-01-01')\n",
    "    df1 = df1.append(df)    \n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close','ma120','volume']].values)\n",
    "    ma120_df1 = pd.DataFrame(data)\n",
    "    ma120_df1['Name']=i\n",
    "    ma120_df1.columns=['close','ma120','volume','name',]\n",
    "    ma120_df1['date'] = df['date']\n",
    "    #print(df1)\n",
    "    ma120_df2 = ma120_df2.append(ma120_df1)\n",
    "    \n",
    "ma120_df2['event_date'] = pd.to_datetime(ma120_df2['date'])\n",
    "df1['event_date'] = pd.to_datetime(df1['Date'])\n",
    "day = str((datetime.now()-timedelta(3)).date())\n",
    "da = str((datetime.now()-timedelta(2)).date())\n",
    "ma120_startday_df = ma120_df2.loc[ma120_df2['event_date'] == day]\n",
    "ma120_today_df = ma120_df2.loc[ma120_df2['event_date'] == da]\n",
    "price_startday_df = df1.loc[df1['event_date'] == day]\n",
    "price_today_df = df1.loc[df1['event_date'] == da]\n",
    "\n",
    "ma120_diff_df = pd.merge(ma120_startday_df[['name','ma120']],ma120_today_df[['name','ma120']],on='name')\n",
    "ma120_diff_df.columns=['name','ma120_startday','ma120_today']\n",
    "ma120_diff_df['ma120_diff']=ma120_diff_df['ma120_today']/ma120_diff_df['ma120_startday']\n",
    "\n",
    "diff_df = pd.merge(price_startday_df[['Name','Close']],price_today_df[['Name','Close']],on='Name')\n",
    "diff_df.columns=['name','price_startday','price_today']\n",
    "diff_df['price_diff']=diff_df['price_today']/diff_df['price_startday']\n",
    "\n",
    "ma120_up = ma120_diff_df[ma120_diff_df['ma120_diff'] > 1]\n",
    "ma120_down = ma120_diff_df[ma120_diff_df['ma120_diff'] < 1]\n",
    "ma120_sum=len(ma120_up)+len(ma120_down)\n",
    "\n",
    "price_up = diff_df[diff_df['price_diff'] > 1]\n",
    "price_down = diff_df[diff_df['price_diff'] < 1]\n",
    "price_sum=len(price_up)+len(price_down)\n",
    "\n",
    "print('ma120_up = {}'.format(len(ma120_up)))\n",
    "print('ma120_down = {}'.format(len(ma120_down)))\n",
    "    \n",
    "print('win_rate={}%'.format((len(ma120_up)/ma120_sum)*100))\n",
    "\n",
    "display((ma120_up.sort_values([\"ma120_diff\"],ascending=False).head(10)))\n",
    "display(ma120_down.sort_values(['ma120_diff']).head(10))\n",
    "display(ma120_diff_df.describe())\n",
    "\n",
    "print('price_up = {}'.format(len(price_up)))\n",
    "print('price_down = {}'.format(len(price_down)))\n",
    "    \n",
    "print('win_rate={}%'.format((len(price_up)/price_sum)*100))\n",
    "\n",
    "display((price_up.sort_values([\"price_diff\"],ascending=False).head(10)))\n",
    "display(price_down.sort_values(['price_diff']).head(10))\n",
    "display(diff_df.describe())\n",
    "\n",
    "total_df = pd.merge(ma120_diff_df,diff_df,on='name')\n",
    "total_df = total_df.sort_values([\"price_diff\"],ascending=False)\n",
    "total_df.to_excel(path_total+choice_date+'.xlsx')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###  관심종목 ma60, ma120, cci 그래프 생성\n",
    "\n",
    "from mod1 import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "\n",
    "def close_ma(df,select1,select2,select3):\n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close',select1,select2,select3]].values)\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1.columns=['close',select1,select2,select3]\n",
    "    df1 = df1.set_index(df['date'])\n",
    "    df1.plot(figsize=(16,4))\n",
    "    plt.title(df['name'][0])\n",
    "    plt.show()\n",
    "\n",
    "path = 'd:\\\\stockdata\\\\close_ma120\\\\close_ma120_'\n",
    "path_total = 'd:\\\\stockdata\\\\close_ma120\\\\total_'\n",
    "\n",
    "choice_date = '2019-10-01'\n",
    "df = pd.read_excel(path_total+choice_date+'.xlsx')\n",
    "df = df['name']\n",
    "name = df.to_list()\n",
    "\n",
    "#name=['hrs','손오공']\n",
    "\n",
    "pure_df = pd.DataFrame()\n",
    "df2 = pd.DataFrame()\n",
    "cci_df = pd.DataFrame()\n",
    "for i in name:\n",
    "    #print(i)\n",
    "    df=select_stock(i,'2010-01-01')\n",
    "    cci_df[['open','high','low','volume','close']] = df[['Open','High','Low','Volume','Close']].astype(float) #  TA-Lib로 평균을 구하려면 실수로 만들어야 함\n",
    "    period = 120\n",
    "    cci_df['cci'] = ta.CCI(cci_df, timeperiod=period)\n",
    "    df['cci'] = cci_df['cci']\n",
    "    close_ma(df,'cci','ma60','ma120')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
