{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import FinanceDataReader as fdr\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime as dt\n",
    "from datetime import datetime,timedelta\n",
    "from urllib.request import urlopen\n",
    "import sqlalchemy \n",
    "import pymysql\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "from matplotlib import font_manager, rc\n",
    "font_name = font_manager.FontProperties(fname=\"c:/Windows/Fonts/malgun.ttf\").get_name()\n",
    "rc('font', family=font_name)\n",
    "\n",
    "now = dt.datetime.today().strftime('%Y-%m-%d')\n",
    "engine = sqlalchemy.create_engine('mysql+pymysql://kkang:leaf2027@localhost/stock?charset=utf8',encoding='utf-8')\n",
    "conn = pymysql.connect(host = 'localhost', user = 'kkang', password = 'leaf2027' ,db = 'stock')\n",
    "curs = conn.cursor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## insert mysql 개별 주식\n",
    "\n",
    "Code = input('주식 Code를 입력하세요')\n",
    "Name = input('주식이름을 입력하세요')\n",
    "\n",
    "#### 기존에 액면분할시 가격조정 안된 기존 data가 있을때\n",
    "query = \"delete from  market where Name = \"+\"'\"+Name+\"'\"\n",
    "curs.execute(query)\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "df = fdr.DataReader(Code, '1995')\n",
    "df.to_excel('d:\\\\'+Code+'.xlsx', encoding='UTF-8')\n",
    "\n",
    "df = pd.read_excel('d:\\\\'+Code+'.xlsx')\n",
    "df['Code']= Code\n",
    "df['Name']= Name\n",
    "\n",
    "df = df[['Date','Code','Name','Open', 'High', 'Low', 'Volume','Close']]\n",
    "\n",
    "df.to_sql(name='market', con=engine, if_exists='append', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "###  선물크롤링하여 맨처음 DB에 future table생성할때\n",
    "\n",
    "# 2019-09-11 수정  mysql future table에서 최종 날짜를 확인해서 그뒤날부터 insert \n",
    "# 기존 daum 주식 사이트 : ajax 방식으로 변경으로 인해 이를 반영한 코드를 수정.\n",
    "# pip install fake-useragent 설치 후 실행 가능\n",
    "\n",
    "import io\n",
    "import json\n",
    "import sys\n",
    "import pandas as pd\n",
    "import sqlalchemy \n",
    "import urllib.request as req\n",
    "from datetime import datetime\n",
    "from fake_useragent import UserAgent\n",
    "\n",
    "engine = sqlalchemy.create_engine('mysql+pymysql://kkang:leaf2027@localhost/stock?charset=utf8',encoding='utf-8')\n",
    "\n",
    "\n",
    "# Fake Header 정보\n",
    "ua = UserAgent()\n",
    "\n",
    "# 헤더 선언\n",
    "headers = {\n",
    "    'User-Agent': ua.ie,\n",
    "    'referer': 'http://finance.daum.net/domestic/futures'\n",
    "}\n",
    "\n",
    "\n",
    "url = \"http://finance.daum.net/api/future/KR4101PC0002/days?pagination=true&page=1\"\n",
    "res = req.urlopen(req.Request(url, headers=headers)).read().decode('utf-8')\n",
    "\n",
    "df1 = pd.DataFrame()\n",
    "for i in range(1,7):\n",
    "    # 다음 주식 요청 URL\n",
    "    url = \"http://finance.daum.net/api/future/KR4101PC0002/days?pagination=true&page=\"+str(i)\n",
    "\n",
    "    res = req.urlopen(req.Request(url, headers=headers)).read().decode('utf-8')\n",
    "    \n",
    "    rank_json = json.loads(res)['data']\n",
    "    \n",
    "    df = pd.DataFrame(rank_json)\n",
    "    df1 = df1.append(df,ignore_index=True)\n",
    "    \n",
    "df2 = df1[['date','tradePrice','change', 'changePrice','changeRate','unsettledVolume','foreignSettlement', 'institutionSettlement', 'privateSettlement']]\n",
    "df2.columns=('Date','Future','change','가격변동','등락률','미결제약정','외국인','기관','개인')\n",
    "df2['Date'] = pd.to_datetime(df2['Date']).dt.date\n",
    "#df2['Date'] = pd.to_datetime(df2['Date']).apply(lambda x: x.date())\n",
    "#df2['Date'] = pd.to_datetime(df2['Date'], format = '%Y-%m-%d') # yyyy-mm-dd hh:mm:ss -> yyyy-mm-dd (속성은그대로 보여주는 형식만 변경)\n",
    "df2 =df2[['Date','Future','미결제약정','외국인','기관','개인']]\n",
    "#df2 = df2[df2.Date > until_date]\n",
    "df2.to_sql(name='future', con=engine, if_exists='append', index = False)\n",
    "df2 = df2.set_index('Date')\n",
    "df2.to_excel('d:\\\\future.xlsx',encoding='utf-8')\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###  선물 DB Update할때\n",
    "\n",
    "# 2019-09-11 수정  mysql future table에서 최종 날짜를 확인해서 그뒤날부터 insert \n",
    "# 기존 daum 주식 사이트 : ajax 방식으로 변경으로 인해 이를 반영한 코드를 수정.\n",
    "# pip install fake-useragent 설치 후 실행 가능\n",
    "\n",
    "import io\n",
    "import json\n",
    "import sys\n",
    "import pandas as pd\n",
    "import sqlalchemy \n",
    "import urllib.request as req\n",
    "from datetime import datetime\n",
    "from fake_useragent import UserAgent\n",
    "\n",
    "engine = sqlalchemy.create_engine('mysql+pymysql://kkang:leaf2027@localhost/stock?charset=utf8',encoding='utf-8')\n",
    "future_df = pd.read_sql(\"select Date from future order by Date desc limit 1\", engine)\n",
    "future_df = str(future_df['Date'])\n",
    "until_date = future_df[5:15]\n",
    "\n",
    "year = until_date.split('-')[0]\n",
    "mm = until_date.split('-')[1]\n",
    "dd = until_date.split('-')[2]\n",
    "#year=year[2:]\n",
    "until_date = year+'-'+mm+'-'+dd\n",
    "until_date = datetime.strptime(until_date, '%Y-%m-%d').date() ## str 을  datetime.date로 type 변경\n",
    "\n",
    "# Fake Header 정보\n",
    "ua = UserAgent()\n",
    "\n",
    "# 헤더 선언\n",
    "headers = {\n",
    "    'User-Agent': ua.ie,\n",
    "    'referer': 'http://finance.daum.net/domestic/futures'\n",
    "}\n",
    "\n",
    "\n",
    "url = \"http://finance.daum.net/api/future/KR4101PC0002/days?pagination=true&page=1\"  #KR4011PC002 \"선물 코스피 200지수 12월물\" 코드는 구글검색이용\n",
    "res = req.urlopen(req.Request(url, headers=headers)).read().decode('utf-8')\n",
    "\n",
    "df1 = pd.DataFrame()\n",
    "for i in range(1,3):\n",
    "    # 다음 주식 요청 URL\n",
    "    url = \"http://finance.daum.net/api/future/KR4101PC0002/days?pagination=true&page=\"+str(i)\n",
    "\n",
    "    res = req.urlopen(req.Request(url, headers=headers)).read().decode('utf-8')\n",
    "    \n",
    "    rank_json = json.loads(res)['data']\n",
    "    \n",
    "    df = pd.DataFrame(rank_json)\n",
    "    df1 = df1.append(df,ignore_index=True)\n",
    "df2 = df1[['date','tradePrice','change', 'changePrice','changeRate','unsettledVolume','foreignSettlement', 'institutionSettlement', 'privateSettlement']]\n",
    "df2.columns=('Date','Close','change','가격변동','등락률','미결제약정','외국인','기관','개인')\n",
    "df2['Date'] = pd.to_datetime(df2['Date']).dt.date\n",
    "#df2['Date'] = pd.to_datetime(df2['Date']).apply(lambda x: x.date())\n",
    "#df2['Date'] = pd.to_datetime(df2['Date'], format = '%Y-%m-%d') # yyyy-mm-dd hh:mm:ss -> yyyy-mm-dd (속성은그대로 보여주는 형식만 변경)\n",
    "df2 =df2[['Date','Future','미결제약정','외국인','기관','개인']]\n",
    "df2 = df2[df2.Date > until_date]\n",
    "df2.to_sql(name='future', con=engine, if_exists='append', index = False)\n",
    "df2 = df2.set_index('Date')\n",
    "df2.to_excel('d:\\\\future.xlsx',encoding='utf-8')\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## 선물  베이시스 graph ( One_graph)\n",
    "## def future_trend_graph():\n",
    "   \n",
    "\n",
    "#query = \"select * from future where Date > '2019-06-13'\"+\"'\"+date+\"'\"\n",
    "query = \"select * from basis where Date > '2019-06-13'\"\n",
    "\n",
    "\n",
    "name=['kpi200','Future']\n",
    "#name=['미결제약정']\n",
    "\n",
    "tuple_name=tuple(name)\n",
    "df1 = pd.DataFrame()\n",
    "    \n",
    "df = pd.read_sql(query ,engine)\n",
    "\n",
    "#df.columns=['Date','kpi200','Close']\n",
    "df = df.set_index('Date')\n",
    "df1=df[name]\n",
    "\n",
    "plt.figure(figsize=(16,4))    \n",
    "for i in range(len(name)):\n",
    "    plt.plot(df1[name[i]]/df1[name[i]].loc[df.index[0]]*100)\n",
    "        \n",
    "plt.legend(loc=0)\n",
    "plt.grid(True,color='0.7',linestyle=':',linewidth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## 선물  베이시스 graph ( One_graph)\n",
    "## def future_trend_graph():\n",
    "   \n",
    "\n",
    "#query = \"select * from future where Date > '2019-06-13'\"+\"'\"+date+\"'\"\n",
    "query = \"select * from future where Date > '2019-06-13'\"\n",
    "\n",
    "\n",
    "name=['Close', '미결제약정', '외국인', '기관', '개인']\n",
    "#name=['미결제약정']\n",
    "\n",
    "tuple_name=tuple(name)\n",
    "df1 = pd.DataFrame()\n",
    "    \n",
    "df = pd.read_sql(query ,engine)\n",
    "\n",
    "df.columns=['Date', 'Close', '미결제약정', '외국인', '기관', '개인']\n",
    "df = df.set_index('Date')\n",
    "df1=df[name]\n",
    "\n",
    "plt.figure(figsize=(16,4))    \n",
    "for i in range(len(name)):\n",
    "    plt.plot(df1[name[i]]/df1[name[i]].loc[df.index[0]]*100)\n",
    "        \n",
    "plt.legend(loc=0)\n",
    "plt.grid(True,color='0.7',linestyle=':',linewidth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## 선물 graph ( One_graph)\n",
    "## def future_trend_graph():\n",
    "    \n",
    "#name = input(\"항목을 입력하세요: 선택항목: 'kpi200', '거래량', '고객예탁금', '신용잔고', '주식형펀드', '혼합형펀드', '채권형펀드'\").split()\n",
    "#date = input(\"날짜를 입력하세요 sample: '2019-01-10':\")\n",
    "    \n",
    "    \n",
    "#query = \"select * from future where Date > '2019-06-13'\"+\"'\"+date+\"'\"\n",
    "query = \"select * from future where Date > '2019-06-13'\"\n",
    "\n",
    "\n",
    "name=['Close', '미결제약정', '외국인', '기관', '개인']\n",
    "#name=['미결제약정']\n",
    "\n",
    "tuple_name=tuple(name)\n",
    "df1 = pd.DataFrame()\n",
    "    \n",
    "df = pd.read_sql(query ,engine)\n",
    "\n",
    "df.columns=['Date', 'Close', '미결제약정', '외국인', '기관', '개인']\n",
    "df = df.set_index('Date')\n",
    "df1=df[name]\n",
    "\n",
    "plt.figure(figsize=(16,4))    \n",
    "for i in range(len(name)):\n",
    "    plt.plot(df1[name[i]]/df1[name[i]].loc[df.index[0]]*100)\n",
    "        \n",
    "plt.legend(loc=0)\n",
    "plt.grid(True,color='0.7',linestyle=':',linewidth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## 선물 graph ( Multi_graph)\n",
    "## def future_trend_graph():\n",
    " \n",
    "#name = input(\"항목을 입력하세요: 선택항목: 'kpi200', '거래량', '고객예탁금', '신용잔고', '주식형펀드', '혼합형펀드', '채권형펀드'\").split()\n",
    "#date = input(\"날짜를 입력하세요 sample: '2019-01-10':\")\n",
    "    \n",
    "#query = \"select * from future where Date > '2019-06-13'\"+\"'\"+date+\"'\"\n",
    "query = \"select * from future where Date > '2019-06-11'\"\n",
    "\n",
    "\n",
    "name=['Close', '미결제약정', '외국인', '기관', '개인']\n",
    "name1=['Close','미결제약정']\n",
    "name2=['외국인', '기관', '개인']\n",
    "\n",
    "#tuple_name=tuple(name)\n",
    "df1 = pd.DataFrame()\n",
    "    \n",
    "df = pd.read_sql(query ,engine)\n",
    "\n",
    "df.columns=['Date', 'Close', '미결제약정', '외국인', '기관', '개인']\n",
    "df = df.set_index('Date')\n",
    "df1=df[name]\n",
    "\n",
    "plt.figure(figsize=(16,4))    \n",
    "for i in range(len(name1)):\n",
    "    #plt.subplot(2,2,i+1)\n",
    "    plt.plot(df1[name1[i]]/df1[name1[i]].loc[df.index[0]]*100,color=colors[i])\n",
    "    \n",
    "plt.legend(loc=0)\n",
    "plt.grid(True,color='0.7',linestyle=':',linewidth=1)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(16,4)) \n",
    "for i in range(len(name2)):\n",
    "    plt.subplot(2,2,i+1)\n",
    "    plt.plot(df1[name2[i]]/df1[name2[i]].loc[df.index[0]]*100,color=colors[i])\n",
    "    \n",
    "    plt.legend(loc=0)\n",
    "    plt.grid(True,color='0.7',linestyle=':',linewidth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Close and Volume graph 표준화\n",
    "\n",
    "import FinanceDataReader as fdr\n",
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "engine = sqlalchemy.create_engine('mysql+pymysql://kkang:leaf2027@localhost/stock?charset=utf8',encoding='utf-8')\n",
    "\n",
    "select_query = \"select Date,Volume,Close from market where Name= \"\n",
    "date_query = \"Date > \"\n",
    "\n",
    "def choice(select):\n",
    "    name = '화천기계'\n",
    "    date = '2019-01-01'\n",
    "    if select == 1:\n",
    "        name = input('주식이름을 입력하세요 : ')\n",
    "        date = input('날짜를 입력하세요: ')\n",
    "        var = select_query +\"'\"+name+\"'\"+\" \"+\"&&\"+\" \"+date_query+\"'\"+date+\"'\" \n",
    "        return var\n",
    "    elif select == 2:\n",
    "        var = select_query +\"'\"+name+\"'\"+\" \"+\"&&\"+\" \"+date_query+\"'\"+date+\"'\" \n",
    "        return var\n",
    "\n",
    "select = input('select 1 or 2: ')\n",
    "select = int(select)\n",
    "\n",
    "df = pd.read_sql(choice(select), engine)\n",
    "\n",
    "source = MinMaxScaler()\n",
    "data = source.fit_transform(df[['Close','Volume']].values.astype(float))\n",
    "df1 = pd.DataFrame(data)\n",
    "df1.columns=['Close','Volume']\n",
    "df1 = df1.set_index(df['Date'])\n",
    "df1.plot(figsize=(16,4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Close and Volume graph 표준화 _ 2\n",
    "\n",
    "import FinanceDataReader as fdr\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "engine = sqlalchemy.create_engine('mysql+pymysql://kkang:leaf2027@localhost/stock?charset=utf8',encoding='utf-8')\n",
    "\n",
    "select_query = \"select Date,Volume,Close from market where Name= \"\n",
    "date_query = \"Date > \"\n",
    "\n",
    "df = pd.read_excel('d:\\\\detect_stock_with_volume.xlsx')\n",
    "df=df['Name']\n",
    "#name = df.values.tolist() ## numpy to list\n",
    "name = df.to_list()              ## DataFrame to list\n",
    "date = '2019-01-01'\n",
    "for i in name:\n",
    "    var = select_query +\"'\"+i+\"'\"+\" \"+\"&&\"+\" \"+date_query+\"'\"+date+\"'\" \n",
    "    df = pd.read_sql(var, engine)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['Close','Volume']].values.astype(float))\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1.columns=['Close','Volume']\n",
    "    df1 = df1.set_index(df['Date'])\n",
    "    df1.plot(figsize=(16,2))\n",
    "    plt.title(i)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Stock Prediction 30 days\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from tqdm import tqdm\n",
    "sns.set()\n",
    "tf.set_random_seed(777)  # reproducibility\n",
    "tf.reset_default_graph()\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter('ignore')\n",
    "\n",
    "import sqlalchemy\n",
    "\n",
    "engine = sqlalchemy.create_engine('mysql+pymysql://kkang:leaf2027@localhost/stock?charset=utf8',encoding='utf-8')\n",
    "var =\"select * from market where Name='HRS' and  Date > '2019-01-01'\" \n",
    "df = pd.read_sql(var ,engine)\n",
    "df.head()\n",
    "\n",
    "minmax = MinMaxScaler().fit(df.iloc[:, 7:].astype('float32')) # Close index\n",
    "df_log = minmax.transform(df.iloc[:, 7:].astype('float32')) # Close index\n",
    "df_log = pd.DataFrame(df_log)\n",
    "df_log.head()\n",
    "\n",
    "simulation_size = 10\n",
    "num_layers = 1\n",
    "size_layer = 128\n",
    "timestamp = 5\n",
    "epoch = 300\n",
    "dropout_rate = 0.8\n",
    "test_size = 30\n",
    "learning_rate = 0.01\n",
    "\n",
    "df_train = df_log\n",
    "df.shape, df_train.shape\n",
    "\n",
    "class Model:\n",
    "    def __init__(\n",
    "        self,\n",
    "        learning_rate,\n",
    "        num_layers,\n",
    "        size,\n",
    "        size_layer,\n",
    "        output_size,\n",
    "        forget_bias = 0.1,\n",
    "    ):\n",
    "        def lstm_cell(size_layer):\n",
    "            return tf.nn.rnn_cell.LSTMCell(size_layer, state_is_tuple = False)\n",
    "\n",
    "        rnn_cells = tf.nn.rnn_cell.MultiRNNCell(\n",
    "            [lstm_cell(size_layer) for _ in range(num_layers)],\n",
    "            state_is_tuple = False,\n",
    "        )\n",
    "        self.X = tf.placeholder(tf.float32, (None, None, size))\n",
    "        self.Y = tf.placeholder(tf.float32, (None, output_size))\n",
    "        drop = tf.contrib.rnn.DropoutWrapper(\n",
    "            rnn_cells, output_keep_prob = forget_bias\n",
    "        )\n",
    "        self.hidden_layer = tf.placeholder(\n",
    "            tf.float32, (None, num_layers * 2 * size_layer)\n",
    "        )\n",
    "        self.outputs, self.last_state = tf.nn.dynamic_rnn(\n",
    "            drop, self.X, initial_state = self.hidden_layer, dtype = tf.float32\n",
    "        )\n",
    "        self.logits = tf.layers.dense(self.outputs[-1], output_size)\n",
    "        self.cost = tf.reduce_mean(tf.square(self.Y - self.logits))\n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate).minimize(\n",
    "            self.cost\n",
    "        )\n",
    "        \n",
    "def calculate_accuracy(real, predict):\n",
    "    real = np.array(real) + 1\n",
    "    predict = np.array(predict) + 1\n",
    "    percentage = 1 - np.sqrt(np.mean(np.square((real - predict) / real)))\n",
    "    return percentage * 100\n",
    "\n",
    "def anchor(signal, weight):\n",
    "    buffer = []\n",
    "    last = signal[0]\n",
    "    for i in signal:\n",
    "        smoothed_val = last * weight + (1 - weight) * i\n",
    "        buffer.append(smoothed_val)\n",
    "        last = smoothed_val\n",
    "    return buffer\n",
    "\n",
    "def forecast():\n",
    "    tf.reset_default_graph()\n",
    "    modelnn = Model(\n",
    "        learning_rate, num_layers, df_log.shape[1], size_layer, df_log.shape[1], dropout_rate\n",
    "    )\n",
    "    sess = tf.InteractiveSession()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    date_ori = pd.to_datetime(df.iloc[:, 0]).tolist()\n",
    "\n",
    "    pbar = tqdm(range(epoch), desc = 'train loop')\n",
    "    for i in pbar:\n",
    "        init_value = np.zeros((1, num_layers * 2 * size_layer))\n",
    "        total_loss, total_acc = [], []\n",
    "        for k in range(0, df_train.shape[0] - 1, timestamp):\n",
    "            index = min(k + timestamp, df_train.shape[0] - 1)\n",
    "            batch_x = np.expand_dims(\n",
    "                df_train.iloc[k : index, :].values, axis = 0\n",
    "            )\n",
    "            batch_y = df_train.iloc[k + 1 : index + 1, :].values\n",
    "            logits, last_state, _, loss = sess.run(\n",
    "                [modelnn.logits, modelnn.last_state, modelnn.optimizer, modelnn.cost],\n",
    "                feed_dict = {\n",
    "                    modelnn.X: batch_x,\n",
    "                    modelnn.Y: batch_y,\n",
    "                    modelnn.hidden_layer: init_value,\n",
    "                },\n",
    "            )        \n",
    "            init_value = last_state\n",
    "            total_loss.append(loss)\n",
    "            total_acc.append(calculate_accuracy(batch_y[:, 0], logits[:, 0]))\n",
    "        pbar.set_postfix(cost = np.mean(total_loss), acc = np.mean(total_acc))\n",
    "    \n",
    "    future_day = test_size\n",
    "\n",
    "    output_predict = np.zeros((df_train.shape[0] + future_day, df_train.shape[1]))\n",
    "    output_predict[0] = df_train.iloc[0]\n",
    "    upper_b = (df_train.shape[0] // timestamp) * timestamp\n",
    "    init_value = np.zeros((1, num_layers * 2 * size_layer))\n",
    "\n",
    "    for k in range(0, (df_train.shape[0] // timestamp) * timestamp, timestamp):\n",
    "        out_logits, last_state = sess.run(\n",
    "            [modelnn.logits, modelnn.last_state],\n",
    "            feed_dict = {\n",
    "                modelnn.X: np.expand_dims(\n",
    "                    df_train.iloc[k : k + timestamp], axis = 0\n",
    "                ),\n",
    "                modelnn.hidden_layer: init_value,\n",
    "            },\n",
    "        )\n",
    "        init_value = last_state\n",
    "        output_predict[k + 1 : k + timestamp + 1] = out_logits\n",
    "\n",
    "    if upper_b != df_train.shape[0]:\n",
    "        out_logits, last_state = sess.run(\n",
    "            [modelnn.logits, modelnn.last_state],\n",
    "            feed_dict = {\n",
    "                modelnn.X: np.expand_dims(df_train.iloc[upper_b:], axis = 0),\n",
    "                modelnn.hidden_layer: init_value,\n",
    "            },\n",
    "        )\n",
    "        output_predict[upper_b + 1 : df_train.shape[0] + 1] = out_logits\n",
    "        future_day -= 1\n",
    "        date_ori.append(date_ori[-1] + timedelta(days = 1))\n",
    "\n",
    "    init_value = last_state\n",
    "    \n",
    "    for i in range(future_day):\n",
    "        o = output_predict[-future_day - timestamp + i:-future_day + i]\n",
    "        out_logits, last_state = sess.run(\n",
    "            [modelnn.logits, modelnn.last_state],\n",
    "            feed_dict = {\n",
    "                modelnn.X: np.expand_dims(o, axis = 0),\n",
    "                modelnn.hidden_layer: init_value,\n",
    "            },\n",
    "        )\n",
    "        init_value = last_state\n",
    "        output_predict[-future_day + i] = out_logits[-1]\n",
    "        date_ori.append(date_ori[-1] + timedelta(days = 1))\n",
    "    \n",
    "    output_predict = minmax.inverse_transform(output_predict)\n",
    "    deep_future = anchor(output_predict[:, 0], 0.4)\n",
    "    \n",
    "    return deep_future\n",
    "\n",
    "results = []\n",
    "for i in range(simulation_size):\n",
    "    print('simulation %d'%(i + 1))\n",
    "    results.append(forecast())\n",
    "    \n",
    "date_ori = pd.to_datetime(df.iloc[:, 0]).tolist()\n",
    "for i in range(test_size):\n",
    "    date_ori.append(date_ori[-1] + timedelta(days = 1))\n",
    "date_ori = pd.Series(date_ori).dt.strftime(date_format = '%Y-%m-%d').tolist()\n",
    "date_ori[-5:]\n",
    "\n",
    "accepted_results = []\n",
    "for r in results:\n",
    "    if (np.array(r[-test_size:]) < np.min(df['Close'])).sum() == 0 and \\\n",
    "    (np.array(r[-test_size:]) > np.max(df['Close']) * 2).sum() == 0:\n",
    "        accepted_results.append(r)\n",
    "len(accepted_results)\n",
    "\n",
    "accuracies = [calculate_accuracy(df['Close'].values, r[:-test_size]) for r in accepted_results]\n",
    "\n",
    "plt.figure(figsize = (15, 5))\n",
    "for no, r in enumerate(accepted_results):\n",
    "    plt.plot(r, label = 'forecast %d'%(no + 1))\n",
    "plt.plot(df['Close'], label = 'true trend', c = 'black')\n",
    "plt.legend()\n",
    "plt.title('average accuracy: %.4f'%(np.mean(accuracies)))\n",
    "\n",
    "x_range_future = np.arange(len(results[0]))\n",
    "plt.xticks(x_range_future[::30], date_ori[::30])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## 상장회사 종가확인\n",
    "# 브라우저 실행\n",
    "from selenium import webdriver\n",
    "driver = webdriver.Chrome('C:/Users/kkang/selenium/chromedriver.exe')\n",
    "\n",
    "# 상장회사검색\n",
    "driver.get('http://marketdata.krx.co.kr/mdi#document=040602')\n",
    "\n",
    "# 다운로드 버튼을 클릭\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "button = driver.find_element(By.XPATH, '//button[text()=\"Excel\"]')\n",
    "button.click()\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "# 다운로드 폴더로 이동\n",
    "folder = 'c:\\\\Users\\\\kkang\\\\Downloads'\n",
    "os.chdir(folder)\n",
    "\n",
    "# 파일 다운로드까지 대기 (1초씩 최대 30회)\n",
    "fname = 'data.xls'\n",
    "for _ in range(30):\n",
    "    if os.path.exists(fname):\n",
    "        break\n",
    "    time.sleep(1)\n",
    "\n",
    "# 파일명 바꾸기\n",
    "os.rename('data.xls', 'price.xls')\n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## MinMaxScaller() 변조및 복조\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "connect = create_engine('mysql+pymysql://kkang:leaf2027@localhost/stock?charset=utf8',encoding='utf-8')\n",
    "df = pd.read_sql(\"SELECT * from market where Code = '036640' and date > '2019-08-05'\", connect)\n",
    "\n",
    "df = df[['Open', 'High', 'Low', 'Volume', 'Close']]\n",
    "\n",
    "dataset = df.values\n",
    "\n",
    "source = MinMaxScaler() # default is 0,1\n",
    "dataset = source.fit_transform(dataset) ### MinMaxScaler 변조\n",
    "\n",
    "display(dataset)\n",
    "print('='*100)\n",
    "\n",
    "source.inverse_transform(dataset) ### MinMaxScaler 복조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## def stock_select_with_Volume_Close():\n",
    "    \n",
    "yesterday = input(\"어제날짜를 입력하세요 : sample: '2019-02-07 00:00:00'  \") \n",
    "today = input(\"오늘날짜를 입력하세요 : sample: '2019-02-07 00:00:00'  \")\n",
    "    \n",
    "select_query = \"select * from market where Date >=\"\n",
    "volume_query = \"&& Volume >  500000\"\n",
    "    \n",
    "var = select_query +\"'\"+yesterday+\"'\"+ volume_query\n",
    "df = pd.read_sql(var ,engine)\n",
    "\n",
    "df1 = df[df['Date'].astype(str) == yesterday]\n",
    "df1 = df1[['Name','Volume','Close']]\n",
    "df1.columns = ['Name','yester_Volume','yester_Close']\n",
    "#display(df1)\n",
    "\n",
    "df2 = df[df['Date'].astype(str) == today]\n",
    "df2 = df2[['Name','Volume','Close']]\n",
    "df2.columns = ['Name','today_Volume','today_Close']\n",
    "#display(df2)\n",
    "\n",
    "df3 = pd.merge(df1,df2,on='Name')\n",
    "df3['Close']=df3['today_Close']/df3['yester_Close']\n",
    "df3['Volume']=df3['today_Volume']/df3['yester_Volume']\n",
    "df3 = df3.sort_values(by=['Volume','Close'],ascending=False)\n",
    "df3 = df3.reset_index(drop=True)\n",
    "df3 = df3[:10]\n",
    "df4 = df3.sort_values(by=['Close','Volume'],ascending=False)\n",
    "df4 = df4.reset_index(drop=True)\n",
    "df4 = df4[:10]\n",
    "display(df3)\n",
    "display(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## def stock_price_graph():\n",
    "    \n",
    "name = input('주식이름을 입력하세요:').split()\n",
    "date = input(\"날짜를 입력하세요 sample: '2019-01-10': \")\n",
    "\n",
    "select_query = \"select Date,Close from market where Name= \"\n",
    "date_query =  \"Date >\"\n",
    "\n",
    "tuple_name=tuple(name)\n",
    "df1 = pd.DataFrame()\n",
    "\n",
    "for x in tuple_name:\n",
    "    var = select_query +\"'\"+x+\"'\"+\" \"+\"&&\"+\" \"+date_query+\"'\"+date+\"'\"\n",
    "    df = pd.read_sql(var ,engine) \n",
    "    df.columns=['Date',x]\n",
    "    if df1.empty:\n",
    "        df1 = df\n",
    "    else:\n",
    "        df1 = pd.merge (df,df1,on='Date')\n",
    "df1=df1.set_index('Date')\n",
    "    \n",
    "plt.figure(figsize=(12,5))\n",
    "    \n",
    "for i in range(len(name)):\n",
    "    plt.plot(df1[name[i]]/df1[name[i]].loc[df['Date'][0]]*100)\n",
    "        \n",
    "plt.legend(loc=0)\n",
    "plt.grid(True,color='0.7',linestyle=':',linewidth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## def money_trend_graph():\n",
    "    \n",
    "name = input(\"항목을 입력하세요: 선택항목: 'kpi200', '거래량', '고객예탁금', '신용잔고', '주식형펀드', '혼합형펀드', '채권형펀드'\").split()\n",
    "date = input(\"날짜를 입력하세요 sample: '2019-01-10':\")\n",
    "    \n",
    "query = \"select * from kpi_with_money where Date >\"+\"'\"+date+\"'\"\n",
    "    \n",
    "tuple_name=tuple(name)\n",
    "df1 = pd.DataFrame()\n",
    "    \n",
    "df = pd.read_sql(query ,engine)\n",
    "\n",
    "df.columns=['Date','kpi200', '거래량', '고객예탁금', '신용잔고', '주식형펀드', '혼합형펀드', '채권형펀드']\n",
    "df = df.set_index('Date')\n",
    "df1=df[name]\n",
    "\n",
    "\n",
    "for i in range(len(name)):\n",
    "    plt.plot(df1[name[i]]/df1[name[i]].loc[df.index[0]]*100)\n",
    "        \n",
    "plt.legend(loc=0)\n",
    "plt.grid(True,color='0.7',linestyle=':',linewidth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## def money_trend_graph():  integrate graph\n",
    "    \n",
    "name = input(\"항목을 입력하세요: 선택항목: 'kpi200', '거래량', '고객예탁금', '신용잔고', '주식형펀드', '혼합형펀드', '채권형펀드'\").split()\n",
    "date = input(\"날짜를 입력하세요 sample: '2019-01-10':\")\n",
    "    \n",
    "query = \"select * from kpi_with_money where Date >\"+\"'\"+date+\"'\"\n",
    "    \n",
    "tuple_name=tuple(name)\n",
    "df1 = pd.DataFrame()\n",
    "    \n",
    "df = pd.read_sql(query ,engine)\n",
    "\n",
    "df.columns=['Date','kpi200', '거래량', '고객예탁금', '신용잔고', '주식형펀드', '혼합형펀드', '채권형펀드']\n",
    "df = df.set_index('Date')\n",
    "df1=df[name]\n",
    "\n",
    "plt.figure(figsize=(16,4))\n",
    "colors = ['red','green','blue','pink','gray']\n",
    "for i in range(len(name)):\n",
    "    plt.subplot(2,2,i+1)\n",
    "    plt.plot(df1[name[i]]/df1[name[i]].loc[df.index[0]]*100,color=colors[i])\n",
    "    \n",
    "    plt.legend(loc=0)\n",
    "    plt.grid(True,color='0.7',linestyle=':',linewidth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## def excel_to_mysql():\n",
    "\n",
    "file_name = input('파일이름을 입력하세요:')\n",
    "        \n",
    "df=pd.read_excel('d:\\\\'+ file_name)\n",
    "if file_name=='kpi200.xlsx':\n",
    "    df.columns=['Date','kpi200','거래량']\n",
    "    table_name = 'kpi200'\n",
    "    #df = df.set_index('Date')\n",
    "elif file_name=='moneytrend.xlsx':\n",
    "    table_name = 'moneytrend'\n",
    "    df.columns=['Date', '고객예탁금', '신용잔고','주식형펀드','혼합형펀드','채권형펀드']\n",
    "    #df = df.set_index('Date')\n",
    "else:\n",
    "    print('\\n file_name error\\n')\n",
    "    \n",
    "df.to_sql(name=table_name, con=engine, if_exists='append', index = False)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## def get_stock_price_from_fdr(end_date=now):\n",
    "        \n",
    "file_name = input('파일이름을 입력하세요:')\n",
    "toward = input('저장 방식을 입력하세요 : sample: excel, sql ')\n",
    "start_date = input(\"시작날자를 입려하세요 : sample: '2015-01-01'\")\n",
    "table_name = input(\"table명을 입력하세요 : sample: market\")\n",
    "data=pd.read_excel('d:\\\\'+ file_name)\n",
    "   \n",
    "code_list = data['종목코드'].tolist()\n",
    "code_list = [str(item).zfill(6) for item in code_list]\n",
    "name_list = data['종목명'].tolist()\n",
    "\n",
    "# 코스피 상장종목 전체\n",
    "stock_dic = dict(list(zip(code_list,name_list)))\n",
    "\n",
    "for code in sorted(stock_dic.keys()):\n",
    "    df  = fdr.DataReader(code,start_date,now)\n",
    "    print(code,stock_dic[code])\n",
    "    df['Code'],df['Name'] = code,stock_dic[code]\n",
    "    df = df[['Code','Name','Open','High','Low','Volume','Close']]\n",
    "    if toward == 'excel':\n",
    "        df.to_excel('d:\\\\data_set\\\\kospi\\\\'+ stock_dic[code] +'.xlsx',engine = 'xlsxwriter')\n",
    "    elif toward == 'sql':\n",
    "        df.to_sql(name=table_name, con=engine, if_exists='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# def stock_price_graph():\n",
    "    \n",
    "name = input('주식이름을 입력하세요:')\n",
    "date = input(\"날짜를 입력하세요 sample: '2019-01-10':\")\n",
    "        \n",
    "select_query = \"select * from market where Name= \"\n",
    "\n",
    "var = select_query +\"'\"+x+\"'\"+\" \"+\"&&\"+\" \"+date_query+\"'\"+date+\"'\"\n",
    "    df = pd.read_sql(var ,engine)\n",
    "    df.columns=['Date',x]\n",
    "    if df1.empty:\n",
    "        df1 = df\n",
    "    else:\n",
    "        df1 = pd.merge (df,df1,on='Date')\n",
    "df1=df1.set_index('Date')\n",
    "    \n",
    "plt.figure(figsize=(12,5))\n",
    "    `\n",
    "for i in range(len(name)):\n",
    "    plt.plot(df1[name[i]]/df1[name[i]].loc[df['Date'][0]]*100)\n",
    "        \n",
    "plt.legend(loc=0)\n",
    "plt.grid(True,color='0.7',linestyle=':',linewidth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## def money_trend_graph():\n",
    "    \n",
    "name = input(\"항목을 입력하세요: 선택항목: 'kpi200', '거래량', '고객예탁금', '신용잔고', '주식형펀드', '혼합형펀드', '채권형펀드'\").split()\n",
    "date = input(\"날짜를 입력하세요 sample: '2019-01-10':\")\n",
    "    \n",
    "query = \"select * from kpi_with_money where Date >\"+\"'\"+date+\"'\"\n",
    "    \n",
    "tuple_name=tuple(name)\n",
    "df1 = pd.DataFrame()\n",
    "    \n",
    "df = pd.read_sql(query ,engine)\n",
    "\n",
    "df.columns=['Date','kpi200', '거래량', '고객예탁금', '신용잔고', '주식형펀드', '혼합형펀드', '채권형펀드']\n",
    "df = df.set_index('Date')\n",
    "df1=df[name]\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "for i in range(len(name)):\n",
    "    plt.plot(df1[name[i]]/df1[name[i]].loc[df.index[0]]*100)\n",
    "        \n",
    "plt.legend(loc=0)\n",
    "plt.grid(True,color='0.7',linestyle=':',linewidth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## def money_trend_graph():\n",
    "    \n",
    "name = input(\"항목을 입력하세요: 선택항목: 'kpi200', '거래량', '고객예탁금', '신용잔고', '주식형펀드', '혼합형펀드', '채권형펀드'\").split()\n",
    "date = input(\"날짜를 입력하세요 sample: '2019-01-10':\")\n",
    "    \n",
    "query = \"select * from kpi_with_money where Date >\"+\"'\"+date+\"'\"\n",
    "    \n",
    "tuple_name=tuple(name)\n",
    "df1 = pd.DataFrame()\n",
    "    \n",
    "df = pd.read_sql(query ,engine)\n",
    "\n",
    "df.columns=['Date','kpi200', '거래량', '고객예탁금', '신용잔고', '주식형펀드', '혼합형펀드', '채권형펀드']\n",
    "df = df.set_index('Date')\n",
    "df1=df[name]\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "for i in range(len(name)):\n",
    "    plt.plot(df1[name[i]]/df1[name[i]].loc[df.index[0]]*100)\n",
    "        \n",
    "plt.legend(loc=0)\n",
    "plt.grid(True,color='0.7',linestyle=':',linewidth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## def money_trend_graph():\n",
    "    \n",
    "name = input(\"항목을 입력하세요: 선택항목: 'kpi200', '거래량', '고객예탁금', '신용잔고', '주식형펀드', '혼합형펀드', '채권형펀드' : \").split()\n",
    "date = input(\"날짜를 입력하세요 sample: '2019-01-10':\")\n",
    "    \n",
    "query = \"select * from kpi_with_money where Date >\"+\"'\"+date+\"'\"\n",
    "    \n",
    "tuple_name=tuple(name)\n",
    "df1 = pd.DataFrame()\n",
    "    \n",
    "df = pd.read_sql(query ,engine)\n",
    "\n",
    "df.columns=['Date','kpi200', '거래량', '고객예탁금', '신용잔고', '주식형펀드', '혼합형펀드', '채권형펀드']\n",
    "df = df.set_index('Date')\n",
    "df1=df[name]\n",
    "\n",
    "plt.figure(figsize=(16,4))\n",
    "colors = ['red','green','blue']\n",
    "for i in range(len(name)):\n",
    "    plt.subplot(2,2,i+1)\n",
    "    plt.plot(df1[name[i]]/df1[name[i]].loc[df.index[0]]*100,color=colors[i] )\n",
    "    \n",
    "    plt.legend(loc=0)\n",
    "    plt.grid(True,color='0.7',linestyle=':',linewidth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## def money_trend_graph():\n",
    "    \n",
    "name = input(\"항목을 입력하세요: 선택항목: 'kpi200', '거래량', '고객예탁금', '신용잔고', '주식형펀드', '혼합형펀드', '채권형펀드'\").split()\n",
    "date = input(\"날짜를 입력하세요 sample: '2019-01-10':\")\n",
    "    \n",
    "query = \"select * from kpi_with_money where Date >\"+\"'\"+date+\"'\"\n",
    "    \n",
    "tuple_name=tuple(name)\n",
    "df1 = pd.DataFrame()\n",
    "    \n",
    "df = pd.read_sql(query ,engine)\n",
    "\n",
    "df.columns=['Date','kpi200', '거래량', '고객예탁금', '신용잔고', '주식형펀드', '혼합형펀드', '채권형펀드']\n",
    "df = df.set_index('Date')\n",
    "df1=df[name]\n",
    "\n",
    "plt.figure(figsize=(16,4))\n",
    "colors = ['red','green','blue','pink','gray']\n",
    "for i in range(len(name)):\n",
    "    plt.subplot(2,2,i+1)\n",
    "    plt.plot(df1[name[i]]/df1[name[i]].loc[df.index[0]]*100,color=colors[i])\n",
    "    \n",
    "    plt.legend(loc=0)\n",
    "    plt.grid(True,color='0.7',linestyle=':',linewidth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Excel to mysql\n",
    "\n",
    "import FinanceDataReader as fdr\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "from  datetime import datetime\n",
    "\n",
    "engine = sqlalchemy.create_engine('mysql+pymysql://kkang:leaf2027@localhost/stock?charset=utf8',encoding='utf-8')\n",
    "\n",
    "date = input('원하는 날짜를 입력하세요 ')\n",
    "path = 'd:\\\\stockdata\\\\관리종목\\\\'+date+'.xlsx'\n",
    "\n",
    "df = pd.read_excel(path)\n",
    "\n",
    "df.to_sql(name='badstock', con=engine, if_exists='append', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Mysql to Excel\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "connect = create_engine('mysql+pymysql://kkang:leaf2027@localhost/stock?charset=utf8',encoding='utf-8')\n",
    "df = pd.read_sql(\"SELECT distinct Name,Code from market where date = '2019-09-05'\", connect)\n",
    "\n",
    "df.to_excel('d:\\\\sql_market.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## 이동 평균선\n",
    "\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "file = 'd:\\\\hrs.xlsx'\n",
    "\n",
    "connect = create_engine('mysql+pymysql://kkang:leaf2027@localhost/stock?charset=utf8',encoding='utf-8')\n",
    "df = pd.read_sql(\"SELECT * from market where Name = 'hrs' && Date > '2019-01-05'\", connect)\n",
    "\n",
    "volume_average_5 = df['Volume'].rolling(window=5,min_periods=1).mean()\n",
    "volume_average_10 = df['Volume'].rolling(window=10,min_periods=1).mean()\n",
    "volume_average_20 = df['Volume'].rolling(window=20,min_periods=1).mean()\n",
    "volume_average_60 = df['Volume'].rolling(window=60,min_periods=1).mean()\n",
    "volume_average_120 = df['Volume'].rolling(window=120,min_periods=1).mean()\n",
    "\n",
    "close_average_5 = df['Close'].rolling(window=5,min_periods=1).mean()\n",
    "close_average_10 = df['Close'].rolling(window=10,min_periods=1).mean()\n",
    "close_average_20 = df['Close'].rolling(window=20,min_periods=1).mean()\n",
    "close_average_60 = df['Close'].rolling(window=60,min_periods=1).mean()\n",
    "close_average_120 = df['Close'].rolling(window=120,min_periods=1).mean()\n",
    "\n",
    "df.insert(len(df.columns), \"Vol_MA5\", volume_average_5)\n",
    "df.insert(len(df.columns), \"Vol_MA10\", volume_average_10)\n",
    "df.insert(len(df.columns), \"Vol_MA20\", volume_average_20)\n",
    "df.insert(len(df.columns), \"Vol_MA60\", volume_average_60)\n",
    "df.insert(len(df.columns), \"Vol_MA120\", volume_average_120)\n",
    "\n",
    "df.insert(len(df.columns), \"Close_MA5\", close_average_5)\n",
    "df.insert(len(df.columns), \"Close_MA10\", close_average_10)\n",
    "df.insert(len(df.columns), \"Close_MA20\", close_average_20)\n",
    "df.insert(len(df.columns), \"Close_MA60\", close_average_60)\n",
    "df.insert(len(df.columns), \"Close_MA120\", close_average_120)\n",
    "\n",
    "df1 = df[['Date','Name','Close','Volume','Vol_MA5','Vol_MA10','Vol_MA20','Vol_MA60','Vol_MA120']]\n",
    "#df1.to_excel(file)\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 일일 종목선정 project 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## 일일 거래량 50만주이상 주식중 전일 거래량 보다 많은 거래량 top15 종목 \n",
    "\n",
    "import FinanceDataReader as fdr\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime as dt\n",
    "from datetime import datetime,timedelta\n",
    "from urllib.request import urlopen\n",
    "import sqlalchemy \n",
    "import pymysql\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "from matplotlib import font_manager, rc\n",
    "font_name = font_manager.FontProperties(fname=\"c:/Windows/Fonts/malgun.ttf\").get_name()\n",
    "rc('font', family=font_name)\n",
    "\n",
    "today = datetime.now()\n",
    "real_yesterday = (today-timedelta(1)).strftime('%Y-%m-%d')\n",
    "real_today = today.strftime('%Y-%m-%d')\n",
    "\n",
    "now = dt.datetime.today().strftime('%Y-%m-%d')\n",
    "engine = sqlalchemy.create_engine('mysql+pymysql://kkang:leaf2027@localhost/stock?charset=utf8',encoding='utf-8')\n",
    "\n",
    "market_df = pd.read_sql(\"select * from market where Date > '2019-01-01'\", engine)\n",
    "#market_df\n",
    "\n",
    "is_hrs=market_df['Name']=='HRS'\n",
    "hrs_df = market_df[is_hrs]\n",
    "yesterday = str(hrs_df['Date'].iloc[0])\n",
    "today = str(hrs_df['Date'].iloc[1])\n",
    "#print(yesterday)\n",
    "#print(today)\n",
    "\n",
    "#var = \"select * from market where (Date = '2019-01-02' OR Date = '2019-01-03')  and Volume >  500000\"\n",
    "#df = pd.read_sql(var ,engine)\n",
    "#df\n",
    "\n",
    "select_query = \"select * from market where (Date = \"\n",
    "volume_query = \"&& Volume >  500000\"\n",
    "    \n",
    "var = select_query +\"'\"+yesterday+\"'\"+'or Date ='+\"'\"+today+\"'\"+')' + volume_query\n",
    "df = pd.read_sql(var ,engine)\n",
    "\n",
    "#df\n",
    "\n",
    "\n",
    "df1 = df[df['Date'].astype(str) == yesterday]\n",
    "df1 = df1[['Name','Volume','Close']]\n",
    "df1.columns = ['Name','yester_Volume','yester_Close']\n",
    "#display(df1)\n",
    "\n",
    "\n",
    "df2 = df[df['Date'].astype(str) == today]\n",
    "df2 = df2[['Name','Volume','Close']]\n",
    "df2.columns = ['Name','today_Volume','today_Close']\n",
    "#display(df2)\n",
    "\n",
    "df3 = pd.merge(df1,df2,on='Name')\n",
    "df3['Close']=df3['today_Close']/df3['yester_Close']\n",
    "df3['Volume']=df3['today_Volume']/df3['yester_Volume']\n",
    "df3 = df3.sort_values(by=['Volume','Close'],ascending=False)\n",
    "df4 = df3.sort_values(by=['Close','Volume'],ascending=False)\n",
    "df3 = df3.reset_index(drop=True)\n",
    "\n",
    "df3 = df3[:15]\n",
    "df4 = df4.reset_index(drop=True)\n",
    "df4 = df4[:15]\n",
    "df3.to_excel('d:\\\\detect_stock_with_volume.xlsx', encoding='utf-8')\n",
    "df4.to_excel('d:\\\\detect_stock_with_price.xlsx', encoding='utf-8')        \n",
    "display(df3)\n",
    "display(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## 일일 거래량 50만주이상 주식중 전일 거래량 보다 많은 거래량 top15 종목  for loop 추가\n",
    "\n",
    "import FinanceDataReader as fdr\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime as dt\n",
    "from datetime import datetime,timedelta\n",
    "from urllib.request import urlopen\n",
    "import sqlalchemy \n",
    "import pymysql\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "from matplotlib import font_manager, rc\n",
    "font_name = font_manager.FontProperties(fname=\"c:/Windows/Fonts/malgun.ttf\").get_name()\n",
    "rc('font', family=font_name)\n",
    "\n",
    "today = datetime.now()\n",
    "real_yesterday = (today-timedelta(1)).strftime('%Y-%m-%d')\n",
    "real_today = today.strftime('%Y-%m-%d')\n",
    "\n",
    "now = dt.datetime.today().strftime('%Y-%m-%d')\n",
    "engine = sqlalchemy.create_engine('mysql+pymysql://kkang:leaf2027@localhost/stock?charset=utf8',encoding='utf-8')\n",
    "\n",
    "market_df = pd.read_sql(\"select * from market where Date > '2019-01-01'\", engine)\n",
    "#market_df\n",
    "\n",
    "is_hrs=market_df['Name']=='HRS'\n",
    "hrs_df = market_df[is_hrs]\n",
    "yesterday = str(hrs_df['Date'].iloc[0])\n",
    "today = str(hrs_df['Date'].iloc[1])\n",
    "\n",
    "#for i in range(hrs_df['Date'].shape[0]):\n",
    "for i in range(3):\n",
    "    yesterday = str(hrs_df['Date'].iloc[i])\n",
    "    today = str(hrs_df['Date'].iloc[i+1])\n",
    "    print('y:{}'.format(yesterday))\n",
    "    print('t:{}'.format(today))\n",
    "    select_query = \"select * from market where (Date = \"\n",
    "    volume_query = \"&& Volume >  500000\"\n",
    "    \n",
    "    var = select_query +\"'\"+yesterday+\"'\"+'or Date ='+\"'\"+today+\"'\"+')' + volume_query\n",
    "    df = pd.read_sql(var ,engine)\n",
    "\n",
    "    #df\n",
    "\n",
    "\n",
    "    df1 = df[df['Date'].astype(str) == yesterday]\n",
    "    df1 = df1[['Name','Volume','Close']]\n",
    "    df1.columns = ['Name','yester_Volume','yester_Close']\n",
    "    #display(df1)\n",
    "\n",
    "\n",
    "    df2 = df[df['Date'].astype(str) == today]\n",
    "    df2 = df2[['Name','Volume','Close']]\n",
    "    df2.columns = ['Name','today_Volume','today_Close']\n",
    "    #display(df2)\n",
    "\n",
    "    df3 = pd.merge(df1,df2,on='Name')\n",
    "    df3['Close']=df3['today_Close']/df3['yester_Close']\n",
    "    df3['Volume']=df3['today_Volume']/df3['yester_Volume']\n",
    "    df3 = df3.sort_values(by=['Volume','Close'],ascending=False)\n",
    "    df4 = df3.sort_values(by=['Close','Volume'],ascending=False)\n",
    "    df3 = df3.reset_index(drop=True)\n",
    "\n",
    "    df3 = df3[:15]\n",
    "    df4 = df4.reset_index(drop=True)\n",
    "    df4 = df4[:15]\n",
    "    df3.to_excel('d:\\\\detect_stock_with_volume.xlsx', encoding='utf-8')\n",
    "    df4.to_excel('d:\\\\detect_stock_with_price.xlsx', encoding='utf-8')        \n",
    "    display(df3)\n",
    "    display(df4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 일일종목선정 project 끝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## 일별 관리종목 추출\n",
    "\n",
    "from  datetime import datetime\n",
    "import pandas as pd\n",
    "import xlsxwriter\n",
    "\n",
    "today = datetime.now()\n",
    "today = today.strftime(\"%Y-%m-%d\")\n",
    "#today=input('입력')\n",
    "url = 'http://finance.naver.com/sise/investorDealTrendDay.nhn?bizdate=2020601&sosok=&page=1'\n",
    "url = 'https://finance.naver.com/sise/management.nhn'\n",
    "source = urlopen(url).read()   # 지정한 페이지에서 코드 읽기\n",
    "source = BeautifulSoup(source, 'lxml')   # 뷰티풀 스프로 태그별로 코드 분류\n",
    "data = []\n",
    "\n",
    "path = 'd:\\\\stockdata\\\\관리종목\\\\'+today+'.xlsx'\n",
    "body = source.find('body')\n",
    "trs = body.find_all('tr')\n",
    "name = []\n",
    "for tr in trs:\n",
    "    tds = tr.find_all('a',{'class':\"tltle\"})\n",
    "    for td in tds:\n",
    "        name.append(td.text.strip())\n",
    "\n",
    "df = pd.DataFrame(name)\n",
    "df['Date']=str(today)\n",
    "df = df.set_index('Date')\n",
    "df.columns=['Name']\n",
    "df.to_excel(path)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pykrx 분석 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pykrx.comm.util import dataframe_empty_handler, singleton\n",
    "from pykrx.comm.http import KrxHttp\n",
    "from pandas import DataFrame\n",
    "import pandas as pd\n",
    "from pykrx import stock\n",
    "\n",
    "a = stock.market.ticker._StockFinder()\n",
    "b = stock.market.ticker._StockTicker()\n",
    "df_a = a.read()\n",
    "df_b = b._get_stock_info_listed()\n",
    "df_finder_kosdaq = df_a[df_a['marketName']=='KOSDAQ']\n",
    "df_finder_kospi = df_a[df_a['marketName']=='KOSPI']\n",
    "#display(df_kosdaq.reset_index(drop=True))\n",
    "#display(df_kospi.reset_index(drop=True))\n",
    "\n",
    "df_ticker_kosdaq = df_b[df_b['시장']=='KOSDAQ']\n",
    "df_ticker_kospi = df_b[df_b['시장']=='KOSPI']\n",
    "\n",
    "df_finder_kosdaq.to_excel('d:\\\\find_kosdaq.xlsx')\n",
    "df_finder_kospi.to_excel('d:\\\\find_kospi.xlsx')\n",
    "df_ticker_kosdaq.to_excel('d:\\\\tick_kosdaq.xlsx')\n",
    "df_ticker_kospi.to_excel('d:\\\\tick_kospi.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('kospi-{}'.format(len(df_finder_kospi)))\n",
    "print('kosdaq-{}'.format(len(df_ticker_kosdaq)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "1360+958"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
