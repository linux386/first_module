{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import FinanceDataReader as fdr\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime as dt\n",
    "from datetime import datetime,timedelta\n",
    "from urllib.request import urlopen\n",
    "import sqlalchemy \n",
    "import pymysql\n",
    "import talib.abstract as ta\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "from matplotlib import font_manager, rc\n",
    "font_name = font_manager.FontProperties(fname=\"c:/Windows/Fonts/malgun.ttf\").get_name()\n",
    "rc('font', family=font_name)\n",
    "\n",
    "now = dt.datetime.today().strftime('%Y-%m-%d')\n",
    "engine = sqlalchemy.create_engine('mysql+pymysql://kkang:leaf2027@localhost/stock?charset=utf8',encoding='utf-8')\n",
    "conn = pymysql.connect(host = 'localhost', user = 'kkang', password = 'leaf2027' ,db = 'stock')\n",
    "curs = conn.cursor()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataBase 입출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## def get_stock_price_from_fdr(end_date=now):  코스피,코스닥 전체종목 입력\n",
    "        \n",
    "file_name = input('파일이름을 입력하세요:')\n",
    "toward = input('저장 방식을 입력하세요 : sample: excel, sql ')\n",
    "start_date = input(\"시작날자를 입려하세요 : sample: '2015-01-01'\")\n",
    "table_name = input(\"table명을 입력하세요 : sample: market\")\n",
    "data=pd.read_excel('d:\\\\'+ file_name)\n",
    "   \n",
    "code_list = data['종목코드'].tolist()\n",
    "code_list = [str(item).zfill(6) for item in code_list]\n",
    "name_list = data['종목명'].tolist()\n",
    "\n",
    "# 코스피 상장종목 전체\n",
    "stock_dic = dict(list(zip(code_list,name_list)))\n",
    "\n",
    "for code in sorted(stock_dic.keys()):\n",
    "    df  = fdr.DataReader(code,start_date,now)\n",
    "    print(code,stock_dic[code])\n",
    "    df['Code'],df['Name'] = code,stock_dic[code]\n",
    "    df = df[['Code','Name','Open','High','Low','Volume','Close']]\n",
    "    if toward == 'excel':\n",
    "        df.to_excel('d:\\\\data_set\\\\kospi\\\\'+ stock_dic[code] +'.xlsx',engine = 'xlsxwriter')\n",
    "    elif toward == 'sql':\n",
    "        df.to_sql(name=table_name, con=engine, if_exists='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#### 기존에 액면분할시 가격조정 안된 기존 data가 있을때\n",
    "## insert mysql 개별 주식\n",
    "\n",
    "Code = input('주식 Code를 입력하세요')\n",
    "Name = input('주식이름을 입력하세요')\n",
    "\n",
    "query = \"delete from  market where Code = \"+\"'\"+Code+\"'\"\n",
    "\n",
    "curs.execute(query)\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "df = fdr.DataReader(Code, '1995')\n",
    "df.to_excel('d:\\\\'+Code+'.xlsx', encoding='UTF-8')\n",
    "\n",
    "df = pd.read_excel('d:\\\\'+Code+'.xlsx')\n",
    "df['Code']= Code\n",
    "df['Name']= Name\n",
    "\n",
    "df = df[['Date','Code','Name','Open', 'High', 'Low', 'Volume','Close']]\n",
    "\n",
    "df.to_sql(name='market', con=engine, if_exists='append', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## def excel_to_mysql():\n",
    "\n",
    "file_name = input('파일이름을 입력하세요:')\n",
    "        \n",
    "df=pd.read_excel('d:\\\\'+ file_name)\n",
    "if file_name=='kpi200.xlsx':\n",
    "    df.columns=['Date','kpi200','거래량']\n",
    "    table_name = 'kpi200'\n",
    "    #df = df.set_index('Date')\n",
    "elif file_name=='moneytrend.xlsx':\n",
    "    table_name = 'moneytrend'\n",
    "    df.columns=['Date', '고객예탁금', '신용잔고','주식형펀드','혼합형펀드','채권형펀드']\n",
    "    #df = df.set_index('Date')\n",
    "else:\n",
    "    print('\\n file_name error\\n')\n",
    "    \n",
    "df.to_sql(name=table_name, con=engine, if_exists='append', index = False)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Excel to mysql\n",
    "\n",
    "import FinanceDataReader as fdr\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "from  datetime import datetime\n",
    "\n",
    "engine = sqlalchemy.create_engine('mysql+pymysql://kkang:leaf2027@localhost/stock?charset=utf8',encoding='utf-8')\n",
    "\n",
    "date = input('원하는 날짜를 입력하세요 ')\n",
    "path = 'd:\\\\stockdata\\\\관리종목\\\\'+date+'.xlsx'\n",
    "\n",
    "df = pd.read_excel(path)\n",
    "\n",
    "df.to_sql(name='badstock', con=engine, if_exists='append', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Mysql to Excel\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "connect = create_engine('mysql+pymysql://kkang:leaf2027@localhost/stock?charset=utf8',encoding='utf-8')\n",
    "df = pd.read_sql(\"SELECT distinct Name,Code from market where date = '2019-09-05'\", connect)\n",
    "\n",
    "df.to_excel('d:\\\\sql_market.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "###  선물크롤링하여 맨처음 DB에 future table생성할때\n",
    "\n",
    "# 2019-09-11 수정  mysql future table에서 최종 날짜를 확인해서 그뒤날부터 insert \n",
    "# 기존 daum 주식 사이트 : ajax 방식으로 변경으로 인해 이를 반영한 코드를 수정.\n",
    "# pip install fake-useragent 설치 후 실행 가능\n",
    "\n",
    "import io\n",
    "import json\n",
    "import sys\n",
    "import pandas as pd\n",
    "import sqlalchemy \n",
    "import urllib.request as req\n",
    "from datetime import datetime\n",
    "from fake_useragent import UserAgent\n",
    "\n",
    "engine = sqlalchemy.create_engine('mysql+pymysql://kkang:leaf2027@localhost/stock?charset=utf8',encoding='utf-8')\n",
    "\n",
    "\n",
    "# Fake Header 정보\n",
    "ua = UserAgent()\n",
    "\n",
    "# 헤더 선언\n",
    "headers = {\n",
    "    'User-Agent': ua.ie,\n",
    "    'referer': 'http://finance.daum.net/domestic/futures'\n",
    "}\n",
    "\n",
    "\n",
    "url = \"http://finance.daum.net/api/future/KR4101PC0002/days?pagination=true&page=1\"\n",
    "res = req.urlopen(req.Request(url, headers=headers)).read().decode('utf-8')\n",
    "\n",
    "df1 = pd.DataFrame()\n",
    "for i in range(1,7):\n",
    "    # 다음 주식 요청 URL\n",
    "    url = \"http://finance.daum.net/api/future/KR4101PC0002/days?pagination=true&page=\"+str(i)\n",
    "\n",
    "    res = req.urlopen(req.Request(url, headers=headers)).read().decode('utf-8')\n",
    "    \n",
    "    rank_json = json.loads(res)['data']\n",
    "    \n",
    "    df = pd.DataFrame(rank_json)\n",
    "    df1 = df1.append(df,ignore_index=True)\n",
    "    \n",
    "df2 = df1[['date','tradePrice','change', 'changePrice','changeRate','unsettledVolume','foreignSettlement', 'institutionSettlement', 'privateSettlement']]\n",
    "df2.columns=('Date','Future','change','가격변동','등락률','미결제약정','외국인','기관','개인')\n",
    "df2['Date'] = pd.to_datetime(df2['Date']).dt.date\n",
    "#df2['Date'] = pd.to_datetime(df2['Date']).apply(lambda x: x.date())\n",
    "#df2['Date'] = pd.to_datetime(df2['Date'], format = '%Y-%m-%d') # yyyy-mm-dd hh:mm:ss -> yyyy-mm-dd (속성은그대로 보여주는 형식만 변경)\n",
    "df2 =df2[['Date','Future','미결제약정','외국인','기관','개인']]\n",
    "#df2 = df2[df2.Date > until_date]\n",
    "df2.to_sql(name='future', con=engine, if_exists='append', index = False)\n",
    "df2 = df2.set_index('Date')\n",
    "df2.to_excel('d:\\\\future.xlsx',encoding='utf-8')\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###  선물 DB Update할때\n",
    "\n",
    "# 2019-09-11 수정  mysql future table에서 최종 날짜를 확인해서 그뒤날부터 insert \n",
    "# 기존 daum 주식 사이트 : ajax 방식으로 변경으로 인해 이를 반영한 코드를 수정.\n",
    "# pip install fake-useragent 설치 후 실행 가능\n",
    "\n",
    "import io\n",
    "import json\n",
    "import sys\n",
    "import pandas as pd\n",
    "import sqlalchemy \n",
    "\n",
    "from datetime import datetime\n",
    "from fake_useragent import UserAgent\n",
    "\n",
    "engine = sqlalchemy.create_engine('mysql+pymysql://kkang:leaf2027@localhost/stock?charset=utf8',encoding='utf-8')\n",
    "future_df = pd.read_sql(\"select Date from future order by Date desc limit 1\", engine)\n",
    "future_df = str(future_df['Date'])\n",
    "until_date = future_df[5:15]\n",
    "\n",
    "year = until_date.split('-')[0]\n",
    "mm = until_date.split('-')[1]\n",
    "dd = until_date.split('-')[2]\n",
    "#year=year[2:]\n",
    "until_date = year+'-'+mm+'-'+dd\n",
    "until_date = datetime.strptime(until_date, '%Y-%m-%d').date() ## str 을  datetime.date로 type 변경\n",
    "\n",
    "# Fake Header 정보\n",
    "ua = UserAgent()\n",
    "\n",
    "# 헤더 선언\n",
    "headers = {\n",
    "    'User-Agent': ua.ie,\n",
    "    'referer': 'http://finance.daum.net/domestic/futures'\n",
    "}\n",
    "\n",
    "\n",
    "url = \"http://finance.daum.net/api/future/KR4101PC0002/days?pagination=true&page=1\"  #KR4011PC002 \"선물 코스피 200지수 12월물\" 코드는 구글검색이용\n",
    "res = req.urlopen(req.Request(url, headers=headers)).read().decode('utf-8')\n",
    "\n",
    "df1 = pd.DataFrame()\n",
    "for i in range(1,3):\n",
    "    # 다음 주식 요청 URL\n",
    "    url = \"http://finance.daum.net/api/future/KR4101PC0002/days?pagination=true&page=\"+str(i)\n",
    "\n",
    "    res = req.urlopen(req.Request(url, headers=headers)).read().decode('utf-8')\n",
    "    \n",
    "    rank_json = json.loads(res)['data']\n",
    "    \n",
    "    df = pd.DataFrame(rank_json)\n",
    "    df1 = df1.append(df,ignore_index=True)\n",
    "df2 = df1[['date','tradePrice','change', 'changePrice','changeRate','unsettledVolume','foreignSettlement', 'institutionSettlement', 'privateSettlement']]\n",
    "df2.columns=('Date','Future','change','가격변동','등락률','미결제약정','외국인','기관','개인')\n",
    "df2['Date'] = pd.to_datetime(df2['Date']).dt.date\n",
    "#df2['Date'] = pd.to_datetime(df2['Date']).apply(lambda x: x.date())\n",
    "#df2['Date'] = pd.to_datetime(df2['Date'], format = '%Y-%m-%d') # yyyy-mm-dd hh:mm:ss -> yyyy-mm-dd (속성은그대로 보여주는 형식만 변경)\n",
    "df2 =df2[['Date','Future','미결제약정','외국인','기관','개인']]\n",
    "df2 = df2[df2.Date > until_date]\n",
    "df2.to_sql(name='future', con=engine, if_exists='append', index = False)\n",
    "df2 = df2.set_index('Date')\n",
    "df2.to_excel('d:\\\\future.xlsx',encoding='utf-8')\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matplotlib를 사용한 Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## 선물  베이시스 graph ( One_graph)\n",
    "## def future_trend_graph():\n",
    "   \n",
    "\n",
    "#query = \"select * from future where Date > '2019-06-13'\"+\"'\"+date+\"'\"\n",
    "query = \"select * from basis where Date > '2019-06-13'\"\n",
    "\n",
    "\n",
    "name=['kpi200','Future']\n",
    "#name=['미결제약정']\n",
    "\n",
    "tuple_name=tuple(name)\n",
    "df1 = pd.DataFrame()\n",
    "    \n",
    "df = pd.read_sql(query ,engine)\n",
    "\n",
    "#df.columns=['Date','kpi200','Close']\n",
    "df = df.set_index('Date')\n",
    "df1=df[name]\n",
    "\n",
    "plt.figure(figsize=(16,4))    \n",
    "for i in range(len(name)):\n",
    "    plt.plot(df1[name[i]]/df1[name[i]].loc[df.index[0]]*100)\n",
    "        \n",
    "plt.legend(loc=0)\n",
    "plt.grid(True,color='0.7',linestyle=':',linewidth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## 선물  베이시스 graph ( One_graph)\n",
    "## def future_trend_graph():\n",
    "   \n",
    "\n",
    "#query = \"select * from future where Date > '2019-06-13'\"+\"'\"+date+\"'\"\n",
    "query = \"select * from future where Date > '2019-06-13'\"\n",
    "\n",
    "\n",
    "name=['Close', '미결제약정', '외국인', '기관', '개인']\n",
    "#name=['미결제약정']\n",
    "\n",
    "tuple_name=tuple(name)\n",
    "df1 = pd.DataFrame()\n",
    "    \n",
    "df = pd.read_sql(query ,engine)\n",
    "\n",
    "df.columns=['Date', 'Close', '미결제약정', '외국인', '기관', '개인']\n",
    "df = df.set_index('Date')\n",
    "df1=df[name]\n",
    "\n",
    "plt.figure(figsize=(16,4))    \n",
    "for i in range(len(name)):\n",
    "    plt.plot(df1[name[i]]/df1[name[i]].loc[df.index[0]]*100)\n",
    "        \n",
    "plt.legend(loc=0)\n",
    "plt.grid(True,color='0.7',linestyle=':',linewidth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## 선물 graph ( One_graph)\n",
    "## def future_trend_graph():\n",
    "    \n",
    "#name = input(\"항목을 입력하세요: 선택항목: 'kpi200', '거래량', '고객예탁금', '신용잔고', '주식형펀드', '혼합형펀드', '채권형펀드'\").split()\n",
    "#date = input(\"날짜를 입력하세요 sample: '2019-01-10':\")\n",
    "    \n",
    "    \n",
    "#query = \"select * from future where Date > '2019-06-13'\"+\"'\"+date+\"'\"\n",
    "query = \"select * from future where Date > '2019-06-13'\"\n",
    "\n",
    "\n",
    "name=['Close', '미결제약정', '외국인', '기관', '개인']\n",
    "#name=['미결제약정']\n",
    "\n",
    "tuple_name=tuple(name)\n",
    "df1 = pd.DataFrame()\n",
    "    \n",
    "df = pd.read_sql(query ,engine)\n",
    "\n",
    "df.columns=['Date', 'Close', '미결제약정', '외국인', '기관', '개인']\n",
    "df = df.set_index('Date')\n",
    "df1=df[name]\n",
    "\n",
    "plt.figure(figsize=(16,4))    \n",
    "for i in range(len(name)):\n",
    "    plt.plot(df1[name[i]]/df1[name[i]].loc[df.index[0]]*100)\n",
    "        \n",
    "plt.legend(loc=0)\n",
    "plt.grid(True,color='0.7',linestyle=':',linewidth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## 선물 graph ( Multi_graph)\n",
    "## def future_trend_graph():\n",
    " \n",
    "#name = input(\"항목을 입력하세요: 선택항목: 'kpi200', '거래량', '고객예탁금', '신용잔고', '주식형펀드', '혼합형펀드', '채권형펀드'\").split()\n",
    "#date = input(\"날짜를 입력하세요 sample: '2019-01-10':\")\n",
    "    \n",
    "#query = \"select * from future where Date > '2019-06-13'\"+\"'\"+date+\"'\"\n",
    "query = \"select * from future where Date > '2019-06-11'\"\n",
    "\n",
    "\n",
    "name=['Close', '미결제약정', '외국인', '기관', '개인']\n",
    "name1=['Close','미결제약정']\n",
    "name2=['외국인', '기관', '개인']\n",
    "\n",
    "#tuple_name=tuple(name)\n",
    "df1 = pd.DataFrame()\n",
    "    \n",
    "df = pd.read_sql(query ,engine)\n",
    "\n",
    "df.columns=['Date', 'Close', '미결제약정', '외국인', '기관', '개인']\n",
    "df = df.set_index('Date')\n",
    "df1=df[name]\n",
    "\n",
    "plt.figure(figsize=(16,4))    \n",
    "for i in range(len(name1)):\n",
    "    #plt.subplot(2,2,i+1)\n",
    "    plt.plot(df1[name1[i]]/df1[name1[i]].loc[df.index[0]]*100,color=colors[i])\n",
    "    \n",
    "plt.legend(loc=0)\n",
    "plt.grid(True,color='0.7',linestyle=':',linewidth=1)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(16,4)) \n",
    "for i in range(len(name2)):\n",
    "    plt.subplot(2,2,i+1)\n",
    "    plt.plot(df1[name2[i]]/df1[name2[i]].loc[df.index[0]]*100,color=colors[i])\n",
    "    \n",
    "    plt.legend(loc=0)\n",
    "    plt.grid(True,color='0.7',linestyle=':',linewidth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Close and Volume graph 표준화\n",
    "\n",
    "import FinanceDataReader as fdr\n",
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "engine = sqlalchemy.create_engine('mysql+pymysql://kkang:leaf2027@localhost/stock?charset=utf8',encoding='utf-8')\n",
    "\n",
    "select_query = \"select Date,Volume,Close from market where Name= \"\n",
    "date_query = \"Date > \"\n",
    "\n",
    "def choice(select):\n",
    "    name = '화천기계'\n",
    "    date = '2019-01-01'\n",
    "    if select == 1:\n",
    "        name = input('주식이름을 입력하세요 : ')\n",
    "        date = input('날짜를 입력하세요: ')\n",
    "        var = select_query +\"'\"+name+\"'\"+\" \"+\"&&\"+\" \"+date_query+\"'\"+date+\"'\" \n",
    "        return var\n",
    "    elif select == 2:\n",
    "        var = select_query +\"'\"+name+\"'\"+\" \"+\"&&\"+\" \"+date_query+\"'\"+date+\"'\" \n",
    "        return var\n",
    "\n",
    "select = input('select 1 or 2: ')\n",
    "select = int(select)\n",
    "\n",
    "df = pd.read_sql(choice(select), engine)\n",
    "\n",
    "source = MinMaxScaler()\n",
    "data = source.fit_transform(df[['Close','Volume']].values.astype(float))\n",
    "df1 = pd.DataFrame(data)\n",
    "df1.columns=['Close','Volume']\n",
    "df1 = df1.set_index(df['Date'])\n",
    "df1.plot(figsize=(16,4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Close and Volume graph 표준화 _ 2  종목을 list로 설정\n",
    "\n",
    "import FinanceDataReader as fdr\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "engine = sqlalchemy.create_engine('mysql+pymysql://kkang:leaf2027@localhost/stock?charset=utf8',encoding='utf-8')\n",
    "\n",
    "select_query = \"select Date,Volume,Close from market where Name= \"\n",
    "date_query = \"Date > \"\n",
    "\n",
    "df = pd.read_excel('d:\\\\detect_stock_with_volume.xlsx')\n",
    "df=df['Name']\n",
    "#name = df.values.tolist() ## numpy to list\n",
    "name = df.to_list()              ## DataFrame to list\n",
    "date = '2019-01-01'\n",
    "for i in name:\n",
    "    var = select_query +\"'\"+i+\"'\"+\" \"+\"&&\"+\" \"+date_query+\"'\"+date+\"'\" \n",
    "    df = pd.read_sql(var, engine)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['Close','Volume']].values.astype(float))\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1.columns=['Close','Volume']\n",
    "    df1 = df1.set_index(df['Date'])\n",
    "    df1.plot(figsize=(16,2))\n",
    "    plt.title(i)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Close and Volume graph 표준화-3  이동평균선 포함\n",
    "\n",
    "import talib.abstract as ta\n",
    "import FinanceDataReader as fdr\n",
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "engine = sqlalchemy.create_engine('mysql+pymysql://kkang:leaf2027@localhost/stock?charset=utf8',encoding='utf-8')\n",
    "\n",
    "select_query = \"select * from market where Name= \"\n",
    "date_query = \"Date > \"\n",
    "\n",
    "def choice(select):\n",
    "    name = 'hrs'\n",
    "    date = '2010-01-01'\n",
    "    if select == 1:\n",
    "        name = input('주식이름을 입력하세요 : ')\n",
    "        date = input('날짜를 입력하세요: ')\n",
    "        var = select_query +\"'\"+name+\"'\"+\" \"+\"&&\"+\" \"+date_query+\"'\"+date+\"'\" \n",
    "        return var\n",
    "    elif select == 2:\n",
    "        var = select_query +\"'\"+name+\"'\"+\" \"+\"&&\"+\" \"+date_query+\"'\"+date+\"'\" \n",
    "        return var\n",
    "\n",
    "select = input('select 1 or 2: ')\n",
    "select = int(select)\n",
    "\n",
    "df = pd.read_sql(choice(select), engine)\n",
    "df[['Open','High','Low','Volume','Close']] = df[['Open','High','Low','Volume','Close']].astype(float) #  TA-Lib로 평균을 구하려면 실수로 만들어야 함\n",
    "df.columns=df.columns.str.lower()\n",
    "\n",
    "talib_ma5 = ta.MA(df, timeperiod=5)\n",
    "df['ma5'] = talib_ma5\n",
    "\n",
    "talib_ma120 = ta.MA(df, timeperiod=120)\n",
    "df['ma120'] = talib_ma120\n",
    "\n",
    "source = MinMaxScaler()\n",
    "data = source.fit_transform(df[['close','volume','ma120']].values)\n",
    "df1 = pd.DataFrame(data)\n",
    "df1.columns=['close','ma120','volume']\n",
    "df1 = df1.set_index(df['date'])\n",
    "df1.plot(figsize=(16,4))\n",
    "\n",
    "choice(select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Close and Volume and MA graph 표준화-3  주식 DataFrame에서   종가, 거래걍, 이동평균선을 graph로 그리는 함수 \n",
    "\n",
    "def close_vol_ma(DataFrame,select):\n",
    "\n",
    "    df = DataFrame\n",
    "    df.columns=df.columns.str.lower()\n",
    "    df[['volume','close']] = df[['volume','close']].astype(float) #  TA-Lib로 평균을 구하려면 실수로 만들어야 함\n",
    "\n",
    "    talib_ma5 = ta.MA(df, timeperiod=5)\n",
    "    df['ma5'] = talib_ma5\n",
    "    \n",
    "    talib_ma10 = ta.MA(df, timeperiod=10)\n",
    "    df['ma10'] = talib_ma10    \n",
    "\n",
    "    talib_ma15 = ta.MA(df, timeperiod=15)\n",
    "    df['ma15'] = talib_ma15\n",
    "\n",
    "    talib_ma20 = ta.MA(df, timeperiod=20)\n",
    "    df['ma20'] = talib_ma20\n",
    "    \n",
    "    talib_ma30 = ta.MA(df, timeperiod=30)\n",
    "    df['ma30'] = talib_ma30    \n",
    "    \n",
    "    talib_ma60 = ta.MA(df, timeperiod=60)\n",
    "    df['ma60'] = talib_ma60    \n",
    "    \n",
    "    talib_ma120 = ta.MA(df, timeperiod=120)\n",
    "    df['ma120'] = talib_ma120    \n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close',select,'volume']].values)\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1.columns=['close',select,'volume']\n",
    "    df1 = df1.set_index(df['date'])\n",
    "    df1.plot(figsize=(16,4))\n",
    "close_vol_ma(df,select='ma20')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## def stock_select_with_Volume_Close():\n",
    "    \n",
    "yesterday = input(\"어제날짜를 입력하세요 : sample: '2019-02-07 00:00:00'  \") \n",
    "today = input(\"오늘날짜를 입력하세요 : sample: '2019-02-07 00:00:00'  \")\n",
    "    \n",
    "select_query = \"select * from market where Date >=\"\n",
    "volume_query = \"&& Volume >  500000\"\n",
    "    \n",
    "var = select_query +\"'\"+yesterday+\"'\"+ volume_query\n",
    "df = pd.read_sql(var ,engine)\n",
    "\n",
    "df1 = df[df['Date'].astype(str) == yesterday]\n",
    "df1 = df1[['Name','Volume','Close']]\n",
    "df1.columns = ['Name','yester_Volume','yester_Close']\n",
    "#display(df1)\n",
    "\n",
    "df2 = df[df['Date'].astype(str) == today]\n",
    "df2 = df2[['Name','Volume','Close']]\n",
    "df2.columns = ['Name','today_Volume','today_Close']\n",
    "#display(df2)\n",
    "\n",
    "df3 = pd.merge(df1,df2,on='Name')\n",
    "df3['Close']=df3['today_Close']/df3['yester_Close']\n",
    "df3['Volume']=df3['today_Volume']/df3['yester_Volume']\n",
    "df3 = df3.sort_values(by=['Volume','Close'],ascending=False)\n",
    "df3 = df3.reset_index(drop=True)\n",
    "df3 = df3[:10]\n",
    "df4 = df3.sort_values(by=['Close','Volume'],ascending=False)\n",
    "df4 = df4.reset_index(drop=True)\n",
    "df4 = df4[:10]\n",
    "display(df3)\n",
    "display(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## def stock_price_graph():\n",
    "    \n",
    "name = input('주식이름을 입력하세요:').split()\n",
    "date = input(\"날짜를 입력하세요 sample: '2019-01-10': \")\n",
    "\n",
    "select_query = \"select Date,Close from market where Name= \"\n",
    "date_query =  \"Date >\"\n",
    "\n",
    "tuple_name=tuple(name)\n",
    "df1 = pd.DataFrame()\n",
    "\n",
    "for x in tuple_name:\n",
    "    var = select_query +\"'\"+x+\"'\"+\" \"+\"&&\"+\" \"+date_query+\"'\"+date+\"'\"\n",
    "    df = pd.read_sql(var ,engine) \n",
    "    df.columns=['Date',x]\n",
    "    if df1.empty:\n",
    "        df1 = df\n",
    "    else:\n",
    "        df1 = pd.merge (df,df1,on='Date')\n",
    "df1=df1.set_index('Date')\n",
    "    \n",
    "plt.figure(figsize=(12,5))\n",
    "    \n",
    "for i in range(len(name)):\n",
    "    plt.plot(df1[name[i]]/df1[name[i]].loc[df['Date'][0]]*100)\n",
    "        \n",
    "plt.legend(loc=0)\n",
    "plt.grid(True,color='0.7',linestyle=':',linewidth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def stock_price_graph():  여러개 입력가능\n",
    "    \n",
    "name = input('주식이름을 입력하세요:')\n",
    "date = input(\"날짜를 입력하세요 sample: '2019-01-10':\")\n",
    "        \n",
    "select_query = \"select * from market where Name= \"\n",
    "\n",
    "var = select_query +\"'\"+x+\"'\"+\" \"+\"&&\"+\" \"+date_query+\"'\"+date+\"'\"\n",
    "    df = pd.read_sql(var ,engine)\n",
    "    df.columns=['Date',x]\n",
    "    if df1.empty:\n",
    "        df1 = df\n",
    "    else:\n",
    "        df1 = pd.merge (df,df1,on='Date')\n",
    "df1=df1.set_index('Date')\n",
    "    \n",
    "plt.figure(figsize=(12,5))\n",
    "    `\n",
    "for i in range(len(name)):\n",
    "    plt.plot(df1[name[i]]/df1[name[i]].loc[df['Date'][0]]*100)\n",
    "        \n",
    "plt.legend(loc=0)\n",
    "plt.grid(True,color='0.7',linestyle=':',linewidth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## def money_trend_graph():\n",
    "    \n",
    "name = input(\"항목을 입력하세요: 선택항목: 'kpi200', '거래량', '고객예탁금', '신용잔고', '주식형펀드', '혼합형펀드', '채권형펀드'\").split()\n",
    "date = input(\"날짜를 입력하세요 sample: '2019-01-10':\")\n",
    "    \n",
    "query = \"select * from kpi_with_money where Date >\"+\"'\"+date+\"'\"\n",
    "    \n",
    "tuple_name=tuple(name)\n",
    "df1 = pd.DataFrame()\n",
    "    \n",
    "df = pd.read_sql(query ,engine)\n",
    "\n",
    "df.columns=['Date','kpi200', '거래량', '고객예탁금', '신용잔고', '주식형펀드', '혼합형펀드', '채권형펀드']\n",
    "df = df.set_index('Date')\n",
    "df1=df[name]\n",
    "\n",
    "\n",
    "for i in range(len(name)):\n",
    "    plt.plot(df1[name[i]]/df1[name[i]].loc[df.index[0]]*100)\n",
    "        \n",
    "plt.legend(loc=0)\n",
    "plt.grid(True,color='0.7',linestyle=':',linewidth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## def money_trend_graph():\n",
    "    \n",
    "name = input(\"항목을 입력하세요: 선택항목: 'kpi200', '거래량', '고객예탁금', '신용잔고', '주식형펀드', '혼합형펀드', '채권형펀드'\").split()\n",
    "date = input(\"날짜를 입력하세요 sample: '2019-01-10':\")\n",
    "    \n",
    "query = \"select * from kpi_with_money where Date >\"+\"'\"+date+\"'\"\n",
    "    \n",
    "tuple_name=tuple(name)\n",
    "df1 = pd.DataFrame()\n",
    "    \n",
    "df = pd.read_sql(query ,engine)\n",
    "\n",
    "df.columns=['Date','kpi200', '거래량', '고객예탁금', '신용잔고', '주식형펀드', '혼합형펀드', '채권형펀드']\n",
    "df = df.set_index('Date')\n",
    "df1=df[name]\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "for i in range(len(name)):\n",
    "    plt.plot(df1[name[i]]/df1[name[i]].loc[df.index[0]]*100)\n",
    "        \n",
    "plt.legend(loc=0)\n",
    "plt.grid(True,color='0.7',linestyle=':',linewidth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## def money_trend_graph():  integrate graph\n",
    "    \n",
    "name = input(\"항목을 입력하세요: 선택항목: 'kpi200', '거래량', '고객예탁금', '신용잔고', '주식형펀드', '혼합형펀드', '채권형펀드'\").split()\n",
    "date = input(\"날짜를 입력하세요 sample: '2019-01-10':\")\n",
    "    \n",
    "query = \"select * from kpi_with_money where Date >\"+\"'\"+date+\"'\"\n",
    "    \n",
    "tuple_name=tuple(name)\n",
    "df1 = pd.DataFrame()\n",
    "    \n",
    "df = pd.read_sql(query ,engine)\n",
    "\n",
    "df.columns=['Date','kpi200', '거래량', '고객예탁금', '신용잔고', '주식형펀드', '혼합형펀드', '채권형펀드']\n",
    "df = df.set_index('Date')\n",
    "df1=df[name]\n",
    "\n",
    "plt.figure(figsize=(16,4))\n",
    "colors = ['red','green','blue','pink','gray']\n",
    "for i in range(len(name)):\n",
    "    plt.subplot(2,2,i+1)\n",
    "    plt.plot(df1[name[i]]/df1[name[i]].loc[df.index[0]]*100,color=colors[i])\n",
    "    \n",
    "    plt.legend(loc=0)\n",
    "    plt.grid(True,color='0.7',linestyle=':',linewidth=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Crawling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 상장회사 종가확인\n",
    "# 브라우저 실행\n",
    "from selenium import webdriver\n",
    "driver = webdriver.Chrome('C:/Users/kkang/selenium/chromedriver.exe')\n",
    "\n",
    "# 상장회사검색\n",
    "driver.get('http://marketdata.krx.co.kr/mdi#document=040602')\n",
    "\n",
    "# 다운로드 버튼을 클릭\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "button = driver.find_element(By.XPATH, '//button[text()=\"Excel\"]')\n",
    "button.click()\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "# 다운로드 폴더로 이동\n",
    "folder = 'c:\\\\Users\\\\kkang\\\\Downloads'\n",
    "os.chdir(folder)\n",
    "\n",
    "# 파일 다운로드까지 대기 (1초씩 최대 30회)\n",
    "fname = 'data.xls'\n",
    "for _ in range(30):\n",
    "    if os.path.exists(fname):\n",
    "        break\n",
    "    time.sleep(1)\n",
    "\n",
    "# 파일명 바꾸기\n",
    "os.rename('data.xls', 'price.xls')\n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 일별 관리종목 추출\n",
    "\n",
    "from  datetime import datetime\n",
    "import pandas as pd\n",
    "import xlsxwriter\n",
    "\n",
    "today = datetime.now()\n",
    "today = today.strftime(\"%Y-%m-%d\")\n",
    "#today=input('입력')\n",
    "url = 'http://finance.naver.com/sise/investorDealTrendDay.nhn?bizdate=2020601&sosok=&page=1'\n",
    "url = 'https://finance.naver.com/sise/management.nhn'\n",
    "source = urlopen(url).read()   # 지정한 페이지에서 코드 읽기\n",
    "source = BeautifulSoup(source, 'lxml')   # 뷰티풀 스프로 태그별로 코드 분류\n",
    "data = []\n",
    "\n",
    "path = 'd:\\\\stockdata\\\\관리종목\\\\'+today+'.xlsx'\n",
    "body = source.find('body')\n",
    "trs = body.find_all('tr')\n",
    "name = []\n",
    "for tr in trs:\n",
    "    tds = tr.find_all('a',{'class':\"tltle\"})\n",
    "    for td in tds:\n",
    "        name.append(td.text.strip())\n",
    "\n",
    "df = pd.DataFrame(name)\n",
    "df['Date']=str(today)\n",
    "df = df.set_index('Date')\n",
    "df.columns=['Name']\n",
    "df.to_excel(path)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### pykrx 모듈을 통한 krx 웹 crawling\n",
    "\n",
    "from pykrx.comm.util import dataframe_empty_handler, singleton\n",
    "from pykrx.comm.http import KrxHttp\n",
    "from pandas import DataFrame\n",
    "import pandas as pd\n",
    "from pykrx import stock\n",
    "\n",
    "a = stock.market.ticker._StockFinder()\n",
    "b = stock.market.ticker._StockTicker()\n",
    "df_a = a.read()\n",
    "df_b = b._get_stock_info_listed()\n",
    "df_finder_kosdaq = df_a[df_a['marketName']=='KOSDAQ']\n",
    "df_finder_kospi = df_a[df_a['marketName']=='KOSPI']\n",
    "#display(df_kosdaq.reset_index(drop=True))\n",
    "#display(df_kospi.reset_index(drop=True))\n",
    "\n",
    "df_ticker_kosdaq = df_b[df_b['시장']=='KOSDAQ']\n",
    "df_ticker_kospi = df_b[df_b['시장']=='KOSPI']\n",
    "\n",
    "df_finder_kosdaq.to_excel('d:\\\\find_kosdaq.xlsx')\n",
    "df_finder_kospi.to_excel('d:\\\\find_kospi.xlsx')\n",
    "df_ticker_kosdaq.to_excel('d:\\\\tick_kosdaq.xlsx')\n",
    "df_ticker_kospi.to_excel('d:\\\\tick_kospi.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock Prediction 관련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  상승추세 종목 발굴 _1\n",
    "\n",
    "## market_good table에서 모든 colume 추출\n",
    "def market_stock(date):\n",
    "    select_query = \"select * from market_good where Date >  \"\n",
    "    var = select_query +\"'\"+date+\"'\" \n",
    "    df = pd.read_sql(var, engine)\n",
    "    return df\n",
    "\n",
    "from mod1 import *\n",
    "\n",
    "## 개별종목이름 리스트 생성\n",
    "df = market_stock('2019-01-01')\n",
    "stock_name=df['Name'].drop_duplicates()\n",
    "stock_name = stock_name.tolist()\n",
    "\n",
    "## 종목별로 이동평균선(ma5 ~ ma120)생성\n",
    "ma_df = pd.DataFrame()\n",
    "for name in stock_name:\n",
    "    print(name)\n",
    "    df1 = df[(df['Name'] == name)]\n",
    "    ma(df1)\n",
    "    ma_df=ma_df.append(df1)\n",
    "    \n",
    "#df3.to_excel('d:\\\\good_stock.xlsx')\n",
    "\n",
    "##  현재 today 종가가 ma120일선 위에있는 (상승추세에있는) 종목 추출\n",
    "df1 = ma_df[['date','code','name','close','volume','ma120']]\n",
    "df2 = df1[(df1['date'].astype(str) == '2019-09-30')]\n",
    "df3 = df2[(df2['close'] >= df2['ma120'])]\n",
    "df3\n",
    "\n",
    "## 상승추세종목 리스트 생성\n",
    "good_name=df3['name']\n",
    "good_name = good_name.tolist()\n",
    "\n",
    "## 상승추세 종목 그래프 생성 \n",
    "for i in good_name:\n",
    "    df=select_stock(i,'17-01-01')\n",
    "    df1 = close_vol_ma(df,'ma120')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  상승추세 종목 발굴 _2\n",
    "##  상승추세종목을 표준화하여 세부적으로 추출\n",
    "\n",
    "from mod1 import *\n",
    "\n",
    "## 개별종목이름 리스트 생성\n",
    "all_df = market_stock('2019-01-01')\n",
    "stock_name=all_df['Name'].drop_duplicates()\n",
    "stock_name = stock_name.tolist()\n",
    "\n",
    "## 종목별로 이동평균선(ma5 ~ ma120)생성\n",
    "ma_df = pd.DataFrame()\n",
    "min_max_df = pd.DataFrame()\n",
    "for name in stock_name:\n",
    "    print(name)\n",
    "    all_df1 = all_df[(all_df['Name'] == name)]\n",
    "    ma(all_df1)\n",
    "    ma_df=ma_df.append(all_df1)\n",
    "    \n",
    "#df3.to_excel('d:\\\\good_stock.xlsx')\n",
    "\n",
    "##  현재 today 종가가 ma120일선 위에있는 (상승추세에있는) 종목 추출\n",
    "first_df1 = ma_df[['date','code','name','close','volume','ma120']]\n",
    "first_df2 = first_df1[(first_df1['date'].astype(str) == '2019-09-30')]\n",
    "first_df3 = first_df2[(first_df2['close'] >= first_df2['ma120'])]\n",
    "first_df3\n",
    "\n",
    "## 상승추세종목 리스트 생성\n",
    "good_name=first_df3['name']\n",
    "good_name = good_name.tolist()\n",
    "\n",
    "## 상승추세종목별로 표준화 (MinMaxSchalr)생성\n",
    "good_stock_df = pd.DataFrame()\n",
    "min_max_df = pd.DataFrame()\n",
    "for name in good_name:\n",
    "    print(name)\n",
    "    good_df1 = select_stock(name,'2019-01-01')\n",
    "    good_stock_df=good_stock_df.append(good_df1)\n",
    "    min_max_df1 = min_max(good_df1,'ma120')\n",
    "    min_max_df=min_max_df.append(min_max_df1)\n",
    "\n",
    "good_stock_df1 = good_stock_df.set_index('Date')\n",
    "min_max_df[['code','name']]=good_stock_df1[['Code','Name']]\n",
    "\n",
    "second_df1 = min_max_df\n",
    "second_df2 = second_df1[(second_df1.index.astype(str) == real_yesterday)]\n",
    "second_df3 = second_df2[(second_df2['close'] <= 0.3) & (second_df2['ma120'] <=0.3)]\n",
    "second_df3\n",
    "\n",
    "## 표준화로 선별한 상승추세종목 리스트 생성\n",
    "min_max_name=second_df3['name']\n",
    "min_max_name = min_max_name.tolist()\n",
    "\n",
    "## 표준화로 선별한 추세 종목 그래프 생성 \n",
    "for i in min_max_name:\n",
    "    all_df=select_stock(i,'17-01-01')\n",
    "    all_df1 = close_vol_ma(all_df,'ma120')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  상승추세 종목 발굴 _3\n",
    "##  상승추세종목을 표준화 함수를 통합하여  속도 향상\n",
    "\n",
    "from mod1 import *\n",
    "\n",
    "all_df = market_stock('2019-10-01')\n",
    "stock_name=all_df['Name'].drop_duplicates()\n",
    "stock_name = stock_name.tolist()\n",
    "\n",
    "## 상승추세종목별로 표준화 (MinMaxSchalr)생성\n",
    "good_stock_df = pd.DataFrame()\n",
    "min_max_df = pd.DataFrame()\n",
    "\n",
    "for name in stock_name:\n",
    "    print(name)\n",
    "    good_df1 = select_stock(name,'2017-01-01')\n",
    "    min_max_df1 = min_max(good_df1,'ma120')\n",
    "    good_stock_df=good_stock_df.append(good_df1)\n",
    "    min_max_df=min_max_df.append(min_max_df1)\n",
    "\n",
    " \n",
    "good_stock_df1 = good_stock_df.set_index('date')\n",
    "min_max_df[['code','name']]=good_stock_df1[['code','name']]\n",
    " \n",
    "second_df1 = min_max_df\n",
    "second_df2 = second_df1[(second_df1.index.astype(str) == '2019-10-02')]\n",
    "second_df3 = second_df2[(second_df2['close'] <= 0.05)]\n",
    "second_df3\n",
    "\n",
    "## 표준화로 선별한 상승추세종목 리스트 생성\n",
    "min_max_name=second_df3['name']\n",
    "min_max_name = min_max_name.tolist()\n",
    "\n",
    "## 표준화로 선별한 추세 종목 그래프 생성 \n",
    "for i in min_max_name:\n",
    "    all_df=select_stock(i,'17-01-01')\n",
    "    all_df1 = close_vol_ma(all_df,'ma120')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Stock Prediction 30 days\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from tqdm import tqdm\n",
    "sns.set()\n",
    "tf.set_random_seed(777)  # reproducibility\n",
    "tf.reset_default_graph()\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter('ignore')\n",
    "\n",
    "import sqlalchemy\n",
    "\n",
    "engine = sqlalchemy.create_engine('mysql+pymysql://kkang:leaf2027@localhost/stock?charset=utf8',encoding='utf-8')\n",
    "var =\"select * from market where Name='HRS' and  Date > '2019-01-01'\" \n",
    "df = pd.read_sql(var ,engine)\n",
    "df.head()\n",
    "\n",
    "minmax = MinMaxScaler().fit(df.iloc[:, 7:].astype('float32')) # Close index\n",
    "df_log = minmax.transform(df.iloc[:, 7:].astype('float32')) # Close index\n",
    "df_log = pd.DataFrame(df_log)\n",
    "df_log.head()\n",
    "\n",
    "simulation_size = 10\n",
    "num_layers = 1\n",
    "size_layer = 128\n",
    "timestamp = 5\n",
    "epoch = 300\n",
    "dropout_rate = 0.8\n",
    "test_size = 30\n",
    "learning_rate = 0.01\n",
    "\n",
    "df_train = df_log\n",
    "df.shape, df_train.shape\n",
    "\n",
    "class Model:\n",
    "    def __init__(\n",
    "        self,\n",
    "        learning_rate,\n",
    "        num_layers,\n",
    "        size,\n",
    "        size_layer,\n",
    "        output_size,\n",
    "        forget_bias = 0.1,\n",
    "    ):\n",
    "        def lstm_cell(size_layer):\n",
    "            return tf.nn.rnn_cell.LSTMCell(size_layer, state_is_tuple = False)\n",
    "\n",
    "        rnn_cells = tf.nn.rnn_cell.MultiRNNCell(\n",
    "            [lstm_cell(size_layer) for _ in range(num_layers)],\n",
    "            state_is_tuple = False,\n",
    "        )\n",
    "        self.X = tf.placeholder(tf.float32, (None, None, size))\n",
    "        self.Y = tf.placeholder(tf.float32, (None, output_size))\n",
    "        drop = tf.contrib.rnn.DropoutWrapper(\n",
    "            rnn_cells, output_keep_prob = forget_bias\n",
    "        )\n",
    "        self.hidden_layer = tf.placeholder(\n",
    "            tf.float32, (None, num_layers * 2 * size_layer)\n",
    "        )\n",
    "        self.outputs, self.last_state = tf.nn.dynamic_rnn(\n",
    "            drop, self.X, initial_state = self.hidden_layer, dtype = tf.float32\n",
    "        )\n",
    "        self.logits = tf.layers.dense(self.outputs[-1], output_size)\n",
    "        self.cost = tf.reduce_mean(tf.square(self.Y - self.logits))\n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate).minimize(\n",
    "            self.cost\n",
    "        )\n",
    "        \n",
    "def calculate_accuracy(real, predict):\n",
    "    real = np.array(real) + 1\n",
    "    predict = np.array(predict) + 1\n",
    "    percentage = 1 - np.sqrt(np.mean(np.square((real - predict) / real)))\n",
    "    return percentage * 100\n",
    "\n",
    "def anchor(signal, weight):\n",
    "    buffer = []\n",
    "    last = signal[0]\n",
    "    for i in signal:\n",
    "        smoothed_val = last * weight + (1 - weight) * i\n",
    "        buffer.append(smoothed_val)\n",
    "        last = smoothed_val\n",
    "    return buffer\n",
    "\n",
    "def forecast():\n",
    "    tf.reset_default_graph()\n",
    "    modelnn = Model(\n",
    "        learning_rate, num_layers, df_log.shape[1], size_layer, df_log.shape[1], dropout_rate\n",
    "    )\n",
    "    sess = tf.InteractiveSession()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    date_ori = pd.to_datetime(df.iloc[:, 0]).tolist()\n",
    "\n",
    "    pbar = tqdm(range(epoch), desc = 'train loop')\n",
    "    for i in pbar:\n",
    "        init_value = np.zeros((1, num_layers * 2 * size_layer))\n",
    "        total_loss, total_acc = [], []\n",
    "        for k in range(0, df_train.shape[0] - 1, timestamp):\n",
    "            index = min(k + timestamp, df_train.shape[0] - 1)\n",
    "            batch_x = np.expand_dims(\n",
    "                df_train.iloc[k : index, :].values, axis = 0\n",
    "            )\n",
    "            batch_y = df_train.iloc[k + 1 : index + 1, :].values\n",
    "            logits, last_state, _, loss = sess.run(\n",
    "                [modelnn.logits, modelnn.last_state, modelnn.optimizer, modelnn.cost],\n",
    "                feed_dict = {\n",
    "                    modelnn.X: batch_x,\n",
    "                    modelnn.Y: batch_y,\n",
    "                    modelnn.hidden_layer: init_value,\n",
    "                },\n",
    "            )        \n",
    "            init_value = last_state\n",
    "            total_loss.append(loss)\n",
    "            total_acc.append(calculate_accuracy(batch_y[:, 0], logits[:, 0]))\n",
    "        pbar.set_postfix(cost = np.mean(total_loss), acc = np.mean(total_acc))\n",
    "    \n",
    "    future_day = test_size\n",
    "\n",
    "    output_predict = np.zeros((df_train.shape[0] + future_day, df_train.shape[1]))\n",
    "    output_predict[0] = df_train.iloc[0]\n",
    "    upper_b = (df_train.shape[0] // timestamp) * timestamp\n",
    "    init_value = np.zeros((1, num_layers * 2 * size_layer))\n",
    "\n",
    "    for k in range(0, (df_train.shape[0] // timestamp) * timestamp, timestamp):\n",
    "        out_logits, last_state = sess.run(\n",
    "            [modelnn.logits, modelnn.last_state],\n",
    "            feed_dict = {\n",
    "                modelnn.X: np.expand_dims(\n",
    "                    df_train.iloc[k : k + timestamp], axis = 0\n",
    "                ),\n",
    "                modelnn.hidden_layer: init_value,\n",
    "            },\n",
    "        )\n",
    "        init_value = last_state\n",
    "        output_predict[k + 1 : k + timestamp + 1] = out_logits\n",
    "\n",
    "    if upper_b != df_train.shape[0]:\n",
    "        out_logits, last_state = sess.run(\n",
    "            [modelnn.logits, modelnn.last_state],\n",
    "            feed_dict = {\n",
    "                modelnn.X: np.expand_dims(df_train.iloc[upper_b:], axis = 0),\n",
    "                modelnn.hidden_layer: init_value,\n",
    "            },\n",
    "        )\n",
    "        output_predict[upper_b + 1 : df_train.shape[0] + 1] = out_logits\n",
    "        future_day -= 1\n",
    "        date_ori.append(date_ori[-1] + timedelta(days = 1))\n",
    "\n",
    "    init_value = last_state\n",
    "    \n",
    "    for i in range(future_day):\n",
    "        o = output_predict[-future_day - timestamp + i:-future_day + i]\n",
    "        out_logits, last_state = sess.run(\n",
    "            [modelnn.logits, modelnn.last_state],\n",
    "            feed_dict = {\n",
    "                modelnn.X: np.expand_dims(o, axis = 0),\n",
    "                modelnn.hidden_layer: init_value,\n",
    "            },\n",
    "        )\n",
    "        init_value = last_state\n",
    "        output_predict[-future_day + i] = out_logits[-1]\n",
    "        date_ori.append(date_ori[-1] + timedelta(days = 1))\n",
    "    \n",
    "    output_predict = minmax.inverse_transform(output_predict)\n",
    "    deep_future = anchor(output_predict[:, 0], 0.4)\n",
    "    \n",
    "    return deep_future\n",
    "\n",
    "results = []\n",
    "for i in range(simulation_size):\n",
    "    print('simulation %d'%(i + 1))\n",
    "    results.append(forecast())\n",
    "    \n",
    "date_ori = pd.to_datetime(df.iloc[:, 0]).tolist()\n",
    "for i in range(test_size):\n",
    "    date_ori.append(date_ori[-1] + timedelta(days = 1))\n",
    "date_ori = pd.Series(date_ori).dt.strftime(date_format = '%Y-%m-%d').tolist()\n",
    "date_ori[-5:]\n",
    "\n",
    "accepted_results = []\n",
    "for r in results:\n",
    "    if (np.array(r[-test_size:]) < np.min(df['Close'])).sum() == 0 and \\\n",
    "    (np.array(r[-test_size:]) > np.max(df['Close']) * 2).sum() == 0:\n",
    "        accepted_results.append(r)\n",
    "len(accepted_results)\n",
    "\n",
    "accuracies = [calculate_accuracy(df['Close'].values, r[:-test_size]) for r in accepted_results]\n",
    "\n",
    "plt.figure(figsize = (15, 5))\n",
    "for no, r in enumerate(accepted_results):\n",
    "    plt.plot(r, label = 'forecast %d'%(no + 1))\n",
    "plt.plot(df['Close'], label = 'true trend', c = 'black')\n",
    "plt.legend()\n",
    "plt.title('average accuracy: %.4f'%(np.mean(accuracies)))\n",
    "\n",
    "x_range_future = np.arange(len(results[0]))\n",
    "plt.xticks(x_range_future[::30], date_ori[::30])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## MinMaxScaller() 변조및 복조\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "connect = create_engine('mysql+pymysql://kkang:leaf2027@localhost/stock?charset=utf8',encoding='utf-8')\n",
    "df = pd.read_sql(\"SELECT * from market where Code = '036640' and date > '2019-08-05'\", connect)\n",
    "\n",
    "df = df[['Open', 'High', 'Low', 'Volume', 'Close']]\n",
    "\n",
    "dataset = df.values\n",
    "\n",
    "source = MinMaxScaler() # default is 0,1\n",
    "dataset = source.fit_transform(dataset) ### MinMaxScaler 변조\n",
    "\n",
    "display(dataset)\n",
    "print('='*100)\n",
    "\n",
    "source.inverse_transform(dataset) ### MinMaxScaler 복조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## 이동 평균선\n",
    "\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "file = 'd:\\\\hrs.xlsx'\n",
    "\n",
    "connect = create_engine('mysql+pymysql://kkang:leaf2027@localhost/stock?charset=utf8',encoding='utf-8')\n",
    "df = pd.read_sql(\"SELECT * from market where Name = 'hrs' && Date > '2019-01-05'\", connect)\n",
    "\n",
    "volume_average_5 = df['Volume'].rolling(window=5,min_periods=1).mean()\n",
    "volume_average_10 = df['Volume'].rolling(window=10,min_periods=1).mean()\n",
    "volume_average_20 = df['Volume'].rolling(window=20,min_periods=1).mean()\n",
    "volume_average_60 = df['Volume'].rolling(window=60,min_periods=1).mean()\n",
    "volume_average_120 = df['Volume'].rolling(window=120,min_periods=1).mean()\n",
    "\n",
    "close_average_5 = df['Close'].rolling(window=5,min_periods=1).mean()\n",
    "close_average_10 = df['Close'].rolling(window=10,min_periods=1).mean()\n",
    "close_average_20 = df['Close'].rolling(window=20,min_periods=1).mean()\n",
    "close_average_60 = df['Close'].rolling(window=60,min_periods=1).mean()\n",
    "close_average_120 = df['Close'].rolling(window=120,min_periods=1).mean()\n",
    "\n",
    "df.insert(len(df.columns), \"Vol_MA5\", volume_average_5)\n",
    "df.insert(len(df.columns), \"Vol_MA10\", volume_average_10)\n",
    "df.insert(len(df.columns), \"Vol_MA20\", volume_average_20)\n",
    "df.insert(len(df.columns), \"Vol_MA60\", volume_average_60)\n",
    "df.insert(len(df.columns), \"Vol_MA120\", volume_average_120)\n",
    "\n",
    "df.insert(len(df.columns), \"Close_MA5\", close_average_5)\n",
    "df.insert(len(df.columns), \"Close_MA10\", close_average_10)\n",
    "df.insert(len(df.columns), \"Close_MA20\", close_average_20)\n",
    "df.insert(len(df.columns), \"Close_MA60\", close_average_60)\n",
    "df.insert(len(df.columns), \"Close_MA120\", close_average_120)\n",
    "\n",
    "df1 = df[['Date','Name','Close','Volume','Vol_MA5','Vol_MA10','Vol_MA20','Vol_MA60','Vol_MA120']]\n",
    "#df1.to_excel(file)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###  RSI\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "import talib.abstract as ta # talib.abstract는 Series나 numpy가 아닌 DataFrame도 대입가능\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import pandas_datareader.data as web\n",
    "import numpy as np\n",
    "from talib import RSI, BBANDS\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "file = 'd:\\\\hrs.xlsx'\n",
    "connect = create_engine('mysql+pymysql://kkang:leaf2027@localhost/stock?charset=utf8',encoding='utf-8')\n",
    "df = pd.read_sql(\"SELECT * from market where Name = 'hrs' && Date > '2019-01-05'\", connect)\n",
    "display(df.head())\n",
    "\n",
    "df = df.set_index('Date')\n",
    "df.columns = df.columns.str.lower()\n",
    "df[['open','high','low','volume','close']] = df[['open','high','low','volume','close']].astype(float)\n",
    "#df = df[['open','high','low','volume','close']]\n",
    "display(df.head())\n",
    "\n",
    "ta_ma5 = ta.MA(df,timeperiod=5 )\n",
    "display(ta_ma5.head())\n",
    "\n",
    "close = df['close'].values\n",
    "up, mid, low = BBANDS(close, timeperiod=20, nbdevup=2, nbdevdn=2, matype=0)\n",
    "df['BB_up']=up\n",
    "df['BB_mid']=mid\n",
    "df['BB_low']=low\n",
    "\n",
    "rsi = RSI(close, timeperiod=14)\n",
    "print(\"RSI (first 10 elements)\\n\", rsi[14:24])\n",
    "df['RSI']=rsi\n",
    "display(df['RSI'].head())\n",
    "\n",
    "up, mid, low = BBANDS(close, timeperiod=20, nbdevup=2, nbdevdn=2, matype=0)\n",
    "bbp = (df['close'] - low) / (up - low)\n",
    "df['BBP']=bbp\n",
    "display(bbp.head())\n",
    "\n",
    "index=df.index\n",
    "max_holding = 100\n",
    "\n",
    "holdings = pd.DataFrame(index=df.index, data={'Holdings': np.array([np.nan] * index.shape[0])})\n",
    "holdings.loc[((df['RSI'] < 30) & (df['BBP'] < 0)), 'Holdings'] = max_holding\n",
    "holdings.loc[((df['RSI'] > 70) & (df['BBP'] > 1)), 'Holdings'] = 0\n",
    "holdings.ffill(inplace=True)\n",
    "holdings.fillna(0, inplace=True)\n",
    "\n",
    "holdings['Order'] = holdings.diff()\n",
    "holdings.dropna(inplace=True)\n",
    "\n",
    "fig, (ax0, ax1, ax2) = plt.subplots(3, 1, sharex=True, figsize=(12, 8))\n",
    "ax0.plot(index, df['close'], label='Close')\n",
    "ax0.set_xlabel('Date')\n",
    "ax0.set_ylabel('close')\n",
    "ax0.grid()\n",
    "\n",
    "for day, holding in holdings.iterrows():\n",
    "    order = holding['Order']\n",
    "    if order > 0:\n",
    "        ax0.scatter(x=day, y=df.loc[day, 'close'], color='green')\n",
    "    elif order < 0:\n",
    "        ax0.scatter(x=day, y=df.loc[day, 'close'], color='red')\n",
    "\n",
    "ax1.plot(index, df['RSI'], label='RSI')\n",
    "ax1.fill_between(index, y1=30, y2=70, color='#adccff', alpha='0.3')\n",
    "ax1.set_xlabel('Date')\n",
    "ax1.set_ylabel('RSI')\n",
    "ax1.grid()\n",
    "\n",
    "ax2.plot(index, df['BB_up'], label='BB_up')\n",
    "ax2.plot(index, df['close'], label='AdjClose')\n",
    "ax2.plot(index, df['BB_low'], label='BB_low')\n",
    "ax2.fill_between(index, y1=df['BB_low'], y2=df['BB_up'], color='#adccff', alpha='0.3')\n",
    "ax2.set_xlabel('Date')\n",
    "ax2.set_ylabel('Bollinger Bands')\n",
    "ax2.grid()\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  ta-lib 이동평균선 그래프 출력\n",
    "\n",
    "import talib.abstract as ta\n",
    "import FinanceDataReader as fdr\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime as dt\n",
    "from datetime import datetime,timedelta\n",
    "from urllib.request import urlopen\n",
    "import sqlalchemy \n",
    "import pymysql\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "from matplotlib import font_manager, rc\n",
    "font_name = font_manager.FontProperties(fname=\"c:/Windows/Fonts/malgun.ttf\").get_name()\n",
    "rc('font', family=font_name)\n",
    "\n",
    "now = dt.datetime.today().strftime('%Y-%m-%d')\n",
    "engine = sqlalchemy.create_engine('mysql+pymysql://kkang:leaf2027@localhost/stock?charset=utf8',encoding='utf-8')\n",
    "\n",
    "\n",
    "df = pd.read_sql(\"SELECT * from market where Code = '036640' and date > '2019-01-05'\", engine)\n",
    "df = df.set_index('Date')\n",
    "df[['Open','High','Low','Volume','Close']] = df[['Open','High','Low','Volume','Close']].astype(float) #  TA-Lib로 평균을 구하려면 실수로 만들어야 함\n",
    "df.columns=df.columns.str.lower()\n",
    "\n",
    "talib_ma5 = ta.MA(df, timeperiod=5)\n",
    "df['ma5'] = talib_ma5\n",
    "\n",
    "talib_ma10 = ta.MA(df, timeperiod=10)\n",
    "df['ma10'] = talib_ma10\n",
    "\n",
    "talib_ma20 = ta.MA(df, timeperiod=20)\n",
    "df['ma20'] = talib_ma20\n",
    "\n",
    "talib_ma60 = ta.MA(df, timeperiod=60)\n",
    "df['ma60'] = talib_ma60\n",
    "\n",
    "talib_ma120 = ta.MA(df, timeperiod=120)\n",
    "df['ma120'] = talib_ma120\n",
    "\n",
    "display(df.iloc[120:].head())\n",
    "\n",
    "plt.figure(figsize=(16,4))\n",
    "plt.plot(df['ma5'],label='ma5')\n",
    "plt.plot(df['ma10'],label='ma10')\n",
    "plt.plot(df['ma20'],label='ma20')\n",
    "plt.plot(df['ma60'],label='ma60')\n",
    "plt.plot(df['ma120'],label='ma120')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  이동평균선  데이타베이스  일괄입력\n",
    "import time\n",
    "import talib.abstract as ta\n",
    "import FinanceDataReader as fdr\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime as dt\n",
    "from datetime import datetime,timedelta\n",
    "from urllib.request import urlopen\n",
    "import sqlalchemy \n",
    "import pymysql\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "from matplotlib import font_manager, rc\n",
    "font_name = font_manager.FontProperties(fname=\"c:/Windows/Fonts/malgun.ttf\").get_name()\n",
    "rc('font', family=font_name)\n",
    "\n",
    "now = dt.datetime.today().strftime('%Y-%m-%d')\n",
    "engine = sqlalchemy.create_engine('mysql+pymysql://kkang:leaf2027@localhost/stock?charset=utf8',encoding='utf-8')\n",
    "\n",
    "df = pd.read_sql(\"SELECT distinct Name from market \", engine)\n",
    "df = df.set_index('Name')\n",
    "name = df.index\n",
    "for i in range(len(name)):\n",
    "    df = pd.read_sql(\"SELECT * from market where Name =\"+\"'\"+name[i]+\"'\", engine)\n",
    "    line = df.shape[0]   \n",
    "    \n",
    "    df[['Open','High','Low','Volume','Close']] = df[['Open','High','Low','Volume','Close']].astype(float) #  TA-Lib로 평균을 구하려면 실수로 만들어야 함\n",
    "    df.columns=df.columns.str.lower()\n",
    "    #df = df.set_index('date')\n",
    "            \n",
    "    if line >= 120:\n",
    "        talib_ma5 = ta.MA(df, timeperiod=5)\n",
    "        df['ma5'] = talib_ma5\n",
    "\n",
    "        talib_ma10 = ta.MA(df, timeperiod=10)\n",
    "        df['ma10'] = talib_ma10\n",
    "\n",
    "        talib_ma20 = ta.MA(df, timeperiod=20)\n",
    "        df['ma20'] = talib_ma20\n",
    "\n",
    "        talib_ma60 = ta.MA(df, timeperiod=60)\n",
    "        df['ma60'] = talib_ma60\n",
    "\n",
    "        talib_ma120 = ta.MA(df, timeperiod=120)\n",
    "        df['ma120'] = talib_ma120\n",
    "\n",
    "        df_ma = df[['date','code','name','ma5','ma10','ma20','ma60','ma120']].round(2)\n",
    "        df_ma.iloc[:4,3]=df_ma.iloc[4,3]\n",
    "        df_ma.iloc[:9,4]=df_ma.iloc[9,4]\n",
    "        df_ma.iloc[:19,5]=df_ma.iloc[19,5]\n",
    "        df_ma.iloc[:59,6]=df_ma.iloc[59,6]\n",
    "        df_ma.iloc[:119,7]=df_ma.iloc[119,7]        \n",
    "        df_ma.columns=['Date','Code','Name','ma5','ma10','ma20','ma60','ma120']\n",
    "        df_ma.to_sql(name='ma', con=engine, if_exists='append', index = False)  \n",
    "        \n",
    "    elif line >= 60 and line < 120:\n",
    "        talib_ma5 = ta.MA(df, timeperiod=5)\n",
    "        df['ma5'] = talib_ma5\n",
    "        \n",
    "        talib_ma10 = ta.MA(df, timeperiod=10)\n",
    "        df['ma10'] = talib_ma10\n",
    "        \n",
    "        talib_ma20 = ta.MA(df, timeperiod=20)\n",
    "        df['ma20'] = talib_ma20\n",
    "        \n",
    "        talib_ma60 = ta.MA(df, timeperiod=60)\n",
    "        df['ma60'] = talib_ma60\n",
    "        \n",
    "        df_ma = df[['date','code','name','ma5','ma10','ma20','ma60']].round(2)\n",
    "        df_ma.iloc[:4,3]=df_ma.iloc[4,3]\n",
    "        df_ma.iloc[:9,4]=df_ma.iloc[9,4]\n",
    "        df_ma.iloc[:19,5]=df_ma.iloc[19,5]\n",
    "        df_ma.iloc[:59,6]=df_ma.iloc[59,6]        \n",
    "        df_ma.columns=['Date','Code','Name','ma5','ma10','ma20','ma60']\n",
    "        df_ma.to_sql(name='ma', con=engine, if_exists='append', index = False) \n",
    "        \n",
    "    elif line >= 20 and line <60:\n",
    "        talib_ma5 = ta.MA(df, timeperiod=5)\n",
    "        df['ma5'] = talib_ma5\n",
    "        \n",
    "        talib_ma10 = ta.MA(df, timeperiod=10)\n",
    "        df['ma10'] = talib_ma10\n",
    "        \n",
    "        talib_ma20 = ta.MA(df, timeperiod=20)\n",
    "        df['ma20'] = talib_ma20\n",
    "        \n",
    "        df_ma = df[['date','code','name','ma5','ma10','ma20']].round(2)\n",
    "        df_ma.iloc[:4,3]=df_ma.iloc[4,3]\n",
    "        df_ma.iloc[:9,4]=df_ma.iloc[9,4]\n",
    "        df_ma.iloc[:19,5]=df_ma.iloc[19,5]\n",
    "        df_ma.columns=['Date','Code','Name','ma5','ma10','ma20']\n",
    "        df_ma.to_sql(name='ma', con=engine, if_exists='append', index = False)\n",
    "        \n",
    "    elif line >= 10 and line <20:\n",
    "        talib_ma5 = ta.MA(df, timeperiod=5)\n",
    "        df['ma5'] = talib_ma5\n",
    "        \n",
    "        talib_ma10 = ta.MA(df, timeperiod=10)\n",
    "        df['ma10'] = talib_ma10\n",
    "        \n",
    "        df_ma = df[['date','code','name','ma5','ma10']].round(2)\n",
    "        df_ma.iloc[:4,3]=df_ma.iloc[4,3]\n",
    "        df_ma.iloc[:9,4]=df_ma.iloc[9,4] \n",
    "        df_ma.columns=['Date','Code','Name','ma5','ma10']\n",
    "        df_ma.to_sql(name='ma', con=engine, if_exists='append', index = False) \n",
    "        \n",
    "    elif line >= 5 and line <10:\n",
    "        talib_ma5 = ta.MA(df, timeperiod=5)\n",
    "        df['ma5'] = talib_ma5 \n",
    "        \n",
    "        df_ma = df[['date','code','name','ma5']].round(2)\n",
    "        df_ma.iloc[:4,3]=df_ma.iloc[4,3]\n",
    "        df_ma.columns=['Date','Code','Name','ma5']\n",
    "        df_ma.to_sql(name='ma', con=engine, if_exists='append', index = False)\n",
    "        \n",
    "    elif line > 5:\n",
    "        pass\n",
    "  \n",
    "    #df_ma.to_excel('d:\\ma_line.xlsx')\n",
    "    #df_ma.columns=['Date','Code','Name','ma5','ma10','ma20','ma60','ma120']\n",
    "    #df_ma.to_sql(name='ma', con=engine, if_exists='append', index = False)\n",
    "    print(df_ma.head(1))\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 일일 종목선정 project 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## 일일 거래량 50만주이상 주식중 전일 거래량 보다 많은 거래량 top15 종목 \n",
    "\n",
    "import FinanceDataReader as fdr\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime as dt\n",
    "from datetime import datetime,timedelta\n",
    "from urllib.request import urlopen\n",
    "import sqlalchemy \n",
    "import pymysql\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "from matplotlib import font_manager, rc\n",
    "font_name = font_manager.FontProperties(fname=\"c:/Windows/Fonts/malgun.ttf\").get_name()\n",
    "rc('font', family=font_name)\n",
    "\n",
    "today = datetime.now()\n",
    "real_yesterday = (today-timedelta(1)).strftime('%Y-%m-%d')\n",
    "real_today = today.strftime('%Y-%m-%d')\n",
    "\n",
    "now = dt.datetime.today().strftime('%Y-%m-%d')\n",
    "engine = sqlalchemy.create_engine('mysql+pymysql://kkang:leaf2027@localhost/stock?charset=utf8',encoding='utf-8')\n",
    "\n",
    "market_df = pd.read_sql(\"select * from market where Date > '2019-01-01'\", engine)\n",
    "#market_df\n",
    "\n",
    "is_hrs=market_df['Name']=='HRS'\n",
    "hrs_df = market_df[is_hrs]\n",
    "yesterday = str(hrs_df['Date'].iloc[0])\n",
    "today = str(hrs_df['Date'].iloc[1])\n",
    "#print(yesterday)\n",
    "#print(today)\n",
    "\n",
    "#var = \"select * from market where (Date = '2019-01-02' OR Date = '2019-01-03')  and Volume >  500000\"\n",
    "#df = pd.read_sql(var ,engine)\n",
    "#df\n",
    "\n",
    "select_query = \"select * from market where (Date = \"\n",
    "volume_query = \"&& Volume >  500000\"\n",
    "    \n",
    "var = select_query +\"'\"+yesterday+\"'\"+'or Date ='+\"'\"+today+\"'\"+')' + volume_query\n",
    "df = pd.read_sql(var ,engine)\n",
    "\n",
    "#df\n",
    "\n",
    "\n",
    "df1 = df[df['Date'].astype(str) == yesterday]\n",
    "df1 = df1[['Name','Volume','Close']]\n",
    "df1.columns = ['Name','yester_Volume','yester_Close']\n",
    "#display(df1)\n",
    "\n",
    "\n",
    "df2 = df[df['Date'].astype(str) == today]\n",
    "df2 = df2[['Name','Volume','Close']]\n",
    "df2.columns = ['Name','today_Volume','today_Close']\n",
    "#display(df2)\n",
    "\n",
    "df3 = pd.merge(df1,df2,on='Name')\n",
    "df3['Close']=df3['today_Close']/df3['yester_Close']\n",
    "df3['Volume']=df3['today_Volume']/df3['yester_Volume']\n",
    "df3 = df3.sort_values(by=['Volume','Close'],ascending=False)\n",
    "df4 = df3.sort_values(by=['Close','Volume'],ascending=False)\n",
    "df3 = df3.reset_index(drop=True)\n",
    "\n",
    "df3 = df3[:19]\n",
    "df4 = df4.reset_index(drop=True)\n",
    "df4 = df4[:19]\n",
    "df3.to_excel('d:\\\\stockdata\\\\vote_stock\\\\detect_stock_with_volume_'+today+'.xlsx', encoding='utf-8')\n",
    "df4.to_excel('d:\\\\stockdata\\\\vote_stock\\\\detect_stock_with_price_'+today+'.xlsx', encoding='utf-8')        \n",
    "display(df3)\n",
    "display(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## 일일 거래량 50만주이상 주식중 전일 거래량 보다 많은 거래량 top19 종목  for loop 추가 및 화일로 저장\n",
    "\n",
    "import FinanceDataReader as fdr\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime as dt\n",
    "from datetime import datetime,timedelta\n",
    "from urllib.request import urlopen\n",
    "import sqlalchemy \n",
    "import pymysql\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "from matplotlib import font_manager, rc\n",
    "font_name = font_manager.FontProperties(fname=\"c:/Windows/Fonts/malgun.ttf\").get_name()\n",
    "rc('font', family=font_name)\n",
    "\n",
    "today = datetime.now()\n",
    "real_yesterday = (today-timedelta(1)).strftime('%Y-%m-%d')\n",
    "real_today = today.strftime('%Y-%m-%d')\n",
    "\n",
    "now = dt.datetime.today().strftime('%Y-%m-%d')\n",
    "engine = sqlalchemy.create_engine('mysql+pymysql://kkang:leaf2027@localhost/stock?charset=utf8',encoding='utf-8')\n",
    "\n",
    "market_df = pd.read_sql(\"select * from market where Date > '2019-05-01'\", engine)\n",
    "#market_df\n",
    "\n",
    "is_hrs=market_df['Name']=='HRS'\n",
    "hrs_df = market_df[is_hrs]\n",
    "yesterday = str(hrs_df['Date'].iloc[0])\n",
    "today = str(hrs_df['Date'].iloc[1])\n",
    "count = hrs_df.shape[0]\n",
    "#for i in range(hrs_df['Date'].shape[0]):\n",
    "for i in range(count):\n",
    "    yesterday = str(hrs_df['Date'].iloc[i])\n",
    "    today = str(hrs_df['Date'].iloc[i+1])\n",
    "    print('y:{}'.format(yesterday))\n",
    "    print('t:{}'.format(today))\n",
    "    select_query = \"select * from market where (Date = \"\n",
    "    volume_query = \"&& Volume >  500000\"\n",
    "    \n",
    "    var = select_query +\"'\"+yesterday+\"'\"+'or Date ='+\"'\"+today+\"'\"+')' + volume_query\n",
    "    df = pd.read_sql(var ,engine)\n",
    "\n",
    "    #df\n",
    "\n",
    "\n",
    "    df1 = df[df['Date'].astype(str) == yesterday]\n",
    "    df1 = df1[['Name','Volume','Close']]\n",
    "    df1.columns = ['Name','yester_Volume','yester_Close']\n",
    "    #display(df1)\n",
    "\n",
    "\n",
    "    df2 = df[df['Date'].astype(str) == today]\n",
    "    df2 = df2[['Name','Volume','Close']]\n",
    "    df2.columns = ['Name','today_Volume','today_Close']\n",
    "    #display(df2)\n",
    "\n",
    "    df3 = pd.merge(df1,df2,on='Name')\n",
    "    df3['Close']=df3['today_Close']/df3['yester_Close']\n",
    "    df3['Volume']=df3['today_Volume']/df3['yester_Volume']\n",
    "    df3 = df3.sort_values(by=['Volume','Close'],ascending=False)\n",
    "    df4 = df3.sort_values(by=['Close','Volume'],ascending=False)\n",
    "    df3 = df3.reset_index(drop=True)\n",
    "\n",
    "    df3 = df3[:19]\n",
    "    df4 = df4.reset_index(drop=True)\n",
    "    df4 = df4[:19]\n",
    "    df3.to_excel('d:\\\\stockdata\\\\vote_stock\\\\detect_stock_with_volume_'+today+'.xlsx', encoding='utf-8')\n",
    "    df4.to_excel('d:\\\\stockdata\\\\vote_stock\\\\detect_stock_with_price_'+today+'.xlsx', encoding='utf-8')        \n",
    "    display(df3)\n",
    "    display(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  전종목 검색하여  종가 > ma120  일일 비교  하여  관심 종목 추출_1\n",
    "\n",
    "from mod1 import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "\n",
    "\n",
    "path = 'd:\\\\stockdata\\\\close_ma120\\\\close_ma120_'\n",
    "\n",
    "df = all_stock('2019-10-10')\n",
    "df = df['Name']\n",
    "\n",
    "name = df.to_list()\n",
    "\n",
    "df2 = pd.DataFrame()\n",
    "for i in name:\n",
    "    #print(i)\n",
    "    df=select_stock(i,'2010-01-01')\n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close','ma120','volume']].values)\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1['Name']=i\n",
    "    df1.columns=['close','ma120','volume','name',]\n",
    "    df1['date'] = df['date']\n",
    "    #print(df1)\n",
    "    df2 = df2.append(df1)\n",
    "    \n",
    "\n",
    "last = len(df2[df2['name'] == name[0]])-1\n",
    "today_df = df2[df2.index == last]\n",
    "\n",
    "ma120_df = today_df[today_df['close'] > today_df['ma120']]\n",
    "ma120_df = ma120_df.sort_values(['ma120'])\n",
    "\n",
    "today = str(ma120_df.iloc[0,4])\n",
    "ma120_df.to_excel(path+today+'.xlsx', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  전종목 검색하여  종가 > ma120  일일 비교  하여  관심 종목 추출_2  날짜를 지정하여 검색 가능\n",
    "\n",
    "from mod1 import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "\n",
    "choice_date='2019-10-22'\n",
    "path = 'd:\\\\stockdata\\\\close_ma120\\\\close_ma120_'\n",
    "\n",
    "df = all_stock('2019-10-10')\n",
    "df = df['Name']\n",
    "\n",
    "name = df.to_list()\n",
    "\n",
    "df2 = pd.DataFrame()\n",
    "for i in name:\n",
    "    #print(i)\n",
    "    df=select_stock(i,'2010-01-01')\n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close','ma120','volume']].values)\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1['Name']=i\n",
    "    df1.columns=['close','ma120','volume','name',]\n",
    "    df1['date'] = df['date']\n",
    "    #print(df1)\n",
    "    df2 = df2.append(df1)\n",
    "    \n",
    "\n",
    "select_query = \"select count(*) from market_good where Name='hrs' and Date > \"\n",
    "var = select_query +\"'\"+choice_date+\"'\" \n",
    "sql_df = pd.read_sql(var, engine)\n",
    "count = sql_df.values.tolist()\n",
    "back_date = count[0][0]\n",
    "back_date\n",
    "today_df = df2.loc[df2['date'] == (today_df['date'].values[0]-timedelta(back_date))]\n",
    "\n",
    "ma120_df = today_df[today_df['close'] > today_df['ma120']]\n",
    "ma120_df = ma120_df.sort_values(['ma120'])\n",
    "\n",
    "ma120_df.to_excel(path+choice_date+'.xlsx', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  전종목 검색하여  종가 > ma120  일일 비교  하여  관심 종목 추출_3  한달단위로 추출\n",
    "\n",
    "from mod1 import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "\n",
    "path = 'd:\\\\stockdata\\\\close_ma120\\\\close_ma120_'\n",
    "\n",
    "df = all_stock('2019-10-10')\n",
    "df = df['Name']\n",
    "\n",
    "name = df.to_list()\n",
    "\n",
    "df2 = pd.DataFrame()\n",
    "for i in name:\n",
    "    #print(i)\n",
    "    df=select_stock(i,'2010-01-01')\n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close','ma60','ma120','volume']].values)\n",
    "    df1 = pd.DataFrame(data)\n",
    "\n",
    "    df1['Name']=i\n",
    "    df1.columns=['close','ma60','ma120','volume','name',]\n",
    "    df1['date'] = df['date']\n",
    "\n",
    "    #print(df1)\n",
    "    df2 = df2.append(df1)\n",
    "\n",
    "select_query = \"select * from market where Name='hrs' and Date >= '2019-10-01' and Date < '2019-11-01' \"\n",
    "df3 = pd.read_sql(select_query, engine)\n",
    "\n",
    "df3 = df3['Date']\n",
    "datelist = df3.to_list()\n",
    "\n",
    "for i in datelist:\n",
    "    choice_df = df2.loc[df2['date'] == i]\n",
    "    strdate = i.strftime('%Y-%m-%d')\n",
    "    ma120_df = choice_df[choice_df['close'] > choice_df['ma120']]\n",
    "    ma120_df = ma120_df.sort_values(['ma120'])\n",
    "    ma120_df.to_excel(path+strdate+'.xlsx')\n",
    "    #print(today_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  전종목 검색하여  종가 > ma120  일일 비교  하여  관심 종목 추출_4  한달단위로  close_ma120, total 동시 추출\n",
    "\n",
    "from mod1 import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "\n",
    "path = 'd:\\\\stockdata\\\\close_ma120\\\\close_ma120_'\n",
    "path_total = 'd:\\\\stockdata\\\\close_ma120\\\\total_'\n",
    "\n",
    "df = all_stock('2019-10-10')\n",
    "df = df['Name']\n",
    "name = df.to_list()\n",
    "\n",
    "pure_df = pd.DataFrame()\n",
    "df2 = pd.DataFrame()\n",
    "\n",
    "for i in name:\n",
    "    #print(i)\n",
    "    df=select_stock(i,'2008-01-01')\n",
    "    pure_df = pure_df.append(df)\n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close','ma60','ma120','volume']].values)\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1['name']=i\n",
    "    df1.columns=['close','ma60','ma120','volume','name']\n",
    "    df1['date'] = df['date']\n",
    "    #print(df1)\n",
    "    df2 = df2.append(df1)\n",
    "\n",
    "pure_df.columns = map(str.lower, pure_df.columns) ## \n",
    "\n",
    "select_query = \"select * from market where Name='hrs' and Date >= '2019-10-01' \"\n",
    "df3 = pd.read_sql(select_query, engine)\n",
    "\n",
    "df3 = df3['Date']\n",
    "datelist = df3.to_list()\n",
    "\n",
    "last_df = df2.loc[df2['date'] == datelist[-1]]\n",
    "last_df = last_df[last_df['ma120'] < 0.1]\n",
    "last_price_df = pure_df.loc[pure_df['date'] == datelist[-1]]\n",
    "\n",
    "for i in datelist:\n",
    "    first_df = df2.loc[df2['date'] == i]\n",
    "    first_price_df = pure_df.loc[pure_df['date'] == i]\n",
    "    ma120_df = pd.merge(first_df,last_df,on='name')\n",
    "    ma_df = pd.merge(first_price_df[['close','name']],ma120_df,on='name')\n",
    "    ma120_df = pd.merge(last_price_df[['close','volume','name']],ma_df,on='name')\n",
    "    ma120_df.columns= ['price_y','volume_z', 'name', 'price_x', 'close_x', 'ma60_x', 'ma120_x','volume_x', 'date_x', 'close_y', 'ma60_y', 'ma120_y', 'volume_y', 'date_y']\n",
    "    ma120_df = ma120_df[['name','close_x','close_y','ma60_x','ma60_y','ma120_x','ma120_y','price_x','price_y','volume_z','date_x']]\n",
    "    ma120_df['price_diff']=ma120_df['price_y']/ma120_df['price_x']\n",
    "    ma120_df =  ma120_df.sort_values([\"price_diff\"],ascending=False)\n",
    "    second_df =  first_df.sort_values([\"ma120\"],ascending=False)\n",
    "    #ma120_df['price_x']=first_price_df['close'].values\n",
    "    #ma120_df['price_y']=last_price_df['close'].values\n",
    "    strdate = i.strftime('%Y-%m-%d')\n",
    "    second_df.to_excel(path+strdate+'.xlsx')\n",
    "    ma120_df.to_excel(path_total+strdate+'.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  전종목 검색하여  종가 > ma120  일일 비교  하여  관심 종목 추출_5  한달단위로  close_ma120, total 동시 추출(1년분)\n",
    "\n",
    "from mod1 import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
    "\n",
    "path = 'd:\\\\stockdata\\\\close_ma120\\\\close_ma120_'\n",
    "path_total = 'd:\\\\stockdata\\\\close_ma120\\\\total_'\n",
    "path_total_a = 'd:\\\\stockdata\\\\close_ma120\\\\total_a_'\n",
    "path_total_b = 'd:\\\\stockdata\\\\close_ma120\\\\total_b_'\n",
    "\n",
    "df = all_stock('2019-10-10')\n",
    "df = df['Name']\n",
    "name = df.to_list()\n",
    "\n",
    "pure_df = pd.DataFrame()\n",
    "df2 = pd.DataFrame()\n",
    "\n",
    "for i in name:\n",
    "    #print(i)\n",
    "    df=select_stock(i,'2019-01-01')\n",
    "    pure_df = pure_df.append(df)\n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close','ma60','ma120','volume']].values)\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1['name']=i\n",
    "    df1.columns=['close','ma60','ma120','volume','name']\n",
    "    df1[['date','code']] = df[['date','code']]\n",
    "\n",
    "    #print(df1)\n",
    "    df2 = df2.append(df1)\n",
    "\n",
    "pure_df.columns = map(str.lower, pure_df.columns) ## \n",
    "\n",
    "select_query = \"select * from market where Name='hrs' and Date >= '2019-10-01' \"\n",
    "df3 = pd.read_sql(select_query, engine)\n",
    "\n",
    "df3 = df3['Date']\n",
    "datelist = df3.to_list()\n",
    "\n",
    "last_df = df2.loc[df2['date'] == datelist[-1]]\n",
    "last_df = last_df[last_df['ma120'] < 0.1]\n",
    "a_df = last_df[last_df['close'] > last_df['ma60']] \n",
    "last_df = a_df[a_df['ma60'] > a_df['ma120']]\n",
    "last_price_df = pure_df.loc[pure_df['date'] == datelist[-1]]\n",
    "\n",
    "for i in datelist:\n",
    "    first_df = df2.loc[df2['date'] == i]\n",
    "    first_price_df = pure_df.loc[pure_df['date'] == i]\n",
    "    one_df = pd.merge(first_df,last_df,on='code')\n",
    "    reset_index_df = last_df.reset_index()\n",
    "    one_df['code']= reset_index_df['code']\n",
    "    ma_df = pd.merge(first_price_df[['close','code']],one_df,on='code')\n",
    "    two_df = pd.merge(last_price_df[['close','code','volume']],ma_df,on='code')\n",
    "    two_df.columns= ['price_y','code', 'volume_z','price_x', 'close_x', 'ma60_x', 'ma120_x', 'volume_x','name_x', 'date_x', 'close_y', 'ma60_y', 'ma120_y', 'volume_y','name_y', 'date_y']\n",
    "\n",
    "    ma120_df = two_df[['name_x','code','close_x','close_y','ma60_x','ma60_y','ma120_x','ma120_y','price_x','price_y','date_x','volume_z']]\n",
    "    ma120_df['price_diff']=ma120_df['price_y']/ma120_df['price_x']\n",
    "    ma120_df =  ma120_df.sort_values([\"price_diff\"],ascending=False)\n",
    "    #second_df =  first_df.sort_values([\"ma120\"],ascending=False)\n",
    "\n",
    "    strdate = i.strftime('%Y-%m-%d')\n",
    "    #second_df.to_excel(path+strdate+'.xlsx')\n",
    "    ma120_df.to_excel(path_total_a+strdate+'.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  전종목 검색하여  종가 > ma120  일일 비교  하여  관심 종목 추출_6  한달단위로  close_ma120, total 동시 추출(11년분)\n",
    "\n",
    "from mod1 import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
    "\n",
    "path = 'd:\\\\stockdata\\\\close_ma120\\\\close_ma120_'\n",
    "path_total = 'd:\\\\stockdata\\\\close_ma120\\\\total_'\n",
    "path_total_a = 'd:\\\\stockdata\\\\close_ma120\\\\total_a_'\n",
    "path_total_b = 'd:\\\\stockdata\\\\close_ma120\\\\total_b_'\n",
    "\n",
    "df = all_stock('2019-10-10')\n",
    "df = df['Name']\n",
    "name = df.to_list()\n",
    "\n",
    "pure_df = pd.DataFrame()\n",
    "df2 = pd.DataFrame()\n",
    "\n",
    "for i in name:\n",
    "    #print(i)\n",
    "    df=select_stock(i,'2008-01-01')\n",
    "    pure_df = pure_df.append(df)\n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close','ma60','ma120','volume']].values)\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1['name']=i\n",
    "    df1.columns=['close','ma60','ma120','volume','name']\n",
    "    df1[['date','code']] = df[['date','code']]\n",
    "\n",
    "    #print(df1)\n",
    "    df2 = df2.append(df1)\n",
    "\n",
    "pure_df.columns = map(str.lower, pure_df.columns) ## \n",
    "\n",
    "select_query = \"select * from market where Name='hrs' and Date >= '2019-10-01' \"\n",
    "df3 = pd.read_sql(select_query, engine)\n",
    "\n",
    "df3 = df3['Date']\n",
    "datelist = df3.to_list()\n",
    "\n",
    "last_df = df2.loc[df2['date'] == datelist[-1]]\n",
    "last_df = last_df[last_df['ma120'] < 0.1]\n",
    "a_df = last_df[last_df['close'] > last_df['ma60']] \n",
    "last_df = a_df[a_df['ma60'] > a_df['ma120']]\n",
    "last_price_df = pure_df.loc[pure_df['date'] == datelist[-1]]\n",
    "\n",
    "for i in datelist:\n",
    "    first_df = df2.loc[df2['date'] == i]\n",
    "    first_price_df = pure_df.loc[pure_df['date'] == i]\n",
    "    one_df = pd.merge(first_df,last_df,on='code')\n",
    "    reset_index_df = last_df.reset_index()\n",
    "    one_df['code']= reset_index_df['code']\n",
    "    ma_df = pd.merge(first_price_df[['close','code']],one_df,on='code')\n",
    "    two_df = pd.merge(last_price_df[['close','code','volume']],ma_df,on='code')\n",
    "    two_df.columns= ['price_y','code', 'volume_z','price_x', 'close_x', 'ma60_x', 'ma120_x', 'volume_x','name_x', 'date_x', 'close_y', 'ma60_y', 'ma120_y', 'volume_y','name_y', 'date_y']\n",
    "\n",
    "    ma120_df = two_df[['name_x','code','close_x','close_y','ma60_x','ma60_y','ma120_x','ma120_y','price_x','price_y','date_x','volume_z']]\n",
    "    ma120_df['price_diff']=ma120_df['price_y']/ma120_df['price_x']\n",
    "    ma120_df =  ma120_df.sort_values([\"price_diff\"],ascending=False)\n",
    "    second_df =  first_df.sort_values([\"ma120\"],ascending=False)\n",
    "\n",
    "    strdate = i.strftime('%Y-%m-%d')\n",
    "    second_df.to_excel(path+strdate+'.xlsx')\n",
    "    ma120_df.to_excel(path_total_b+strdate+'.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  전종목 검색하여  종가 > ma120  일일 비교  하여  관심 종목 추출_7  한달단위로  close_ma120, total (1년분),close_ma120, total (11년분) 동시 추출\n",
    "\n",
    "from mod1 import *\n",
    "#import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "#from pandas.core.common import SettingWithCopyWarning\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
    "\n",
    "path = 'd:\\\\stockdata\\\\close_ma120\\\\close_ma120_'\n",
    "path_total = 'd:\\\\test\\\\total_'\n",
    "path_total_a = 'd:\\\\test\\\\total_a_'\n",
    "path_total_b = 'd:\\\\test\\\\total_b_'\n",
    "\n",
    "#df = all_stock('2019-10-10')\n",
    "#df = df['Name']\n",
    "#name = df.to_list()\n",
    "    \n",
    "name = ['필룩스','MP한강','금호전기','나이벡']\n",
    "\n",
    "select_start_a = '2019-01-01'\n",
    "select_start_b = '2008-01-01'\n",
    "    \n",
    "def search_stock(name,select_start):   \n",
    "    print(name)\n",
    "    print(select_start)\n",
    "    pure_df = pd.DataFrame()\n",
    "    df2 = pd.DataFrame() \n",
    "    for i in name:\n",
    "        #print(i)\n",
    "        df=select_stock(i,select_start)\n",
    "        #print(df)\n",
    "        pure_df = pure_df.append(df)\n",
    "        ma(df)\n",
    "\n",
    "        source = MinMaxScaler()\n",
    "        data = source.fit_transform(df[['close','ma60','ma120','volume']].values)\n",
    "        df1 = pd.DataFrame(data)\n",
    "        df1['name']=i\n",
    "        df1.columns=['close','ma60','ma120','volume','name']\n",
    "        df1[['date','code']] = df[['date','code']]\n",
    "        #print(df1)\n",
    "        df2 = df2.append(df1)\n",
    "\n",
    "    pure_df.columns = map(str.lower, pure_df.columns) ## \n",
    "\n",
    "    select_query = \"select * from market where Name='hrs' and Date >= '2019-10-01' \"\n",
    "    df3 = pd.read_sql(select_query, engine)\n",
    "\n",
    "    df3 = df3['Date']\n",
    "    datelist = df3.to_list()\n",
    "\n",
    "    last_df = df2.loc[df2['date'] == datelist[-1]]\n",
    "    last_df = last_df[last_df['ma120'] < 0.1]\n",
    "    last_price_df = pure_df.loc[pure_df['date'] == datelist[-1]]\n",
    "\n",
    "    for i in datelist:\n",
    "        first_df = df2.loc[df2['date'] == i]\n",
    "        first_price_df = pure_df.loc[pure_df['date'] == i]\n",
    "        one_df = pd.merge(first_df,last_df,on='code')\n",
    "        reset_index_df = last_df.reset_index()\n",
    "        one_df['code']= reset_index_df['code']\n",
    "        ma_df = pd.merge(first_price_df[['close','code']],one_df,on='code')\n",
    "        two_df = pd.merge(last_price_df[['close','code']],ma_df,on='code')\n",
    "        two_df.columns= ['price_y','code', 'price_x', 'close_x', 'ma60_x', 'ma120_x', 'volume_x','name_x', 'date_x', 'close_y', 'ma60_y', 'ma120_y', 'volume_y','name_y', 'date_y']\n",
    "        ma120_df = two_df[['name_x','code','close_x','close_y','ma60_x','ma60_y','ma120_x','ma120_y','price_x','price_y','date_x']]\n",
    "        ma120_df['price_diff']=ma120_df['price_y']/ma120_df['price_x']\n",
    "        ma120_df =  ma120_df.sort_values([\"price_diff\"],ascending=False)\n",
    "        second_df =  first_df.sort_values([\"ma120\"],ascending=False)\n",
    "        #ma120_df['price_x']=first_price_df['close'].values\n",
    "        #ma120_df['price_y']=last_price_df['close'].values\n",
    "        strdate = i.strftime('%Y-%m-%d')\n",
    "        #second_df.to_excel(path+strdate+'.xlsx')\n",
    "        if select_start == select_start_a:\n",
    "            ma120_df.to_excel(path_total_a+strdate+'.xlsx')\n",
    "        else:\n",
    "            ma120_df.to_excel(path_total_b+strdate+'.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  전종목 검색하여  종가 > ma120  일일 비교  하여  관심 종목 추출_8  total_a(1년분) ,total_b(11년분) 의 공통종목을 추출\n",
    "\n",
    "from mod1 import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
    "\n",
    "path = 'd:\\\\stockdata\\\\close_ma120\\\\close_ma120_'\n",
    "path_total = 'd:\\\\stockdata\\\\close_ma120\\\\total_'\n",
    "path_total_a = 'd:\\\\stockdata\\\\close_ma120\\\\total_a_'\n",
    "path_total_b = 'd:\\\\stockdata\\\\close_ma120\\\\total_b_'\n",
    "\n",
    "select_query = \"select * from market where Name='hrs' and Date >= '2019-10-01' \"\n",
    "df3 = pd.read_sql(select_query, engine)\n",
    "\n",
    "df3 = df3['Date']\n",
    "datelist = df3.to_list()\n",
    "\n",
    "for i in datelist:\n",
    "    strdate = i.strftime('%Y-%m-%d')\n",
    "    df_a = pd.read_excel(path_total_a+strdate+'.xlsx')\n",
    "    df_b = pd.read_excel(path_total_b+strdate+'.xlsx')\n",
    "    #df_ab = pd.DataFrame()\n",
    "    df_ab = pd.merge(df_a[['name_x']],df_b,on='name_x')\n",
    "    \n",
    "    total_df = df_ab[['name_x', 'code', 'close_x', 'close_y', 'ma60_x', 'ma60_y', 'ma120_x', 'ma120_y', 'price_x', 'price_y', 'date_x','volume_z', 'price_diff']]\n",
    "    total_df.to_excel(path_total+strdate+'.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  전종목 검색하여  종가 > ma120  일일 비교  하여  관심 종목 추출_9  total_a(1년분) ,total_b(11년분) 추출 및  공통종목을 추출\n",
    "\n",
    "from mod1 import *\n",
    "#import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "#from pandas.core.common import SettingWithCopyWarning\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
    "\n",
    "path = 'd:\\\\stockdata\\\\close_ma120\\\\close_ma120_'\n",
    "path_total = 'd:\\\\stockdata\\\\close_ma120\\\\total_'\n",
    "path_total_a = 'd:\\\\stockdata\\\\close_ma120\\\\total_a_'\n",
    "path_total_b = 'd:\\\\stockdata\\\\close_ma120\\\\total_b_'\n",
    "\n",
    "\n",
    "df = all_stock('2019-10-10')\n",
    "df = df['Name']\n",
    "name = df.to_list()\n",
    "    \n",
    "select_start_a = '2019-01-01'\n",
    "select_start_b = '2008-01-01'\n",
    "\n",
    "select_query = \"select * from market where Name='hrs' and Date >= '2019-10-01' \"\n",
    "df3 = pd.read_sql(select_query, engine)\n",
    "\n",
    "df3 = df3['Date']\n",
    "datelist = df3.to_list()\n",
    "    \n",
    "def search_stock(name,select_start):   \n",
    "    print(name)\n",
    "    print(select_start)\n",
    "    pure_df = pd.DataFrame()\n",
    "    df2 = pd.DataFrame() \n",
    "    for i in name:\n",
    "        #print(i)\n",
    "        df=select_stock(i,select_start)\n",
    "        #print(df)\n",
    "        pure_df = pure_df.append(df)\n",
    "        ma(df)\n",
    "\n",
    "        source = MinMaxScaler()\n",
    "        data = source.fit_transform(df[['close','ma60','ma120','volume']].values)\n",
    "        df1 = pd.DataFrame(data)\n",
    "        df1['name']=i\n",
    "        df1.columns=['close','ma60','ma120','volume','name']\n",
    "        df1[['date','code']] = df[['date','code']]\n",
    "        #print(df1)\n",
    "        df2 = df2.append(df1)\n",
    "\n",
    "    pure_df.columns = map(str.lower, pure_df.columns) ## \n",
    "\n",
    "    last_df = df2.loc[df2['date'] == datelist[-1]]\n",
    "    last_df = last_df[last_df['ma120'] < 0.1]\n",
    "    last_price_df = pure_df.loc[pure_df['date'] == datelist[-1]]\n",
    "\n",
    "    for i in datelist:\n",
    "        first_df = df2.loc[df2['date'] == i]\n",
    "        first_price_df = pure_df.loc[pure_df['date'] == i]\n",
    "        one_df = pd.merge(first_df,last_df,on='code')\n",
    "        reset_index_df = last_df.reset_index()\n",
    "        one_df['code']= reset_index_df['code']\n",
    "        ma_df = pd.merge(first_price_df[['close','code']],one_df,on='code')\n",
    "        two_df = pd.merge(last_price_df[['close','code','volume']],ma_df,on='code')\n",
    "        two_df.columns= ['price_y','code', 'volume_z','price_x', 'close_x', 'ma60_x', 'ma120_x', 'volume_x','name_x', 'date_x', 'close_y', 'ma60_y', 'ma120_y', 'volume_y','name_y', 'date_y']\n",
    "\n",
    "        ma120_df = two_df[['name_x','code','close_x','close_y','ma60_x','ma60_y','ma120_x','ma120_y','price_x','price_y','date_x','volume_z']]\n",
    "        ma120_df['price_diff']=ma120_df['price_y']/ma120_df['price_x']\n",
    "        ma120_df =  ma120_df.sort_values([\"price_diff\"],ascending=False)\n",
    "        second_df =  first_df.sort_values([\"ma120\"],ascending=False)\n",
    "        #ma120_df['price_x']=first_price_df['close'].values\n",
    "        #ma120_df['price_y']=last_price_df['close'].values\n",
    "        strdate = i.strftime('%Y-%m-%d')\n",
    "        #second_df.to_excel(path+strdate+'.xlsx')\n",
    "        if select_start == select_start_a:\n",
    "            ma120_df.to_excel(path_total_a+strdate+'.xlsx')\n",
    "        else:\n",
    "            ma120_df.to_excel(path_total_b+strdate+'.xlsx')\n",
    "            \n",
    "def intersection( ):\n",
    "    for i in datelist:\n",
    "        strdate = i.strftime('%Y-%m-%d')\n",
    "        df_a = pd.read_excel(path_total_a+strdate+'.xlsx')\n",
    "        df_b = pd.read_excel(path_total_b+strdate+'.xlsx')\n",
    "        #df_ab = pd.DataFrame()\n",
    "        df_ab = pd.merge(df_a[['name_x']],df_b,on='name_x')\n",
    "\n",
    "        total_df = df_ab[['name_x', 'code', 'close_x', 'close_y', 'ma60_x', 'ma60_y', 'ma120_x', 'ma120_y', 'price_x', 'price_y', 'date_x','volume_z', 'price_diff']]\n",
    "        total_df.to_excel(path_total+strdate+'.xlsx')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##  관심종목에서 종가 비교하기\n",
    "\n",
    "from mod1 import *\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "\n",
    "path = 'd:\\\\stockdata\\\\close_ma120\\\\close_ma120_'\n",
    "\n",
    "back_date=1\n",
    "choice_date='2019-10-18'\n",
    "\n",
    "df = pd.read_excel(path+choice_date+'.xlsx')\n",
    "df = df['name']\n",
    "name = df.to_list()\n",
    "\n",
    "df1 = pd.DataFrame()\n",
    "diff_df = pd.DataFrame()\n",
    "for i in name:\n",
    "    #print(i)\n",
    "    df=select_stock(i,'2019-01-01')\n",
    "    df1 = df1.append(df)\n",
    "\n",
    "last = len(df1[df1['Name'] == name[0]])-1\n",
    "price_startday_df = df1[df1.index == (last-back_date)]\n",
    "price_today_df = df1[df1.index == last]\n",
    "\n",
    "diff_df = pd.merge(price_startday_df[['Name','Close']],price_today_df[['Name','Close']],on='Name')\n",
    "diff_df.columns=['name','price_startday','price_today']\n",
    "diff_df['diff']=diff_df['price_today']/diff_df['price_startday']\n",
    "\n",
    "price_up = diff_df[diff_df['diff'] > 1]\n",
    "price_down = diff_df[diff_df['diff'] < 1]\n",
    "price_sum=len(price_up)+len(price_down)\n",
    "print('price_up = {}'.format(len(price_up)))\n",
    "print('price_down = {}'.format(len(price_down)))\n",
    "    \n",
    "print('win_rate={}%'.format((len(price_up)/price_sum)*100))\n",
    "\n",
    "display((price_up.sort_values([\"diff\"],ascending=False).head(10)))\n",
    "display(price_down.sort_values(['diff']).head(10))\n",
    "display(diff_df.describe())\n",
    "\n",
    "#sort_df = diff_df.sort_values([\"diff\"],ascending=False)  ##  상승, 하락 을  순서별로 정렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mod1 import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "\n",
    "path = 'd:\\\\stockdata\\\\close_ma120\\\\close_ma120_'\n",
    "path_total = 'd:\\\\stockdata\\\\close_ma120\\\\total_'\n",
    "\n",
    "df = all_stock('2019-10-10')\n",
    "df = df['Name']\n",
    "name = df.to_list()\n",
    "\n",
    "pure_df = pd.DataFrame()\n",
    "df2 = pd.DataFrame()\n",
    "for i in name:\n",
    "    #print(i)\n",
    "    df=select_stock(i,'2008-01-01')\n",
    "    pure_df = pure_df.append(df)\n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close','ma60','ma120','volume']].values)\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1['name']=i\n",
    "    df1.columns=['close','ma60','ma120','volume','name']\n",
    "    df1[['date','code']] = df[['date','code']]\n",
    "    #print(df1)\n",
    "    df2 = df2.append(df1)\n",
    "\n",
    "pure_df.columns = map(str.lower, pure_df.columns) ## \n",
    " \n",
    "select_query = \"select * from market where Name='hrs' and Date >= '2019-10-01' and Date < '2019-11-01' \"\n",
    "df3 = pd.read_sql(select_query, engine)\n",
    "\n",
    "df3 = df3['Date']\n",
    "datelist = df3.to_list()\n",
    "\n",
    "last_df = df2.loc[df2['date'] == datelist[-1]]\n",
    "last_df = last_df[last_df['ma120'] < 0.1]\n",
    "last_price_df = pure_df.loc[pure_df['date'] == datelist[-1]]\n",
    "\n",
    "for i in datelist:\n",
    "    first_df = df2.loc[df2['date'] == i]\n",
    "    first_price_df = pure_df.loc[pure_df['date'] == i]\n",
    "    one_df = pd.merge(first_df,last_df,on='code')\n",
    "    reset_index_df = last_df.reset_index()\n",
    "    one_df['code']= reset_index_df['code']\n",
    "    ma_df = pd.merge(first_price_df[['close','code']],one_df,on='code')\n",
    "    two_df = pd.merge(last_price_df[['close','code']],ma_df,on='code')\n",
    "    two_df.columns= ['price_y','code', 'price_x', 'close_x', 'ma60_x', 'ma120_x', 'volume_x','name_x', 'date_x', 'close_y', 'ma60_y', 'ma120_y', 'volume_y','name_y', 'date_y']\n",
    "    ma120_df = two_df[['name_x','code','close_x','close_y','ma60_x','ma60_y','ma120_x','ma120_y','price_x','price_y','date_x']]\n",
    "    ma120_df['price_diff']=ma120_df['price_y']/ma120_df['price_x']\n",
    "    ma120_df =  ma120_df.sort_values([\"price_diff\"],ascending=False)\n",
    "    second_df =  first_df.sort_values([\"ma120\"],ascending=False)\n",
    "    #ma120_df['price_x']=first_price_df['close'].values\n",
    "    #ma120_df['price_y']=last_price_df['close'].values\n",
    "    strdate = i.strftime('%Y-%m-%d')\n",
    "    second_df.to_excel(path+strdate+'.xlsx')\n",
    "    ma120_df.to_excel(path_total+strdate+'.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  관심종목  ma120 일선 비교하기\n",
    "\n",
    "from mod1 import *\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "\n",
    "path = 'd:\\\\stockdata\\\\close_ma120\\\\close_ma120_'\n",
    "\n",
    "back_date=1\n",
    "choice_date='2019-10-25'\n",
    "\n",
    "df = pd.read_excel(path+choice_date+'.xlsx')\n",
    "df = df['name']\n",
    "name = df.to_list()\n",
    "\n",
    "df1 = pd.DataFrame()\n",
    "diff_df = pd.DataFrame()\n",
    "ma120_df2 = pd.DataFrame()\n",
    "for i in name:\n",
    "    #print(i)\n",
    "    df=select_stock(i,'2010-01-01')\n",
    "    df1 = df1.append(df)    \n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close','ma120','volume']].values)\n",
    "    ma120_df1 = pd.DataFrame(data)\n",
    "    ma120_df1['Name']=i\n",
    "    ma120_df1.columns=['close','ma120','volume','name',]\n",
    "    ma120_df1['date'] = df['date']\n",
    "    #print(df1)\n",
    "    ma120_df2 = ma120_df2.append(ma120_df1)\n",
    "    \n",
    "\n",
    "last = len(ma120_df2[ma120_df2['name'] == name[0]])-1\n",
    "startday_df = ma120_df2[ma120_df2.index == (last-back_date)]\n",
    "#yesterday_df = df2[df2.index == (last-1)]\n",
    "today_df = ma120_df2[ma120_df2.index == last]\n",
    "\n",
    "ma120_diff_df = pd.merge(startday_df[['name','ma120']],today_df[['name','ma120']],on='name')\n",
    "ma120_diff_df.columns=['name','startday','today']\n",
    "ma120_diff_df['diff']=ma120_diff_df['today']/ma120_diff_df['startday']\n",
    "\n",
    "ma120_up = ma120_diff_df[ma120_diff_df['diff'] > 1]\n",
    "ma120_down = ma120_diff_df[ma120_diff_df['diff'] < 1]\n",
    "ma120_sum=len(ma120_up)+len(ma120_down)\n",
    "print('ma120_up = {}'.format(len(ma120_up)))\n",
    "print('ma120_down = {}'.format(len(ma120_down)))\n",
    "    \n",
    "print('win_rate={}%'.format((len(ma120_up)/ma120_sum)*100))\n",
    "\n",
    "display((ma120_up.sort_values([\"diff\"],ascending=False).head(10)))\n",
    "display(ma120_down.sort_values(['diff']).head(10))\n",
    "display(ma120_diff_df.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  관심종목  종가, ma120 일선별로   상세히 비교 하기\n",
    "\n",
    "from mod1 import *\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "\n",
    "path = 'd:\\\\stockdata\\\\close_ma120\\\\close_ma120_'\n",
    "path_total = 'd:\\\\stockdata\\\\close_ma120\\\\total_'\n",
    "\n",
    "back_date=1\n",
    "choice_date='2019-10-25'\n",
    "\n",
    "df = pd.read_excel(path+choice_date+'.xlsx')\n",
    "df = df['name']\n",
    "name = df.to_list()\n",
    "\n",
    "df1 = pd.DataFrame()\n",
    "diff_df = pd.DataFrame()\n",
    "ma120_df2 = pd.DataFrame()\n",
    "for i in name:\n",
    "    #print(i)\n",
    "    df=select_stock(i,'2010-01-01')\n",
    "    df1 = df1.append(df)    \n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close','ma120','volume']].values)\n",
    "    ma120_df1 = pd.DataFrame(data)\n",
    "    ma120_df1['Name']=i\n",
    "    ma120_df1.columns=['close','ma120','volume','name',]\n",
    "    ma120_df1['date'] = df['date']\n",
    "    #print(df1)\n",
    "    ma120_df2 = ma120_df2.append(ma120_df1)\n",
    "    \n",
    "\n",
    "last = len(ma120_df2[ma120_df2['name'] == name[0]])-1\n",
    "ma120_startday_df = ma120_df2[ma120_df2.index == (last-back_date)]\n",
    "ma120_today_df = ma120_df2[ma120_df2.index == last]\n",
    "price_startday_df = df1[df1.index == (last-back_date)]\n",
    "price_today_df = df1[df1.index == last]\n",
    "\n",
    "ma120_diff_df = pd.merge(ma120_startday_df[['name','ma120']],ma120_today_df[['name','ma120']],on='name')\n",
    "ma120_diff_df.columns=['name','ma120_startday','ma120_today']\n",
    "ma120_diff_df['ma120_diff']=ma120_diff_df['ma120_today']/ma120_diff_df['ma120_startday']\n",
    "\n",
    "diff_df = pd.merge(price_startday_df[['Name','Close']],price_today_df[['Name','Close']],on='Name')\n",
    "diff_df.columns=['name','price_startday','price_today']\n",
    "diff_df['price_diff']=diff_df['price_today']/diff_df['price_startday']\n",
    "\n",
    "ma120_up = ma120_diff_df[ma120_diff_df['ma120_diff'] > 1]\n",
    "ma120_down = ma120_diff_df[ma120_diff_df['ma120_diff'] < 1]\n",
    "ma120_sum=len(ma120_up)+len(ma120_down)\n",
    "\n",
    "price_up = diff_df[diff_df['price_diff'] > 1]\n",
    "price_down = diff_df[diff_df['price_diff'] < 1]\n",
    "price_sum=len(price_up)+len(price_down)\n",
    "\n",
    "print('ma120_up = {}'.format(len(ma120_up)))\n",
    "print('ma120_down = {}'.format(len(ma120_down)))\n",
    "    \n",
    "print('win_rate={}%'.format((len(ma120_up)/ma120_sum)*100))\n",
    "\n",
    "display((ma120_up.sort_values([\"ma120_diff\"],ascending=False).head(10)))\n",
    "display(ma120_down.sort_values(['ma120_diff']).head(10))\n",
    "display(ma120_diff_df.describe())\n",
    "\n",
    "print('price_up = {}'.format(len(price_up)))\n",
    "print('price_down = {}'.format(len(price_down)))\n",
    "    \n",
    "print('win_rate={}%'.format((len(price_up)/price_sum)*100))\n",
    "\n",
    "display((price_up.sort_values([\"price_diff\"],ascending=False).head(10)))\n",
    "display(price_down.sort_values(['price_diff']).head(10))\n",
    "display(diff_df.describe())\n",
    "\n",
    "total_df = pd.merge(ma120_diff_df,diff_df,on='name')\n",
    "total_df = total_df.sort_values([\"price_diff\"],ascending=False)\n",
    "total_df.to_excel(path_total+choice_date+'.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  관심종목  종가, ma120 일선별로 상세히 비교 하기 _ back_date 자동계산 및 Volume 추가\n",
    "\n",
    "from mod1 import *\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "\n",
    "path = 'd:\\\\stockdata\\\\close_ma120\\\\close_ma120_'\n",
    "path_total = 'd:\\\\stockdata\\\\close_ma120\\\\total_'\n",
    "\n",
    "choice_date='2019-10-11'\n",
    "select_query = \"select count(*) from market_good where Name='hrs' and Date > \"\n",
    "var = select_query +\"'\"+choice_date+\"'\" \n",
    "df = pd.read_sql(var, engine)\n",
    "count = df.values.tolist()\n",
    "back_date = count[0][0]\n",
    "\n",
    "df = pd.read_excel(path+choice_date+'.xlsx')\n",
    "df = df['name']\n",
    "name = df.to_list()\n",
    "\n",
    "df1 = pd.DataFrame()\n",
    "diff_df = pd.DataFrame()\n",
    "ma120_df2 = pd.DataFrame()\n",
    "for i in name:\n",
    "    #print(i)\n",
    "    df=select_stock(i,'2010-01-01')\n",
    "    df1 = df1.append(df)    \n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close','ma120','volume']].values)\n",
    "    ma120_df1 = pd.DataFrame(data)\n",
    "    ma120_df1['Name']=i\n",
    "    ma120_df1.columns=['close','ma120','volume','name',]\n",
    "    ma120_df1['date'] = df['date']\n",
    "    #print(df1)\n",
    "    ma120_df2 = ma120_df2.append(ma120_df1)\n",
    "    \n",
    "\n",
    "last = len(ma120_df2[ma120_df2['name'] == name[0]])-1\n",
    "ma120_startday_df = ma120_df2[ma120_df2.index == (last-back_date)]\n",
    "ma120_today_df = ma120_df2[ma120_df2.index == last]\n",
    "price_startday_df = df1[df1.index == (last-back_date)]\n",
    "price_today_df = df1[df1.index == last]\n",
    "\n",
    "ma120_diff_df = pd.merge(ma120_startday_df[['name','ma120']],ma120_today_df[['name','ma120']],on='name')\n",
    "ma120_diff_df.columns=['name','ma120_startday','ma120_today']\n",
    "ma120_diff_df['ma120_diff']=ma120_diff_df['ma120_today']/ma120_diff_df['ma120_startday']\n",
    "\n",
    "diff_df = pd.merge(price_startday_df[['Name','Close','Volume']],price_today_df[['Name','Close','Volume']],on='Name')\n",
    "diff_df.columns=['name','price_startday','volume_startday','price_today','volume_today']\n",
    "diff_df['price_diff']=diff_df['price_today']/diff_df['price_startday']\n",
    "\n",
    "ma120_up = ma120_diff_df[ma120_diff_df['ma120_diff'] > 1]\n",
    "ma120_down = ma120_diff_df[ma120_diff_df['ma120_diff'] < 1]\n",
    "ma120_sum=len(ma120_up)+len(ma120_down)\n",
    "\n",
    "price_up = diff_df[diff_df['price_diff'] > 1]\n",
    "price_down = diff_df[diff_df['price_diff'] < 1]\n",
    "price_sum=len(price_up)+len(price_down)\n",
    "\n",
    "print('ma120_up = {}'.format(len(ma120_up)))\n",
    "print('ma120_down = {}'.format(len(ma120_down)))\n",
    "    \n",
    "print('win_rate={}%'.format((len(ma120_up)/ma120_sum)*100))\n",
    "\n",
    "display((ma120_up.sort_values([\"ma120_diff\"],ascending=False).head(10)))\n",
    "display(ma120_down.sort_values(['ma120_diff']).head(10))\n",
    "display(ma120_diff_df.describe())\n",
    "\n",
    "print('price_up = {}'.format(len(price_up)))\n",
    "print('price_down = {}'.format(len(price_down)))\n",
    "    \n",
    "print('win_rate={}%'.format((len(price_up)/price_sum)*100))\n",
    "\n",
    "display((price_up.sort_values([\"price_diff\"],ascending=False).head(10)))\n",
    "display(price_down.sort_values(['price_diff']).head(10))\n",
    "display(diff_df.describe())\n",
    "\n",
    "total_df = pd.merge(ma120_diff_df,diff_df,on='name')\n",
    "total_df  = total_df[['name','ma120_startday','ma120_today','ma120_diff','price_startday','price_today','volume_startday','volume_today','price_diff']]\n",
    "total_df = total_df.sort_values([\"price_diff\"],ascending=False)\n",
    "total_df.to_excel(path_total+choice_date+'.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##  전종목  종가 > ma120  일일 비교 하여  종목 pick 하고 pick한 종목의  종가를  비교분석\n",
    "\n",
    "from mod1 import *\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "\n",
    "\n",
    "path = 'd:\\\\stockdata\\\\close_ma120\\\\close_ma120_'\n",
    "back_date=1\n",
    "choice_date='2019-10-11'\n",
    "\n",
    "all_df = all_stock(choice_date)\n",
    "all_name_df = all_df['Name']\n",
    "\n",
    "all_name = all_name_df.to_list()\n",
    "\n",
    "all_df2 = pd.DataFrame()\n",
    "for i in all_name:\n",
    "    #print(i)\n",
    "    all_df=select_stock(i,'2010-01-01')\n",
    "    ma(all_df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(all_df[['close','ma120','volume']].values)\n",
    "    all_df1 = pd.DataFrame(data)\n",
    "    all_df1['Name']=i\n",
    "    all_df1.columns=['close','ma120','volume','name',]\n",
    "    all_df1['date'] = all_df['date']\n",
    "    #print(df1)\n",
    "    all_df2 = all_df2.append(all_df1)\n",
    "    \n",
    "\n",
    "last = len(all_df2[all_df2['name'] == all_name[0]])-1\n",
    "all_today_df = all_df2[all_df2.index == last]\n",
    "\n",
    "ma120_df = all_today_df[all_today_df['close'] > all_today_df['ma120']]\n",
    "\n",
    "today = str(ma120_df.iloc[0,4])\n",
    "ma120_df.to_excel(path+today+'.xlsx', encoding='utf-8')\n",
    "\n",
    "pick_df = pd.read_excel(path+choice_date+'.xlsx')\n",
    "pick_df = pick_df['name']\n",
    "pick_name = pick_df.to_list()\n",
    "\n",
    "pick_df1 = pd.DataFrame()\n",
    "diff_df = pd.DataFrame()\n",
    "for i in pick_name:\n",
    "    #print(i)\n",
    "    pick_df=select_stock(i,'2019-01-01')\n",
    "    pick_df1 = pick_df1.append(pick_df)\n",
    "\n",
    "last = len(pick_df1[pick_df1['Name'] == pick_name[0]])-1\n",
    "startday_df = pick_df1[pick_df1.index == (last-back_date)]\n",
    "today_df = pick_df1[pick_df1.index == last]\n",
    "\n",
    "diff_df = pd.merge(startday_df[['Name','Close']],today_df[['Name','Close']],on='Name')\n",
    "diff_df.columns=['name','startday','today']\n",
    "diff_df['diff']=diff_df['today']/diff_df['startday']\n",
    "\n",
    "up = diff_df[diff_df['diff'] > 1]\n",
    "down = diff_df[diff_df['diff'] < 1]\n",
    "sum=len(up)+len(down)\n",
    "print('up = {}'.format(len(up)))\n",
    "print('down = {}'.format(len(down)))\n",
    "    \n",
    "print('win_rate={}%'.format((len(up)/sum)*100))\n",
    "\n",
    "display((up.sort_values([\"diff\"],ascending=False).head(10)))\n",
    "display(down.sort_values(['diff']).head(10))\n",
    "display(diff_df.describe())\n",
    "\n",
    "#kk = datetime.now()-datetime(2019,10,13)\n",
    "#print(kk.days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##  전종목  종가, ma120 일선 비교하기\n",
    "\n",
    "from mod1 import *\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "\n",
    "path = 'd:\\\\stockdata\\\\close_ma120\\\\close_ma120_'\n",
    "path_total = 'd:\\\\stockdata\\\\close_ma120\\\\all_'\n",
    "\n",
    "back_date=5\n",
    "choice_date='2019-10-11'\n",
    "\n",
    "df = all_stock(choice_date)\n",
    "#df.columns=['date', 'code', 'name', 'open', 'high', 'low', 'volume', 'close']\n",
    "df.columns = map(str.lower, df.columns)\n",
    "df = df['name']\n",
    "name = df.to_list()\n",
    "\n",
    "df1 = pd.DataFrame()\n",
    "diff_df = pd.DataFrame()\n",
    "ma120_df2 = pd.DataFrame()\n",
    "for i in name:\n",
    "    #print(i)\n",
    "    df=select_stock(i,'2010-01-01')\n",
    "    df1 = df1.append(df)    \n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close','ma120','volume']].values)\n",
    "    ma120_df1 = pd.DataFrame(data)\n",
    "    ma120_df1['Name']=i\n",
    "    ma120_df1.columns=['close','ma120','volume','name',]\n",
    "    ma120_df1['date'] = df['date']\n",
    "    #print(df1)\n",
    "    ma120_df2 = ma120_df2.append(ma120_df1)\n",
    "    \n",
    "ma120_df2['event_date'] = pd.to_datetime(ma120_df2['date'])\n",
    "df1['event_date'] = pd.to_datetime(df1['Date'])\n",
    "day = str((datetime.now()-timedelta(3)).date())\n",
    "da = str((datetime.now()-timedelta(2)).date())\n",
    "ma120_startday_df = ma120_df2.loc[ma120_df2['event_date'] == day]\n",
    "ma120_today_df = ma120_df2.loc[ma120_df2['event_date'] == da]\n",
    "price_startday_df = df1.loc[df1['event_date'] == day]\n",
    "price_today_df = df1.loc[df1['event_date'] == da]\n",
    "\n",
    "ma120_diff_df = pd.merge(ma120_startday_df[['name','ma120']],ma120_today_df[['name','ma120']],on='name')\n",
    "ma120_diff_df.columns=['name','ma120_startday','ma120_today']\n",
    "ma120_diff_df['ma120_diff']=ma120_diff_df['ma120_today']/ma120_diff_df['ma120_startday']\n",
    "\n",
    "diff_df = pd.merge(price_startday_df[['Name','Close']],price_today_df[['Name','Close']],on='Name')\n",
    "diff_df.columns=['name','price_startday','price_today']\n",
    "diff_df['price_diff']=diff_df['price_today']/diff_df['price_startday']\n",
    "\n",
    "ma120_up = ma120_diff_df[ma120_diff_df['ma120_diff'] > 1]\n",
    "ma120_down = ma120_diff_df[ma120_diff_df['ma120_diff'] < 1]\n",
    "ma120_sum=len(ma120_up)+len(ma120_down)\n",
    "\n",
    "price_up = diff_df[diff_df['price_diff'] > 1]\n",
    "price_down = diff_df[diff_df['price_diff'] < 1]\n",
    "price_sum=len(price_up)+len(price_down)\n",
    "\n",
    "print('ma120_up = {}'.format(len(ma120_up)))\n",
    "print('ma120_down = {}'.format(len(ma120_down)))\n",
    "    \n",
    "print('win_rate={}%'.format((len(ma120_up)/ma120_sum)*100))\n",
    "\n",
    "display((ma120_up.sort_values([\"ma120_diff\"],ascending=False).head(10)))\n",
    "display(ma120_down.sort_values(['ma120_diff']).head(10))\n",
    "display(ma120_diff_df.describe())\n",
    "\n",
    "print('price_up = {}'.format(len(price_up)))\n",
    "print('price_down = {}'.format(len(price_down)))\n",
    "    \n",
    "print('win_rate={}%'.format((len(price_up)/price_sum)*100))\n",
    "\n",
    "display((price_up.sort_values([\"price_diff\"],ascending=False).head(10)))\n",
    "display(price_down.sort_values(['price_diff']).head(10))\n",
    "display(diff_df.describe())\n",
    "\n",
    "total_df = pd.merge(ma120_diff_df,diff_df,on='name')\n",
    "total_df = total_df.sort_values([\"price_diff\"],ascending=False)\n",
    "total_df.to_excel(path_total+choice_date+'.xlsx')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###  관심종목 ma60, ma120, cci 그래프 생성\n",
    "\n",
    "from mod1 import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "\n",
    "def close_ma(df,select1,select2,select3):\n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close',select1,select2,select3]].values)\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1.columns=['close',select1,select2,select3]\n",
    "    df1 = df1.set_index(df['date'])\n",
    "    df1.plot(figsize=(16,4))\n",
    "    plt.title(df['name'][0])\n",
    "    plt.show()\n",
    "\n",
    "path = 'd:\\\\stockdata\\\\close_ma120\\\\close_ma120_'\n",
    "path_total = 'd:\\\\stockdata\\\\close_ma120\\\\total_'\n",
    "\n",
    "choice_date = '2019-10-01'\n",
    "df = pd.read_excel(path_total+choice_date+'.xlsx')\n",
    "df = df['name']\n",
    "name = df.to_list()\n",
    "\n",
    "#name=['hrs','손오공']\n",
    "\n",
    "pure_df = pd.DataFrame()\n",
    "df2 = pd.DataFrame()\n",
    "cci_df = pd.DataFrame()\n",
    "for i in name:\n",
    "    #print(i)\n",
    "    df=select_stock(i,'2010-01-01')\n",
    "    cci_df[['open','high','low','volume','close']] = df[['Open','High','Low','Volume','Close']].astype(float) #  TA-Lib로 평균을 구하려면 실수로 만들어야 함\n",
    "    period = 120\n",
    "    cci_df['cci'] = ta.CCI(cci_df, timeperiod=period)\n",
    "    df['cci'] = cci_df['cci']\n",
    "    close_ma(df,'cci','ma60','ma120')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
