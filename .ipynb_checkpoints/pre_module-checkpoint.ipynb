{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  ##  일봉,주봉,월봉 데이터 생성\n",
    "\n",
    "from mod1 import *\n",
    "\n",
    "def day_week_month_data(market='일야', start_day = '2020-01-01',period ='month'):\n",
    "    if market=='kospi' or market=='kosdaq':\n",
    "        df = select_market(market,start_day)\n",
    "    else :\n",
    "        df = select_stock(market,start_day)\n",
    "    df['Date']=pd.to_datetime(df['Date'])\n",
    "    months = [g for n, g in df.groupby(pd.Grouper(key='Date',freq='M'))]  ##   월별\n",
    "    weeks = [g for n, g in df.groupby(pd.Grouper(key='Date',freq='W'))]  ##   주별\n",
    "    columns = ['Date','Open', 'High', 'Low', 'Close', 'Volume']\n",
    "    rows = []    \n",
    "\n",
    "    if period == 'day':\n",
    "        \n",
    "        df=df[['Date','Open', 'High', 'Low','Close', 'Volume']]\n",
    "        df.columns=columns\n",
    "        #df = df.set_index(df['date'])\n",
    "        return df\n",
    "    \n",
    "    elif period == 'month':\n",
    "        period = months\n",
    "        \n",
    "    elif period == 'week':\n",
    "        period = weeks\n",
    "        \n",
    "    for i in range(len(period)):\n",
    "        rows.append(period[i].iloc[-1]['Date'])\n",
    "        rows.append(period[i].iloc[0][\"Open\"])\n",
    "        rows.append(max(period[i]['High']))\n",
    "        rows.append(min(period[i]['Low']))\n",
    "        rows.append(period[i].iloc[-1]['Close'])\n",
    "        rows.append(sum(period[i]['Volume']))\n",
    "        \n",
    "    arr = np.array(rows)\n",
    "    arr1 = arr.reshape(len(period),6)\n",
    "    df = pd.DataFrame(data=arr1, columns=columns)\n",
    "    df = df.set_index(df['Date'])\n",
    "    df.rename(columns = {'Date' : 'Date1'}, inplace = True)\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  일봉,주봉,월봉에서  연속으로 하락한 종목을 순서대로 정렬\n",
    "\n",
    "\n",
    "from mod1 import *\n",
    "\n",
    "def day_week_month_data(market='일야', start_day = '2020-01-01',period ='month'):\n",
    "    if market=='kospi' or market=='kosdaq':\n",
    "        df = select_market(market,start_day)\n",
    "    else :\n",
    "        df = select_stock(market,start_day)\n",
    "    df['Date']=pd.to_datetime(df['Date'])\n",
    "    months = [g for n, g in df.groupby(pd.Grouper(key='Date',freq='M'))]  ##   월별\n",
    "    weeks = [g for n, g in df.groupby(pd.Grouper(key='Date',freq='W'))]  ##   주별\n",
    "    columns = ['Date','Open', 'High', 'Low', 'Close', 'Volume']\n",
    "    rows = []    \n",
    "\n",
    "    if period == 'day':\n",
    "        \n",
    "        df=df[['Date','Open', 'High', 'Low','Close', 'Volume']]\n",
    "        df.columns=columns\n",
    "        #df = df.set_index(df['date'])\n",
    "        return df\n",
    "    \n",
    "    elif period == 'month':\n",
    "        period = months\n",
    "        \n",
    "    elif period == 'week':\n",
    "        period = weeks\n",
    "        \n",
    "    for i in range(len(period)):\n",
    "        rows.append(period[i].iloc[-1]['Date'])\n",
    "        rows.append(period[i].iloc[0][\"Open\"])\n",
    "        rows.append(max(period[i]['High']))\n",
    "        rows.append(min(period[i]['Low']))\n",
    "        rows.append(period[i].iloc[-1]['Close'])\n",
    "        rows.append(sum(period[i]['Volume']))\n",
    "        \n",
    "    arr = np.array(rows)\n",
    "    arr1 = arr.reshape(len(period),6)\n",
    "    df = pd.DataFrame(data=arr1, columns=columns)\n",
    "    df = df.set_index(df['Date'])\n",
    "    df.rename(columns = {'Date' : 'Date1'}, inplace = True)\n",
    "    return df \n",
    "\n",
    "def depress(period):\n",
    "    today = datetime.now().strftime('%Y-%m-%d')\n",
    "    path_depress = 'd:\\\\stockdata\\\\depress\\\\depress_'\n",
    "    if period=='month':\n",
    "        start_day='2019-01-01'\n",
    "        \n",
    "    elif period=='week' :\n",
    "        start_day='2020-01-01'\n",
    "        \n",
    "    else :\n",
    "        start_day='2020-05-01'\n",
    "        \n",
    "    df = all_stock('2020-06-15')\n",
    "    df = df['Name']\n",
    "    name = df.to_list()\n",
    "\n",
    "    #name=['일야','hrs','디지털대성']\n",
    "    count = 0\n",
    "    depress=[]\n",
    "    for i in name:\n",
    "        df = day_week_month_data(market=i,start_day=start_day,period=period)\n",
    "        df['yesterday']=df.Close.shift(1)\n",
    "        df['minus']=(df['Close']-df['yesterday']) < 0\n",
    "        df1 = df.sort_values(by=['Date'], axis=0, ascending=False,ignore_index=True )\n",
    "        minus = df1.minus.values\n",
    "\n",
    "        for i in minus:\n",
    "            if i == True:\n",
    "                count += 1\n",
    "\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        #print(count)\n",
    "        depress.append(count)\n",
    "        count=0\n",
    "\n",
    "\n",
    "    df2= pd.DataFrame()\n",
    "    df2['name']=name\n",
    "    df2['count']=depress\n",
    "    df3 = df2.sort_values(by=['count'], axis=0, ascending=False,ignore_index=True )\n",
    "    if period=='month':\n",
    "        df3 = df3.iloc[:100]\n",
    "    elif period=='week':\n",
    "        df3 = df3.iloc[:200]\n",
    "    elif period=='day':\n",
    "        df3 = df3.iloc[:300]\n",
    "    #else:\n",
    "       # break\n",
    "    df3.to_excel(path_depress+today+'_'+period+'.xlsx')\n",
    "    #return df3\n",
    "\n",
    "\n",
    "three_period=['day','week','month']\n",
    "for i in three_period:\n",
    "    depress(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  일봉상 연속으로 하락한 종목을 순서대로 정렬\n",
    "\n",
    "from mod1 import *\n",
    "\n",
    "df = all_stock('2020-06-12')\n",
    "df = df['Name']\n",
    "name = df.to_list()\n",
    "\n",
    "count = 0\n",
    "depress=[]\n",
    "for i in name:\n",
    "    df = select_stock(i,'2020-05-01')\n",
    "    df['yesterday']=df.Close.shift(1)\n",
    "    df['minus']=(df['Close']-df['yesterday']) < 0\n",
    "    df1 = df.sort_values(by=['Date'], axis=0, ascending=False,ignore_index=True )\n",
    "    minus = df1.minus.values\n",
    "\n",
    "    for i in minus:\n",
    "        \n",
    "\n",
    "        if i == True:\n",
    "            count += 1\n",
    "\n",
    "        else:\n",
    "            \n",
    "            break\n",
    "        \n",
    "    print(count)\n",
    "    depress.append(count)\n",
    "    count=0\n",
    "\n",
    "\n",
    "df2= pd.DataFrame()\n",
    "df2['name']=name\n",
    "df2['count']=depress\n",
    "df3 = df2.sort_values(by=['count'], axis=0, ascending=False,ignore_index=True )\n",
    "df3.to_excel('d:\\depress_day.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###  기간동안 종목별 종가중 최대값 \n",
    "\n",
    "from  mod1 import *\n",
    "\n",
    "def all_stock_period(date1, date2='2021-01-01'):\n",
    "    select_query = \"select * from market_good where Date >=  \"\n",
    "    var = select_query +\"'\"+date1+\"'\"  +\" \"+ 'and Date <=' + \"'\"+date2+\"'\"\n",
    "    df = pd.read_sql(var, engine)\n",
    "    return df\n",
    "\n",
    "df = all_stock_period('2020-03-05','2020-03-10')\n",
    "\n",
    "max(df[df['Code']=='000547'].Close) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  기간동안 낙폭 과대종목 검색 (기간동안 최저점에서 현재가 비교)_1\n",
    "\n",
    "\n",
    "from  mod1 import *\n",
    "\n",
    "def all_stock_period(date1, date2='2021-01-01'):\n",
    "    select_query = \"select * from market_good where Date >=  \"\n",
    "    var = select_query +\"'\"+date1+\"'\"  +\" \"+ 'and Date <=' + \"'\"+date2+\"'\"\n",
    "    df = pd.read_sql(var, engine)\n",
    "    return df\n",
    "\n",
    "\n",
    "df = all_stock_period('2020-02-20','2020-03-25')\n",
    "df_uniq = df['Name'].unique()\n",
    "df_uniq_list=df_uniq.tolist()\n",
    "\n",
    "min_data = []\n",
    "for x in df_uniq_list:\n",
    "    min_value = min(df[df['Name']== x ].Close)\n",
    "    min_data.append(min_value)\n",
    "\n",
    "min_close = pd.DataFrame(min_data)\n",
    "\n",
    "df_a=pd.DataFrame(df_uniq)\n",
    "\n",
    "\n",
    "df_first=pd.DataFrame()\n",
    "df_first['Name']=df_a[0]\n",
    "df_first['Close']=min_close[0]\n",
    "df_to = all_stock('2020-07-20')\n",
    "df_last=df_to[['Name','Close']]\n",
    "df = pd.merge(df_first,df_last,on='Name')\n",
    "\n",
    "df['diff']=df['Close_y']/df['Close_x']\n",
    "df.head()\n",
    "\n",
    "close_diff_df =  df.sort_values([\"diff\"],ascending=True)\n",
    "close_diff_df.head()\n",
    "\n",
    "close_diff_df.to_excel(\"d:\\\\b_1.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  기간동안 낙폭 과대종목 검색 (기간동안 최저점에서 현재가 비교)_2\n",
    "\n",
    "import time\n",
    "from  mod1 import *\n",
    "\n",
    "start = time.time()  # 시작 시간 저장\n",
    "\n",
    "from  mod1 import *\n",
    "\n",
    "today = datetime.now().strftime('%Y-%m-%d')\n",
    "current=today\n",
    "def all_stock_period(date1, date2='2021-01-01'):\n",
    "    select_query = \"select * from market_good where Date >=  \"\n",
    "    var = select_query +\"'\"+date1+\"'\"  +\" \"+ 'and Date <=' + \"'\"+date2+\"'\"\n",
    "    df = pd.read_sql(var, engine)\n",
    "    return df\n",
    "\n",
    "df = all_stock_period('2020-02-19','2020-03-25')\n",
    "df_start=pd.DataFrame()\n",
    "name = df['Name'].unique()\n",
    "\n",
    "df = df.set_index('Name')\n",
    "\n",
    "min_list=[ ]\n",
    "for i in name:\n",
    "    min_close  = min(df.loc[i].Close)\n",
    "    min_list.append(min_close)\n",
    "\n",
    "df_start=pd.DataFrame(name)\n",
    "df_start['Name']=pd.DataFrame(name)\n",
    "df_start['Close']=pd.DataFrame(min_list)\n",
    "df_start=df_start[['Name','Close']]\n",
    "df1 = all_stock(current)\n",
    "df1_last = df1[['Name','Close']]\n",
    "\n",
    "df2 = pd.merge(df_start, df1_last, on=\"Name\")\n",
    "df2['diff']=df2['Close_y']/df2['Close_x']\n",
    "df2 = df2.sort_values(by=['diff'], ascending='True')\n",
    "\n",
    "df2.to_excel('d:\\\\down_'+current+'.xlsx')\n",
    "print(\"time :\", time.time() - start)  # 현재시각 - 시작시간 = 실행 시간"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  기간동안 낙폭 과대종목 검색\n",
    "\n",
    "from mod1 import *\n",
    "today = datetime.now().strftime('%Y-%m-%d')\n",
    "current=today\n",
    "\n",
    "df_from = all_stock('2020-03-05')\n",
    "df_to = all_stock(current)\n",
    "df_first=df_from[['Name','Close']]\n",
    "df_last=df_to[['Name','Close']]\n",
    "df = pd.merge(df_first,df_last,on='Name')\n",
    "\n",
    "df['diff']=df['Close_y']/df['Close_x']\n",
    "df.head()\n",
    "\n",
    "close_diff_df =  df.sort_values([\"diff\"],ascending=True)\n",
    "close_diff_df.head()\n",
    "\n",
    "close_diff_df.to_excel('d:\\\\down_'+current+'.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 월봉 만들기\n",
    "\n",
    "df = select_stock('아스트','2019-01-01')\n",
    "how = {'Open': 'first', 'High': 'max', 'Low': 'min', 'Close': 'last', 'Volume': 'sum'}\n",
    "def resample_df(df, freq, how):\n",
    "    df['Date'] = df['Date'].astype('datetime64[ns]')\n",
    "    df = df.set_index('Date')\n",
    "    df = df[['Open','High','Low','Close','Volume']]\n",
    "    #how = {'Open': 'first', 'High': 'max', 'Low': 'min', 'Close': 'last', 'Volume': 'sum'}\n",
    "    if freq != 'd' and len(df) > 0:\n",
    "        if freq == 'm':\n",
    "            df = df.resample('M').apply(how)\n",
    "            #df.index = df.index.strftime('%Y%m')\n",
    "        elif freq == 'y':\n",
    "            df = df.resample('Y').apply(how)\n",
    "            #df.index = df.index.strftime('%Y')\n",
    "        else:\n",
    "            print(\"choose a freq parameter in ('m', 'y', 'd')\")\n",
    "            raise RuntimeError\n",
    "    return df\n",
    "\n",
    "df = resample_df(df,'m',how)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  기간동안 종목 가격 변화 \n",
    "\n",
    "from  mod1 import *\n",
    "\n",
    "price_path = 'd:/stockdata/vote_stock/detect_stock_with_price_'\n",
    "volume_path = 'd:/stockdata/vote_stock/detect_stock_with_volume_'\n",
    "\n",
    "df = pd.read_excel(volume_path+'2020-07-14.xlsx', index_col=0)\n",
    "\n",
    "data = pd.DataFrame()\n",
    "for x in df['Name']:\n",
    "    current = select_stock(x,'2020-07-20')\n",
    "    data = data.append(current['Close'])\n",
    "\n",
    "data = data.reset_index(drop=True)\n",
    "data.columns=['current_Close']\n",
    "\n",
    "df['current_Close']=data['current_Close']\n",
    "df['diff']=df['current_Close'] / df['today_Close']\n",
    "\n",
    "df = df.sort_values(['diff'], ascending=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## datetime.date  -> pd.to_datetime \n",
    "\n",
    "#!/usr/bin/env python3\n",
    "# coding: utf-8\n",
    "\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "# create a datetime data object\n",
    "d_time = datetime.date(2010, 11, 12)\n",
    "\n",
    "# create a pandas Timestamp object\n",
    "t_stamp = pd.to_datetime('2010/11/12')\n",
    "\n",
    "# cast `datetime_timestamp` as Timestamp object and compare\n",
    "d_time2t_stamp = pd.to_datetime(d_time)\n",
    "\n",
    "# print to double check\n",
    "print(d_time)\n",
    "print(t_stamp)\n",
    "print(d_time2t_stamp)\n",
    "\n",
    "# since the conversion succeds this prints `True`\n",
    "print(d_time2t_stamp == t_stamp)\n",
    "\n",
    "\n",
    "## sample \n",
    "t = pd.Timestamp('2013-12-25 00:00:00')\n",
    "\n",
    "t.date()\n",
    "#datetime.date(2013, 12, 25)\n",
    "\n",
    "t.date() == datetime.date(2013, 12, 25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import FinanceDataReader as fdr\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime as dt\n",
    "from datetime import datetime,timedelta\n",
    "from urllib.request import urlopen\n",
    "import sqlalchemy \n",
    "import pymysql\n",
    "import talib.abstract as ta\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "from matplotlib import font_manager, rc\n",
    "font_name = font_manager.FontProperties(fname=\"c:/Windows/Fonts/malgun.ttf\").get_name()\n",
    "rc('font', family=font_name)\n",
    "\n",
    "now = dt.datetime.today().strftime('%Y-%m-%d')\n",
    "engine = sqlalchemy.create_engine('mysql+pymysql://kkang:leaf2027@localhost/stock?charset=utf8',encoding='utf-8')\n",
    "conn = pymysql.connect(host = 'localhost', user = 'kkang', password = 'leaf2027' ,db = 'stock')\n",
    "curs = conn.cursor()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataBase 입출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  코스피, 코드닥 지수 Database에 입력\n",
    "\n",
    "from mod1 import *\n",
    "def market_index_to_database(startday, lastday='20251231', market='코스피'):\n",
    "\n",
    "    df = get_index_ohlcv_by_date(startday, lastday, market)\n",
    "\n",
    "    df.index.names = ['Date']\n",
    "    df.columns  = ('Open','High','Low','Close','Volume')\n",
    "    if market == '코스피':\n",
    "        df['Market']='kospi'\n",
    "        df.to_sql(name='kospi', con=engine, if_exists='append')\n",
    "    elif market == '코스닥':\n",
    "        df['Market']='kosdaq'\n",
    "        df.to_sql(name='kosdaq', con=engine, if_exists='append')\n",
    "    #df.to_excel('d:\\\\kospi.xlsx')\n",
    "market_index_to_database(\"20200713\",'20251231','코스피')\n",
    "market_index_to_database(\"20200713\",'20251231','코스닥')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "파일이름을 입력하세요:market.xlsx\n",
      "저장 방식을 입력하세요 : sample: excel, sql sql\n",
      "시작날자를 입려하세요 : sample: '2015-01-01'2020-07-15\n",
      "table명을 입력하세요 : sample: marketmarket\n",
      "000020 동화약품\n",
      "000040 KR모터스\n",
      "000050 경방\n",
      "000060 메리츠화재\n",
      "000070 삼양홀딩스\n",
      "000075 삼양홀딩스우\n",
      "000080 하이트진로\n",
      "000087 하이트진로2우B\n",
      "000100 유한양행\n",
      "000105 유한양행우\n",
      "000120 CJ대한통운\n",
      "000140 하이트진로홀딩스\n",
      "000145 하이트진로홀딩스우\n",
      "000150 두산\n",
      "000155 두산우\n",
      "000157 두산2우B\n",
      "000180 성창기업지주\n",
      "000210 대림산업\n",
      "000215 대림산업우\n",
      "000220 유유제약\n",
      "000225 유유제약1우\n",
      "000227 유유제약2우B\n",
      "000230 일동홀딩스\n",
      "000240 한국테크놀로지그룹\n",
      "000250 삼천당제약\n",
      "000270 기아차\n",
      "000300 대유플러스\n",
      "000320 노루홀딩스\n",
      "000325 노루홀딩스우\n",
      "000370 한화손해보험\n",
      "000390 삼화페인트\n",
      "000400 롯데손해보험\n",
      "000430 대원강업\n",
      "000440 중앙에너비스\n",
      "000480 조선내화\n",
      "000490 대동공업\n",
      "000500 가온전선\n",
      "000520 삼일제약\n",
      "000540 흥국화재\n",
      "000545 흥국화재우\n",
      "000547 흥국화재2우B\n",
      "000590 CS홀딩스\n",
      "000640 동아쏘시오홀딩스\n",
      "000650 천일고속\n",
      "000660 SK하이닉스\n",
      "000670 영풍\n",
      "000680 LS네트웍스\n",
      "000700 유수홀딩스\n",
      "000720 현대건설\n",
      "000725 현대건설우\n",
      "000760 이화산업\n",
      "000810 삼성화재\n",
      "000815 삼성화재우\n",
      "000850 화천기공\n",
      "000860 강남제비스코\n",
      "000880 한화\n",
      "000885 한화우\n",
      "000890 보해양조\n",
      "000910 유니온\n",
      "000950 전방\n",
      "000970 한국주철관\n",
      "000990 DB하이텍\n",
      "000995 DB하이텍1우\n",
      "001000 신라섬유\n",
      "001020 페이퍼코리아\n",
      "001040 CJ\n",
      "001045 CJ우\n",
      "001060 JW중외제약\n",
      "001065 JW중외제약우\n",
      "001067 JW중외제약2우B\n",
      "001070 대한방직\n",
      "001080 만호제강\n",
      "001120 LG상사\n",
      "001130 대한제분\n",
      "001140 국보\n",
      "001200 유진투자증권\n",
      "001210 금호전기\n",
      "001230 동국제강\n",
      "001250 GS글로벌\n",
      "001260 남광토건\n",
      "001270 부국증권\n",
      "001275 부국증권우\n",
      "001290 상상인증권\n",
      "001340 백광산업\n",
      "001360 삼성제약\n",
      "001380 SG충방\n",
      "001390 KG케미칼\n",
      "001420 태원물산\n",
      "001430 세아베스틸\n",
      "001440 대한전선\n",
      "001450 현대해상\n",
      "001460 BYC\n",
      "001465 BYC우\n",
      "001470 삼부토건\n",
      "001500 현대차증권\n",
      "001510 SK증권\n",
      "001515 SK증권우\n",
      "001520 동양\n",
      "001525 동양우\n",
      "001527 동양2우B\n",
      "001529 동양3우B\n",
      "001530 DI동일\n",
      "001540 안국약품\n",
      "001550 조비\n",
      "001560 제일연마\n",
      "001570 금양\n",
      "001620 케이비아이동국실업\n",
      "001630 종근당홀딩스\n",
      "001680 대상\n",
      "001685 대상우\n",
      "001720 신영증권\n",
      "001725 신영증권우\n",
      "001740 SK네트웍스\n",
      "001745 SK네트웍스우\n",
      "001750 한양증권\n",
      "001755 한양증권우\n",
      "001770 신화실업\n",
      "001780 알루코\n",
      "001790 대한제당\n",
      "001795 대한제당우\n",
      "001799 대한제당3우B\n",
      "001800 오리온홀딩스\n",
      "001810 무림SP\n",
      "001820 삼화콘덴서\n",
      "001840 이화공영\n",
      "001880 삼호\n",
      "001940 KISCO홀딩스\n",
      "002020 코오롱\n",
      "002025 코오롱우\n",
      "002030 아세아\n",
      "002070 남영비비안\n",
      "002100 경농\n",
      "002140 고려산업\n",
      "002150 도화엔지니어링\n",
      "002170 삼양통상\n",
      "002200 수출포장\n",
      "002210 동성제약\n",
      "002220 한일철강\n",
      "002230 피에스텍\n",
      "002240 고려제강\n",
      "002270 롯데푸드\n",
      "002290 삼일기업공사\n",
      "002300 한국제지\n",
      "002310 아세아제지\n",
      "002320 한진\n",
      "002350 넥센타이어\n",
      "002355 넥센타이어1우B\n",
      "002360 SH에너지화학\n",
      "002380 KCC\n",
      "002390 한독\n",
      "002410 범양건영\n",
      "002420 세기상사\n",
      "002450 삼익악기\n",
      "002460 화성산업\n",
      "002600 조흥\n",
      "002620 제일파마홀딩스\n",
      "002630 오리엔트바이오\n",
      "002680 한탑\n",
      "002690 동일제강\n",
      "002700 신일산업\n",
      "002710 TCC스틸\n",
      "002720 국제약품\n",
      "002760 보락\n",
      "002780 진흥기업\n",
      "002785 진흥기업우B\n",
      "002787 진흥기업2우B\n",
      "002790 아모레G\n",
      "002795 아모레G우\n",
      "002800 신신제약\n",
      "002810 삼영무역\n",
      "002820 선창산업\n",
      "002840 미원상사\n",
      "002870 신풍제지\n",
      "002880 대유에이텍\n",
      "002900 동양물산\n",
      "002920 유성기업\n",
      "002960 한국쉘석유\n",
      "002990 금호산업\n",
      "002995 금호산업우\n",
      "003000 부광약품\n",
      "003010 혜인\n",
      "003030 세아제강지주\n",
      "003060 에이프로젠제약\n",
      "003070 코오롱글로벌\n",
      "003075 코오롱글로벌우\n",
      "003080 성보화학\n",
      "003090 대웅\n",
      "003100 선광\n",
      "003120 일성신약\n",
      "003160 디아이\n",
      "003200 일신방직\n",
      "003220 대원제약\n",
      "003230 삼양식품\n",
      "003240 태광산업\n",
      "003280 흥아해운\n",
      "003300 한일홀딩스\n",
      "003310 대주산업\n",
      "003350 한국화장품제조\n",
      "003380 하림지주\n",
      "003410 쌍용양회\n",
      "003415 쌍용양회우\n",
      "003460 유화증권\n",
      "003465 유화증권우\n",
      "003470 유안타증권\n",
      "003475 유안타증권우\n",
      "003480 한진중공업홀딩스\n",
      "003490 대한항공\n",
      "003495 대한항공우\n",
      "003520 영진약품\n",
      "003530 한화투자증권\n",
      "003535 한화투자증권우\n",
      "003540 대신증권\n",
      "003545 대신증권우\n",
      "003547 대신증권2우B\n",
      "003550 LG\n",
      "003555 LG우\n",
      "003560 IHQ\n",
      "003570 S&T중공업\n",
      "003580 넥스트사이언스\n",
      "003610 방림\n",
      "003620 쌍용차\n",
      "003650 미창석유\n",
      "003670 포스코케미칼\n",
      "003680 한성기업\n",
      "003690 코리안리\n",
      "003720 삼영화학\n",
      "003780 진양산업\n",
      "003800 에이스침대\n",
      "003830 대한화섬\n",
      "003850 보령제약\n",
      "003920 남양유업\n",
      "003925 남양유업우\n",
      "003960 사조대림\n",
      "004000 롯데정밀화학\n",
      "004020 현대제철\n",
      "004060 SG세계물산\n",
      "004080 신흥\n",
      "004090 한국석유\n",
      "004100 태양금속\n",
      "004105 태양금속우\n",
      "004140 동방\n",
      "004150 한솔홀딩스\n",
      "004170 신세계\n",
      "004200 고려개발\n",
      "004250 NPC\n",
      "004255 NPC우\n",
      "004270 남성\n",
      "004310 현대약품\n",
      "004360 세방\n",
      "004365 세방우\n",
      "004370 농심\n",
      "004380 삼익THK\n",
      "004410 서울식품\n",
      "004415 서울식품우\n",
      "004430 송원산업\n",
      "004440 대림씨엔에스\n",
      "004450 삼화왕관\n",
      "004490 세방전지\n",
      "004540 깨끗한나라\n",
      "004545 깨끗한나라우\n",
      "004560 현대비앤지스틸\n",
      "004565 현대비앤지스틸우\n",
      "004590 한국가구\n",
      "004650 창해에탄올\n",
      "004690 삼천리\n",
      "004700 조광피혁\n",
      "004710 한솔테크닉스\n",
      "004720 우리들제약\n",
      "004770 써니전자\n",
      "004780 대륙제관\n",
      "004800 효성\n",
      "004830 덕성\n",
      "004835 덕성우\n",
      "004840 DRB동일\n",
      "004870 티웨이홀딩스\n",
      "004890 동일산업\n",
      "004910 조광페인트\n",
      "004920 씨아이테크\n",
      "004960 한신공영\n",
      "004970 신라교역\n",
      "004980 성신양회\n",
      "004985 성신양회우\n",
      "004990 롯데지주\n",
      "005010 휴스틸\n",
      "005030 부산주공\n",
      "005070 코스모신소재\n",
      "005090 삼광글라스\n",
      "005110 한창\n",
      "005160 동국산업\n",
      "005180 빙그레\n",
      "005190 동성화학\n",
      "005250 녹십자홀딩스\n",
      "005257 녹십자홀딩스2우\n",
      "005290 동진쎄미켐\n",
      "005300 롯데칠성\n",
      "005305 롯데칠성우\n",
      "005320 국동\n",
      "005360 모나미\n",
      "005380 현대차\n",
      "005385 현대차우\n",
      "005387 현대차2우B\n",
      "005389 현대차3우B\n",
      "005390 신성통상\n",
      "005420 코스모화학\n",
      "005430 한국공항\n",
      "005440 현대그린푸드\n",
      "005450 신한\n",
      "005490 POSCO\n",
      "005500 삼진제약\n",
      "005610 SPC삼립\n",
      "005670 푸드웰\n",
      "005680 삼영전자\n",
      "005690 파미셀\n",
      "005710 대원산업\n",
      "005720 넥센\n",
      "005725 넥센우\n",
      "005740 크라운해태홀딩스\n",
      "005745 크라운해태홀딩스우\n",
      "005750 대림B&Co\n",
      "005800 신영와코루\n",
      "005810 풍산홀딩스\n",
      "005820 원림\n",
      "005830 DB손해보험\n",
      "005850 에스엘\n",
      "005860 한일사료\n",
      "005870 휴니드\n",
      "005880 대한해운\n",
      "005930 삼성전자\n",
      "005935 삼성전자우\n",
      "005940 NH투자증권\n",
      "005945 NH투자증권우\n",
      "005950 이수화학\n",
      "005960 동부건설\n",
      "005965 동부건설우\n",
      "005990 매일홀딩스\n",
      "006040 동원산업\n",
      "006050 국영지앤엠\n",
      "006060 화승인더\n",
      "006090 사조오양\n",
      "006110 삼아알미늄\n",
      "006120 SK디스커버리\n",
      "006125 SK디스커버리우\n",
      "006140 피제이전자\n",
      "006200 한국전자홀딩스\n",
      "006220 제주은행\n",
      "006260 LS\n",
      "006280 녹십자\n",
      "006340 대원전선\n",
      "006345 대원전선우\n",
      "006360 GS건설\n",
      "006370 대구백화점\n",
      "006380 카프로\n",
      "006390 한일현대시멘트\n",
      "006400 삼성SDI\n",
      "006405 삼성SDI우\n",
      "006490 인스코비\n",
      "006570 대림통상\n",
      "006580 대양제지\n",
      "006620 동구바이오제약\n",
      "006650 대한유화\n",
      "006660 삼성공조\n",
      "006730 서부T&D\n",
      "006740 영풍제지\n",
      "006800 미래에셋대우\n",
      "006805 미래에셋대우우\n",
      "006840 AK홀딩스\n",
      "006880 신송홀딩스\n",
      "006890 태경화학\n",
      "006910 보성파워텍\n",
      "006920 모헨즈\n",
      "006980 우성사료\n",
      "007070 GS리테일\n",
      "007110 일신석재\n",
      "007120 미래아이앤지\n",
      "007160 사조산업\n",
      "007210 벽산\n",
      "007280 한국특수형강\n",
      "007310 오뚜기\n",
      "007330 푸른저축은행\n",
      "007340 디티알오토모티브\n",
      "007370 진양제약\n",
      "007390 네이처셀\n",
      "007460 에이프로젠 KIC\n",
      "007530 영신금속\n",
      "007540 샘표\n",
      "007570 일양약품\n",
      "007575 일양약품우\n",
      "007590 동방아그로\n",
      "007610 선도전기\n",
      "007630 폴루스바이오팜\n",
      "007660 이수페타시스\n",
      "007680 대원\n",
      "007690 국도화학\n",
      "007700 F&F\n",
      "007720 대명코퍼레이션\n",
      "007770 한일화학\n",
      "007810 코리아써키트\n",
      "007815 코리아써우\n",
      "007820 에스엠코어\n",
      "007860 서연\n",
      "007980 태평양물산\n",
      "008040 사조동아원\n",
      "008060 대덕전자\n",
      "008110 대동전자\n",
      "008250 이건산업\n",
      "008260 NI스틸\n",
      "008290 원풍물산\n",
      "008350 남선알미늄\n",
      "008355 남선알미우\n",
      "008370 원풍\n",
      "008420 문배철강\n",
      "008470 부스타\n",
      "008490 서흥\n",
      "008500 일정실업\n",
      "008560 메리츠종금증권\n",
      "008600 윌비스\n",
      "008700 아남전자\n",
      "008730 율촌화학\n",
      "008770 호텔신라\n",
      "008775 호텔신라우\n",
      "008800 행남사\n",
      "008830 대동기어\n",
      "008870 금비\n",
      "008930 한미사이언스\n",
      "008970 동양철관\n",
      "009070 KCTC\n",
      "009140 경인전자\n",
      "009150 삼성전기\n",
      "009155 삼성전기우\n",
      "009160 SIMPAC\n",
      "009180 한솔로지스틱스\n",
      "009190 대양금속\n",
      "009200 무림페이퍼\n",
      "009240 한샘\n",
      "009270 신원\n",
      "009275 신원우\n",
      "009290 광동제약\n",
      "009300 삼아제약\n",
      "009310 참엔지니어링\n",
      "009320 대우부품\n",
      "009410 태영건설\n",
      "009415 태영건설우\n",
      "009420 한올바이오파마\n",
      "009440 KC그린홀딩스\n",
      "009450 경동나비엔\n",
      "009460 한창제지\n",
      "009470 삼화전기\n",
      "009520 포스코엠텍\n",
      "009540 한국조선해양\n",
      "009580 무림P&P\n",
      "009620 삼보산업\n",
      "009680 모토닉\n",
      "009730 코센\n",
      "009770 삼정펄프\n",
      "009780 엠에스씨\n",
      "009810 엔케이물산\n",
      "009830 한화솔루션\n",
      "009835 한화솔루션우\n",
      "009970 영원무역홀딩스\n",
      "010040 한국내화\n",
      "010050 우리종금\n",
      "010060 OCI\n",
      "010100 한국프랜지\n",
      "010120 LS산전\n",
      "010130 고려아연\n",
      "010140 삼성중공업\n",
      "010145 삼성중공우\n",
      "010170 대한광통신\n",
      "010240 흥국\n",
      "010280 쌍용정보통신\n",
      "010400 우진아이엔에스\n",
      "010420 한솔PNS\n",
      "010470 오리콤\n",
      "010580 지코\n",
      "010600 웰바이오텍\n",
      "010620 현대미포조선\n",
      "010640 진양폴리\n",
      "010660 화천기계\n",
      "010690 화신\n",
      "010770 평화홀딩스\n",
      "010780 아이에스동서\n",
      "010820 퍼스텍\n",
      "010950 S-Oil\n",
      "010955 S-Oil우\n",
      "010960 삼호개발\n",
      "011000 진원생명과학\n",
      "011040 경동제약\n",
      "011070 LG이노텍\n",
      "011080 형지I&C\n",
      "011090 에넥스\n",
      "011150 CJ씨푸드\n",
      "011155 CJ씨푸드1우\n",
      "011160 두산건설\n",
      "011170 롯데케미칼\n",
      "011200 현대상선\n",
      "011210 현대위아\n",
      "011230 삼화전자\n",
      "011280 태림포장\n",
      "011300 성안\n",
      "011320 유니크\n",
      "011330 유니켐\n",
      "011370 서한\n",
      "011390 부산산업\n",
      "011420 갤럭시아에스엠\n",
      "011500 한농화성\n",
      "011560 세보엠이씨\n",
      "011690 유양디앤유\n",
      "011700 한신기계\n",
      "011760 현대상사\n",
      "011780 금호석유\n",
      "011785 금호석유우\n",
      "011790 SKC\n",
      "011810 STX\n",
      "011930 신성이엔지\n",
      "012030 DB\n",
      "012160 영흥철강\n",
      "012170 키위미디어그룹\n",
      "012200 계양전기\n",
      "012205 계양전기우\n",
      "012280 영화금속\n",
      "012320 경동인베스트\n",
      "012330 현대모비스\n",
      "012340 뉴인텍\n",
      "012450 한화에어로스페이스\n",
      "012510 더존비즈온\n",
      "012600 청호컴넷\n",
      "012610 경인양행\n",
      "012620 원일특강\n",
      "012630 HDC\n",
      "012690 모나리자\n",
      "012700 리드코프\n",
      "012750 에스원\n",
      "012790 신일제약\n",
      "012800 대창\n",
      "012860 모베이스전자\n",
      "013000 세우글로벌\n",
      "013030 하이록코리아\n",
      "013120 동원개발\n",
      "013310 아진산업\n",
      "013360 일성건설\n",
      "013520 화승알앤에이\n",
      "013570 디와이\n",
      "013580 계룡건설\n",
      "013700 까뮤이앤씨\n",
      "013720 청보산업\n",
      "013810 스페코\n",
      "013870 지엠비코리아\n",
      "013890 지누스\n",
      "013990 아가방컴퍼니\n",
      "014100 메디앙스\n",
      "014130 한익스프레스\n",
      "014160 대영포장\n",
      "014190 원익큐브\n",
      "014200 광림\n",
      "014280 금강공업\n",
      "014285 금강공업우\n",
      "014440 영보화학\n",
      "014470 부방\n",
      "014530 극동유화\n",
      "014570 고려제약\n",
      "014580 백광소재\n",
      "014620 성광벤드\n",
      "014680 한솔케미칼\n",
      "014710 사조씨푸드\n",
      "014790 한라\n",
      "014820 동원시스템즈\n",
      "014825 동원시스템즈우\n",
      "014830 유니드\n",
      "014910 성문전자\n",
      "014915 성문전자우\n",
      "014940 오리엔탈정공\n",
      "014970 삼륭물산\n",
      "014990 인디에프\n",
      "015020 이스타코\n",
      "015230 대창단조\n",
      "015260 에이엔피\n",
      "015350 부산가스\n",
      "015360 예스코홀딩스\n",
      "015540 쎌마테라퓨틱스\n",
      "015590 큐로\n",
      "015710 코콤\n",
      "015750 성우하이텍\n",
      "015760 한국전력\n",
      "015860 일진홀딩스\n",
      "015890 태경산업\n",
      "016090 대현\n",
      "016100 리더스코스메틱\n",
      "016250 이테크건설\n",
      "016360 삼성증권\n",
      "016380 동부제철\n",
      "016385 동부제철우\n",
      "016450 한세예스24홀딩스\n",
      "016580 환인제약\n",
      "016590 신대양제지\n",
      "016600 큐캐피탈\n",
      "016610 DB금융투자\n",
      "016670 포비스티앤씨\n",
      "016710 대성홀딩스\n",
      "016740 두올\n",
      "016790 현대사료\n",
      "016800 퍼시스\n",
      "016880 웅진\n",
      "016920 카스\n",
      "017000 신원종합개발\n",
      "017040 광명전기\n",
      "017180 명문제약\n",
      "017250 인터엠\n",
      "017370 우신시스템\n",
      "017390 서울가스\n",
      "017480 삼현철강\n",
      "017510 세명전기\n",
      "017550 수산중공업\n",
      "017650 대림제지\n",
      "017670 SK텔레콤\n",
      "017800 현대엘리베이\n",
      "017810 풀무원\n",
      "017890 한국알콜\n",
      "017900 광전자\n",
      "017940 E1\n",
      "017960 한국카본\n",
      "018000 유니슨\n",
      "018120 진로발효\n",
      "018250 애경산업\n",
      "018260 삼성에스디에스\n",
      "018290 브이티지엠피\n",
      "018310 삼목에스폼\n",
      "018470 조일알미늄\n",
      "018500 동원금속\n",
      "018620 우진비앤지\n",
      "018670 SK가스\n",
      "018680 서울제약\n",
      "018700 바른손\n",
      "018880 한온시스템\n",
      "019010 베뉴지\n",
      "019170 신풍제약\n",
      "019175 신풍제약우\n",
      "019180 티에이치엔\n",
      "019210 와이지-원\n",
      "019440 세아특수강\n",
      "019490 하이트론\n",
      "019540 일지테크\n",
      "019550 SBI인베스트먼트\n",
      "019570 리더스 기술투자\n",
      "019590 엠벤처투자\n",
      "019660 글로본\n",
      "019680 대교\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "019685 대교우B\n",
      "019770 서연탑메탈\n",
      "019990 에너토크\n",
      "020000 한섬\n",
      "020120 키다리스튜디오\n",
      "020150 일진머티리얼즈\n",
      "020180 대신정보통신\n",
      "020400 대동금속\n",
      "020560 아시아나항공\n",
      "020710 시공테크\n",
      "020760 일진디스플\n",
      "021040 대호피앤씨\n",
      "021045 대호피앤씨우\n",
      "021050 서원\n",
      "021080 에이티넘인베스트\n",
      "021240 코웨이\n",
      "021320 KCC건설\n",
      "021650 한국큐빅\n",
      "021820 세원정공\n",
      "021880 메이슨캐피탈\n",
      "022100 포스코 ICT\n",
      "022220 정산애강\n",
      "023000 삼원강재\n",
      "023150 MH에탄올\n",
      "023160 태광\n",
      "023350 한국종합기술\n",
      "023410 유진기업\n",
      "023440 제일제강\n",
      "023450 동남합성\n",
      "023460 CNH\n",
      "023530 롯데쇼핑\n",
      "023590 다우기술\n",
      "023600 삼보판지\n",
      "023760 한국캐피탈\n",
      "023770 플레이위드\n",
      "023790 동일철강\n",
      "023800 인지컨트롤스\n",
      "023810 인팩\n",
      "023890 한국아트라스비엑스\n",
      "023900 풍국주정\n",
      "023910 대한약품\n",
      "023960 에쓰씨엔지니어링\n",
      "024060 흥구석유\n",
      "024070 WISCOM\n",
      "024090 디씨엠\n",
      "024110 기업은행\n",
      "024120 KB오토시스\n",
      "024720 한국콜마홀딩스\n",
      "024740 한일단조\n",
      "024800 유성티엔에스\n",
      "024810 이화전기\n",
      "024830 세원물산\n",
      "024840 KBI메탈\n",
      "024850 피에스엠씨\n",
      "024880 케이피에프\n",
      "024890 대원화성\n",
      "024900 덕양산업\n",
      "024910 경창산업\n",
      "024940 PN풍년\n",
      "024950 삼천리자전거\n",
      "025000 KPX케미칼\n",
      "025320 시노펙스\n",
      "025440 대성엘텍\n",
      "025530 SJM홀딩스\n",
      "025540 한국단자\n",
      "025550 한국선재\n",
      "025560 미래산업\n",
      "025620 제이준코스메틱\n",
      "025750 한솔홈데코\n",
      "025770 한국정보통신\n",
      "025820 이구산업\n",
      "025860 남해화학\n",
      "025870 신라에스지\n",
      "025880 케이씨피드\n",
      "025890 한국주강\n",
      "025900 동화기업\n",
      "025950 동신건설\n",
      "025980 아난티\n",
      "026040 제이에스티나\n",
      "026150 특수건설\n",
      "026890 디피씨\n",
      "026910 광진실업\n",
      "026940 부국철강\n",
      "026960 동서\n",
      "027040 서울전자통신\n",
      "027050 코리아나\n",
      "027360 아주IB투자\n",
      "027390 한화갤러리아타임월드\n",
      "027410 BGF\n",
      "027580 상보\n",
      "027710 팜스토리\n",
      "027740 마니커\n",
      "027830 대성창투\n",
      "027970 세하\n",
      "028040 미래SCI\n",
      "028050 삼성엔지니어링\n",
      "028080 휴맥스홀딩스\n",
      "028100 동아지질\n",
      "028150 GS홈쇼핑\n",
      "028260 삼성물산\n",
      "028300 에이치엘비\n",
      "028670 팬오션\n",
      "029460 케이씨\n",
      "029480 바른테크놀로지\n",
      "029530 신도리코\n",
      "029780 삼성카드\n",
      "029960 코엔텍\n",
      "030000 제일기획\n",
      "030190 NICE평가정보\n",
      "030200 KT\n",
      "030210 KTB투자증권\n",
      "030270 에스마크\n",
      "030350 드래곤플라이\n",
      "030520 한글과컴퓨터\n",
      "030530 원익홀딩스\n",
      "030610 교보증권\n",
      "030720 동원수산\n",
      "030790 동양네트웍스\n",
      "030960 양지사\n",
      "031310 아이즈비전\n",
      "031330 에스에이엠티\n",
      "031390 녹십자셀\n",
      "031430 신세계인터내셔날\n",
      "031440 신세계푸드\n",
      "031510 오스템\n",
      "031820 콤텍시스템\n",
      "031860 엔에스엔\n",
      "031980 피에스케이홀딩스\n",
      "032080 아즈텍WB\n",
      "032190 다우데이타\n",
      "032280 삼일\n",
      "032350 롯데관광개발\n",
      "032500 케이엠더블유\n",
      "032540 TJ미디어\n",
      "032560 황금에스티\n",
      "032580 피델릭스\n",
      "032620 유비케어\n",
      "032640 LG유플러스\n",
      "032680 소프트센\n",
      "032685 소프트센우\n",
      "032750 삼진\n",
      "032790 엠젠플러스\n",
      "032800 판타지오\n",
      "032820 우리기술\n",
      "032830 삼성생명\n",
      "032850 비트컴퓨터\n",
      "032860 글로스퍼랩스\n",
      "032940 원익\n",
      "032960 동일기연\n",
      "032980 바이온\n",
      "033050 제이엠아이\n",
      "033100 제룡전기\n",
      "033110 코너스톤네트웍스\n",
      "033130 디지틀조선\n",
      "033160 엠케이전자\n",
      "033170 시그네틱스\n",
      "033180 필룩스\n",
      "033200 모아텍\n",
      "033230 인성정보\n",
      "033240 자화전자\n",
      "033250 체시스\n",
      "033270 유나이티드제약\n",
      "033290 코웰패션\n",
      "033310 디케이디앤아이\n",
      "033320 제이씨현시스템\n",
      "033340 좋은사람들\n",
      "033430 디에스티\n",
      "033500 동성화인텍\n",
      "033530 세종공업\n",
      "033540 파라텍\n",
      "033560 블루콤\n",
      "033600 럭슬\n",
      "033640 네패스\n",
      "033660 아주캐피탈\n",
      "033780 KT&G\n",
      "033790 스카이문스테크놀로지\n",
      "033830 티비씨\n",
      "033920 무학\n",
      "034020 두산중공업\n",
      "034120 SBS\n",
      "034220 LG디스플레이\n",
      "034230 파라다이스\n",
      "034300 신세계건설\n",
      "034310 NICE\n",
      "034590 인천도시가스\n",
      "034730 SK\n",
      "034810 해성산업\n",
      "034830 한국토지신탁\n",
      "034940 조아제약\n",
      "034950 한국기업평가\n",
      "035000 지투알\n",
      "035080 인터파크홀딩스\n",
      "035150 백산\n",
      "035200 프럼파스트\n",
      "035250 강원랜드\n",
      "035290 더블유에프엠\n",
      "035420 NAVER\n",
      "035460 기산텔레콤\n",
      "035510 신세계 I&C\n",
      "035600 KG이니시스\n",
      "035610 솔본\n",
      "035620 바른손이앤에이\n",
      "035720 카카오\n",
      "035760 CJ ENM\n",
      "035810 이지바이오\n",
      "035890 서희건설\n",
      "035900 JYP Ent.\n",
      "036000 예림당\n",
      "036010 아비코전자\n",
      "036030 KTH\n",
      "036090 위지트\n",
      "036120 SCI평가정보\n",
      "036170 라이브파이낸셜\n",
      "036180 영인프런티어\n",
      "036190 금화피에스시\n",
      "036200 유니셈\n",
      "036260 이매진아시아\n",
      "036420 제이콘텐트리\n",
      "036460 한국가스공사\n",
      "036480 대성미생물\n",
      "036490 SK머티리얼즈\n",
      "036530 S&T홀딩스\n",
      "036540 SFA반도체\n",
      "036560 영풍정밀\n",
      "036570 엔씨소프트\n",
      "036580 팜스코\n",
      "036620 버추얼텍\n",
      "036630 세종텔레콤\n",
      "036640 HRS\n",
      "036670 KCI\n",
      "036690 코맥스\n",
      "036710 심텍홀딩스\n",
      "036800 나이스정보통신\n",
      "036810 에프에스티\n",
      "036830 솔브레인\n",
      "036890 진성티이씨\n",
      "036930 주성엔지니어링\n",
      "037030 파워넷\n",
      "037070 파세코\n",
      "037230 한국팩키지\n",
      "037270 YG PLUS\n",
      "037330 인지디스플레\n",
      "037350 성도이엔지\n",
      "037370 EG\n",
      "037400 우리조명\n",
      "037440 희림\n",
      "037460 삼지전자\n",
      "037560 LG헬로비전\n",
      "037710 광주신세계\n",
      "037760 쎄니트\n",
      "037950 엘컴텍\n",
      "038010 제일테크노스\n",
      "038060 루멘스\n",
      "038070 서린바이오\n",
      "038110 에코플라스틱\n",
      "038160 팍스넷\n",
      "038290 마크로젠\n",
      "038340 UCI\n",
      "038390 레드캡투어\n",
      "038460 바이오스마트\n",
      "038500 삼표시멘트\n",
      "038530 골드퍼시픽\n",
      "038540 상상인\n",
      "038620 위즈코프\n",
      "038680 에스넷\n",
      "038870 에코바이오\n",
      "038880 아이에이\n",
      "038950 파인디지털\n",
      "039010 현대통신\n",
      "039020 이건홀딩스\n",
      "039030 이오테크닉스\n",
      "039130 하나투어\n",
      "039200 오스코텍\n",
      "039230 에이아이비트\n",
      "039240 경남스틸\n",
      "039290 인포뱅크\n",
      "039310 세중\n",
      "039340 한국경제TV\n",
      "039420 케이엘넷\n",
      "039440 에스티아이\n",
      "039490 키움증권\n",
      "039560 다산네트웍스\n",
      "039570 HDC아이콘트롤스\n",
      "039610 화성밸브\n",
      "039670 한류타임즈\n",
      "039740 한국정보공학\n",
      "039830 오로라\n",
      "039840 디오\n",
      "039860 나노엔텍\n",
      "039980 리노스\n",
      "040160 누리텔레콤\n",
      "040300 YTN\n",
      "040350 큐로컴\n",
      "040420 정상제이엘에스\n",
      "040610 SG&G\n",
      "040910 아이씨디\n",
      "041020 인프라웨어\n",
      "041140 넥슨지티\n",
      "041190 우리기술투자\n",
      "041440 에버다임\n",
      "041460 한국전자인증\n",
      "041510 에스엠\n",
      "041520 이라이콤\n",
      "041590 젬백스지오\n",
      "041650 상신브레이크\n",
      "041830 인바디\n",
      "041910 에스텍파마\n",
      "041920 메디아나\n",
      "041930 동아화성\n",
      "041960 코미팜\n",
      "042000 카페24\n",
      "042040 케이피엠테크\n",
      "042110 에스씨디\n",
      "042370 비츠로테크\n",
      "042420 네오위즈홀딩스\n",
      "042500 링네트\n",
      "042510 라온시큐어\n",
      "042520 한스바이오메드\n",
      "042600 새로닉스\n",
      "042660 대우조선해양\n",
      "042670 두산인프라코어\n",
      "042700 한미반도체\n",
      "042940 상지카일룸\n",
      "043090 큐브앤컴퍼니\n",
      "043100 솔고바이오\n",
      "043150 바텍\n",
      "043200 파루\n",
      "043220 에이치엘비파워\n",
      "043260 성호전자\n",
      "043290 케이맥\n",
      "043340 에쎈테크\n",
      "043360 디지아이\n",
      "043370 평화정공\n",
      "043590 크로바하이텍\n",
      "043610 지니뮤직\n",
      "043650 국순당\n",
      "043710 서울리거\n",
      "043910 자연과환경\n",
      "044060 조광ILI\n",
      "044180 KD\n",
      "044340 위닉스\n",
      "044380 주연테크\n",
      "044450 KSS해운\n",
      "044480 바이오제네틱스\n",
      "044490 태웅\n",
      "044780 에이치케이\n",
      "044820 코스맥스비티아이\n",
      "044960 이글벳\n",
      "045060 오공\n",
      "045100 한양이엔지\n",
      "045300 성우테크론\n",
      "045340 토탈소프트\n",
      "045390 대아티아이\n",
      "045510 정원엔시스\n",
      "045520 크린앤사이언스\n",
      "045660 에이텍\n",
      "045890 GV\n",
      "045970 코아시아\n",
      "046070 코다코\n",
      "046110 한일네트웍스\n",
      "046120 오르비텍\n",
      "046140 SBS콘텐츠허브\n",
      "046210 파나진\n",
      "046310 백금T&A\n",
      "046390 삼화네트웍스\n",
      "046440 KG모빌리언스\n",
      "046890 서울반도체\n",
      "046940 우원개발\n",
      "046970 우리로\n",
      "047040 대우건설\n",
      "047050 포스코인터내셔널\n",
      "047080 한빛소프트\n",
      "047310 파워로직스\n",
      "047400 유니온머티리얼\n",
      "047560 이스트소프트\n",
      "047770 코데즈컴바인\n",
      "047810 한국항공우주\n",
      "047820 초록뱀\n",
      "047920 메디포럼제약\n",
      "048260 오스템임플란트\n",
      "048410 현대바이오\n",
      "048430 유라테크\n",
      "048470 대동스틸\n",
      "048530 인트론바이오\n",
      "048550 SM C&C\n",
      "048770 TPC\n",
      "048830 엔피케이\n",
      "048870 시너지이노베이션\n",
      "048910 대원미디어\n",
      "049070 인탑스\n",
      "049080 기가레인\n",
      "049120 파인디앤씨\n",
      "049180 셀루메드\n",
      "049430 코메론\n",
      "049470 SGA\n",
      "049480 오픈베이스\n",
      "049520 유아이엘\n",
      "049550 잉크테크\n",
      "049630 재영솔루텍\n",
      "049720 고려신용정보\n",
      "049770 동원F&B\n",
      "049800 우진플라임\n",
      "049830 승일\n",
      "049950 미래컴퍼니\n",
      "049960 쎌바이오텍\n",
      "050090 휘닉스소재\n",
      "050110 캠시스\n",
      "050120 라이브플렉스\n",
      "050320 에이앤티앤\n",
      "050540 한국코퍼레이션\n",
      "050760 에스폴리텍\n",
      "050860 아세아텍\n",
      "050890 쏠리드\n",
      "050960 수산아이앤티\n",
      "051160 지어소프트\n",
      "051360 토비스\n",
      "051370 인터플렉스\n",
      "051380 피씨디렉트\n",
      "051390 YW\n",
      "051490 나라엠앤디\n",
      "051500 CJ프레시웨이\n",
      "051600 한전KPS\n",
      "051630 진양화학\n",
      "051780 큐로홀딩스\n",
      "051900 LG생활건강\n",
      "051905 LG생활건강우\n",
      "051910 LG화학\n",
      "051915 LG화학우\n",
      "051980 센트럴바이오\n",
      "052020 에스티큐브\n",
      "052190 이에스에이\n",
      "052220 iMBC\n",
      "052260 SK바이오랜드\n",
      "052300 W홀딩컴퍼니\n",
      "052330 코텍\n",
      "052400 코나아이\n",
      "052420 오성첨단소재\n",
      "052460 아이크래프트\n",
      "052600 한네트\n",
      "052670 제일바이오\n",
      "052690 한전기술\n",
      "052710 아모텍\n",
      "052770 와이디온라인\n",
      "052790 액토즈소프트\n",
      "052860 아이앤씨\n",
      "052900 KMH하이텍\n",
      "053030 바이넥스\n",
      "053050 지에스이\n",
      "053060 세동\n",
      "053110 소리바다\n",
      "053160 프리엠스\n",
      "053210 스카이라이프\n",
      "053260 금강철강\n",
      "053270 구영테크\n",
      "053280 예스24\n",
      "053290 NE능률\n",
      "053300 한국정보인증\n",
      "053350 이니텍\n",
      "053450 세코닉스\n",
      "053580 웹케시\n",
      "053590 한국테크놀로지\n",
      "053610 프로텍\n",
      "053620 태양\n",
      "053660 현진소재\n",
      "053690 한미글로벌\n",
      "053700 삼보모터스\n",
      "053800 안랩\n",
      "053950 경남제약\n",
      "053980 오상자이엘\n",
      "054040 한국컴퓨터\n",
      "054050 농우바이오\n",
      "054090 삼진엘앤디\n",
      "054180 중앙오션\n",
      "054210 이랜텍\n",
      "054220 비츠로시스\n",
      "054300 팬스타엔터프라이즈\n",
      "054340 피앤텔\n",
      "054410 케이피티유\n",
      "054450 텔레칩스\n",
      "054540 삼영엠텍\n",
      "054620 APS홀딩스\n",
      "054630 에이디칩스\n",
      "054670 대한뉴팜\n",
      "054780 키이스트\n",
      "054800 아이디스홀딩스\n",
      "054920 한컴위드\n",
      "054930 유신\n",
      "054940 엑사이엔씨\n",
      "054950 제이브이엠\n",
      "055490 테이팩스\n",
      "055550 신한지주\n",
      "056000 네스엠\n",
      "056080 유진로봇\n",
      "056090 유앤아이\n",
      "056190 에스에프에이\n",
      "056360 코위버\n",
      "056700 신화인터텍\n",
      "056730 포스링크\n",
      "057030 YBM넷\n",
      "057050 현대홈쇼핑\n",
      "057500 SKC 솔믹스\n",
      "057540 옴니시스템\n",
      "057680 옴니텔\n",
      "057880 필로시스헬스케어\n",
      "058110 멕아이씨에스\n",
      "058220 아리온\n",
      "058400 KNN\n",
      "058420 제이웨이\n",
      "058430 포스코강판\n",
      "058450 일야\n",
      "058470 리노공업\n",
      "058530 슈펙스비앤피\n",
      "058610 에스피지\n",
      "058630 엠게임\n",
      "058650 세아홀딩스\n",
      "058730 다스코\n",
      "058820 CMG제약\n",
      "058850 KTcs\n",
      "058860 KTis\n",
      "059090 미코\n",
      "059100 아이컴포넌트\n",
      "059120 아진엑스텍\n",
      "059210 메타바이오메드\n",
      "060150 인선이엔티\n",
      "060230 이그잭스\n",
      "060240 룽투코리아\n",
      "060250 NHN한국사이버결제\n",
      "060260 뉴보텍\n",
      "060280 큐렉소\n",
      "060300 레드로버\n",
      "060310 3S\n",
      "060370 KT서브마린\n",
      "060380 동양에스텍\n",
      "060480 국일신동\n",
      "060540 에스에이티\n",
      "060560 홈센타홀딩스\n",
      "060570 드림어스컴퍼니\n",
      "060590 씨티씨바이오\n",
      "060720 KH바텍\n",
      "060900 케이알피앤이\n",
      "060980 한라홀딩스\n",
      "061040 알에프텍\n",
      "061250 화일약품\n",
      "061970 엘비세미콘\n",
      "062860 티엘아이\n",
      "062970 피피아이\n",
      "063080 게임빌\n",
      "063160 종근당바이오\n",
      "063170 서울옥션\n",
      "063440 SM Life Design\n",
      "063570 한국전자금융\n",
      "063760 이엘피\n",
      "064090 에프앤리퍼블릭\n",
      "064240 홈캐스트\n",
      "064260 다날\n",
      "064290 인텍플러스\n",
      "064350 현대로템\n",
      "064480 브리지텍\n",
      "064510 에코마이스터\n",
      "064520 바른전자\n",
      "064550 바이오니아\n",
      "064760 티씨케이\n",
      "064800 필링크\n",
      "064820 케이프\n",
      "064960 S&T모티브\n",
      "065060 지엔코\n",
      "065130 탑엔지니어링\n",
      "065150 MP그룹\n",
      "065170 넥스트BT\n",
      "065350 신성델타테크\n",
      "065370 위세아이텍\n",
      "065420 에스아이리소스\n",
      "065440 이루온\n",
      "065450 빅텍\n",
      "065500 오리엔트정공\n",
      "065510 휴비츠\n",
      "065530 전파기지국\n",
      "065560 녹원씨엔아이\n",
      "065570 삼영이엔씨\n",
      "065620 제낙스\n",
      "065650 메디프론\n",
      "065660 안트로젠\n",
      "065680 우주일렉트로\n",
      "065690 파커스\n",
      "065710 서호전기\n",
      "065770 CS\n",
      "065940 바이오빌\n",
      "065950 웰크론\n",
      "066110 한프\n",
      "066130 하츠\n",
      "066310 큐에스아이\n",
      "066360 체리부로\n",
      "066410 버킷스튜디오\n",
      "066430 와이오엠\n",
      "066570 LG전자\n",
      "066575 LG전자우\n",
      "066590 우수AMS\n",
      "066620 국보디자인\n",
      "066670 디스플레이텍\n",
      "066700 테라젠이텍스\n",
      "066790 씨씨에스\n",
      "066900 디에이피\n",
      "066910 손오공\n",
      "066970 엘앤에프\n",
      "066980 브레인콘텐츠\n",
      "067000 조이시티\n",
      "067010 이씨에스\n",
      "067080 대화제약\n",
      "067160 아프리카TV\n",
      "067170 오텍\n",
      "067280 멀티캠퍼스\n",
      "067290 JW신약\n",
      "067310 하나마이크론\n",
      "067390 아스트\n",
      "067570 엔브이에이치코리아\n",
      "067630 에이치엘비생명과학\n",
      "067730 로지시스\n",
      "067770 세진티에스\n",
      "067830 세이브존I&C\n",
      "067900 와이엔텍\n",
      "067920 이글루시큐리티\n",
      "067990 도이치모터스\n",
      "068050 팬엔터테인먼트\n",
      "068240 다원시스\n",
      "068270 셀트리온\n",
      "068290 삼성출판사\n",
      "068330 일신바이오\n",
      "068400 SK렌터카\n",
      "068760 셀트리온제약\n",
      "068790 DMS\n",
      "068930 디지털대성\n",
      "068940 아이씨케이\n",
      "069080 웹젠\n",
      "069110 코스온\n",
      "069140 누리플랜\n",
      "069260 휴켐스\n",
      "069330 유아이디\n",
      "069410 엔텔스\n",
      "069460 대호에이엘\n",
      "069510 에스텍\n",
      "069540 라이트론\n",
      "069620 대웅제약\n",
      "069640 한세엠케이\n",
      "069730 DSR제강\n",
      "069920 아이에스이커머스\n",
      "069960 현대백화점\n",
      "070300 한솔시큐어\n",
      "070590 한솔인티큐브\n",
      "070960 용평리조트\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "071050 한국금융지주\n",
      "071055 한국금융지주우\n",
      "071090 하이스틸\n",
      "071200 인피니트헬스케어\n",
      "071280 로체시스템즈\n",
      "071320 지역난방공사\n",
      "071460 위니아딤채\n",
      "071670 에이테크솔루션\n",
      "071840 롯데하이마트\n",
      "071850 캐스텍코리아\n",
      "071950 코아스\n",
      "071970 STX중공업\n",
      "072020 중앙백신\n",
      "072130 유엔젤\n",
      "072470 우리산업홀딩스\n",
      "072520 제넨바이오\n",
      "072710 농심홀딩스\n",
      "072770 율호\n",
      "072870 메가스터디\n",
      "072950 빛샘전자\n",
      "072990 에이치시티\n",
      "073010 케이에스피\n",
      "073070 에스모\n",
      "073110 엘엠에스\n",
      "073190 듀오백\n",
      "073240 금호타이어\n",
      "073490 이노와이어리스\n",
      "073540 에프알텍\n",
      "073560 우리손에프앤지\n",
      "073570 WI\n",
      "073640 삼원테크\n",
      "074430 아미노로직스\n",
      "074600 원익QnC\n",
      "074610 나노메딕스\n",
      "075130 플랜티넷\n",
      "075180 새론오토모티브\n",
      "075580 세진중공업\n",
      "075970 동국알앤에스\n",
      "076080 웰크론한텍\n",
      "076610 해성옵틱스\n",
      "077360 덕산하이메탈\n",
      "077500 유니퀘스트\n",
      "077970 STX엔진\n",
      "078000 텔코웨어\n",
      "078020 이베스트투자증권\n",
      "078070 유비쿼스홀딩스\n",
      "078130 국일제지\n",
      "078140 대봉엘에스\n",
      "078150 HB테크놀러지\n",
      "078160 메디포스트\n",
      "078340 컴투스\n",
      "078350 한양디지텍\n",
      "078520 에이블씨엔씨\n",
      "078590 두올산업\n",
      "078600 대주전자재료\n",
      "078650 코렌\n",
      "078860 아이오케이\n",
      "078890 가온미디어\n",
      "078930 GS\n",
      "078935 GS우\n",
      "078940 코드네이처\n",
      "079000 와토스코리아\n",
      "079160 CJ CGV\n",
      "079170 한창산업\n",
      "079190 EMW\n",
      "079370 제우스\n",
      "079430 현대리바트\n",
      "079550 LIG넥스원\n",
      "079650 서산\n",
      "079810 디이엔티\n",
      "079940 가비아\n",
      "079950 인베니아\n",
      "079960 동양이엔피\n",
      "079970 투비소프트\n",
      "079980 휴비스\n",
      "080000 에스엔유\n",
      "080010 이상네트웍스\n",
      "080160 모두투어\n",
      "080220 제주반도체\n",
      "080420 모다이노칩\n",
      "080440 에스제이케이\n",
      "080470 성창오토텍\n",
      "080520 오디텍\n",
      "080530 코디\n",
      "080580 오킨스전자\n",
      "080720 한국유니온제약\n",
      "081000 일진다이아\n",
      "081150 티플랙스\n",
      "081580 성우전자\n",
      "081660 휠라코리아\n",
      "082210 옵트론텍\n",
      "082270 젬백스\n",
      "082640 동양생명\n",
      "082660 코스나인\n",
      "082740 HSD엔진\n",
      "082800 루미마이크로\n",
      "082850 우리바이오\n",
      "082920 비츠로셀\n",
      "083310 엘오티베큠\n",
      "083370 동북아12호\n",
      "083380 동북아13호\n",
      "083420 그린케미칼\n",
      "083450 GST\n",
      "083470 KJ프리텍\n",
      "083500 에프엔에스테크\n",
      "083550 케이엠\n",
      "083640 인콘\n",
      "083650 비에이치아이\n",
      "083660 CSA 코스믹\n",
      "083790 크리스탈\n",
      "083930 아바코\n",
      "084010 대한제강\n",
      "084110 휴온스글로벌\n",
      "084180 수성\n",
      "084370 유진테크\n",
      "084650 랩지노믹스\n",
      "084670 동양고속\n",
      "084680 이월드\n",
      "084690 대상홀딩스\n",
      "084695 대상홀딩스우\n",
      "084730 팅크웨어\n",
      "084850 아이티엠반도체\n",
      "084870 TBH글로벌\n",
      "084990 헬릭스미스\n",
      "085310 엔케이\n",
      "085370 루트로닉\n",
      "085620 미래에셋생명\n",
      "085660 차바이오텍\n",
      "085670 뉴프렉스\n",
      "085810 알티캐스트\n",
      "085910 네오티스\n",
      "086040 바이오톡스텍\n",
      "086060 진바이오텍\n",
      "086250 이노와이즈\n",
      "086280 현대글로비스\n",
      "086390 유니테스트\n",
      "086450 동국제약\n",
      "086520 에코프로\n",
      "086670 비엠티\n",
      "086790 하나금융지주\n",
      "086820 바이오솔루션\n",
      "086890 이수앱지스\n",
      "086900 메디톡스\n",
      "086960 한컴MDS\n",
      "086980 쇼박스\n",
      "087010 펩트론\n",
      "087260 모바일어플라이언스\n",
      "087600 픽셀플러스\n",
      "087730 에스모 머티리얼즈\n",
      "088130 동아엘텍\n",
      "088260 이리츠코크렙\n",
      "088290 이원컴포텍\n",
      "088350 한화생명\n",
      "088390 이녹스\n",
      "088790 진도\n",
      "088800 에이스테크\n",
      "088910 동우팜투테이블\n",
      "088980 맥쿼리인프라\n",
      "089010 켐트로닉스\n",
      "089030 테크윙\n",
      "089140 넥스턴\n",
      "089150 케이씨티\n",
      "089230 THE E&M\n",
      "089470 HDC현대EP\n",
      "089530 에이티세미콘\n",
      "089590 제주항공\n",
      "089600 나스미디어\n",
      "089790 제이티\n",
      "089850 유비벨록스\n",
      "089890 코세스\n",
      "089970 에이피티씨\n",
      "089980 상아프론테크\n",
      "090080 평화산업\n",
      "090150 광진윈텍\n",
      "090350 노루페인트\n",
      "090355 노루페인트우\n",
      "090360 로보스타\n",
      "090370 메타랩스\n",
      "090410 덕신하우징\n",
      "090430 아모레퍼시픽\n",
      "090435 아모레퍼시픽우\n",
      "090460 비에이치\n",
      "090470 제이스텍\n",
      "090710 휴림로봇\n",
      "090740 아이엠이연이\n",
      "090850 이지웰페어\n",
      "091090 세원셀론텍\n",
      "091120 이엠텍\n",
      "091340 S&K폴리텍\n",
      "091440 텔레필드\n",
      "091580 상신이디피\n",
      "091590 남화토건\n",
      "091700 파트론\n",
      "091810 티웨이항공\n",
      "091970 나노캠텍\n",
      "091990 셀트리온헬스케어\n",
      "092040 아미코젠\n",
      "092070 디엔에프\n",
      "092130 이크레더블\n",
      "092200 디아이씨\n",
      "092220 KEC\n",
      "092230 KPX홀딩스\n",
      "092300 현우산업\n",
      "092440 기신정기\n",
      "092460 한라IMS\n",
      "092600 앤씨앤\n",
      "092730 네오팜\n",
      "092780 동양피스톤\n",
      "092870 엑시콘\n",
      "093050 LF\n",
      "093190 빅솔론\n",
      "093230 이아이디\n",
      "093240 형지엘리트\n",
      "093320 케이아이엔엑스\n",
      "093370 후성\n",
      "093380 풍강\n",
      "093520 매커스\n",
      "093640 다믈멀티미디어\n",
      "093920 서원인텍\n",
      "094170 동운아나텍\n",
      "094190 이엘케이\n",
      "094280 효성ITX\n",
      "094360 칩스앤미디어\n",
      "094480 갤럭시아컴즈\n",
      "094800 맵스리얼티1\n",
      "094820 일진파워\n",
      "094840 슈프리마에이치큐\n",
      "094850 참좋은여행\n",
      "094860 코닉글로리\n",
      "094940 푸른기술\n",
      "094970 제이엠티\n",
      "095190 이엠코리아\n",
      "095270 웨이브일렉트로\n",
      "095340 ISC\n",
      "095500 미래나노텍\n",
      "095570 AJ네트웍스\n",
      "095610 테스\n",
      "095660 네오위즈\n",
      "095700 제넥신\n",
      "095720 웅진씽크빅\n",
      "095910 에스에너지\n",
      "096040 이트론\n",
      "096240 청담러닝\n",
      "096300 베트남개발1\n",
      "096350 대창솔루션\n",
      "096530 씨젠\n",
      "096610 알에프세미\n",
      "096630 에스코넥\n",
      "096640 멜파스\n",
      "096690 제이스테판\n",
      "096760 JW홀딩스\n",
      "096770 SK이노베이션\n",
      "096775 SK이노베이션우\n",
      "096870 엘디티\n",
      "097230 한진중공업\n",
      "097520 엠씨넥스\n",
      "097780 에스맥\n",
      "097800 윈팩\n",
      "097870 효성오앤비\n",
      "097950 CJ제일제당\n",
      "097955 CJ제일제당 우\n",
      "098120 마이크로컨텍솔\n",
      "098460 고영\n",
      "098660 에스티오\n",
      "099190 아이센스\n",
      "099220 SDN\n",
      "099320 쎄트렉아이\n",
      "099340 하나니켈1호\n",
      "099350 하나니켈2호\n",
      "099410 동방선기\n",
      "099440 스맥\n",
      "099520 ITX엠투엠\n",
      "099750 이지케어텍\n",
      "100030 모바일리더\n",
      "100090 삼강엠앤티\n",
      "100120 뷰웍스\n",
      "100130 동국S&C\n",
      "100220 비상교육\n",
      "100250 진양홀딩스\n",
      "100590 머큐리\n",
      "100660 서암기계공업\n",
      "100700 세운메디칼\n",
      "100790 미래에셋벤처투자\n",
      "100840 S&TC\n",
      "101000 상상인인더스트리\n",
      "101060 SBS미디어홀딩스\n",
      "101140 비티원\n",
      "101160 월덱스\n",
      "101170 우림기계\n",
      "101240 씨큐브\n",
      "101330 모베이스\n",
      "101390 아이엠\n",
      "101400 엔시트론\n",
      "101490 에스앤에스텍\n",
      "101530 해태제과식품\n",
      "101670 코리아에스이\n",
      "101680 한국정밀기계\n",
      "101730 조이맥스\n",
      "101930 인화정공\n",
      "102120 어보브반도체\n",
      "102210 해덕파워웨이\n",
      "102260 동성코퍼레이션\n",
      "102280 쌍방울\n",
      "102460 이연제약\n",
      "102710 이엔에프테크놀로지\n",
      "102940 코오롱생명과학\n",
      "103130 웅진에너지\n",
      "103140 풍산\n",
      "103230 에스앤더블류\n",
      "103590 일진전기\n",
      "103840 우양\n",
      "104040 대성파인텍\n",
      "104200 NHN벅스\n",
      "104460 동양피엔에프\n",
      "104480 티케이케미칼\n",
      "104540 코렌텍\n",
      "104620 노랑풍선\n",
      "104700 한국철강\n",
      "104830 원익머트리얼즈\n",
      "105330 케이엔더블유\n",
      "105550 트루윈\n",
      "105560 KB금융\n",
      "105630 한세실업\n",
      "105740 디케이락\n",
      "105840 우진\n",
      "106080 하이소닉\n",
      "106190 하이텍팜\n",
      "106240 파인테크닉스\n",
      "106520 디지탈옵틱\n",
      "107590 미원홀딩스\n",
      "108230 톱텍\n",
      "108320 실리콘웍스\n",
      "108380 대양전기공업\n",
      "108490 로보티즈\n",
      "108670 LG하우시스\n",
      "108675 LG하우시스우\n",
      "108790 인터파크\n",
      "108860 셀바스AI\n",
      "109070 컨버즈\n",
      "109080 옵티시스\n",
      "109610 에스와이\n",
      "109740 디에스케이\n",
      "109820 진매트릭스\n",
      "109860 동일금속\n",
      "109960 에이프로젠 H&G\n",
      "110020 전진바이오팜\n",
      "110790 크리스에프앤씨\n",
      "110990 디아이티\n",
      "111110 호전실업\n",
      "111710 남화산업\n",
      "111770 영원무역\n",
      "111820 지와이커머스\n",
      "111870 삼본전자\n",
      "112040 위메이드\n",
      "112240 에스에프씨\n",
      "112610 씨에스윈드\n",
      "113810 디젠스\n",
      "114090 GKL\n",
      "114120 크루셜텍\n",
      "114190 강원\n",
      "114450 KPX생명과학\n",
      "114570 지스마트글로벌\n",
      "114630 우노앤컴퍼니\n",
      "114810 아이원스\n",
      "115160 휴맥스\n",
      "115180 큐리언트\n",
      "115310 인포바인\n",
      "115390 락앤락\n",
      "115440 우리넷\n",
      "115450 지트리비앤티\n",
      "115480 씨유메디칼\n",
      "115500 케이씨에스\n",
      "115530 씨엔플러스\n",
      "115570 스타플렉스\n",
      "115610 이미지스\n",
      "115960 연우\n",
      "117580 대성에너지\n",
      "117670 알파홀딩스\n",
      "117730 티로보틱스\n",
      "118000 우리들휴브레인\n",
      "118990 모트렉스\n",
      "119500 포메탈\n",
      "119610 인터로조\n",
      "119650 KC코트렐\n",
      "119830 아이텍\n",
      "119850 지엔씨에너지\n",
      "119860 다나와\n",
      "120030 조선선재\n",
      "120110 코오롱인더\n",
      "120115 코오롱인더우\n",
      "120240 대정화금\n",
      "121440 골프존뉴딘홀딩스\n",
      "121600 나노신소재\n",
      "121800 비덴트\n",
      "121850 코이즈\n",
      "121890 에스디시스템\n",
      "122310 제노레이\n",
      "122350 삼기오토모티브\n",
      "122450 KMH\n",
      "122640 예스티\n",
      "122690 서진오토모티브\n",
      "122870 와이지엔터테인먼트\n",
      "122900 아이마켓코리아\n",
      "122990 와이솔\n",
      "123010 아이에이네트웍스\n",
      "123040 엠에스오토텍\n",
      "123260 파인넥스\n",
      "123330 제닉\n",
      "123410 코리아에프티\n",
      "123420 선데이토즈\n",
      "123570 이엠넷\n",
      "123690 한국화장품\n",
      "123700 SJM\n",
      "123750 알톤스포츠\n",
      "123840 한일진공\n",
      "123860 아나패스\n",
      "123890 한국자산신탁\n",
      "124500 아이티센\n",
      "124560 태웅로직스\n",
      "125210 아모그린텍\n",
      "126560 현대에이치씨엔\n",
      "126600 코프라\n",
      "126640 화신정공\n",
      "126700 하이비젼시스템\n",
      "126870 뉴로스\n",
      "126880 제이엔케이히터\n",
      "127120 디엔에이링크\n",
      "127160 매직마이크로\n",
      "127710 아시아경제\n",
      "128540 에코캡\n",
      "128660 피제이메탈\n",
      "128820 대성산업\n",
      "128940 한미약품\n",
      "129260 인터지스\n",
      "130500 GH신소재\n",
      "130580 나이스디앤비\n",
      "130660 한전산업\n",
      "130740 티피씨글로벌\n",
      "131030 디에이치피코리아\n",
      "131090 시큐브\n",
      "131100 알이피\n",
      "131180 딜리\n",
      "131220 대한과학\n",
      "131290 티에스이\n",
      "131370 알서포트\n",
      "131390 피앤이솔루션\n",
      "131400 액트\n",
      "131760 파인텍\n",
      "131970 테스나\n",
      "133750 메가엠디\n",
      "133820 화인베스틸\n",
      "134060 이퓨쳐\n",
      "134380 미원화학\n",
      "134580 디엠티\n",
      "134780 화진\n",
      "134790 시디즈\n",
      "136480 하림\n",
      "136490 선진\n",
      "136510 쎄미시스코\n",
      "136540 윈스\n",
      "137400 피엔티\n",
      "137940 넥스트아이\n",
      "137950 제이씨케미칼\n",
      "138040 메리츠금융지주\n",
      "138070 신진에스엠\n",
      "138080 오이솔루션\n",
      "138250 엔에스쇼핑\n",
      "138360 에이씨티\n",
      "138490 코오롱플라스틱\n",
      "138580 비즈니스온\n",
      "138610 나이벡\n",
      "138690 엘아이에스\n",
      "138930 BNK금융지주\n",
      "139050 데일리블록체인\n",
      "139130 DGB금융지주\n",
      "139480 이마트\n",
      "139670 키네마스터\n",
      "140070 서플러스글로벌\n",
      "140410 메지온\n",
      "140520 대창스틸\n",
      "140670 알에스오토메이션\n",
      "140860 파크시스템스\n",
      "140910 에이리츠\n",
      "141000 비아트론\n",
      "141020 포티스\n",
      "141070 맥스로텍\n",
      "141080 레고켐바이오\n",
      "142210 유니트론텍\n",
      "142280 녹십자엠에스\n",
      "142760 바이오리더스\n",
      "143160 아이디스\n",
      "143210 핸즈코퍼레이션\n",
      "143240 사람인에이치알\n",
      "143540 영우디에스피\n",
      "144510 녹십자랩셀\n",
      "144620 코오롱머티리얼\n",
      "144960 뉴파워프라즈마\n",
      "145020 휴젤\n",
      "145210 세화아이엠씨\n",
      "145270 케이탑리츠\n",
      "145720 덴티움\n",
      "145990 삼양사\n",
      "145995 삼양사우\n",
      "147760 마이크로프랜드\n",
      "147830 제룡산업\n",
      "148140 비디아이\n",
      "148150 세경하이테크\n",
      "148250 알엔투테크놀로지\n",
      "149940 모다\n",
      "149950 아바텍\n",
      "149980 하이로닉\n",
      "150840 인트로메딕\n",
      "150900 파수닷컴\n",
      "151860 KG ETS\n",
      "151910 나노스\n",
      "152330 코리아오토글라스\n",
      "152550 한국ANKOR유전\n",
      "153360 하이골드3호\n",
      "153460 네이블\n",
      "153490 우리이앤엘\n",
      "153710 옵티팜\n",
      "154030 아시아종묘\n",
      "154040 솔루에타\n",
      "155650 와이엠씨\n",
      "155660 DSR\n",
      "155900 바다로19호\n",
      "156100 엘앤케이바이오\n",
      "158310 스타모빌리티\n",
      "158430 아톤\n",
      "159580 제로투세븐\n",
      "159650 하이골드8호\n",
      "159910 스킨앤스킨\n",
      "160550 NEW\n",
      "160600 에스엔텍비엠\n",
      "160980 싸이맥스\n",
      "161000 애경유화\n",
      "161390 한국타이어앤테크놀로지\n",
      "161570 THE MIDONG\n",
      "161580 필옵틱스\n",
      "161890 한국콜마\n",
      "163560 동일고무벨트\n",
      "166090 하나머티리얼즈\n",
      "166480 코아스템\n",
      "168330 내츄럴엔도텍\n",
      "168490 한국패러랠\n",
      "170030 현대공업\n",
      "170790 파이오링크\n",
      "170900 동아에스티\n",
      "170920 엘티씨\n",
      "171010 램테크놀러지\n",
      "171090 선익시스템\n",
      "171120 라이온켐텍\n",
      "172580 하이골드12호\n",
      "173130 오파스넷\n",
      "173940 에프엔씨엔터\n",
      "174880 장원테크\n",
      "174900 앱클론\n",
      "175140 인포마크\n",
      "175250 아이큐어\n",
      "175330 JB금융지주\n",
      "176440 에이치엔티\n",
      "177350 베셀\n",
      "177830 파버나인\n",
      "178320 서진시스템\n",
      "178780 유테크\n",
      "178920 SKC코오롱PI\n",
      "179290 엠아이텍\n",
      "179900 유티아이\n",
      "180400 캔서롭\n",
      "180640 한진칼\n",
      "181340 이즈미디어\n",
      "181710 NHN\n",
      "182360 큐브엔터\n",
      "182400 엔케이맥스\n",
      "182690 테라셈\n",
      "183190 아세아시멘트\n",
      "183300 코미코\n",
      "183490 엔지켐생명과학\n",
      "184230 SGA솔루션즈\n",
      "185490 아이진\n",
      "185750 종근당\n",
      "186230 그린플러스\n",
      "187220 디티앤씨\n",
      "187270 신화콘텍\n",
      "187420 제노포커스\n",
      "187790 나노\n",
      "187870 디바이스이엔지\n",
      "189300 인텔리안테크\n",
      "189690 포시에스\n",
      "189860 서전기전\n",
      "189980 흥국에프엔비\n",
      "190510 나무가\n",
      "190650 코리아에셋투자증권\n",
      "191410 육일씨엔에쓰\n",
      "191420 테고사이언스\n",
      "192080 더블유게임즈\n",
      "192250 케이사인\n",
      "192390 윈하이텍\n",
      "192400 쿠쿠홀딩스\n",
      "192410 감마누\n",
      "192440 슈피겐코리아\n",
      "192650 드림텍\n",
      "192820 코스맥스\n",
      "193250 와이제이엠게임즈\n",
      "194370 제이에스코퍼레이션\n",
      "194480 데브시스터즈\n",
      "194510 파티게임즈\n",
      "194700 노바렉스\n",
      "195440 퓨전\n",
      "195500 마니커에프앤지\n",
      "195870 해성디에스\n",
      "195990 에이비프로바이오\n",
      "196170 알테오젠\n",
      "196300 애니젠\n",
      "196450 디오스텍\n",
      "196490 디에이테크놀로지\n",
      "196700 웹스\n",
      "197140 디지캡\n",
      "197210 리드\n",
      "198440 고려시멘트\n",
      "200130 콜마비앤에이치\n",
      "200230 텔콘RF제약\n",
      "200470 하이셈\n",
      "200670 휴메딕스\n",
      "200710 에이디테크놀로지\n",
      "200780 비씨월드제약\n",
      "200880 서연이화\n",
      "201490 미투온\n",
      "203450 유니온커뮤니티\n",
      "203650 드림시큐리티\n",
      "203690 프로스테믹스\n",
      "204020 그리티\n",
      "204210 모두투어리츠\n",
      "204320 만도\n",
      "204620 글로벌텍스프리\n",
      "204630 화이브라더스코리아\n",
      "204840 지엘팜텍\n",
      "204990 코썬바이오\n",
      "205100 엑셈\n",
      "205470 휴마시스\n",
      "205500 액션스퀘어\n",
      "206400 엔터메이트\n",
      "206560 덱스터\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206640 바디텍메드\n",
      "206650 유바이오로직스\n",
      "207760 미스터블루\n",
      "207940 삼성바이오로직스\n",
      "208140 정다운\n",
      "208340 파멥신\n",
      "208350 지란지교시큐리티\n",
      "208370 셀바스헬스케어\n",
      "208640 썸에이지\n",
      "208710 바이오로그디바이스\n",
      "208860 엔지스테크널러지\n",
      "210540 디와이파워\n",
      "210980 SK디앤디\n",
      "211270 AP위성\n",
      "212560 네오오토\n",
      "213090 미래테크놀로지\n",
      "213420 덕산네오룩스\n",
      "213500 한솔제지\n",
      "214150 클래시스\n",
      "214180 민앤지\n",
      "214260 라파스\n",
      "214270 퓨쳐스트림네트웍스\n",
      "214310 세미콘라이트\n",
      "214320 이노션\n",
      "214330 금호에이치티\n",
      "214370 케어젠\n",
      "214390 경보제약\n",
      "214420 토니모리\n",
      "214430 아이쓰리시스템\n",
      "214450 파마리서치프로덕트\n",
      "214680 디알텍\n",
      "214870 뉴지랩\n",
      "215000 골프존\n",
      "215090 유니맥스글로벌\n",
      "215100 로보로보\n",
      "215200 메가스터디교육\n",
      "215360 우리산업\n",
      "215380 우정바이오\n",
      "215480 토박스코리아\n",
      "215600 신라젠\n",
      "215790 이노인스트루먼트\n",
      "216050 인크로스\n",
      "216080 제테마\n",
      "217190 제너셈\n",
      "217270 넵튠\n",
      "217330 싸이토젠\n",
      "217480 에스디생명공학\n",
      "217500 러셀\n",
      "217600 켐온\n",
      "217620 디딤\n",
      "217730 강스템바이오텍\n",
      "217820 엔에스\n",
      "218150 미래생명자원\n",
      "218410 RFHIC\n",
      "219130 타이거일렉\n",
      "219420 링크제니시스\n",
      "219550 MP한강\n",
      "219750 지티지웰니스\n",
      "220100 퓨쳐켐\n",
      "220180 핸디소프트\n",
      "220260 켐트로스\n",
      "220630 해마로푸드서비스\n",
      "221610 한솔씨앤피\n",
      "221840 하이즈항공\n",
      "221980 케이디켐\n",
      "222040 코스맥스엔비티\n",
      "222080 씨아이에스\n",
      "222110 팬젠\n",
      "222420 쎄노텍\n",
      "222800 심텍\n",
      "222810 한류AI센터\n",
      "222980 한국맥널티\n",
      "223310 이에스브이\n",
      "224060 코디엠\n",
      "224110 에이텍티앤\n",
      "225190 삼양옵틱스\n",
      "225330 씨엠에스에듀\n",
      "225430 케이엠제약\n",
      "225530 보광산업\n",
      "225570 넷게임즈\n",
      "225590 패션플랫폼\n",
      "226320 잇츠한불\n",
      "226330 신테카바이오\n",
      "226340 본느\n",
      "226350 아이엠텍\n",
      "226360 이엑스티\n",
      "226400 오스테오닉\n",
      "226440 한송네오텍\n",
      "226950 올릭스\n",
      "227100 디자인\n",
      "227610 아우딘퓨쳐스\n",
      "227840 현대코퍼레이션홀딩스\n",
      "227950 마이크로텍\n",
      "228340 동양파일\n",
      "228670 레이\n",
      "228760 지노믹트리\n",
      "228850 레이언스\n",
      "229640 LS전선아시아\n",
      "230240 에치에프알\n",
      "230360 에코마케팅\n",
      "230980 솔트웍스\n",
      "232140 와이아이케이\n",
      "234080 JW생명과학\n",
      "234100 세원\n",
      "234300 에스트래픽\n",
      "234340 세틀뱅크\n",
      "234690 녹십자웰빙\n",
      "234920 자이글\n",
      "235980 메드팩토\n",
      "236200 슈프리마\n",
      "237690 에스티팜\n",
      "237750 피앤씨테크\n",
      "237880 클리오\n",
      "238090 앤디포스\n",
      "238120 로고스바이오\n",
      "238200 비피도\n",
      "238490 힘스\n",
      "239340 줌인터넷\n",
      "239610 에이치엘사이언스\n",
      "240810 원익IPS\n",
      "241520 DSC인베스트먼트\n",
      "241560 두산밥캣\n",
      "241590 화승엔터프라이즈\n",
      "241690 유니테크노\n",
      "241710 코스메카코리아\n",
      "241770 메카로\n",
      "241790 오션브릿지\n",
      "241820 피씨엘\n",
      "241840 에이스토리\n",
      "242040 나무기술\n",
      "243070 휴온스\n",
      "243840 신흥에스이씨\n",
      "244460 올리패스\n",
      "245620 EDGC\n",
      "246690 TS인베스트먼트\n",
      "246710 티앤알바이오팹\n",
      "246720 아스타\n",
      "246960 이노테라피\n",
      "247540 에코프로비엠\n",
      "248170 샘표식품\n",
      "249420 일동제약\n",
      "250000 보라티알\n",
      "250060 모비스\n",
      "250930 예선테크\n",
      "251270 넷마블\n",
      "251370 와이엠티\n",
      "251630 브이원텍\n",
      "251970 펌텍코리아\n",
      "252500 세화피앤씨\n",
      "253450 스튜디오드래곤\n",
      "253590 네오셈\n",
      "253840 수젠텍\n",
      "254120 자비스\n",
      "255220 SG\n",
      "255440 야스\n",
      "256150 한독크린텍\n",
      "256630 포인트엔지니어링\n",
      "256840 한국비엔씨\n",
      "256940 케이피에스\n",
      "257370 명성티엔에스\n",
      "258610 이더블유케이\n",
      "258790 소프트캠프\n",
      "258830 세종메디칼\n",
      "259630 엠플러스\n",
      "260660 알리코제약\n",
      "260930 씨티케이코스메틱스\n",
      "261200 하나금융9호스팩\n",
      "263020 디케이앤디\n",
      "263050 유틸렉스\n",
      "263540 샘코\n",
      "263600 덕우전자\n",
      "263690 디알젬\n",
      "263700 케어랩스\n",
      "263720 디앤씨미디어\n",
      "263750 펄어비스\n",
      "263770 유에스티\n",
      "263800 데이타솔루션\n",
      "263810 상신전자\n",
      "263860 지니언스\n",
      "263920 블러썸엠앤씨\n",
      "264450 유비쿼스\n",
      "264660 씨앤지하이테크\n",
      "264850 이랜시스\n",
      "264900 크라운제과\n",
      "265520 AP시스템\n",
      "265560 영화테크\n",
      "267250 현대중공업지주\n",
      "267260 현대일렉트릭\n",
      "267270 현대건설기계\n",
      "267290 경동도시가스\n",
      "267320 교보7호스팩\n",
      "267790 배럴\n",
      "267850 아시아나IDT\n",
      "267980 매일유업\n",
      "268280 미원에스씨\n",
      "268600 셀리버리\n",
      "269620 시스웍\n",
      "270520 하나금융10호스팩\n",
      "270870 뉴트리\n",
      "271560 오리온\n",
      "271740 한국제5호스팩\n",
      "271980 제일약품\n",
      "272110 케이엔제이\n",
      "272210 한화시스템\n",
      "272290 이녹스첨단소재\n",
      "272450 진에어\n",
      "272550 삼양패키징\n",
      "273060 엔에이치스팩12호\n",
      "275630 에스에스알\n",
      "276920 IBKS제7호스팩\n",
      "277070 린드먼아시아\n",
      "277410 인산가\n",
      "277480 신한제4호스팩\n",
      "278280 천보\n",
      "278650 노터스\n",
      "279410 한화에이스스팩4호\n",
      "279600 미디어젠\n",
      "280360 롯데제과\n",
      "281410 한국제6호스팩\n",
      "281740 동부스팩5호\n",
      "281820 케이씨텍\n",
      "282330 BGF리테일\n",
      "282690 동아타이어\n",
      "282880 코윈테크\n",
      "284620 하나금융11호스팩\n",
      "284740 쿠쿠홈시스\n",
      "285130 SK케미칼\n",
      "285490 노바텍\n",
      "286750 나노브릭\n",
      "286940 롯데정보통신\n",
      "287410 유안타제3호스팩\n",
      "288330 브릿지바이오테라퓨틱스\n",
      "288620 에스퓨얼셀\n",
      "289010 아이스크림에듀\n",
      "289080 SV인베스트먼트\n",
      "290120 대유에이피\n",
      "290270 휴네시온\n",
      "290380 대유\n",
      "290510 코리아센터\n",
      "290550 디케이티\n",
      "290650 엘앤씨바이오\n",
      "290660 네오펙트\n",
      "290670 대보마그네틱\n",
      "290720 푸드나무\n",
      "290740 액트로\n",
      "291210 한국제7호스팩\n",
      "291230 삼성스팩2호\n",
      "293480 하나제약\n",
      "293580 나우IB\n",
      "293780 압타바이오\n",
      "293940 신한알파리츠\n",
      "294140 레몬\n",
      "294630 서남\n",
      "294870 HDC현대산업개발\n",
      "297090 씨에스베어링\n",
      "297570 알로이스\n",
      "298000 효성화학\n",
      "298020 효성티앤씨\n",
      "298040 효성중공업\n",
      "298050 효성첨단소재\n",
      "298380 에이비엘바이오\n",
      "298690 에어부산\n",
      "299170 IBKS제10호스팩\n",
      "299660 셀리드\n",
      "299900 위지윅스튜디오\n",
      "299910 베스파\n",
      "300080 플리토\n",
      "300120 라온피플\n",
      "300720 한일시멘트\n",
      "302430 이노메트리\n",
      "302550 리메드\n",
      "303030 지니틱스\n",
      "305090 마이크로디지탈\n",
      "306040 에스제이그룹\n",
      "306200 세아제강\n",
      "306620 네온테크\n",
      "307070 SK4호스팩\n",
      "307160 하나머스트제6호스팩\n",
      "307180 아이엘사이언스\n",
      "307280 교보8호스팩\n",
      "307750 대신밸런스제6호스팩\n",
      "307870 상상인이안1호스팩\n",
      "307930 컴퍼니케이\n",
      "307950 현대오토에버\n",
      "308100 까스텔바작\n",
      "308170 센트랄모텍\n",
      "309930 삼성머스트스팩3호\n",
      "310200 애니플러스\n",
      "310840 엔에이치스팩13호\n",
      "310870 한국제8호스팩\n",
      "311270 키움제5호스팩\n",
      "311390 네오크레마\n",
      "311690 천랩\n",
      "312610 에이에프더블류\n",
      "313750 유안타제4호스팩\n",
      "313760 윌링스\n",
      "316140 우리금융지주\n",
      "317030 케이비17호스팩\n",
      "317120 라닉스\n",
      "317240 하이제4호스팩\n",
      "317320 한화에스비아이스팩\n",
      "317330 덕산테코피아\n",
      "317400 자이에스앤디\n",
      "317530 캐리소프트\n",
      "317770 슈프리마아이디\n",
      "317830 에스피시스템스\n",
      "317850 대모\n",
      "317870 엔바이오니아\n",
      "318000 한국바이오젠\n",
      "318010 팜스빌\n",
      "319400 엔에이치스팩14호\n",
      "319660 피에스케이\n",
      "320000 하나금융13호스팩\n",
      "321260 유진스팩4호\n",
      "321550 티움바이오\n",
      "322000 현대에너지솔루션\n",
      "322180 티라유텍\n",
      "322510 제이엘케이인스펙션\n",
      "322780 DB금융스팩7호\n",
      "323210 이베스트이안스팩1호\n",
      "323230 신한제5호스팩\n",
      "323280 신영스팩5호\n",
      "323940 케이비제18호스팩\n",
      "327260 메탈라이프\n",
      "328380 미래에셋대우스팩3호\n",
      "329560 상상인이안제2호스팩\n",
      "330590 롯데리츠\n",
      "330990 케이비제19호스팩\n",
      "331380 유진스팩5호\n",
      "331520 교보9호스팩\n",
      "332290 대신밸런스제7호스팩\n",
      "332710 하나금융14호스팩\n",
      "333050 신한제6호스팩\n",
      "333430 미래에셋대우스팩4호\n",
      "335870 IBKS제12호스팩\n",
      "335890 IBKS제11호스팩\n",
      "336060 유안타제5호스팩\n",
      "336260 두산퓨얼셀\n",
      "336370 두산솔루스\n",
      "336570 대신밸런스제8호스팩\n",
      "337450 SK5호스팩\n",
      "338100 NH프라임리츠\n",
      "339950 엔에이치스팩15호\n",
      "340120 하이제5호스팩\n",
      "340360 유안타제6호스팩\n",
      "340440 한화플러스제1호스팩\n",
      "341160 하나금융15호스팩\n",
      "342550 케이비제20호스팩\n",
      "344820 케이씨씨글라스\n",
      "900040 차이나그레이트\n",
      "900070 글로벌에스엠\n",
      "900080 에스앤씨엔진그룹\n",
      "900100 뉴프라이드\n",
      "900110 이스트아시아홀딩스\n",
      "900120 씨케이에이치\n",
      "900140 엘브이엠씨홀딩스\n",
      "900250 크리스탈신소재\n",
      "900260 로스웰\n",
      "900270 헝셩그룹\n",
      "900280 골든센츄리\n",
      "900290 GRT\n",
      "900300 오가닉티코스메틱\n",
      "900310 컬러레이\n",
      "900340 윙입푸드\n",
      "950110 SBI핀테크솔루션즈\n",
      "950130 엑세스바이오\n",
      "950140 잉글우드랩\n",
      "950160 코오롱티슈진\n",
      "950170 JTC\n",
      "950180 SNK\n"
     ]
    }
   ],
   "source": [
    "## def get_stock_price_from_fdr(end_date=now):  코스피,코스닥 전체종목 입력\n",
    "        \n",
    "file_name = input('파일이름을 입력하세요:')\n",
    "toward = input('저장 방식을 입력하세요 : sample: excel, sql ')\n",
    "start_date = input(\"시작날자를 입려하세요 : sample: '2015-01-01'\")\n",
    "table_name = input(\"table명을 입력하세요 : sample: market\")\n",
    "data=pd.read_excel('d:\\\\'+ file_name)\n",
    "   \n",
    "code_list = data['종목코드'].tolist()\n",
    "code_list = [str(item).zfill(6) for item in code_list]\n",
    "name_list = data['종목명'].tolist()\n",
    "\n",
    "# 코스피 상장종목 전체\n",
    "stock_dic = dict(list(zip(code_list,name_list)))\n",
    "\n",
    "for code in sorted(stock_dic.keys()):\n",
    "    df  = fdr.DataReader(code,start_date,now)\n",
    "    print(code,stock_dic[code])\n",
    "    df['Code'],df['Name'] = code,stock_dic[code]\n",
    "    df = df[['Code','Name','Open','High','Low','Volume','Close']]\n",
    "    if toward == 'excel':\n",
    "        df.to_excel('d:\\\\data_set\\\\kospi\\\\'+ stock_dic[code] +'.xlsx',engine = 'xlsxwriter')\n",
    "    elif toward == 'sql':\n",
    "        df.to_sql(name=table_name, con=engine, if_exists='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#### 기존에 액면분할시 가격조정 안된 기존 data가 있을때\n",
    "## insert mysql 개별 주식\n",
    "\n",
    "Code = input('주식 Code를 입력하세요')\n",
    "Name = input('주식이름을 입력하세요')\n",
    "\n",
    "query = \"delete from  market where Code = \"+\"'\"+Code+\"'\"\n",
    "\n",
    "curs.execute(query)\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "df = fdr.DataReader(Code, '1995')\n",
    "df.to_excel('d:\\\\'+Code+'.xlsx', encoding='UTF-8')\n",
    "\n",
    "df = pd.read_excel('d:\\\\'+Code+'.xlsx')\n",
    "df['Code']= Code\n",
    "df['Name']= Name\n",
    "\n",
    "df = df[['Date','Code','Name','Open', 'High', 'Low', 'Volume','Close']]\n",
    "\n",
    "df.to_sql(name='market', con=engine, if_exists='append', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel('d:\\\\kospi_sector.xlsx')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## def excel_to_mysql():\n",
    "\n",
    "file_name = input('파일이름을 입력하세요:')\n",
    "        \n",
    "df=pd.read_excel('d:\\\\'+ file_name)\n",
    "if file_name=='kpi200.xlsx':\n",
    "    df.columns=['Date','kpi200','거래량']\n",
    "    table_name = 'kpi200'\n",
    "    #df = df.set_index('Date')\n",
    "elif file_name=='moneytrend.xlsx':\n",
    "    table_name = 'moneytrend'\n",
    "    df.columns=['Date', '고객예탁금', '신용잔고','주식형펀드','혼합형펀드','채권형펀드']\n",
    "    #df = df.set_index('Date')\n",
    "elif file_name=='kospi_sector.xlsx':\n",
    "    table_name = 'kospi_sector'\n",
    "    df.columns=['Date', 'sectorName', 'changeRate', 'first', 'second']\n",
    "elif file_name=='kosdaq_sector.xlsx':\n",
    "    table_name = 'kosdaq_sector'\n",
    "    df.columns=['Date', 'sectorName', 'changeRate', 'first', 'second']\n",
    "else:\n",
    "    print('\\n file_name error\\n')\n",
    "    \n",
    "df.to_sql(name=table_name, con=engine, if_exists='append', index = False)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  코스피 , 코스닥 누락데이터 입력\n",
    "\n",
    "from mod1 import *\n",
    "\n",
    "kospi_df = pd.read_sql(\"select Date from kospi order by Date desc limit 1\", engine)\n",
    "kospi_df = str(kospi_df['Date'])\n",
    "kospi_date = kospi_df[5:15]\n",
    "\n",
    "kosdaq_df = pd.read_sql(\"select Date from kosdaq order by Date desc limit 1\", engine)\n",
    "kosdaq_df = str(kosdaq_df['Date'])\n",
    "kosdaq_date = kosdaq_df[5:15]\n",
    "\n",
    "\n",
    "start_kospi = datetime.strptime(kospi_date , \"%Y-%m-%d\")\n",
    "kospi_date= (start_kospi + timedelta(days=1)).strftime('%Y%m%d')\n",
    "\n",
    "start_kosdaq = datetime.strptime(kosdaq_date , \"%Y-%m-%d\")\n",
    "kosdaq_date= (start_kosdaq + timedelta(days=1)).strftime('%Y%m%d')\n",
    "\n",
    "\n",
    "df_kospi = get_index_ohlcv_by_date(kospi_date, \"20250228\", \"코스피\")\n",
    "df_kospi.index.names = ['Date']\n",
    "df_kospi.columns  = ('Open','High','Low','Close','Volume')\n",
    "df_kospi['Market']='kospi'\n",
    "df_kospi.to_sql(name='kospi', con=engine, if_exists='append')\n",
    "\n",
    "\n",
    "df_kosdaq = get_index_ohlcv_by_date(kosdaq_date, \"20250228\", \"코스닥\")\n",
    "df_kosdaq.index.names = ['Date']\n",
    "df_kosdaq.columns  = ('Open','High','Low','Close','Volume')\n",
    "df_kosdaq['Market']='kosdaq'\n",
    "df_kosdaq.to_sql(name='kosdaq', con=engine, if_exists='append')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Excel to mysql\n",
    "\n",
    "import FinanceDataReader as fdr\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "from  datetime import datetime\n",
    "\n",
    "engine = sqlalchemy.create_engine('mysql+pymysql://kkang:leaf2027@localhost/stock?charset=utf8',encoding='utf-8')\n",
    "\n",
    "date = input('원하는 날짜를 입력하세요 ')\n",
    "path = 'd:\\\\stockdata\\\\관리종목\\\\'+date+'.xlsx'\n",
    "\n",
    "df = pd.read_excel(path)\n",
    "\n",
    "df.to_sql(name='badstock', con=engine, if_exists='append', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Mysql to Excel\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "connect = create_engine('mysql+pymysql://kkang:leaf2027@localhost/stock?charset=utf8',encoding='utf-8')\n",
    "df = pd.read_sql(\"SELECT distinct Name,Code from market where date = '2019-09-05'\", connect)\n",
    "\n",
    "df.to_excel('d:\\\\sql_market.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### kospi, kosdaq  지수 DB 입력  version_1\n",
    "\n",
    "from mod1 import *\n",
    "\n",
    "df_kospi  = get_index_kospi_ohlcv_by_date(\"20200113\",\"20200120\", \"코스피\")\n",
    "df_kospi.index.names = ['Date']\n",
    "df_kospi.columns  = ('Open','High','Low','Close','Volume')\n",
    "df_kospi['Market']='kospi'\n",
    "df_kospi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### kospi, kosdaq  지수 DB 입력  version_2\n",
    "\n",
    "from mod1 import *\n",
    "\n",
    "df_kospi  = get_index_ohlcv_by_date(\"20200410\",\"20210410\", \"코스피\")\n",
    "df_kospi.index.names = ['Date']\n",
    "df_kospi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### kospi, kosdaq  지수 DB 입력  version_2\n",
    "\n",
    "from mod1 import *\n",
    "\n",
    "df_kospi  = get_index_ohlcv_by_date(\"20200413\",\"20210410\", \"코스피\")\n",
    "df_kospi.index.names = ['Date']\n",
    "df_kospi.columns  = ('Open','High','Low','Close','Volume')\n",
    "df_kospi['Market']='kospi'\n",
    "df_kospi.to_sql(name='kospi', con=engine, if_exists='append')\n",
    "\n",
    "df_kosdaq = get_index_ohlcv_by_date(\"20200413\",\"20210410\", \"코스닥\")\n",
    "df_kosdaq.index.names = ['Date']\n",
    "df_kosdaq.columns  = ('Open','High','Low','Close','Volume')\n",
    "df_kosdaq['Market']='kosdaq'\n",
    "df_kosdaq.to_sql(name='kosdaq', con=engine, if_exists='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### kospi, kosdaq  지수 DB 입력 version_3\n",
    "\n",
    "from mod1 import *\n",
    "\n",
    "kospi_df = pd.read_sql(\"select Date from kospi order by Date desc limit 1\", engine)\n",
    "kospi_df = str(kospi_df['Date'])\n",
    "kospi_date = kospi_df[5:15]\n",
    "\n",
    "kosdaq_df = pd.read_sql(\"select Date from kosdaq order by Date desc limit 1\", engine)\n",
    "kosdaq_df = str(kosdaq_df['Date'])\n",
    "kosdaq_date = kosdaq_df[5:15]\n",
    "\n",
    "\n",
    "start_kospi = datetime.strptime(kospi_date , \"%Y-%m-%d\")\n",
    "kospi_date= (start_kospi + timedelta(days=1)).strftime('%Y%m%d')\n",
    "\n",
    "start_kosdaq = datetime.strptime(kosdaq_date , \"%Y-%m-%d\")\n",
    "kosdaq_date= (start_kosdaq + timedelta(days=1)).strftime('%Y%m%d')\n",
    "\n",
    "\n",
    "df_kospi = get_index_ohlcv_by_date(kospi_date, \"20250228\", \"코스피\")\n",
    "df_kospi.index.names = ['Date']\n",
    "df_kospi.columns  = ('Open','High','Low','Close','Volume')\n",
    "df_kospi['Market']='kospi'\n",
    "df_kospi.to_sql(name='kospi', con=engine, if_exists='append')\n",
    "\n",
    "df_kosdaq = get_index_ohlcv_by_date(kosdaq_date, \"20250228\", \"코스피\")\n",
    "df_kosdaq.index.names = ['Date']\n",
    "df_kosdaq.columns  = ('Open','High','Low','Close','Volume')\n",
    "df_kosdaq['Market']='kosdaq'\n",
    "df_kosdaq.to_sql(name='kosdaq', con=engine, if_exists='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "###  선물크롤링하여 맨처음 DB에 future table생성할때\n",
    "\n",
    "# 2019-09-11 수정  mysql future table에서 최종 날짜를 확인해서 그뒤날부터 insert \n",
    "# 기존 daum 주식 사이트 : ajax 방식으로 변경으로 인해 이를 반영한 코드를 수정.\n",
    "# pip install fake-useragent 설치 후 실행 가능\n",
    "\n",
    "import io\n",
    "import json\n",
    "import sys\n",
    "import pandas as pd\n",
    "import sqlalchemy \n",
    "import urllib.request as req\n",
    "from datetime import datetime\n",
    "from fake_useragent import UserAgent\n",
    "\n",
    "engine = sqlalchemy.create_engine('mysql+pymysql://kkang:leaf2027@localhost/stock?charset=utf8',encoding='utf-8')\n",
    "\n",
    "\n",
    "# Fake Header 정보\n",
    "ua = UserAgent()\n",
    "\n",
    "# 헤더 선언\n",
    "headers = {\n",
    "    'User-Agent': ua.ie,\n",
    "    'referer': 'http://finance.daum.net/domestic/futures'\n",
    "}\n",
    "\n",
    "\n",
    "url = \"http://finance.daum.net/api/future/KR4101Q30005/days?pagination=true&page=1\"\n",
    "res = req.urlopen(req.Request(url, headers=headers)).read().decode('utf-8')\n",
    "\n",
    "df1 = pd.DataFrame()\n",
    "for i in range(1,7):\n",
    "    # 다음 주식 요청 URL\n",
    "    url = \"http://finance.daum.net/api/future/KR4101Q30005/days?pagination=true&page=\"+str(i)\n",
    "\n",
    "    res = req.urlopen(req.Request(url, headers=headers)).read().decode('utf-8')\n",
    "    \n",
    "    rank_json = json.loads(res)['data']\n",
    "    \n",
    "    df = pd.DataFrame(rank_json)\n",
    "    df1 = df1.append(df,ignore_index=True)\n",
    "    \n",
    "df2 = df1[['date','tradePrice','change', 'changePrice','changeRate','unsettledVolume','foreignSettlement', 'institutionSettlement', 'privateSettlement']]\n",
    "df2.columns=('Date','Future','change','가격변동','등락률','미결제약정','외국인','기관','개인')\n",
    "df2['Date'] = pd.to_datetime(df2['Date']).dt.date\n",
    "#df2['Date'] = pd.to_datetime(df2['Date']).apply(lambda x: x.date())\n",
    "#df2['Date'] = pd.to_datetime(df2['Date'], format = '%Y-%m-%d') # yyyy-mm-dd hh:mm:ss -> yyyy-mm-dd (속성은그대로 보여주는 형식만 변경)\n",
    "df2 =df2[['Date','Future','미결제약정','외국인','기관','개인']]\n",
    "#df2 = df2[df2.Date > until_date]\n",
    "df2.to_sql(name='future', con=engine, if_exists='append', index = False)\n",
    "df2 = df2.set_index('Date')\n",
    "df2.to_excel('d:\\\\future.xlsx',encoding='utf-8')\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2019-01-28 수정\n",
    "# 기존 daum 주식 사이트 : ajax 방식으로 변경으로 인해 이를 반영한 코드를 수정.\n",
    "# pip install fake-useragent 설치 후 실행 가능\n",
    "import time\n",
    "import io\n",
    "import json\n",
    "import sys\n",
    "import pandas as pd\n",
    "import urllib.request as req\n",
    "\n",
    "from fake_useragent import UserAgent\n",
    "\n",
    "start = time.time()  # 시작 시간 저장\n",
    "\n",
    "#sys.stdout = io.TextIOWrapper(sys.stdout.detach(), encoding='utf-8')\n",
    "#sys.stderr = io.TextIOWrapper(sys.stderr.detach(), encoding='utf-8')\n",
    "\n",
    "# Fake Header 정보\n",
    "ua = UserAgent()\n",
    "\n",
    "# 헤더 선언\n",
    "headers = {\n",
    "    'User-Agent': ua.ie,\n",
    "    'referer': 'http://finance.daum.net/domestic/all_stocks'\n",
    "}\n",
    "\n",
    "# 다음 주식 요청 URL\n",
    "kospi_sector_url = \"http://finance.daum.net/api/quotes/sectors?fieldName=&order=&perPage=&market=KOSPI&page=&changes=UPPER_LIMIT%2CRISE%2CEVEN%2CFALL%2CLOWER_LIMIT\"\n",
    "kosdaq_sector_url = \"http://finance.daum.net/api/quotes/sectors?fieldName=&order=&perPage=&market=KOSDAQ&page=&changes=UPPER_LIMIT%2CRISE%2CEVEN%2CFALL%2CLOWER_LIMI\"\n",
    "\n",
    "# 요청\n",
    "kospi_sector_res = req.urlopen(req.Request(kospi_sector_url, headers=headers)).read().decode('utf-8')\n",
    "kosdaq_sector_res = req.urlopen(req.Request(kosdaq_sector_url, headers=headers)).read().decode('utf-8')\n",
    "# 응답 데이터 확인(Json Data)\n",
    "# print('res', res)\n",
    "\n",
    "# 응답 데이터 str -> json 변환 및 data 값 저장\n",
    "kospi_sector = json.loads(kospi_sector_res)['data']\n",
    "kosdaq_sector = json.loads(kosdaq_sector_res)['data']\n",
    "# 중간 확인\n",
    "#print('중간 확인 : ', rank_json, '\\n')\n",
    "\n",
    "#for elm in rank_json:\n",
    "    # print(type(elm)) #Type 확인\n",
    "    #print('순위 : {}, 금액 : {}, 회사명 : {}'.format(elm['rank'], elm['tradePrice'], elm['name']), )\n",
    "\n",
    "kospi_sector_df = pd.DataFrame(kospi_sector)\n",
    "kosdaq_sector_df = pd.DataFrame(kosdaq_sector)\n",
    "\n",
    "kospi_name=[]\n",
    "kosdaq_name=[]\n",
    "\n",
    "for i in range(len(kospi_sector_df.index)):\n",
    "    stock_name = [kospi_sector_df['includedStocks'][i][0]['name'],kospi_sector_df['includedStocks'][i][1]['name']]\n",
    "    kospi_name.append(stock_name)\n",
    "kospi_name_df=pd.DataFrame(kospi_name)\n",
    "\n",
    "kospi_sector_df = kospi_sector_df[['date','sectorName','change','changeRate']]\n",
    "kospi_sector_df['changeRate'] = kospi_sector_df['changeRate']*100\n",
    "\n",
    "kospi_sector_df = kospi_sector_df.sort_values(['change','changeRate'], ascending=[False,False])\n",
    "\n",
    "for i in range(len(kosdaq_sector_df.index)):\n",
    "    stock_name = [kosdaq_sector_df['includedStocks'][i][0]['name'],kosdaq_sector_df['includedStocks'][i][1]['name']]\n",
    "    kosdaq_name.append(stock_name)\n",
    "kosdaq_name_df=pd.DataFrame(kosdaq_name)\n",
    "\n",
    "kosdaq_sector_df = kosdaq_sector_df[['date','sectorName','change','changeRate']]\n",
    "kosdaq_sector_df['changeRate'] = kosdaq_sector_df['changeRate']*100\n",
    "\n",
    "\n",
    "kospi_sector_df = kospi_sector_df.join(kospi_name_df)\n",
    "kosdaq_sector_df = kosdaq_sector_df.join(kosdaq_name_df)\n",
    "\n",
    "kospi_sector_df.columns=('date', 'sectorName', 'change', 'changeRate', 'first', 'second')\n",
    "kosdaq_sector_df.columns=('date', 'sectorName', 'change', 'changeRate', 'first', 'second')\n",
    "\n",
    "kosdaq_sector_df = kosdaq_sector_df.sort_values(['change','changeRate'], ascending=[False,False])\n",
    "\n",
    "#display(kospi_sector_df.set_index('date')) \n",
    "#display(kosdaq_sector_df.set_index('date')) \n",
    "\n",
    "\n",
    "##########  업종별시세 column중에 changeRate 'FALL' data를 일관되게 -수치로 바꾸는 code\n",
    " \n",
    "kospi = kospi_sector_df.set_index('change')  ##  index롤 분류하기위한 indeㅌing\n",
    "kosdaq = kosdaq_sector_df.set_index('change')  ##  index롤 분류하기위한 indeㅌing\n",
    "\n",
    "for i in [kospi,kosdaq]:\n",
    "    cols = i.index.difference(['RISE'])      ## cols는 DateFrame이 아닌 change값이 FALL을 가리키는 객체\n",
    "    b = i.loc[cols]\n",
    "    b['changeRate']=i.loc[cols]['changeRate'].mul(-1)\n",
    "    i.loc[cols]=b        ## a change 값이 FALL인 행을 chageRate값을 -로 바꾼 b로 치환   \n",
    "\n",
    "kospi_sector = kospi.set_index('date')\n",
    "kosdaq_sector = kosdaq.set_index('date')\n",
    "kospi_df =  kospi_sector.sort_values([\"changeRate\"],ascending=False)\n",
    "kosdaq_df =  kosdaq_sector.sort_values([\"changeRate\"],ascending=False)\n",
    "\n",
    "\n",
    "kospi_df.to_sql(name='kospi_sector', con=engine, if_exists='append')\n",
    "kosdaq_df.to_sql(name='kosdaq_seotor', con=engine, if_exists='append')\n",
    "print(\"time :\", time.time() - start)  # 현재시각 - 시작시간 = 실행 시간"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kosdaq_sector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###  선물 DB Update할때\n",
    "\n",
    "# 2019-09-11 수정  mysql future table에서 최종 날짜를 확인해서 그뒤날부터 insert \n",
    "# 기존 daum 주식 사이트 : ajax 방식으로 변경으로 인해 이를 반영한 코드를 수정.\n",
    "# pip ainstall fake-useragent 설치 후 실행 가능\n",
    "\n",
    "import io\n",
    "import json\n",
    "import sys\n",
    "import pandas as pd\n",
    "import sqlalchemy \n",
    "import urllib.request as req\n",
    "from datetime import datetime\n",
    "from fake_useragent import UserAgent\n",
    "\n",
    "from datetime import datetime\n",
    "from fake_useragent import UserAgent\n",
    "\n",
    "engine = sqlalchemy.create_engine('mysql+pymysql://kkang:leaf2027@localhost/stock?charset=utf8',encoding='utf-8')\n",
    "future_df = pd.read_sql(\"select Date from future order by Date desc limit 1\", engine)\n",
    "future_df = str(future_df['Date'])\n",
    "until_date = future_df[5:15]\n",
    "\n",
    "year = until_date.split('-')[0]\n",
    "mm = until_date.split('-')[1]\n",
    "dd = until_date.split('-')[2]\n",
    "#year=year[2:]\n",
    "until_date = year+'-'+mm+'-'+dd\n",
    "until_date = datetime.strptime(until_date, '%Y-%m-%d').date() ## str 을  datetime.date로 type 변경\n",
    "\n",
    "# Fake Header 정보\n",
    "ua = UserAgent()\n",
    "\n",
    "# 헤더 선언\n",
    "headers = {\n",
    "    'User-Agent': ua.ie,\n",
    "    'referer': 'http://finance.daum.net/domestic/futures'\n",
    "}\n",
    "\n",
    "\n",
    "url = \"http://finance.daum.net/api/future/KR4101Q60002/days?pagination=true&page=1\"  #KR4011PC002 \"선물 코스피 200지수 12월물\" 코드는 구글검색이용\n",
    "res = req.urlopen(req.Request(url, headers=headers)).read().decode('utf-8')\n",
    "\n",
    "df1 = pd.DataFrame()\n",
    "for i in range(1,3):\n",
    "    # 다음 주식 요청 URL\n",
    "    url = \"http://finance.daum.net/api/future/KR4101Q60002/days?pagination=true&page=\"+str(i)\n",
    "\n",
    "    res = req.urlopen(req.Request(url, headers=headers)).read().decode('utf-8')\n",
    "    \n",
    "    rank_json = json.loads(res)['data']\n",
    "    \n",
    "    df = pd.DataFrame(rank_json)\n",
    "    df1 = df1.append(df,ignore_index=True)\n",
    "df2 = df1[['date','tradePrice','change', 'changePrice','changeRate','unsettledVolume','foreignSettlement', 'institutionSettlement', 'privateSettlement']]\n",
    "df2.columns=('Date','Future','change','가격변동','등락률','미결제약정','외국인','기관','개인')\n",
    "df2['Date'] = pd.to_datetime(df2['Date']).dt.date\n",
    "#df2['Date'] = pd.to_datetime(df2['Date']).apply(lambda x: x.date())\n",
    "#df2['Date'] = pd.to_datetime(df2['Date'], format = '%Y-%m-%d') # yyyy-mm-dd hh:mm:ss -> yyyy-mm-dd (속성은그대로 보여주는 형식만 변경)\n",
    "df2 =df2[['Date','Future','미결제약정','외국인','기관','개인']]\n",
    "df2 = df2[df2.Date > until_date]\n",
    "df2.to_sql(name='future', con=engine, if_exists='append', index = False)\n",
    "df2 = df2.set_index('Date')\n",
    "df2.to_excel('d:\\\\future.xlsx',encoding='utf-8')\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matplotlib를 사용한 Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## 선물  베이시스 graph ( One_graph)\n",
    "## def future_trend_graph():\n",
    "   \n",
    "\n",
    "#query = \"select * from future where Date > '2019-06-13'\"+\"'\"+date+\"'\"\n",
    "query = \"select * from basis where Date > '2019-06-13'\"\n",
    "\n",
    "\n",
    "name=['kpi200','Future']\n",
    "#name=['미결제약정']\n",
    "\n",
    "tuple_name=tuple(name)\n",
    "df1 = pd.DataFrame()\n",
    "    \n",
    "df = pd.read_sql(query ,engine)\n",
    "\n",
    "#df.columns=['Date','kpi200','Close']\n",
    "df = df.set_index('Date')\n",
    "df1=df[name]\n",
    "\n",
    "plt.figure(figsize=(16,4))    \n",
    "for i in range(len(name)):\n",
    "    plt.plot(df1[name[i]]/df1[name[i]].loc[df.index[0]]*100, label=name[i])\n",
    "        \n",
    "#plt.legend(loc=0)\n",
    "plt.legend(loc=0)\n",
    "plt.grid(True,color='0.7',linestyle=':',linewidth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## 선물  베이시스 graph ( One_graph)\n",
    "## def future_trend_graph():\n",
    "   \n",
    "\n",
    "#query = \"select * from future where Date > '2019-06-13'\"+\"'\"+date+\"'\"\n",
    "query = \"select * from future where Date > '2019-06-13'\"\n",
    "\n",
    "\n",
    "name=['Close', '미결제약정', '외국인', '기관', '개인']\n",
    "#name=['미결제약정']\n",
    "\n",
    "tuple_name=tuple(name)\n",
    "df1 = pd.DataFrame()\n",
    "    \n",
    "df = pd.read_sql(query ,engine)\n",
    "\n",
    "df.columns=['Date', 'Close', '미결제약정', '외국인', '기관', '개인']\n",
    "df = df.set_index('Date')\n",
    "df1=df[name]\n",
    "\n",
    "plt.figure(figsize=(16,4))    \n",
    "for i in range(len(name)):\n",
    "    plt.plot(df1[name[i]]/df1[name[i]].loc[df.index[0]]*100)\n",
    "        \n",
    "#plt.legend(loc=0)\n",
    "plt.legend(name)\n",
    "plt.grid(True,color='0.7',linestyle=':',linewidth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## 선물 graph ( One_graph)\n",
    "## def future_trend_graph():\n",
    "    \n",
    "#name = input(\"항목을 입력하세요: 선택항목: 'kpi200', '거래량', '고객예탁금', '신용잔고', '주식형펀드', '혼합형펀드', '채권형펀드'\").split()\n",
    "#date = input(\"날짜를 입력하세요 sample: '2019-01-10':\")\n",
    "    \n",
    "    \n",
    "#query = \"select * from future where Date > '2019-06-13'\"+\"'\"+date+\"'\"\n",
    "query = \"select * from future where Date > '2019-06-13'\"\n",
    "\n",
    "\n",
    "name=['Close', '미결제약정', '외국인', '기관', '개인']\n",
    "#name=['미결제약정']\n",
    "\n",
    "tuple_name=tuple(name)\n",
    "df1 = pd.DataFrame()\n",
    "    \n",
    "df = pd.read_sql(query ,engine)\n",
    "\n",
    "df.columns=['Date', 'Close', '미결제약정', '외국인', '기관', '개인']\n",
    "df = df.set_index('Date')\n",
    "df1=df[name]\n",
    "\n",
    "plt.figure(figsize=(16,4))    \n",
    "for i in range(len(name)):\n",
    "    plt.plot(df1[name[i]]/df1[name[i]].loc[df.index[0]]*100)\n",
    "        \n",
    "plt.legend(name,loc=0)\n",
    "plt.grid(True,color='0.7',linestyle=':',linewidth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## 선물 graph ( Multi_graph)\n",
    "## def future_trend_graph():\n",
    " \n",
    "#name = input(\"항목을 입력하세요: 선택항목: 'kpi200', '거래량', '고객예탁금', '신용잔고', '주식형펀드', '혼합형펀드', '채권형펀드'\").split()\n",
    "#date = input(\"날짜를 입력하세요 sample: '2019-01-10':\")\n",
    "    \n",
    "#query = \"select * from future where Date > '2019-06-13'\"+\"'\"+date+\"'\"\n",
    "query = \"select * from future where Date > '2019-06-11'\"\n",
    "\n",
    "\n",
    "name=['Close', '미결제약정', '외국인', '기관', '개인']\n",
    "name1=['Close','미결제약정']\n",
    "name2=['외국인', '기관', '개인']\n",
    "\n",
    "#tuple_name=tuple(name)\n",
    "df1 = pd.DataFrame()\n",
    "    \n",
    "df = pd.read_sql(query ,engine)\n",
    "\n",
    "df.columns=['Date', 'Close', '미결제약정', '외국인', '기관', '개인']\n",
    "df = df.set_index('Date')\n",
    "df1=df[name]\n",
    "\n",
    "plt.figure(figsize=(16,4))    \n",
    "for i in range(len(name1)):\n",
    "    #plt.subplot(2,2,i+1)\n",
    "    plt.plot(df1[name1[i]]/df1[name1[i]].loc[df.index[0]]*100,color=colors[i])\n",
    "    \n",
    "plt.legend(loc=0)\n",
    "plt.grid(True,color='0.7',linestyle=':',linewidth=1)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(16,4)) \n",
    "for i in range(len(name2)):\n",
    "    plt.subplot(2,2,i+1)\n",
    "    plt.plot(df1[name2[i]]/df1[name2[i]].loc[df.index[0]]*100,color=colors[i])\n",
    "    \n",
    "    plt.legend(loc=0)\n",
    "    plt.grid(True,color='0.7',linestyle=':',linewidth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Close and Volume graph 표준화\n",
    "\n",
    "import FinanceDataReader as fdr\n",
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "engine = sqlalchemy.create_engine('mysql+pymysql://kkang:leaf2027@localhost/stock?charset=utf8',encoding='utf-8')\n",
    "\n",
    "select_query = \"select Date,Volume,Close from market where Name= \"\n",
    "date_query = \"Date > \"\n",
    "\n",
    "def choice(select):\n",
    "    name = '화천기계'\n",
    "    date = '2019-01-01'\n",
    "    if select == 1:\n",
    "        name = input('주식이름을 입력하세요 : ')\n",
    "        date = input('날짜를 입력하세요: ')\n",
    "        var = select_query +\"'\"+name+\"'\"+\" \"+\"&&\"+\" \"+date_query+\"'\"+date+\"'\" \n",
    "        return var\n",
    "    elif select == 2:\n",
    "        var = select_query +\"'\"+name+\"'\"+\" \"+\"&&\"+\" \"+date_query+\"'\"+date+\"'\" \n",
    "        return var\n",
    "\n",
    "select = input('select 1 or 2: ')\n",
    "select = int(select)\n",
    "\n",
    "df = pd.read_sql(choice(select), engine)\n",
    "\n",
    "source = MinMaxScaler()\n",
    "data = source.fit_transform(df[['Close','Volume']].values.astype(float))\n",
    "df1 = pd.DataFrame(data)\n",
    "df1.columns=['Close','Volume']\n",
    "df1 = df1.set_index(df['Date'])\n",
    "df1.plot(figsize=(16,4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Close and Volume graph 표준화 _ 2  종목을 list로 설정\n",
    "\n",
    "import FinanceDataReader as fdr\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "engine = sqlalchemy.create_engine('mysql+pymysql://kkang:leaf2027@localhost/stock?charset=utf8',encoding='utf-8')\n",
    "\n",
    "select_query = \"select Date,Volume,Close from market where Name= \"\n",
    "date_query = \"Date > \"\n",
    "\n",
    "df = pd.read_excel('d:\\\\detect_stock_with_volume.xlsx')\n",
    "df=df['Name']\n",
    "#name = df.values.tolist() ## numpy to list\n",
    "name = df.to_list()              ## DataFrame to list\n",
    "date = '2019-01-01'\n",
    "for i in name:\n",
    "    var = select_query +\"'\"+i+\"'\"+\" \"+\"&&\"+\" \"+date_query+\"'\"+date+\"'\" \n",
    "    df = pd.read_sql(var, engine)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['Close','Volume']].values.astype(float))\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1.columns=['Close','Volume']\n",
    "    df1 = df1.set_index(df['Date'])\n",
    "    df1.plot(figsize=(16,2))\n",
    "    plt.title(i)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Close and Volume graph 표준화-3  이동평균선 포함\n",
    "\n",
    "import talib.abstract as ta\n",
    "import FinanceDataReader as fdr\n",
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "engine = sqlalchemy.create_engine('mysql+pymysql://kkang:leaf2027@localhost/stock?charset=utf8',encoding='utf-8')\n",
    "\n",
    "select_query = \"select * from market where Name= \"\n",
    "date_query = \"Date > \"\n",
    "\n",
    "def choice(select):\n",
    "    name = 'hrs'\n",
    "    date = '2010-01-01'\n",
    "    if select == 1:\n",
    "        name = input('주식이름을 입력하세요 : ')\n",
    "        date = input('날짜를 입력하세요: ')\n",
    "        var = select_query +\"'\"+name+\"'\"+\" \"+\"&&\"+\" \"+date_query+\"'\"+date+\"'\" \n",
    "        return var\n",
    "    elif select == 2:\n",
    "        var = select_query +\"'\"+name+\"'\"+\" \"+\"&&\"+\" \"+date_query+\"'\"+date+\"'\" \n",
    "        return var\n",
    "\n",
    "select = input('select 1 or 2: ')\n",
    "select = int(select)\n",
    "\n",
    "df = pd.read_sql(choice(select), engine)\n",
    "df[['Open','High','Low','Volume','Close']] = df[['Open','High','Low','Volume','Close']].astype(float) #  TA-Lib로 평균을 구하려면 실수로 만들어야 함\n",
    "df.columns=df.columns.str.lower()\n",
    "\n",
    "talib_ma5 = ta.MA(df, timeperiod=5)\n",
    "df['ma5'] = talib_ma5\n",
    "\n",
    "talib_ma120 = ta.MA(df, timeperiod=120)\n",
    "df['ma120'] = talib_ma120\n",
    "\n",
    "source = MinMaxScaler()\n",
    "data = source.fit_transform(df[['close','volume','ma120']].values)\n",
    "df1 = pd.DataFrame(data)\n",
    "df1.columns=['close','ma120','volume']\n",
    "df1 = df1.set_index(df['date'])\n",
    "df1.plot(figsize=(16,4))\n",
    "\n",
    "choice(select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Close and Volume and MA graph 표준화-3  주식 DataFrame에서   종가, 거래걍, 이동평균선을 graph로 그리는 함수 \n",
    "\n",
    "def close_vol_ma(DataFrame,select):\n",
    "\n",
    "    df = DataFrame\n",
    "    df.columns=df.columns.str.lower()\n",
    "    df[['volume','close']] = df[['volume','close']].astype(float) #  TA-Lib로 평균을 구하려면 실수로 만들어야 함\n",
    "\n",
    "    talib_ma5 = ta.MA(df, timeperiod=5)\n",
    "    df['ma5'] = talib_ma5\n",
    "    \n",
    "    talib_ma10 = ta.MA(df, timeperiod=10)\n",
    "    df['ma10'] = talib_ma10    \n",
    "\n",
    "    talib_ma15 = ta.MA(df, timeperiod=15)\n",
    "    df['ma15'] = talib_ma15\n",
    "\n",
    "    talib_ma20 = ta.MA(df, timeperiod=20)\n",
    "    df['ma20'] = talib_ma20\n",
    "    \n",
    "    talib_ma30 = ta.MA(df, timeperiod=30)\n",
    "    df['ma30'] = talib_ma30    \n",
    "    \n",
    "    talib_ma60 = ta.MA(df, timeperiod=60)\n",
    "    df['ma60'] = talib_ma60    \n",
    "    \n",
    "    talib_ma120 = ta.MA(df, timeperiod=120)\n",
    "    df['ma120'] = talib_ma120    \n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close',select,'volume']].values)\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1.columns=['close',select,'volume']\n",
    "    df1 = df1.set_index(df['date'])\n",
    "    df1.plot(figsize=(16,4))\n",
    "close_vol_ma(df,select='ma20')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## def stock_select_with_Volume_Close():\n",
    "    \n",
    "yesterday = input(\"어제날짜를 입력하세요 : sample: '2019-02-07 00:00:00'  \") \n",
    "today = input(\"오늘날짜를 입력하세요 : sample: '2019-02-07 00:00:00'  \")\n",
    "    \n",
    "select_query = \"select * from market where Date >=\"\n",
    "volume_query = \"&& Volume >  500000\"\n",
    "    \n",
    "var = select_query +\"'\"+yesterday+\"'\"+ volume_query\n",
    "df = pd.read_sql(var ,engine)\n",
    "\n",
    "df1 = df[df['Date'].astype(str) == yesterday]\n",
    "df1 = df1[['Name','Volume','Close']]\n",
    "df1.columns = ['Name','yester_Volume','yester_Close']\n",
    "#display(df1)\n",
    "\n",
    "df2 = df[df['Date'].astype(str) == today]\n",
    "df2 = df2[['Name','Volume','Close']]\n",
    "df2.columns = ['Name','today_Volume','today_Close']\n",
    "#display(df2)\n",
    "\n",
    "df3 = pd.merge(df1,df2,on='Name')\n",
    "df3['Close']=df3['today_Close']/df3['yester_Close']\n",
    "df3['Volume']=df3['today_Volume']/df3['yester_Volume']\n",
    "df3 = df3.sort_values(by=['Volume','Close'],ascending=False)\n",
    "df3 = df3.reset_index(drop=True)\n",
    "df3 = df3[:10]\n",
    "df4 = df3.sort_values(by=['Close','Volume'],ascending=False)\n",
    "df4 = df4.reset_index(drop=True)\n",
    "df4 = df4[:10]\n",
    "display(df3)\n",
    "display(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## def stock_price_graph():\n",
    "    \n",
    "name = input('주식이름을 입력하세요:').split()\n",
    "date = input(\"날짜를 입력하세요 sample: '2019-01-10': \")\n",
    "\n",
    "select_query = \"select Date,Close from market where Name= \"\n",
    "date_query =  \"Date >\"\n",
    "\n",
    "tuple_name=tuple(name)\n",
    "df1 = pd.DataFrame()\n",
    "\n",
    "for x in tuple_name:\n",
    "    var = select_query +\"'\"+x+\"'\"+\" \"+\"&&\"+\" \"+date_query+\"'\"+date+\"'\"\n",
    "    df = pd.read_sql(var ,engine) \n",
    "    df.columns=['Date',x]\n",
    "    if df1.empty:\n",
    "        df1 = df\n",
    "    else:\n",
    "        df1 = pd.merge (df,df1,on='Date')\n",
    "df1=df1.set_index('Date')\n",
    "    \n",
    "plt.figure(figsize=(12,5))\n",
    "    \n",
    "for i in range(len(name)):\n",
    "    plt.plot(df1[name[i]]/df1[name[i]].loc[df['Date'][0]]*100)\n",
    "        \n",
    "plt.legend(loc=0)\n",
    "plt.grid(True,color='0.7',linestyle=':',linewidth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def stock_price_graph():  여러개 입력가능\n",
    "    \n",
    "## def stock_price_graph():\n",
    "    \n",
    "name = input('주식이름을 입력하세요:').split(',')\n",
    "date = input(\"날짜를 입력하세요 sample: '2019-01-10':\")\n",
    "        \n",
    "select_query = \"select Date,Close from market where Name= \"\n",
    "date_query = \"Date > \"\n",
    "    \n",
    "\n",
    "tuple_name=tuple(name)\n",
    "df1 = pd.DataFrame()\n",
    "    \n",
    "for x in tuple_name:\n",
    "    var = select_query +\"'\"+x+\"'\"+\" \"+\"&&\"+\" \"+date_query+\"'\"+date+\"'\"\n",
    "    df = pd.read_sql(var ,engine)\n",
    "    df.columns=['Date',x]\n",
    "    if df1.empty:\n",
    "        df1 = df\n",
    "    else:\n",
    "        df1 = pd.merge (df,df1,on='Date')\n",
    "df1=df1.set_index('Date')\n",
    "    \n",
    "plt.figure(figsize=(12,5))\n",
    "    \n",
    "for i in range(len(name)):\n",
    "    plt.plot(df1[name[i]]/df1[name[i]].loc[df['Date'][0]]*100)\n",
    "        \n",
    "plt.legend(name,loc=0)\n",
    "plt.grid(True,color='0.7',linestyle=':',linewidth=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def stock_price_graph():  여러개 입력가능\n",
    "    \n",
    "## def stock_price_graph():\n",
    "    \n",
    "name = input('주식이름을 입력하세요:').split(',')\n",
    "date = input(\"날짜를 입력하세요 sample: '2019-01-10':\")\n",
    "        \n",
    "select_query = \"select Date,Close from market where Name= \"\n",
    "date_query = \"Date > \"\n",
    "    \n",
    "\n",
    "tuple_name=tuple(name)\n",
    "df1 = pd.DataFrame()\n",
    "    \n",
    "for x in tuple_name:\n",
    "    var = select_query +\"'\"+x+\"'\"+\" \"+\"&&\"+\" \"+date_query+\"'\"+date+\"'\"\n",
    "    df = pd.read_sql(var ,engine)\n",
    "    df.columns=['Date',x]\n",
    "    if df1.empty:\n",
    "        df1 = df\n",
    "    else:\n",
    "        df1 = pd.merge (df,df1,on='Date')\n",
    "df1=df1.set_index('Date')\n",
    "    \n",
    "plt.figure(figsize=(12,5))\n",
    "    \n",
    "for i in range(len(name)):\n",
    "    plt.plot(df1[name[i]]/df1[name[i]].loc[df['Date'][0]]*100)\n",
    "        \n",
    "plt.legend(name,loc=0)\n",
    "plt.grid(True,color='0.7',linestyle=':',linewidth=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def stock_volume and price_graph():  여러개 입력가능\n",
    "\n",
    "import io\n",
    "import json\n",
    "import sys\n",
    "from fake_useragent import UserAgent\n",
    "import FinanceDataReader as fdr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime as dt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from datetime import datetime,timedelta\n",
    "from urllib.request import urlopen\n",
    "import urllib.request as req\n",
    "import sqlalchemy \n",
    "import pymysql\n",
    "import talib.abstract as ta\n",
    "from talib import RSI, BBANDS\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "from matplotlib import font_manager, rc\n",
    "plt.rcParams.update({'figure.max_open_warning': 0})\n",
    "font_name = font_manager.FontProperties(fname=\"c:/Windows/Fonts/malgun.ttf\").get_name()\n",
    "rc('font', family=font_name)\n",
    "\n",
    "today = datetime.now()\n",
    "real_yesterday = (today-timedelta(1)).strftime('%Y-%m-%d')\n",
    "real_today = today.strftime('%Y-%m-%d')\n",
    "date_list = ['2008-01-01','2013-01-01','2018-01-01','2019-01-01']\n",
    "\n",
    "now = dt.datetime.today().strftime('%Y-%m-%d')\n",
    "engine = sqlalchemy.create_engine('mysql+pymysql://kkang:leaf2027@localhost/stock?charset=utf8',encoding='utf-8')\n",
    "conn = pymysql.connect(host = 'localhost', user = 'kkang', password = 'leaf2027' ,db = 'stock')\n",
    "curs = conn.cursor()\n",
    "\n",
    "path_price = 'd:\\\\stockdata\\\\vote_stock\\\\detect_stock_with_price_'\n",
    "path_volume = 'd:\\\\stockdata\\\\vote_stock\\\\detect_stock_with_volume_'\n",
    "path = 'd:\\\\stockdata\\\\close_ma120\\\\close_ma120_'\n",
    "path_total = 'd:\\\\stockdata\\\\close_ma120\\\\total_'\n",
    "path_total_f = 'd:\\\\stockdata\\\\close_ma120\\\\total_filter_'\n",
    "path_total_a = 'd:\\\\stockdata\\\\close_ma120\\\\total_a_'\n",
    "path_total_b = 'd:\\\\stockdata\\\\close_ma120\\\\total_b_'\n",
    "path_total_c = 'd:\\\\stockdata\\\\close_ma120\\\\total_c_'\n",
    "\n",
    "def select_market(name,date):\n",
    "    select_query = \"select * from \"\n",
    "    date_query = \" where Date > \"    \n",
    "    var = select_query + name + date_query+\"'\"+date+\"'\" \n",
    "    df = pd.read_sql(var, engine)\n",
    "    return df\n",
    "\n",
    "def min_max(df,select):\n",
    "    ma(df)\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close',select,'volume']].values)\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1.columns=['close',select,'volume']\n",
    "    df1 = df1.set_index(df['date'])\n",
    "    return df1\n",
    "\n",
    "def ma(DataFrame):\n",
    "    df = DataFrame\n",
    "    df.columns=df.columns.str.lower()\n",
    "    df[['volume','close']] = df[['volume','close']].astype(float) #  TA-Lib로 평균을 구하려면 실수로 만들어야 함\n",
    "\n",
    "    talib_ma5 = ta.MA(df, timeperiod=5)\n",
    "    df['ma5'] = talib_ma5\n",
    "    \n",
    "    talib_ma10 = ta.MA(df, timeperiod=10)\n",
    "    df['ma10'] = talib_ma10    \n",
    "\n",
    "    talib_ma15 = ta.MA(df, timeperiod=15)\n",
    "    df['ma15'] = talib_ma15\n",
    "\n",
    "    talib_ma20 = ta.MA(df, timeperiod=20)\n",
    "    df['ma20'] = talib_ma20\n",
    "    \n",
    "    talib_ma30 = ta.MA(df, timeperiod=30)\n",
    "    df['ma30'] = talib_ma30    \n",
    "    \n",
    "    talib_ma60 = ta.MA(df, timeperiod=60)\n",
    "    df['ma60'] = talib_ma60    \n",
    "    \n",
    "    talib_ma120 = ta.MA(df, timeperiod=120)\n",
    "    df['ma120'] = talib_ma120  \n",
    "\n",
    "    \n",
    "def market_ma(df,select1,select2):\n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close',select1,select2]].values)\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1.columns=['close',select1,select2]\n",
    "    df1 = df1.set_index(df['date'])\n",
    "    df1.plot(figsize=(16,4))\n",
    "    plt.title(df['market'][0])\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def get_graph(choice=1):\n",
    "    graph_name_list=['stock','money', 'program','future']\n",
    "    date='2018-01-01'\n",
    "    future_date='2019-12-11'  ##  선물마감 하루전\n",
    "    if choice == 1:\n",
    "        df = select_market('kospi','2015-01-01')\n",
    "        market_ma(df,'ma60','ma120')\n",
    "        df = select_market('kosdaq','2015-01-01')\n",
    "        market_ma(df,'ma60','ma120')\n",
    "      \n",
    "        kpi200_df = pd.read_sql(\"select Date from kpi200 order by Date desc limit 2\", engine)\n",
    "        yesterday = str(kpi200_df['Date'][1])\n",
    "        today = str(kpi200_df['Date'][0])\n",
    "        \n",
    "      \n",
    "        for i in graph_name_list:\n",
    "            if i == 'stock' :\n",
    "                name = pd.read_excel(path_volume+today+'.xlsx', encoding='utf-8')\n",
    "                name_all = name['Name']\n",
    "                name_all = name_all.to_list()\n",
    "                \n",
    "                name = name['Name']\n",
    "                name = name[0:2]\n",
    "                name = name.to_list()\n",
    "                print(name)\n",
    "\n",
    "                select_query = \"select Date,Volume,Close from market where Name= \"\n",
    "                date_query = \"Date > \"\n",
    "\n",
    "\n",
    "                tuple_name=tuple(name)\n",
    "                df1 = pd.DataFrame()\n",
    "\n",
    "                for x in tuple_name:\n",
    "                    var = select_query +\"'\"+x+\"'\"+\" \"+\"&&\"+\" \"+date_query+\"'\"+date+\"'\"\n",
    "                    df = pd.read_sql(var ,engine)\n",
    "                    df.columns=['Date',x+'거래량',x]\n",
    "                    if df1.empty:\n",
    "                        df1 = df\n",
    "                    else:\n",
    "                        df1 = pd.merge (df,df1,on='Date')\n",
    "                df1=df1.set_index('Date')\n",
    "                size = len(df1.index)\n",
    "\n",
    "\n",
    "                plt.figure(figsize=(16,4)) \n",
    "                for i in range(len(name)):\n",
    "                    plt.plot(df1[name[i]]/df1[name[i]].loc[df['Date'][0]]*100,label=name[i])\n",
    "                    plt.legend(loc=0)\n",
    "                    plt.grid(True,color='0.7',linestyle=':',linewidth=1)\n",
    "\n",
    "                plt.figure(figsize=(16,4))\n",
    "                for i in range(len(name)):\n",
    "                    volume_average = df1[name[i]+'거래량'].sum(axis=0)/size\n",
    "                    plt.plot(df1[name[i]+'거래량']/volume_average, label=name[i])\n",
    "                    #plt.plot(df1[name[i]+'거래량']/df1[name[i]+'거래량'].loc[df['Date'][0]]*100, label =[name[i]+'거래량'] )\n",
    "                    plt.legend(loc=0)\n",
    "                    plt.grid(True,color='0.7',linestyle=':',linewidth=1)  \n",
    "\n",
    "get_graph(choice=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## def money_trend_graph():\n",
    "    \n",
    "name = input(\"항목을 입력하세요: 선택항목: 'kpi200', '거래량', '고객예탁금', '신용잔고', '주식형펀드', '혼합형펀드', '채권형펀드'\").split()\n",
    "date = input(\"날짜를 입력하세요 sample: '2019-01-10':\")\n",
    "    \n",
    "query = \"select * from kpi_with_money where Date >\"+\"'\"+date+\"'\"\n",
    "    \n",
    "tuple_name=tuple(name)\n",
    "df1 = pd.DataFrame()\n",
    "    \n",
    "df = pd.read_sql(query ,engine)\n",
    "\n",
    "df.columns=['Date','kpi200', '거래량', '고객예탁금', '신용잔고', '주식형펀드', '혼합형펀드', '채권형펀드']\n",
    "df = df.set_index('Date')\n",
    "df1=df[name]\n",
    "\n",
    "\n",
    "for i in range(len(name)):\n",
    "    plt.plot(df1[name[i]]/df1[name[i]].loc[df.index[0]]*100)\n",
    "        \n",
    "plt.legend(loc=0)\n",
    "plt.grid(True,color='0.7',linestyle=':',linewidth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## def money_trend_graph():\n",
    "    \n",
    "name = input(\"항목을 입력하세요: 선택항목: 'kpi200', '거래량', '고객예탁금', '신용잔고', '주식형펀드', '혼합형펀드', '채권형펀드'\").split()\n",
    "date = input(\"날짜를 입력하세요 sample: '2019-01-10':\")\n",
    "    \n",
    "query = \"select * from kpi_with_money where Date >\"+\"'\"+date+\"'\"\n",
    "    \n",
    "tuple_name=tuple(name)\n",
    "df1 = pd.DataFrame()\n",
    "    \n",
    "df = pd.read_sql(query ,engine)\n",
    "\n",
    "df.columns=['Date','kpi200', '거래량', '고객예탁금', '신용잔고', '주식형펀드', '혼합형펀드', '채권형펀드']\n",
    "df = df.set_index('Date')\n",
    "df1=df[name]\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "for i in range(len(name)):\n",
    "    plt.plot(df1[name[i]]/df1[name[i]].loc[df.index[0]]*100)\n",
    "        \n",
    "plt.legend(loc=0)\n",
    "plt.grid(True,color='0.7',linestyle=':',linewidth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## def money_trend_graph():  integrate graph\n",
    "    \n",
    "name = input(\"항목을 입력하세요: 선택항목: 'kpi200', '거래량', '고객예탁금', '신용잔고', '주식형펀드', '혼합형펀드', '채권형펀드'\").split()\n",
    "date = input(\"날짜를 입력하세요 sample: '2019-01-10':\")\n",
    "    \n",
    "query = \"select * from kpi_with_money where Date >\"+\"'\"+date+\"'\"\n",
    "    \n",
    "tuple_name=tuple(name)\n",
    "df1 = pd.DataFrame()\n",
    "    \n",
    "df = pd.read_sql(query ,engine)\n",
    "\n",
    "df.columns=['Date','kpi200', '거래량', '고객예탁금', '신용잔고', '주식형펀드', '혼합형펀드', '채권형펀드']\n",
    "df = df.set_index('Date')\n",
    "df1=df[name]\n",
    "\n",
    "plt.figure(figsize=(16,4))\n",
    "colors = ['red','green','blue','pink','gray']\n",
    "for i in range(len(name)):\n",
    "    plt.subplot(2,2,i+1)\n",
    "    plt.plot(df1[name[i]]/df1[name[i]].loc[df.index[0]]*100,color=colors[i])\n",
    "    \n",
    "    plt.legend(loc=0)\n",
    "    plt.grid(True,color='0.7',linestyle=':',linewidth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 엑셀에서 종목별로 다양한 graph 출력\n",
    "\n",
    "from mod1 import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "\n",
    "def close_ma(df,select1,select2):\n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close',select1,select2]].values)\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1.columns=['close',select1,select2]\n",
    "    df1 = df1.set_index(df['date'])\n",
    "    df1.plot(figsize=(16,4))\n",
    "    plt.title(df['name'][0])\n",
    "    plt.show()\n",
    "\n",
    "def close_ma_vol(df,select1,select2,select3):\n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close',select1,select2,select3]].values)\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1.columns=['close',select1,select2,select3]\n",
    "    df1 = df1.set_index(df['date'])\n",
    "    df1.plot(figsize=(16,4))\n",
    "    plt.title(df['name'][0])\n",
    "    plt.show()    \n",
    "    \n",
    "    \n",
    "path = 'd:\\\\stockdata\\\\close_ma120\\\\close_ma120_'\n",
    "path_total_f = 'd:\\\\stockdata\\\\close_ma120\\\\total_filter_'\n",
    "\n",
    "choice_date='2019-10-01'\n",
    "#df = pd.read_excel(path_total_f+choice_date+'.xlsx')\n",
    "df = pd.read_excel('d:\\\\stockdata\\\\close_ma120\\\\2019_10\\\\total_2019-10-01.xlsx')\n",
    "name_df = df['name']\n",
    "name = name_df.to_list()\n",
    "#name=['hrs','디엔에프','푸드나무','에스퓨얼셀']\n",
    "\n",
    "for i in name:\n",
    "    df = select_stock(i, '2019-10-01')\n",
    "    #close_ma_vol(df,'ma60','ma120','volume')\n",
    "    close_ma(df,'ma5','ma10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## analysis graph (rsi, obv, ma60, ma120, volume)\n",
    "\n",
    "from mod1 import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "\n",
    "def close_ma(df,select1,select2):\n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close',select1,select2]].values)\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1.columns=['close',select1,select2]\n",
    "    df1 = df1.set_index(df['date'])\n",
    "    df1.iloc[14:].plot(grid=True,figsize=(16,4));\n",
    "    plt.title(df['name'][0])\n",
    "    plt.show()\n",
    "\n",
    "def close_ma_vol(df,select1,select2,select3):\n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close',select1,select2,select3]].values)\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1.columns=['close',select1,select2,select3]\n",
    "    df1 = df1.set_index(df['date'])\n",
    "    df1.iloc[14:].plot(grid=True,figsize=(16,4));\n",
    "    plt.title(df['name'][0])\n",
    "    plt.show()    \n",
    "    \n",
    "def rsi(df):\n",
    "    df = df.set_index('date')\n",
    "    talib_rsi = ta.RSI(df, timeperiod=14)\n",
    "    talib_rsi.iloc[14:].plot( grid=True,figsize=(16,4))\n",
    "    plt.fill_between(df.index,y1=30, y2=70, color='#adccff', alpha='0.3')\n",
    "    plt.show()\n",
    "    \n",
    "def obv(df):\n",
    "    df = df.set_index('date')\n",
    "    real = ta.OBV(df)\n",
    "    real.iloc[14:].plot( y=['volume'], grid=True,figsize=(16,4));\n",
    "    plt.show()\n",
    "    \n",
    "name = ['서원','hrs']   \n",
    "for i in name:\n",
    "    df = select_stock(i,'2016-04-01')\n",
    "    close_ma(df,'ma60','ma120')\n",
    "    rsi(df)\n",
    "    obv(df)\n",
    "    close_ma_vol(df,'ma60','ma120','volume')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Crawling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 상장회사 종가확인\n",
    "# 브라우저 실행\n",
    "from selenium import webdriver\n",
    "driver = webdriver.Chrome('C:/Users/kkang/selenium/chromedriver.exe')\n",
    "\n",
    "# 상장회사검색\n",
    "driver.get('http://marketdata.krx.co.kr/mdi#document=040602')\n",
    "\n",
    "# 다운로드 버튼을 클릭\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "button = driver.find_element(By.XPATH, '//button[text()=\"Excel\"]')\n",
    "button.click()\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "# 다운로드 폴더로 이동\n",
    "folder = 'c:\\\\Users\\\\kkang\\\\Downloads'\n",
    "os.chdir(folder)\n",
    "\n",
    "# 파일 다운로드까지 대기 (1초씩 최대 30회)\n",
    "fname = 'data.xls'\n",
    "for _ in range(30):\n",
    "    if os.path.exists(fname):\n",
    "        break\n",
    "    time.sleep(1)\n",
    "\n",
    "# 파일명 바꾸기\n",
    "os.rename('data.xls', 'price.xls')\n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 일별 관리종목 추출\n",
    "\n",
    "from  datetime import datetime\n",
    "import pandas as pd\n",
    "import xlsxwriter\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "today = datetime.now()\n",
    "today = today.strftime(\"%Y-%m-%d\")\n",
    "#today=input('입력')\n",
    "#url = 'http://finance.naver.com/sise/investorDealTrendDay.nhn?bizdate=2020601&sosok=&page=1'\n",
    "url = 'https://finance.naver.com/sise/management.nhn'\n",
    "source = urlopen(url).read()   # 지정한 페이지에서 코드 읽기\n",
    "source = BeautifulSoup(source, 'lxml')   # 뷰티풀 스프로 태그별로 코드 분류\n",
    "data = []\n",
    "\n",
    "path = 'd:\\\\stockdata\\\\관리종목\\\\'+today+'.xlsx'\n",
    "body = source.find('body')\n",
    "trs = body.find_all('tr')\n",
    "name = []\n",
    "for tr in trs:\n",
    "    tds = tr.find_all('a',{'class':\"tltle\"})\n",
    "    for td in tds:\n",
    "        name.append(td.text.strip())\n",
    "\n",
    "df = pd.DataFrame(name)\n",
    "df['Date']=str(today)\n",
    "df = df.set_index('Date')\n",
    "df.columns=['Name']\n",
    "df.to_excel(path)\n",
    "df = pd.read_excel(path)\n",
    "df.to_sql(name='badstock', con=engine, if_exists='append', index = False)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### pykrx 모듈을 통한 krx 웹 crawling\n",
    "\n",
    "from pykrx.comm.util import dataframe_empty_handler, singleton\n",
    "from pykrx.comm.http import KrxHttp\n",
    "from pandas import DataFrame\n",
    "import pandas as pd\n",
    "from pykrx import stock\n",
    "\n",
    "a = stock.market.ticker._StockFinder()\n",
    "b = stock.market.ticker._StockTicker()\n",
    "df_a = a.read()\n",
    "df_b = b._get_stock_info_listed()\n",
    "df_finder_kosdaq = df_a[df_a['marketName']=='KOSDAQ']\n",
    "df_finder_kospi = df_a[df_a['marketName']=='KOSPI']\n",
    "#display(df_kosdaq.reset_index(drop=True))\n",
    "#display(df_kospi.reset_index(drop=True))\n",
    "\n",
    "df_ticker_kosdaq = df_b[df_b['시장']=='KOSDAQ']\n",
    "df_ticker_kospi = df_b[df_b['시장']=='KOSPI']\n",
    "\n",
    "df_finder_kosdaq.to_excel('d:\\\\find_kosdaq.xlsx')\n",
    "df_finder_kospi.to_excel('d:\\\\find_kospi.xlsx')\n",
    "df_ticker_kosdaq.to_excel('d:\\\\tick_kosdaq.xlsx')\n",
    "df_ticker_kospi.to_excel('d:\\\\tick_kospi.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock Prediction 관련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  상승추세 종목 발굴 _1\n",
    "\n",
    "## market_good table에서 모든 colume 추출\n",
    "def market_stock(date):\n",
    "    select_query = \"select * from market_good where Date >  \"\n",
    "    var = select_query +\"'\"+date+\"'\" \n",
    "    df = pd.read_sql(var, engine)\n",
    "    return df\n",
    "\n",
    "from mod1 import *\n",
    "\n",
    "## 개별종목이름 리스트 생성\n",
    "df = market_stock('2019-01-01')\n",
    "stock_name=df['Name'].drop_duplicates()\n",
    "stock_name = stock_name.tolist()\n",
    "\n",
    "## 종목별로 이동평균선(ma5 ~ ma120)생성\n",
    "ma_df = pd.DataFrame()\n",
    "for name in stock_name:\n",
    "    print(name)\n",
    "    df1 = df[(df['Name'] == name)]\n",
    "    ma(df1)\n",
    "    ma_df=ma_df.append(df1)\n",
    "    \n",
    "#df3.to_excel('d:\\\\good_stock.xlsx')\n",
    "\n",
    "##  현재 today 종가가 ma120일선 위에있는 (상승추세에있는) 종목 추출\n",
    "df1 = ma_df[['date','code','name','close','volume','ma120']]\n",
    "df2 = df1[(df1['date'].astype(str) == '2019-09-30')]\n",
    "df3 = df2[(df2['close'] >= df2['ma120'])]\n",
    "df3\n",
    "\n",
    "## 상승추세종목 리스트 생성\n",
    "good_name=df3['name']\n",
    "good_name = good_name.tolist()\n",
    "\n",
    "## 상승추세 종목 그래프 생성 \n",
    "for i in good_name:\n",
    "    df=select_stock(i,'17-01-01')\n",
    "    df1 = close_vol_ma(df,'ma120')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  상승추세 종목 발굴 _2\n",
    "##  상승추세종목을 표준화하여 세부적으로 추출\n",
    "\n",
    "from mod1 import *\n",
    "\n",
    "## 개별종목이름 리스트 생성\n",
    "all_df = market_stock('2019-01-01')\n",
    "stock_name=all_df['Name'].drop_duplicates()\n",
    "stock_name = stock_name.tolist()\n",
    "\n",
    "## 종목별로 이동평균선(ma5 ~ ma120)생성\n",
    "ma_df = pd.DataFrame()\n",
    "min_max_df = pd.DataFrame()\n",
    "for name in stock_name:\n",
    "    print(name)\n",
    "    all_df1 = all_df[(all_df['Name'] == name)]\n",
    "    ma(all_df1)\n",
    "    ma_df=ma_df.append(all_df1)\n",
    "    \n",
    "#df3.to_excel('d:\\\\good_stock.xlsx')\n",
    "\n",
    "##  현재 today 종가가 ma120일선 위에있는 (상승추세에있는) 종목 추출\n",
    "first_df1 = ma_df[['date','code','name','close','volume','ma120']]\n",
    "first_df2 = first_df1[(first_df1['date'].astype(str) == '2019-09-30')]\n",
    "first_df3 = first_df2[(first_df2['close'] >= first_df2['ma120'])]\n",
    "first_df3\n",
    "\n",
    "## 상승추세종목 리스트 생성\n",
    "good_name=first_df3['name']\n",
    "good_name = good_name.tolist()\n",
    "\n",
    "## 상승추세종목별로 표준화 (MinMaxSchalr)생성\n",
    "good_stock_df = pd.DataFrame()\n",
    "min_max_df = pd.DataFrame()\n",
    "for name in good_name:\n",
    "    print(name)\n",
    "    good_df1 = select_stock(name,'2019-01-01')\n",
    "    good_stock_df=good_stock_df.append(good_df1)\n",
    "    min_max_df1 = min_max(good_df1,'ma120')\n",
    "    min_max_df=min_max_df.append(min_max_df1)\n",
    "\n",
    "good_stock_df1 = good_stock_df.set_index('Date')\n",
    "min_max_df[['code','name']]=good_stock_df1[['Code','Name']]\n",
    "\n",
    "second_df1 = min_max_df\n",
    "second_df2 = second_df1[(second_df1.index.astype(str) == real_yesterday)]\n",
    "second_df3 = second_df2[(second_df2['close'] <= 0.3) & (second_df2['ma120'] <=0.3)]\n",
    "second_df3\n",
    "\n",
    "## 표준화로 선별한 상승추세종목 리스트 생성\n",
    "min_max_name=second_df3['name']\n",
    "min_max_name = min_max_name.tolist()\n",
    "\n",
    "## 표준화로 선별한 추세 종목 그래프 생성 \n",
    "for i in min_max_name:\n",
    "    all_df=select_stock(i,'17-01-01')\n",
    "    all_df1 = close_vol_ma(all_df,'ma120')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  상승추세 종목 발굴 _3\n",
    "##  상승추세종목을 표준화 함수를 통합하여  속도 향상\n",
    "\n",
    "from mod1 import *\n",
    "\n",
    "all_df = market_stock('2019-10-01')\n",
    "stock_name=all_df['Name'].drop_duplicates()\n",
    "stock_name = stock_name.tolist()\n",
    "\n",
    "## 상승추세종목별로 표준화 (MinMaxSchalr)생성\n",
    "good_stock_df = pd.DataFrame()\n",
    "min_max_df = pd.DataFrame()\n",
    "\n",
    "for name in stock_name:\n",
    "    print(name)\n",
    "    good_df1 = select_stock(name,'2017-01-01')\n",
    "    min_max_df1 = min_max(good_df1,'ma120')\n",
    "    good_stock_df=good_stock_df.append(good_df1)\n",
    "    min_max_df=min_max_df.append(min_max_df1)\n",
    "\n",
    " \n",
    "good_stock_df1 = good_stock_df.set_index('date')\n",
    "min_max_df[['code','name']]=good_stock_df1[['code','name']]\n",
    " \n",
    "second_df1 = min_max_df\n",
    "second_df2 = second_df1[(second_df1.index.astype(str) == '2019-10-02')]\n",
    "second_df3 = second_df2[(second_df2['close'] <= 0.05)]\n",
    "second_df3\n",
    "\n",
    "## 표준화로 선별한 상승추세종목 리스트 생성\n",
    "min_max_name=second_df3['name']\n",
    "min_max_name = min_max_name.tolist()\n",
    "\n",
    "## 표준화로 선별한 추세 종목 그래프 생성 \n",
    "for i in min_max_name:\n",
    "    all_df=select_stock(i,'17-01-01')\n",
    "    all_df1 = close_vol_ma(all_df,'ma120')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Stock Prediction 30 days\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from tqdm import tqdm\n",
    "sns.set()\n",
    "tf.set_random_seed(777)  # reproducibility\n",
    "tf.reset_default_graph()\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter('ignore')\n",
    "\n",
    "import sqlalchemy\n",
    "\n",
    "engine = sqlalchemy.create_engine('mysql+pymysql://kkang:leaf2027@localhost/stock?charset=utf8',encoding='utf-8')\n",
    "var =\"select * from market where Name='HRS' and  Date > '2019-01-01'\" \n",
    "df = pd.read_sql(var ,engine)\n",
    "df.head()\n",
    "\n",
    "minmax = MinMaxScaler().fit(df.iloc[:, 7:].astype('float32')) # Close index\n",
    "df_log = minmax.transform(df.iloc[:, 7:].astype('float32')) # Close index\n",
    "df_log = pd.DataFrame(df_log)\n",
    "df_log.head()\n",
    "\n",
    "simulation_size = 10\n",
    "num_layers = 1\n",
    "size_layer = 128\n",
    "timestamp = 5\n",
    "epoch = 300\n",
    "dropout_rate = 0.8\n",
    "test_size = 30\n",
    "learning_rate = 0.01\n",
    "\n",
    "df_train = df_log\n",
    "df.shape, df_train.shape\n",
    "\n",
    "class Model:\n",
    "    def __init__(\n",
    "        self,\n",
    "        learning_rate,\n",
    "        num_layers,\n",
    "        size,\n",
    "        size_layer,\n",
    "        output_size,\n",
    "        forget_bias = 0.1,\n",
    "    ):\n",
    "        def lstm_cell(size_layer):\n",
    "            return tf.nn.rnn_cell.LSTMCell(size_layer, state_is_tuple = False)\n",
    "\n",
    "        rnn_cells = tf.nn.rnn_cell.MultiRNNCell(\n",
    "            [lstm_cell(size_layer) for _ in range(num_layers)],\n",
    "            state_is_tuple = False,\n",
    "        )\n",
    "        self.X = tf.placeholder(tf.float32, (None, None, size))\n",
    "        self.Y = tf.placeholder(tf.float32, (None, output_size))\n",
    "        drop = tf.contrib.rnn.DropoutWrapper(\n",
    "            rnn_cells, output_keep_prob = forget_bias\n",
    "        )\n",
    "        self.hidden_layer = tf.placeholder(\n",
    "            tf.float32, (None, num_layers * 2 * size_layer)\n",
    "        )\n",
    "        self.outputs, self.last_state = tf.nn.dynamic_rnn(\n",
    "            drop, self.X, initial_state = self.hidden_layer, dtype = tf.float32\n",
    "        )\n",
    "        self.logits = tf.layers.dense(self.outputs[-1], output_size)\n",
    "        self.cost = tf.reduce_mean(tf.square(self.Y - self.logits))\n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate).minimize(\n",
    "            self.cost\n",
    "        )\n",
    "        \n",
    "def calculate_accuracy(real, predict):\n",
    "    real = np.array(real) + 1\n",
    "    predict = np.array(predict) + 1\n",
    "    percentage = 1 - np.sqrt(np.mean(np.square((real - predict) / real)))\n",
    "    return percentage * 100\n",
    "\n",
    "def anchor(signal, weight):\n",
    "    buffer = []\n",
    "    last = signal[0]\n",
    "    for i in signal:\n",
    "        smoothed_val = last * weight + (1 - weight) * i\n",
    "        buffer.append(smoothed_val)\n",
    "        last = smoothed_val\n",
    "    return buffer\n",
    "\n",
    "def forecast():\n",
    "    tf.reset_default_graph()\n",
    "    modelnn = Model(\n",
    "        learning_rate, num_layers, df_log.shape[1], size_layer, df_log.shape[1], dropout_rate\n",
    "    )\n",
    "    sess = tf.InteractiveSession()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    date_ori = pd.to_datetime(df.iloc[:, 0]).tolist()\n",
    "\n",
    "    pbar = tqdm(range(epoch), desc = 'train loop')\n",
    "    for i in pbar:\n",
    "        init_value = np.zeros((1, num_layers * 2 * size_layer))\n",
    "        total_loss, total_acc = [], []\n",
    "        for k in range(0, df_train.shape[0] - 1, timestamp):\n",
    "            index = min(k + timestamp, df_train.shape[0] - 1)\n",
    "            batch_x = np.expand_dims(\n",
    "                df_train.iloc[k : index, :].values, axis = 0\n",
    "            )\n",
    "            batch_y = df_train.iloc[k + 1 : index + 1, :].values\n",
    "            logits, last_state, _, loss = sess.run(\n",
    "                [modelnn.logits, modelnn.last_state, modelnn.optimizer, modelnn.cost],\n",
    "                feed_dict = {\n",
    "                    modelnn.X: batch_x,\n",
    "                    modelnn.Y: batch_y,\n",
    "                    modelnn.hidden_layer: init_value,\n",
    "                },\n",
    "            )        \n",
    "            init_value = last_state\n",
    "            total_loss.append(loss)\n",
    "            total_acc.append(calculate_accuracy(batch_y[:, 0], logits[:, 0]))\n",
    "        pbar.set_postfix(cost = np.mean(total_loss), acc = np.mean(total_acc))\n",
    "    \n",
    "    future_day = test_size\n",
    "\n",
    "    output_predict = np.zeros((df_train.shape[0] + future_day, df_train.shape[1]))\n",
    "    output_predict[0] = df_train.iloc[0]\n",
    "    upper_b = (df_train.shape[0] // timestamp) * timestamp\n",
    "    init_value = np.zeros((1, num_layers * 2 * size_layer))\n",
    "\n",
    "    for k in range(0, (df_train.shape[0] // timestamp) * timestamp, timestamp):\n",
    "        out_logits, last_state = sess.run(\n",
    "            [modelnn.logits, modelnn.last_state],\n",
    "            feed_dict = {\n",
    "                modelnn.X: np.expand_dims(\n",
    "                    df_train.iloc[k : k + timestamp], axis = 0\n",
    "                ),\n",
    "                modelnn.hidden_layer: init_value,\n",
    "            },\n",
    "        )\n",
    "        init_value = last_state\n",
    "        output_predict[k + 1 : k + timestamp + 1] = out_logits\n",
    "\n",
    "    if upper_b != df_train.shape[0]:\n",
    "        out_logits, last_state = sess.run(\n",
    "            [modelnn.logits, modelnn.last_state],\n",
    "            feed_dict = {\n",
    "                modelnn.X: np.expand_dims(df_train.iloc[upper_b:], axis = 0),\n",
    "                modelnn.hidden_layer: init_value,\n",
    "            },\n",
    "        )\n",
    "        output_predict[upper_b + 1 : df_train.shape[0] + 1] = out_logits\n",
    "        future_day -= 1\n",
    "        date_ori.append(date_ori[-1] + timedelta(days = 1))\n",
    "\n",
    "    init_value = last_state\n",
    "    \n",
    "    for i in range(future_day):\n",
    "        o = output_predict[-future_day - timestamp + i:-future_day + i]\n",
    "        out_logits, last_state = sess.run(\n",
    "            [modelnn.logits, modelnn.last_state],\n",
    "            feed_dict = {\n",
    "                modelnn.X: np.expand_dims(o, axis = 0),\n",
    "                modelnn.hidden_layer: init_value,\n",
    "            },\n",
    "        )\n",
    "        init_value = last_state\n",
    "        output_predict[-future_day + i] = out_logits[-1]\n",
    "        date_ori.append(date_ori[-1] + timedelta(days = 1))\n",
    "    \n",
    "    output_predict = minmax.inverse_transform(output_predict)\n",
    "    deep_future = anchor(output_predict[:, 0], 0.4)\n",
    "    \n",
    "    return deep_future\n",
    "\n",
    "results = []\n",
    "for i in range(simulation_size):\n",
    "    print('simulation %d'%(i + 1))\n",
    "    results.append(forecast())\n",
    "    \n",
    "date_ori = pd.to_datetime(df.iloc[:, 0]).tolist()\n",
    "for i in range(test_size):\n",
    "    date_ori.append(date_ori[-1] + timedelta(days = 1))\n",
    "date_ori = pd.Series(date_ori).dt.strftime(date_format = '%Y-%m-%d').tolist()\n",
    "date_ori[-5:]\n",
    "\n",
    "accepted_results = []\n",
    "for r in results:\n",
    "    if (np.array(r[-test_size:]) < np.min(df['Close'])).sum() == 0 and \\\n",
    "    (np.array(r[-test_size:]) > np.max(df['Close']) * 2).sum() == 0:\n",
    "        accepted_results.append(r)\n",
    "len(accepted_results)\n",
    "\n",
    "accuracies = [calculate_accuracy(df['Close'].values, r[:-test_size]) for r in accepted_results]\n",
    "\n",
    "plt.figure(figsize = (15, 5))\n",
    "for no, r in enumerate(accepted_results):\n",
    "    plt.plot(r, label = 'forecast %d'%(no + 1))\n",
    "plt.plot(df['Close'], label = 'true trend', c = 'black')\n",
    "plt.legend()\n",
    "plt.title('average accuracy: %.4f'%(np.mean(accuracies)))\n",
    "\n",
    "x_range_future = np.arange(len(results[0]))\n",
    "plt.xticks(x_range_future[::30], date_ori[::30])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## MinMaxScaller() 변조및 복조\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "connect = create_engine('mysql+pymysql://kkang:leaf2027@localhost/stock?charset=utf8',encoding='utf-8')\n",
    "df = pd.read_sql(\"SELECT * from market where Code = '036640' and date > '2019-08-05'\", connect)\n",
    "\n",
    "df = df[['Open', 'High', 'Low', 'Volume', 'Close']]\n",
    "\n",
    "dataset = df.values\n",
    "\n",
    "source = MinMaxScaler() # default is 0,1\n",
    "dataset = source.fit_transform(dataset) ### MinMaxScaler 변조\n",
    "\n",
    "display(dataset)\n",
    "print('='*100)\n",
    "\n",
    "source.inverse_transform(dataset) ### MinMaxScaler 복조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## 이동 평균선\n",
    "\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "file = 'd:\\\\hrs.xlsx'\n",
    "\n",
    "connect = create_engine('mysql+pymysql://kkang:leaf2027@localhost/stock?charset=utf8',encoding='utf-8')\n",
    "df = pd.read_sql(\"SELECT * from market where Name = 'hrs' && Date > '2019-01-05'\", connect)\n",
    "\n",
    "volume_average_5 = df['Volume'].rolling(window=5,min_periods=1).mean()\n",
    "volume_average_10 = df['Volume'].rolling(window=10,min_periods=1).mean()\n",
    "volume_average_20 = df['Volume'].rolling(window=20,min_periods=1).mean()\n",
    "volume_average_60 = df['Volume'].rolling(window=60,min_periods=1).mean()\n",
    "volume_average_120 = df['Volume'].rolling(window=120,min_periods=1).mean()\n",
    "\n",
    "close_average_5 = df['Close'].rolling(window=5,min_periods=1).mean()\n",
    "close_average_10 = df['Close'].rolling(window=10,min_periods=1).mean()\n",
    "close_average_20 = df['Close'].rolling(window=20,min_periods=1).mean()\n",
    "close_average_60 = df['Close'].rolling(window=60,min_periods=1).mean()\n",
    "close_average_120 = df['Close'].rolling(window=120,min_periods=1).mean()\n",
    "\n",
    "df.insert(len(df.columns), \"Vol_MA5\", volume_average_5)\n",
    "df.insert(len(df.columns), \"Vol_MA10\", volume_average_10)\n",
    "df.insert(len(df.columns), \"Vol_MA20\", volume_average_20)\n",
    "df.insert(len(df.columns), \"Vol_MA60\", volume_average_60)\n",
    "df.insert(len(df.columns), \"Vol_MA120\", volume_average_120)\n",
    "\n",
    "df.insert(len(df.columns), \"Close_MA5\", close_average_5)\n",
    "df.insert(len(df.columns), \"Close_MA10\", close_average_10)\n",
    "df.insert(len(df.columns), \"Close_MA20\", close_average_20)\n",
    "df.insert(len(df.columns), \"Close_MA60\", close_average_60)\n",
    "df.insert(len(df.columns), \"Close_MA120\", close_average_120)\n",
    "\n",
    "df1 = df[['Date','Name','Close','Volume','Vol_MA5','Vol_MA10','Vol_MA20','Vol_MA60','Vol_MA120']]\n",
    "#df1.to_excel(file)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###  RSI\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "import talib.abstract as ta # talib.abstract는 Series나 numpy가 아닌 DataFrame도 대입가능\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import pandas_datareader.data as web\n",
    "import numpy as np\n",
    "from talib import RSI, BBANDS\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "file = 'd:\\\\hrs.xlsx'\n",
    "connect = create_engine('mysql+pymysql://kkang:leaf2027@localhost/stock?charset=utf8',encoding='utf-8')\n",
    "df = pd.read_sql(\"SELECT * from market where Name = 'hrs' && Date > '2019-01-05'\", connect)\n",
    "display(df.head())\n",
    "\n",
    "df = df.set_index('Date')\n",
    "df.columns = df.columns.str.lower()\n",
    "df[['open','high','low','volume','close']] = df[['open','high','low','volume','close']].astype(float)\n",
    "#df = df[['open','high','low','volume','close']]\n",
    "display(df.head())\n",
    "\n",
    "ta_ma5 = ta.MA(df,timeperiod=5 )\n",
    "display(ta_ma5.head())\n",
    "\n",
    "close = df['close'].values\n",
    "up, mid, low = BBANDS(close, timeperiod=20, nbdevup=2, nbdevdn=2, matype=0)\n",
    "df['BB_up']=up\n",
    "df['BB_mid']=mid\n",
    "df['BB_low']=low\n",
    "\n",
    "rsi = RSI(close, timeperiod=14)\n",
    "print(\"RSI (first 10 elements)\\n\", rsi[14:24])\n",
    "df['RSI']=rsi\n",
    "display(df['RSI'].head())\n",
    "\n",
    "up, mid, low = BBANDS(close, timeperiod=20, nbdevup=2, nbdevdn=2, matype=0)\n",
    "bbp = (df['close'] - low) / (up - low)\n",
    "df['BBP']=bbp\n",
    "display(bbp.head())\n",
    "\n",
    "index=df.index\n",
    "max_holding = 100\n",
    "\n",
    "holdings = pd.DataFrame(index=df.index, data={'Holdings': np.array([np.nan] * index.shape[0])})\n",
    "holdings.loc[((df['RSI'] < 30) & (df['BBP'] < 0)), 'Holdings'] = max_holding\n",
    "holdings.loc[((df['RSI'] > 70) & (df['BBP'] > 1)), 'Holdings'] = 0\n",
    "holdings.ffill(inplace=True)\n",
    "holdings.fillna(0, inplace=True)\n",
    "\n",
    "holdings['Order'] = holdings.diff()\n",
    "holdings.dropna(inplace=True)\n",
    "\n",
    "fig, (ax0, ax1, ax2) = plt.subplots(3, 1, sharex=True, figsize=(12, 8))\n",
    "ax0.plot(index, df['close'], label='Close')\n",
    "ax0.set_xlabel('Date')\n",
    "ax0.set_ylabel('close')\n",
    "ax0.grid()\n",
    "\n",
    "for day, holding in holdings.iterrows():\n",
    "    order = holding['Order']\n",
    "    if order > 0:\n",
    "        ax0.scatter(x=day, y=df.loc[day, 'close'], color='green')\n",
    "    elif order < 0:\n",
    "        ax0.scatter(x=day, y=df.loc[day, 'close'], color='red')\n",
    "\n",
    "ax1.plot(index, df['RSI'], label='RSI')\n",
    "ax1.fill_between(index, y1=30, y2=70, color='#adccff', alpha='0.3')\n",
    "ax1.set_xlabel('Date')\n",
    "ax1.set_ylabel('RSI')\n",
    "ax1.grid()\n",
    "\n",
    "ax2.plot(index, df['BB_up'], label='BB_up')\n",
    "ax2.plot(index, df['close'], label='AdjClose')\n",
    "ax2.plot(index, df['BB_low'], label='BB_low')\n",
    "ax2.fill_between(index, y1=df['BB_low'], y2=df['BB_up'], color='#adccff', alpha='0.3')\n",
    "ax2.set_xlabel('Date')\n",
    "ax2.set_ylabel('Bollinger Bands')\n",
    "ax2.grid()\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  ta-lib 이동평균선 그래프 출력\n",
    "\n",
    "import talib.abstract as ta\n",
    "import FinanceDataReader as fdr\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime as dt\n",
    "from datetime import datetime,timedelta\n",
    "from urllib.request import urlopen\n",
    "import sqlalchemy \n",
    "import pymysql\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "from matplotlib import font_manager, rc\n",
    "font_name = font_manager.FontProperties(fname=\"c:/Windows/Fonts/malgun.ttf\").get_name()\n",
    "rc('font', family=font_name)\n",
    "\n",
    "now = dt.datetime.today().strftime('%Y-%m-%d')\n",
    "engine = sqlalchemy.create_engine('mysql+pymysql://kkang:leaf2027@localhost/stock?charset=utf8',encoding='utf-8')\n",
    "\n",
    "\n",
    "df = pd.read_sql(\"SELECT * from market where Code = '036640' and date > '2019-01-05'\", engine)\n",
    "df = df.set_index('Date')\n",
    "df[['Open','High','Low','Volume','Close']] = df[['Open','High','Low','Volume','Close']].astype(float) #  TA-Lib로 평균을 구하려면 실수로 만들어야 함\n",
    "df.columns=df.columns.str.lower()\n",
    "\n",
    "talib_ma5 = ta.MA(df, timeperiod=5)\n",
    "df['ma5'] = talib_ma5\n",
    "\n",
    "talib_ma10 = ta.MA(df, timeperiod=10)\n",
    "df['ma10'] = talib_ma10\n",
    "\n",
    "talib_ma20 = ta.MA(df, timeperiod=20)\n",
    "df['ma20'] = talib_ma20\n",
    "\n",
    "talib_ma60 = ta.MA(df, timeperiod=60)\n",
    "df['ma60'] = talib_ma60\n",
    "\n",
    "talib_ma120 = ta.MA(df, timeperiod=120)\n",
    "df['ma120'] = talib_ma120\n",
    "\n",
    "display(df.iloc[120:].head())\n",
    "\n",
    "plt.figure(figsize=(16,4))\n",
    "plt.plot(df['ma5'],label='ma5')\n",
    "plt.plot(df['ma10'],label='ma10')\n",
    "plt.plot(df['ma20'],label='ma20')\n",
    "plt.plot(df['ma60'],label='ma60')\n",
    "plt.plot(df['ma120'],label='ma120')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  이동평균선  데이타베이스  일괄입력\n",
    "import time\n",
    "import talib.abstract as ta\n",
    "import FinanceDataReader as fdr\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime as dt\n",
    "from datetime import datetime,timedelta\n",
    "from urllib.request import urlopen\n",
    "import sqlalchemy \n",
    "import pymysql\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "from matplotlib import font_manager, rc\n",
    "font_name = font_manager.FontProperties(fname=\"c:/Windows/Fonts/malgun.ttf\").get_name()\n",
    "rc('font', family=font_name)\n",
    "\n",
    "now = dt.datetime.today().strftime('%Y-%m-%d')\n",
    "engine = sqlalchemy.create_engine('mysql+pymysql://kkang:leaf2027@localhost/stock?charset=utf8',encoding='utf-8')\n",
    "\n",
    "df = pd.read_sql(\"SELECT distinct Name from market \", engine)\n",
    "df = df.set_index('Name')\n",
    "name = df.index\n",
    "for i in range(len(name)):\n",
    "    df = pd.read_sql(\"SELECT * from market where Name =\"+\"'\"+name[i]+\"'\", engine)\n",
    "    line = df.shape[0]   \n",
    "    \n",
    "    df[['Open','High','Low','Volume','Close']] = df[['Open','High','Low','Volume','Close']].astype(float) #  TA-Lib로 평균을 구하려면 실수로 만들어야 함\n",
    "    df.columns=df.columns.str.lower()\n",
    "    #df = df.set_index('date')\n",
    "            \n",
    "    if line >= 120:\n",
    "        talib_ma5 = ta.MA(df, timeperiod=5)\n",
    "        df['ma5'] = talib_ma5\n",
    "\n",
    "        talib_ma10 = ta.MA(df, timeperiod=10)\n",
    "        df['ma10'] = talib_ma10\n",
    "\n",
    "        talib_ma20 = ta.MA(df, timeperiod=20)\n",
    "        df['ma20'] = talib_ma20\n",
    "\n",
    "        talib_ma60 = ta.MA(df, timeperiod=60)\n",
    "        df['ma60'] = talib_ma60\n",
    "\n",
    "        talib_ma120 = ta.MA(df, timeperiod=120)\n",
    "        df['ma120'] = talib_ma120\n",
    "\n",
    "        df_ma = df[['date','code','name','ma5','ma10','ma20','ma60','ma120']].round(2)\n",
    "        df_ma.iloc[:4,3]=df_ma.iloc[4,3]\n",
    "        df_ma.iloc[:9,4]=df_ma.iloc[9,4]\n",
    "        df_ma.iloc[:19,5]=df_ma.iloc[19,5]\n",
    "        df_ma.iloc[:59,6]=df_ma.iloc[59,6]\n",
    "        df_ma.iloc[:119,7]=df_ma.iloc[119,7]        \n",
    "        df_ma.columns=['Date','Code','Name','ma5','ma10','ma20','ma60','ma120']\n",
    "        df_ma.to_sql(name='ma', con=engine, if_exists='append', index = False)  \n",
    "        \n",
    "    elif line >= 60 and line < 120:\n",
    "        talib_ma5 = ta.MA(df, timeperiod=5)\n",
    "        df['ma5'] = talib_ma5\n",
    "        \n",
    "        talib_ma10 = ta.MA(df, timeperiod=10)\n",
    "        df['ma10'] = talib_ma10\n",
    "        \n",
    "        talib_ma20 = ta.MA(df, timeperiod=20)\n",
    "        df['ma20'] = talib_ma20\n",
    "        \n",
    "        talib_ma60 = ta.MA(df, timeperiod=60)\n",
    "        df['ma60'] = talib_ma60\n",
    "        \n",
    "        df_ma = df[['date','code','name','ma5','ma10','ma20','ma60']].round(2)\n",
    "        df_ma.iloc[:4,3]=df_ma.iloc[4,3]\n",
    "        df_ma.iloc[:9,4]=df_ma.iloc[9,4]\n",
    "        df_ma.iloc[:19,5]=df_ma.iloc[19,5]\n",
    "        df_ma.iloc[:59,6]=df_ma.iloc[59,6]        \n",
    "        df_ma.columns=['Date','Code','Name','ma5','ma10','ma20','ma60']\n",
    "        df_ma.to_sql(name='ma', con=engine, if_exists='append', index = False) \n",
    "        \n",
    "    elif line >= 20 and line <60:\n",
    "        talib_ma5 = ta.MA(df, timeperiod=5)\n",
    "        df['ma5'] = talib_ma5\n",
    "        \n",
    "        talib_ma10 = ta.MA(df, timeperiod=10)\n",
    "        df['ma10'] = talib_ma10\n",
    "        \n",
    "        talib_ma20 = ta.MA(df, timeperiod=20)\n",
    "        df['ma20'] = talib_ma20\n",
    "        \n",
    "        df_ma = df[['date','code','name','ma5','ma10','ma20']].round(2)\n",
    "        df_ma.iloc[:4,3]=df_ma.iloc[4,3]\n",
    "        df_ma.iloc[:9,4]=df_ma.iloc[9,4]\n",
    "        df_ma.iloc[:19,5]=df_ma.iloc[19,5]\n",
    "        df_ma.columns=['Date','Code','Name','ma5','ma10','ma20']\n",
    "        df_ma.to_sql(name='ma', con=engine, if_exists='append', index = False)\n",
    "        \n",
    "    elif line >= 10 and line <20:\n",
    "        talib_ma5 = ta.MA(df, timeperiod=5)\n",
    "        df['ma5'] = talib_ma5\n",
    "        \n",
    "        talib_ma10 = ta.MA(df, timeperiod=10)\n",
    "        df['ma10'] = talib_ma10\n",
    "        \n",
    "        df_ma = df[['date','code','name','ma5','ma10']].round(2)\n",
    "        df_ma.iloc[:4,3]=df_ma.iloc[4,3]\n",
    "        df_ma.iloc[:9,4]=df_ma.iloc[9,4] \n",
    "        df_ma.columns=['Date','Code','Name','ma5','ma10']\n",
    "        df_ma.to_sql(name='ma', con=engine, if_exists='append', index = False) \n",
    "        \n",
    "    elif line >= 5 and line <10:\n",
    "        talib_ma5 = ta.MA(df, timeperiod=5)\n",
    "        df['ma5'] = talib_ma5 \n",
    "        \n",
    "        df_ma = df[['date','code','name','ma5']].round(2)\n",
    "        df_ma.iloc[:4,3]=df_ma.iloc[4,3]\n",
    "        df_ma.columns=['Date','Code','Name','ma5']\n",
    "        df_ma.to_sql(name='ma', con=engine, if_exists='append', index = False)\n",
    "        \n",
    "    elif line > 5:\n",
    "        pass\n",
    "  \n",
    "    #df_ma.to_excel('d:\\ma_line.xlsx')\n",
    "    #df_ma.columns=['Date','Code','Name','ma5','ma10','ma20','ma60','ma120']\n",
    "    #df_ma.to_sql(name='ma', con=engine, if_exists='append', index = False)\n",
    "    print(df_ma.head(1))\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 일일 종목선정 project 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## 일일 거래량 50만주이상 주식중 전일 거래량 보다 많은 거래량 top15 종목 \n",
    "\n",
    "import FinanceDataReader as fdr\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime as dt\n",
    "from datetime import datetime,timedelta\n",
    "from urllib.request import urlopen\n",
    "import sqlalchemy \n",
    "import pymysql\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "from matplotlib import font_manager, rc\n",
    "font_name = font_manager.FontProperties(fname=\"c:/Windows/Fonts/malgun.ttf\").get_name()\n",
    "rc('font', family=font_name)\n",
    "\n",
    "today = datetime.now()\n",
    "real_yesterday = (today-timedelta(1)).strftime('%Y-%m-%d')\n",
    "real_today = today.strftime('%Y-%m-%d')\n",
    "\n",
    "now = dt.datetime.today().strftime('%Y-%m-%d')\n",
    "engine = sqlalchemy.create_engine('mysql+pymysql://kkang:leaf2027@localhost/stock?charset=utf8',encoding='utf-8')\n",
    "\n",
    "market_df = pd.read_sql(\"select * from market where Date > '2019-01-01'\", engine)\n",
    "#market_df\n",
    "\n",
    "is_hrs=market_df['Name']=='HRS'\n",
    "hrs_df = market_df[is_hrs]\n",
    "yesterday = str(hrs_df['Date'].iloc[0])\n",
    "today = str(hrs_df['Date'].iloc[1])\n",
    "#print(yesterday)\n",
    "#print(today)\n",
    "\n",
    "#var = \"select * from market where (Date = '2019-01-02' OR Date = '2019-01-03')  and Volume >  500000\"\n",
    "#df = pd.read_sql(var ,engine)\n",
    "#df\n",
    "\n",
    "select_query = \"select * from market where (Date = \"\n",
    "volume_query = \"&& Volume >  500000\"\n",
    "    \n",
    "var = select_query +\"'\"+yesterday+\"'\"+'or Date ='+\"'\"+today+\"'\"+')' + volume_query\n",
    "df = pd.read_sql(var ,engine)\n",
    "\n",
    "#df\n",
    "\n",
    "\n",
    "df1 = df[df['Date'].astype(str) == yesterday]\n",
    "df1 = df1[['Name','Volume','Close']]\n",
    "df1.columns = ['Name','yester_Volume','yester_Close']\n",
    "#display(df1)\n",
    "\n",
    "\n",
    "df2 = df[df['Date'].astype(str) == today]\n",
    "df2 = df2[['Name','Volume','Close']]\n",
    "df2.columns = ['Name','today_Volume','today_Close']\n",
    "#display(df2)\n",
    "\n",
    "df3 = pd.merge(df1,df2,on='Name')\n",
    "df3['Close']=df3['today_Close']/df3['yester_Close']\n",
    "df3['Volume']=df3['today_Volume']/df3['yester_Volume']\n",
    "df3 = df3.sort_values(by=['Volume','Close'],ascending=False)\n",
    "df4 = df3.sort_values(by=['Close','Volume'],ascending=False)\n",
    "df3 = df3.reset_index(drop=True)\n",
    "\n",
    "df3 = df3[:19]\n",
    "df4 = df4.reset_index(drop=True)\n",
    "df4 = df4[:19]\n",
    "df3.to_excel('d:\\\\stockdata\\\\vote_stock\\\\detect_stock_with_volume_'+today+'.xlsx', encoding='utf-8')\n",
    "df4.to_excel('d:\\\\stockdata\\\\vote_stock\\\\detect_stock_with_price_'+today+'.xlsx', encoding='utf-8')        \n",
    "display(df3)\n",
    "display(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## 일일 거래량 50만주이상 주식중 전일 거래량 보다 많은 거래량 top19 종목  for loop 추가 및 화일로 저장\n",
    "\n",
    "import FinanceDataReader as fdr\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime as dt\n",
    "from datetime import datetime,timedelta\n",
    "from urllib.request import urlopen\n",
    "import sqlalchemy \n",
    "import pymysql\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "from matplotlib import font_manager, rc\n",
    "font_name = font_manager.FontProperties(fname=\"c:/Windows/Fonts/malgun.ttf\").get_name()\n",
    "rc('font', family=font_name)\n",
    "\n",
    "today = datetime.now()\n",
    "real_yesterday = (today-timedelta(1)).strftime('%Y-%m-%d')\n",
    "real_today = today.strftime('%Y-%m-%d')\n",
    "\n",
    "now = dt.datetime.today().strftime('%Y-%m-%d')\n",
    "engine = sqlalchemy.create_engine('mysql+pymysql://kkang:leaf2027@localhost/stock?charset=utf8',encoding='utf-8')\n",
    "\n",
    "market_df = pd.read_sql(\"select * from market where Date > '2019-05-01'\", engine)\n",
    "#market_df\n",
    "\n",
    "is_hrs=market_df['Name']=='HRS'\n",
    "hrs_df = market_df[is_hrs]\n",
    "yesterday = str(hrs_df['Date'].iloc[0])\n",
    "today = str(hrs_df['Date'].iloc[1])\n",
    "count = hrs_df.shape[0]\n",
    "#for i in range(hrs_df['Date'].shape[0]):\n",
    "for i in range(count):\n",
    "    yesterday = str(hrs_df['Date'].iloc[i])\n",
    "    today = str(hrs_df['Date'].iloc[i+1])\n",
    "    print('y:{}'.format(yesterday))\n",
    "    print('t:{}'.format(today))\n",
    "    select_query = \"select * from market where (Date = \"\n",
    "    volume_query = \"&& Volume >  500000\"\n",
    "    \n",
    "    var = select_query +\"'\"+yesterday+\"'\"+'or Date ='+\"'\"+today+\"'\"+')' + volume_query\n",
    "    df = pd.read_sql(var ,engine)\n",
    "\n",
    "    #df\n",
    "\n",
    "\n",
    "    df1 = df[df['Date'].astype(str) == yesterday]\n",
    "    df1 = df1[['Name','Volume','Close']]\n",
    "    df1.columns = ['Name','yester_Volume','yester_Close']\n",
    "    #display(df1)\n",
    "\n",
    "\n",
    "    df2 = df[df['Date'].astype(str) == today]\n",
    "    df2 = df2[['Name','Volume','Close']]\n",
    "    df2.columns = ['Name','today_Volume','today_Close']\n",
    "    #display(df2)\n",
    "\n",
    "    df3 = pd.merge(df1,df2,on='Name')\n",
    "    df3['Close']=df3['today_Close']/df3['yester_Close']\n",
    "    df3['Volume']=df3['today_Volume']/df3['yester_Volume']\n",
    "    df3 = df3.sort_values(by=['Volume','Close'],ascending=False)\n",
    "    df4 = df3.sort_values(by=['Close','Volume'],ascending=False)\n",
    "    df3 = df3.reset_index(drop=True)\n",
    "\n",
    "    df3 = df3[:19]\n",
    "    df4 = df4.reset_index(drop=True)\n",
    "    df4 = df4[:19]\n",
    "    df3.to_excel('d:\\\\stockdata\\\\vote_stock\\\\detect_stock_with_volume_'+today+'.xlsx', encoding='utf-8')\n",
    "    df4.to_excel('d:\\\\stockdata\\\\vote_stock\\\\detect_stock_with_price_'+today+'.xlsx', encoding='utf-8')        \n",
    "    display(df3)\n",
    "    display(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  전종목 검색하여  종가 > ma120  일일 비교  하여  관심 종목 추출_1\n",
    "\n",
    "from mod1 import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "\n",
    "\n",
    "path = 'd:\\\\stockdata\\\\close_ma120\\\\close_ma120_'\n",
    "\n",
    "df = all_stock('2019-10-10')\n",
    "df = df['Name']\n",
    "\n",
    "name = df.to_list()\n",
    "\n",
    "df2 = pd.DataFrame()\n",
    "for i in name:\n",
    "    #print(i)\n",
    "    df=select_stock(i,'2010-01-01')\n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close','ma120','volume']].values)\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1['Name']=i\n",
    "    df1.columns=['close','ma120','volume','name',]\n",
    "    df1['date'] = df['date']\n",
    "    #print(df1)\n",
    "    df2 = df2.append(df1)\n",
    "    \n",
    "\n",
    "last = len(df2[df2['name'] == name[0]])-1\n",
    "today_df = df2[df2.index == last]\n",
    "\n",
    "ma120_df = today_df[today_df['close'] > today_df['ma120']]\n",
    "ma120_df = ma120_df.sort_values(['ma120'])\n",
    "\n",
    "today = str(ma120_df.iloc[0,4])\n",
    "ma120_df.to_excel(path+today+'.xlsx', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  전종목 검색하여  종가 > ma120  일일 비교  하여  관심 종목 추출_2  날짜를 지정하여 검색 가능\n",
    "\n",
    "from mod1 import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "\n",
    "choice_date='2019-10-22'\n",
    "path = 'd:\\\\stockdata\\\\close_ma120\\\\close_ma120_'\n",
    "\n",
    "df = all_stock('2019-10-10')\n",
    "df = df['Name']\n",
    "\n",
    "name = df.to_list()\n",
    "\n",
    "df2 = pd.DataFrame()\n",
    "for i in name:\n",
    "    #print(i)\n",
    "    df=select_stock(i,'2010-01-01')\n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close','ma120','volume']].values)\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1['Name']=i\n",
    "    df1.columns=['close','ma120','volume','name',]\n",
    "    df1['date'] = df['date']\n",
    "    #print(df1)\n",
    "    df2 = df2.append(df1)\n",
    "    \n",
    "\n",
    "select_query = \"select count(*) from market_good where Name='hrs' and Date > \"\n",
    "var = select_query +\"'\"+choice_date+\"'\" \n",
    "sql_df = pd.read_sql(var, engine)\n",
    "count = sql_df.values.tolist()\n",
    "back_date = count[0][0]\n",
    "back_date\n",
    "today_df = df2.loc[df2['date'] == (today_df['date'].values[0]-timedelta(back_date))]\n",
    "\n",
    "ma120_df = today_df[today_df['close'] > today_df['ma120']]\n",
    "ma120_df = ma120_df.sort_values(['ma120'])\n",
    "\n",
    "ma120_df.to_excel(path+choice_date+'.xlsx', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  전종목 검색하여  종가 > ma120  일일 비교  하여  관심 종목 추출_3  한달단위로 추출\n",
    "\n",
    "from mod1 import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "\n",
    "path = 'd:\\\\stockdata\\\\close_ma120\\\\close_ma120_'\n",
    "\n",
    "df = all_stock('2019-10-10')\n",
    "df = df['Name']\n",
    "\n",
    "name = df.to_list()\n",
    "\n",
    "df2 = pd.DataFrame()\n",
    "for i in name:\n",
    "    #print(i)\n",
    "    df=select_stock(i,'2010-01-01')\n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close','ma60','ma120','volume']].values)\n",
    "    df1 = pd.DataFrame(data)\n",
    "\n",
    "    df1['Name']=i\n",
    "    df1.columns=['close','ma60','ma120','volume','name',]\n",
    "    df1['date'] = df['date']\n",
    "\n",
    "    #print(df1)\n",
    "    df2 = df2.append(df1)\n",
    "\n",
    "select_query = \"select * from market where Name='hrs' and Date >= '2019-10-01' and Date < '2019-11-01' \"\n",
    "df3 = pd.read_sql(select_query, engine)\n",
    "\n",
    "df3 = df3['Date']\n",
    "datelist = df3.to_list()\n",
    "\n",
    "for i in datelist:\n",
    "    choice_df = df2.loc[df2['date'] == i]\n",
    "    strdate = i.strftime('%Y-%m-%d')\n",
    "    ma120_df = choice_df[choice_df['close'] > choice_df['ma120']]\n",
    "    ma120_df = ma120_df.sort_values(['ma120'])\n",
    "    ma120_df.to_excel(path+strdate+'.xlsx')\n",
    "    #print(today_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  전종목 검색하여  종가 > ma120  일일 비교  하여  관심 종목 추출_4  한달단위로  close_ma120, total 동시 추출\n",
    "\n",
    "from mod1 import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "\n",
    "path = 'd:\\\\stockdata\\\\close_ma120\\\\close_ma120_'\n",
    "path_total = 'd:\\\\stockdata\\\\close_ma120\\\\total_'\n",
    "\n",
    "df = all_stock('2019-10-10')\n",
    "df = df['Name']\n",
    "name = df.to_list()\n",
    "\n",
    "pure_df = pd.DataFrame()\n",
    "df2 = pd.DataFrame()\n",
    "\n",
    "for i in name:\n",
    "    #print(i)\n",
    "    df=select_stock(i,'2008-01-01')\n",
    "    pure_df = pure_df.append(df)\n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close','ma60','ma120','volume']].values)\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1['name']=i\n",
    "    df1.columns=['close','ma60','ma120','volume','name']\n",
    "    df1['date'] = df['date']\n",
    "    #print(df1)\n",
    "    df2 = df2.append(df1)\n",
    "\n",
    "pure_df.columns = map(str.lower, pure_df.columns) ## \n",
    "\n",
    "select_query = \"select * from market where Name='hrs' and Date >= '2019-10-01' \"\n",
    "df3 = pd.read_sql(select_query, engine)\n",
    "\n",
    "df3 = df3['Date']\n",
    "datelist = df3.to_list()\n",
    "\n",
    "last_df = df2.loc[df2['date'] == datelist[-1]]\n",
    "last_df = last_df[last_df['ma120'] < 0.1]\n",
    "last_price_df = pure_df.loc[pure_df['date'] == datelist[-1]]\n",
    "\n",
    "for i in datelist:\n",
    "    first_df = df2.loc[df2['date'] == i]\n",
    "    first_price_df = pure_df.loc[pure_df['date'] == i]\n",
    "    ma120_df = pd.merge(first_df,last_df,on='name')\n",
    "    ma_df = pd.merge(first_price_df[['close','name']],ma120_df,on='name')\n",
    "    ma120_df = pd.merge(last_price_df[['close','volume','name']],ma_df,on='name')\n",
    "    ma120_df.columns= ['price_y','volume_z', 'name', 'price_x', 'close_x', 'ma60_x', 'ma120_x','volume_x', 'date_x', 'close_y', 'ma60_y', 'ma120_y', 'volume_y', 'date_y']\n",
    "    ma120_df = ma120_df[['name','close_x','close_y','ma60_x','ma60_y','ma120_x','ma120_y','price_x','price_y','volume_z','date_x']]\n",
    "    ma120_df['price_diff']=ma120_df['price_y']/ma120_df['price_x']\n",
    "    ma120_df =  ma120_df.sort_values([\"price_diff\"],ascending=False)\n",
    "    second_df =  first_df.sort_values([\"ma120\"],ascending=False)\n",
    "    #ma120_df['price_x']=first_price_df['close'].values\n",
    "    #ma120_df['price_y']=last_price_df['close'].values\n",
    "    strdate = i.strftime('%Y-%m-%d')\n",
    "    second_df.to_excel(path+strdate+'.xlsx')\n",
    "    ma120_df.to_excel(path_total+strdate+'.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  전종목 검색하여  종가 > ma120  일일 비교  하여  관심 종목 추출_5  한달단위로  close_ma120, total 동시 추출(1년분)\n",
    "\n",
    "from mod1 import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
    "\n",
    "path = 'd:\\\\stockdata\\\\close_ma120\\\\close_ma120_'\n",
    "path_total = 'd:\\\\stockdata\\\\close_ma120\\\\total_'\n",
    "path_total_a = 'd:\\\\stockdata\\\\close_ma120\\\\total_a_'\n",
    "path_total_b = 'd:\\\\stockdata\\\\close_ma120\\\\total_b_'\n",
    "\n",
    "df = all_stock('2019-10-10')\n",
    "df = df['Name']\n",
    "name = df.to_list()\n",
    "\n",
    "pure_df = pd.DataFrame()\n",
    "df2 = pd.DataFrame()\n",
    "\n",
    "for i in name:\n",
    "    #print(i)\n",
    "    df=select_stock(i,'2019-01-01')\n",
    "    pure_df = pure_df.append(df)\n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close','ma60','ma120','volume']].values)\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1['name']=i\n",
    "    df1.columns=['close','ma60','ma120','volume','name']\n",
    "    df1[['date','code']] = df[['date','code']]\n",
    "\n",
    "    #print(df1)\n",
    "    df2 = df2.append(df1)\n",
    "\n",
    "pure_df.columns = map(str.lower, pure_df.columns) ## \n",
    "\n",
    "select_query = \"select * from market where Name='hrs' and Date >= '2019-10-01' \"\n",
    "df3 = pd.read_sql(select_query, engine)\n",
    "\n",
    "df3 = df3['Date']\n",
    "datelist = df3.to_list()\n",
    "\n",
    "last_df = df2.loc[df2['date'] == datelist[-1]]\n",
    "last_df = last_df[last_df['ma120'] < 0.1]\n",
    "a_df = last_df[last_df['close'] > last_df['ma60']] \n",
    "last_df = a_df[a_df['ma60'] > a_df['ma120']]\n",
    "last_price_df = pure_df.loc[pure_df['date'] == datelist[-1]]\n",
    "\n",
    "for i in datelist:\n",
    "    first_df = df2.loc[df2['date'] == i]\n",
    "    first_price_df = pure_df.loc[pure_df['date'] == i]\n",
    "    one_df = pd.merge(first_df,last_df,on='code')\n",
    "    reset_index_df = last_df.reset_index()\n",
    "    one_df['code']= reset_index_df['code']\n",
    "    ma_df = pd.merge(first_price_df[['close','code']],one_df,on='code')\n",
    "    two_df = pd.merge(last_price_df[['close','code','volume']],ma_df,on='code')\n",
    "    two_df.columns= ['price_y','code', 'volume_z','price_x', 'close_x', 'ma60_x', 'ma120_x', 'volume_x','name_x', 'date_x', 'close_y', 'ma60_y', 'ma120_y', 'volume_y','name_y', 'date_y']\n",
    "\n",
    "    ma120_df = two_df[['name_x','code','close_x','close_y','ma60_x','ma60_y','ma120_x','ma120_y','price_x','price_y','date_x','volume_z']]\n",
    "    ma120_df['price_diff']=ma120_df['price_y']/ma120_df['price_x']\n",
    "    ma120_df =  ma120_df.sort_values([\"price_diff\"],ascending=False)\n",
    "    #second_df =  first_df.sort_values([\"ma120\"],ascending=False)\n",
    "\n",
    "    strdate = i.strftime('%Y-%m-%d')\n",
    "    #second_df.to_excel(path+strdate+'.xlsx')\n",
    "    ma120_df.to_excel(path_total_a+strdate+'.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  전종목 검색하여  종가 > ma120  일일 비교  하여  관심 종목 추출_6  한달단위로  close_ma120, total 동시 추출(11년분)\n",
    "\n",
    "from mod1 import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
    "\n",
    "path = 'd:\\\\stockdata\\\\close_ma120\\\\close_ma120_'\n",
    "path_total = 'd:\\\\stockdata\\\\close_ma120\\\\total_'\n",
    "path_total_a = 'd:\\\\stockdata\\\\close_ma120\\\\total_a_'\n",
    "path_total_b = 'd:\\\\stockdata\\\\close_ma120\\\\total_b_'\n",
    "\n",
    "df = all_stock('2019-10-10')\n",
    "df = df['Name']\n",
    "name = df.to_list()\n",
    "\n",
    "pure_df = pd.DataFrame()\n",
    "df2 = pd.DataFrame()\n",
    "\n",
    "for i in name:\n",
    "    #print(i)\n",
    "    df=select_stock(i,'2008-01-01')\n",
    "    pure_df = pure_df.append(df)\n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close','ma60','ma120','volume']].values)\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1['name']=i\n",
    "    df1.columns=['close','ma60','ma120','volume','name']\n",
    "    df1[['date','code']] = df[['date','code']]\n",
    "\n",
    "    #print(df1)\n",
    "    df2 = df2.append(df1)\n",
    "\n",
    "pure_df.columns = map(str.lower, pure_df.columns) ## \n",
    "\n",
    "select_query = \"select * from market where Name='hrs' and Date >= '2019-10-01' \"\n",
    "df3 = pd.read_sql(select_query, engine)\n",
    "\n",
    "df3 = df3['Date']\n",
    "datelist = df3.to_list()\n",
    "\n",
    "last_df = df2.loc[df2['date'] == datelist[-1]]\n",
    "last_df = last_df[last_df['ma120'] < 0.1]\n",
    "a_df = last_df[last_df['close'] > last_df['ma60']] \n",
    "last_df = a_df[a_df['ma60'] > a_df['ma120']]\n",
    "last_price_df = pure_df.loc[pure_df['date'] == datelist[-1]]\n",
    "\n",
    "for i in datelist:\n",
    "    first_df = df2.loc[df2['date'] == i]\n",
    "    first_price_df = pure_df.loc[pure_df['date'] == i]\n",
    "    one_df = pd.merge(first_df,last_df,on='code')\n",
    "    reset_index_df = last_df.reset_index()\n",
    "    one_df['code']= reset_index_df['code']\n",
    "    ma_df = pd.merge(first_price_df[['close','code']],one_df,on='code')\n",
    "    two_df = pd.merge(last_price_df[['close','code','volume']],ma_df,on='code')\n",
    "    two_df.columns= ['price_y','code', 'volume_z','price_x', 'close_x', 'ma60_x', 'ma120_x', 'volume_x','name_x', 'date_x', 'close_y', 'ma60_y', 'ma120_y', 'volume_y','name_y', 'date_y']\n",
    "\n",
    "    ma120_df = two_df[['name_x','code','close_x','close_y','ma60_x','ma60_y','ma120_x','ma120_y','price_x','price_y','date_x','volume_z']]\n",
    "    ma120_df['price_diff']=ma120_df['price_y']/ma120_df['price_x']\n",
    "    ma120_df =  ma120_df.sort_values([\"price_diff\"],ascending=False)\n",
    "    second_df =  first_df.sort_values([\"ma120\"],ascending=False)\n",
    "\n",
    "    strdate = i.strftime('%Y-%m-%d')\n",
    "    second_df.to_excel(path+strdate+'.xlsx')\n",
    "    ma120_df.to_excel(path_total_b+strdate+'.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  전종목 검색하여  종가 > ma120  일일 비교  하여  관심 종목 추출_7  한달단위로  close_ma120, total (1년분),close_ma120, total (11년분) 동시 추출\n",
    "\n",
    "from mod1 import *\n",
    "#import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "#from pandas.core.common import SettingWithCopyWarning\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
    "\n",
    "path = 'd:\\\\stockdata\\\\close_ma120\\\\close_ma120_'\n",
    "path_total = 'd:\\\\test\\\\total_'\n",
    "path_total_a = 'd:\\\\test\\\\total_a_'\n",
    "path_total_b = 'd:\\\\test\\\\total_b_'\n",
    "\n",
    "#df = all_stock('2019-10-10')\n",
    "#df = df['Name']\n",
    "#name = df.to_list()\n",
    "    \n",
    "name = ['필룩스','MP한강','금호전기','나이벡']\n",
    "\n",
    "select_start_a = '2019-01-01'\n",
    "select_start_b = '2008-01-01'\n",
    "    \n",
    "def search_stock(name,select_start):   \n",
    "    print(name)\n",
    "    print(select_start)\n",
    "    pure_df = pd.DataFrame()\n",
    "    df2 = pd.DataFrame() \n",
    "    for i in name:\n",
    "        #print(i)\n",
    "        df=select_stock(i,select_start)\n",
    "        #print(df)\n",
    "        pure_df = pure_df.append(df)\n",
    "        ma(df)\n",
    "\n",
    "        source = MinMaxScaler()\n",
    "        data = source.fit_transform(df[['close','ma60','ma120','volume']].values)\n",
    "        df1 = pd.DataFrame(data)\n",
    "        df1['name']=i\n",
    "        df1.columns=['close','ma60','ma120','volume','name']\n",
    "        df1[['date','code']] = df[['date','code']]\n",
    "        #print(df1)\n",
    "        df2 = df2.append(df1)\n",
    "\n",
    "    pure_df.columns = map(str.lower, pure_df.columns) ## \n",
    "\n",
    "    select_query = \"select * from market where Name='hrs' and Date >= '2019-10-01' \"\n",
    "    df3 = pd.read_sql(select_query, engine)\n",
    "\n",
    "    df3 = df3['Date']\n",
    "    datelist = df3.to_list()\n",
    "\n",
    "    last_df = df2.loc[df2['date'] == datelist[-1]]\n",
    "    last_df = last_df[last_df['ma120'] < 0.1]\n",
    "    a_df = last_df[last_df['close'] > last_df['ma60']] \n",
    "    last_df = a_df[a_df['ma60'] > a_df['ma120']]\n",
    "    last_price_df = pure_df.loc[pure_df['date'] == datelist[-1]]\n",
    "\n",
    "    for i in datelist:\n",
    "        first_df = df2.loc[df2['date'] == i]\n",
    "        first_price_df = pure_df.loc[pure_df['date'] == i]\n",
    "        one_df = pd.merge(first_df,last_df,on='code')\n",
    "        reset_index_df = last_df.reset_index()\n",
    "        one_df['code']= reset_index_df['code']\n",
    "        ma_df = pd.merge(first_price_df[['close','code']],one_df,on='code')\n",
    "        two_df = pd.merge(last_price_df[['close','code']],ma_df,on='code')\n",
    "        two_df.columns= ['price_y','code', 'price_x', 'close_x', 'ma60_x', 'ma120_x', 'volume_x','name_x', 'date_x', 'close_y', 'ma60_y', 'ma120_y', 'volume_y','name_y', 'date_y']\n",
    "        ma120_df = two_df[['name_x','code','close_x','close_y','ma60_x','ma60_y','ma120_x','ma120_y','price_x','price_y','date_x']]\n",
    "        ma120_df['price_diff']=ma120_df['price_y']/ma120_df['price_x']\n",
    "        ma120_df =  ma120_df.sort_values([\"price_diff\"],ascending=False)\n",
    "        second_df =  first_df.sort_values([\"ma120\"],ascending=False)\n",
    "        #ma120_df['price_x']=first_price_df['close'].values\n",
    "        #ma120_df['price_y']=last_price_df['close'].values\n",
    "        strdate = i.strftime('%Y-%m-%d')\n",
    "        #second_df.to_excel(path+strdate+'.xlsx')\n",
    "        if select_start == select_start_a:\n",
    "            ma120_df.to_excel(path_total_a+strdate+'.xlsx')\n",
    "        else:\n",
    "            ma120_df.to_excel(path_total_b+strdate+'.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  전종목 검색하여  종가 > ma120  일일 비교  하여  관심 종목 추출_8  total_a(1년분) ,total_b(11년분) 의 공통종목을 추출\n",
    "\n",
    "from mod1 import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
    "\n",
    "path = 'd:\\\\stockdata\\\\close_ma120\\\\close_ma120_'\n",
    "path_total = 'd:\\\\stockdata\\\\close_ma120\\\\total_'\n",
    "path_total_a = 'd:\\\\stockdata\\\\close_ma120\\\\total_a_'\n",
    "path_total_b = 'd:\\\\stockdata\\\\close_ma120\\\\total_b_'\n",
    "\n",
    "select_query = \"select * from market where Name='hrs' and Date >= '2019-10-01' \"\n",
    "df3 = pd.read_sql(select_query, engine)\n",
    "\n",
    "df3 = df3['Date']\n",
    "datelist = df3.to_list()\n",
    "\n",
    "for i in datelist:\n",
    "    strdate = i.strftime('%Y-%m-%d')\n",
    "    df_a = pd.read_excel(path_total_a+strdate+'.xlsx')\n",
    "    df_b = pd.read_excel(path_total_b+strdate+'.xlsx')\n",
    "    #df_ab = pd.DataFrame()\n",
    "    df_ab = pd.merge(df_a[['name_x']],df_b,on='name_x')\n",
    "    \n",
    "    total_df = df_ab[['name_x', 'code', 'close_x', 'close_y', 'ma60_x', 'ma60_y', 'ma120_x', 'ma120_y', 'price_x', 'price_y', 'date_x','volume_z', 'price_diff']]\n",
    "    total_df.to_excel(path_total+strdate+'.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  전종목 검색하여  종가 > ma120  일일 비교  하여  관심 종목 추출_9  total_a(1년분) ,total_b(11년분) 추출 및  공통종목을 추출\n",
    "\n",
    "from mod1 import *\n",
    "#import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "#from pandas.core.common import SettingWithCopyWarning\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
    "\n",
    "path = 'd:\\\\stockdata\\\\close_ma120\\\\close_ma120_'\n",
    "path_total = 'd:\\\\stockdata\\\\close_ma120\\\\total_'\n",
    "path_total_f = 'd:\\\\stockdata\\\\close_ma120\\\\total_filter_'\n",
    "path_total_a = 'd:\\\\stockdata\\\\close_ma120\\\\total_a_'\n",
    "path_total_b = 'd:\\\\stockdata\\\\close_ma120\\\\total_b_'\n",
    "path_total_c = 'd:\\\\stockdata\\\\close_ma120\\\\total_c_'\n",
    "\n",
    "\n",
    "df = all_stock('2019-10-10')\n",
    "df = df['Name']\n",
    "name = df.to_list()\n",
    "    \n",
    "select_start_a = '2019-01-01'\n",
    "select_start_b = '2008-01-01'\n",
    "\n",
    "select_query = \"select * from market where Name='hrs' and Date >= '2019-10-01' \"\n",
    "df3 = pd.read_sql(select_query, engine)\n",
    "\n",
    "df3 = df3['Date']\n",
    "datelist = df3.to_list()\n",
    "    \n",
    "def search_stock(name,select_start):   \n",
    "    print(name)\n",
    "    print(select_start)\n",
    "    pure_df = pd.DataFrame()\n",
    "    df2 = pd.DataFrame() \n",
    "    for i in name:\n",
    "        #print(i)\n",
    "        df=select_stock(i,select_start)\n",
    "        #print(df)\n",
    "        pure_df = pure_df.append(df)\n",
    "        ma(df)\n",
    "\n",
    "        source = MinMaxScaler()\n",
    "        data = source.fit_transform(df[['close','ma60','ma120','volume']].values)\n",
    "        df1 = pd.DataFrame(data)\n",
    "        df1['name']=i\n",
    "        df1.columns=['close','ma60','ma120','volume','name']\n",
    "        df1[['date','code']] = df[['date','code']]\n",
    "        #print(df1)\n",
    "        df2 = df2.append(df1)\n",
    "\n",
    "    pure_df.columns = map(str.lower, pure_df.columns) ## \n",
    "\n",
    "    last_df = df2.loc[df2['date'] == datelist[-1]]\n",
    "    last_close_df = last_df[last_df['close'] < 0.1]\n",
    "    last_ma_df = last_df[last_df['ma120'] < 0.1]\n",
    "    a_df = last_ma_df[last_ma_df['close'] > last_ma_df['ma60']] \n",
    "    last_ma_df = a_df[a_df['ma60'] > a_df['ma120']]\n",
    "    last_price_df = pure_df.loc[pure_df['date'] == datelist[-1]]\n",
    "    \n",
    "    for i in datelist:\n",
    "        first_df = df2.loc[df2['date'] == i]\n",
    "        first_price_df = pure_df.loc[pure_df['date'] == i]\n",
    "        one_close_df = pd.merge(first_df,last_close_df,on='code')\n",
    "        one_df = pd.merge(first_df,last_ma_df,on='code')\n",
    "        reset_close_df = last_close_df.reset_index()\n",
    "        reset_ma_df = last_ma_df.reset_index()\n",
    "        one_close_df['code']= reset_close_df['code']\n",
    "        one_df['code']= reset_ma_df['code']\n",
    "        close_df = pd.merge(first_price_df[['close','code']],one_close_df,on='code')\n",
    "        ma_df = pd.merge(first_price_df[['close','code']],one_df,on='code')        \n",
    "        two_close_df = pd.merge(last_price_df[['close','code','volume']],close_df,on='code')\n",
    "        two_df = pd.merge(last_price_df[['close','code','volume']],ma_df,on='code')\n",
    "        two_close_df.columns= ['price_y','code', 'volume_z','price_x', 'close_x', 'ma60_x', 'ma120_x', 'volume_x','name_x', 'date_x', 'close_y', 'ma60_y', 'ma120_y', 'volume_y','name_y', 'date_y']\n",
    "        two_df.columns= ['price_y','code', 'volume_z','price_x', 'close_x', 'ma60_x', 'ma120_x', 'volume_x','name_x', 'date_x', 'close_y', 'ma60_y', 'ma120_y', 'volume_y','name_y', 'date_y']\n",
    "\n",
    "        price_df = two_close_df[['name_x','code','close_x','close_y','ma60_x','ma60_y','ma120_x','ma120_y','price_x','price_y','date_x','volume_z']]\n",
    "        ma120_df = two_df[['name_x','code','close_x','close_y','ma60_x','ma60_y','ma120_x','ma120_y','price_x','price_y','date_x','volume_z']]\n",
    "        price_df['price_diff']=price_df['price_y']/price_df['price_x']\n",
    "        ma120_df['price_diff']=ma120_df['price_y']/ma120_df['price_x']\n",
    "        price_df =  price_df.sort_values([\"price_diff\"],ascending=True)\n",
    "        ma120_df =  ma120_df.sort_values([\"price_diff\"],ascending=True)\n",
    "        second_df =  first_df.sort_values([\"ma120\"],ascending=True)\n",
    "        #ma120_df['price_x']=first_price_df['close'].values\n",
    "        #ma120_df['price_y']=last_price_df['close'].values\n",
    "        strdate = i.strftime('%Y-%m-%d')\n",
    "       \n",
    "        if select_start == select_start_a:\n",
    "            ma120_df.to_excel(path_total_a+strdate+'.xlsx')\n",
    "            price_df.to_excel(path_total_c+strdate+'.xlsx')\n",
    "        else:\n",
    "            ma120_df.to_excel(path_total_b+strdate+'.xlsx')\n",
    "            second_df.to_excel(path+strdate+'.xlsx')\n",
    "            \n",
    "def total_ab_intersection( ):\n",
    "    for i in datelist:\n",
    "        strdate = i.strftime('%Y-%m-%d')\n",
    "        df_a = pd.read_excel(path_total_a+strdate+'.xlsx')\n",
    "        filter_df_a = df_a[df_a['close_y'] < 0.2]\n",
    "        df_b = pd.read_excel(path_total_b+strdate+'.xlsx')\n",
    "        #df_ab = pd.DataFrame()\n",
    "        df_ab = pd.merge(df_a[['name_x']],df_b,on='name_x')\n",
    "        filter_df_ab = pd.merge(filter_df_a[['name_x']],df_b,on='name_x')\n",
    "\n",
    "        total_df = df_ab[['name_x', 'code', 'close_x', 'close_y', 'ma60_x', 'ma60_y', 'ma120_x', 'ma120_y', 'price_x', 'price_y', 'date_x','volume_z', 'price_diff']]\n",
    "        filter_total_df = filter_df_ab[['name_x', 'code', 'close_x', 'close_y', 'ma60_x', 'ma60_y', 'ma120_x', 'ma120_y', 'price_x', 'price_y', 'date_x','volume_z', 'price_diff']]\n",
    "        total_df.to_excel(path_total+strdate+'.xlsx')\n",
    "        filter_total_df.to_excel(path_total_f+strdate+'.xlsx') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  전종목 검색하여  종가 > ma120  일일 비교  하여  관심 종목 추출_9  total_a(1년분) ,total_b(11년분) 추출 및  공통종목을 추출 another method\n",
    "\n",
    "from mod1 import *\n",
    "#import pandas as pd\n",
    "\n",
    "path = 'd:\\\\test\\\\close_ma120_'\n",
    "path_total = 'd:\\\\test\\\\total_'\n",
    "path_total_a = 'd:\\\\test\\\\total_a_'\n",
    "path_total_b = 'd:\\\\test\\\\total_b_'\n",
    "path_total_c = 'd:\\\\test\\\\total_c_'\n",
    "\n",
    "#df = all_stock('2019-10-10')\n",
    "#df = df['Name']\n",
    "#name = df.to_list()\n",
    "    \n",
    "name = ['HRS','디엔에프','푸드나무','화성밸브','미래생명자원','웹케시']\n",
    "\n",
    "select_start_a = '2019-01-01'\n",
    "select_start_b = '2008-01-01'\n",
    "\n",
    "select_query = \"select * from market where Name='hrs' and Date >= '2019-10-01' \"\n",
    "df3 = pd.read_sql(select_query, engine)\n",
    "\n",
    "df3 = df3['Date']\n",
    "datelist = df3.to_list()\n",
    "    \n",
    "def search_stock(name,select_start_a,select_start_b):   \n",
    "    #print(name)\n",
    "    #print(select_start)\n",
    "    pure_df_a = pd.DataFrame()\n",
    "    df2_a = pd.DataFrame() \n",
    "    pure_df_b = pd.DataFrame()\n",
    "    df2_b = pd.DataFrame() \n",
    "    for i in name:\n",
    "        #print(i)\n",
    "        df_a=select_stock(i,select_start_a)\n",
    "        df_b=select_stock(i,select_start_b)\n",
    "        #print(df)\n",
    "        pure_df_a = pure_df_a.append(df_a)\n",
    "        pure_df_b = pure_df_b.append(df_b)\n",
    "        ma(df_a)\n",
    "        ma(df_b)\n",
    "\n",
    "        source = MinMaxScaler()\n",
    "        data_a = source.fit_transform(df_a[['close','ma60','ma120','volume']].values)\n",
    "        data_b = source.fit_transform(df_b[['close','ma60','ma120','volume']].values)\n",
    "        df1_a = pd.DataFrame(data_a)\n",
    "        df1_b = pd.DataFrame(data_b)\n",
    "        df1_a['name']=i\n",
    "        df1_b['name']=i\n",
    "        df1_a.columns=['close','ma60','ma120','volume','name']\n",
    "        df1_b.columns=['close','ma60','ma120','volume','name']\n",
    "        df1_a[['date','code','price']] = df_a[['date','code','close']]\n",
    "        df1_b[['date','code','price']] = df_b[['date','code','close']]\n",
    "        df2_a = df2_a.append(df1_a)\n",
    "        df2_b = df2_b.append(df1_b)        \n",
    "        \n",
    "    pure_df_a.columns = map(str.lower, pure_df_a.columns) ## \n",
    "    pure_df_b.columns = map(str.lower, pure_df_a.columns) ##\n",
    "    \n",
    "    pure_df_a = pure_df_a[['name','close','volume','date']]\n",
    "    pure_df_b = pure_df_b[['name','close','volume','date']]\n",
    "        \n",
    "    choice_day = pd.Timestamp('2019-09-30 00:00:00')\n",
    "    c = df2_a[df2_a['date']>choice_day]\n",
    "    d = df2_b[df2_b['date']>choice_day]\n",
    "    e = pure_df_a[pure_df_a['date']>choice_day]\n",
    "    f = pure_df_b[pure_df_b['date']>choice_day]\n",
    "    \n",
    "    last_df_a = c.loc[c['date'] == datelist[-1]]\n",
    "    last_close_df_a = last_df_a[last_df_a['close'] < 0.1]\n",
    "    last_ma_df_a = last_df_a[last_df_a['ma120'] < 0.1]\n",
    "    a_df_a = last_ma_df_a[last_ma_df_a['close'] > last_ma_df_a['ma60']] \n",
    "    last_ma_df_a = a_df_a[a_df_a['ma60'] > a_df_a['ma120']]\n",
    "    last_price_df_a = e.loc[e['date'] == datelist[-1]]\n",
    "    last_price_df_a = last_price_df_a[['name','volume']]\n",
    "    last_ma_df_a  = pd.merge(last_ma_df_a,last_price_df_a,on='name')\n",
    "\n",
    "    last_df_b = d.loc[d['date'] == datelist[-1]]\n",
    "    last_close_df_b = last_df_b[last_df_b['close'] < 0.1]\n",
    "    last_ma_df_b = last_df_b[last_df_b['ma120'] < 0.1]\n",
    "    a_df_b = last_ma_df_b[last_ma_df_b['close'] > last_ma_df_b['ma60']] \n",
    "    last_ma_df_b = a_df_b[a_df_b['ma60'] > a_df_b['ma120']]\n",
    "    last_price_df_b = f.loc[f['date'] == datelist[-1]]\n",
    "    last_price_df_b = last_price_df_b[['name','volume']]\n",
    "    last_ma_df_b  = pd.merge(last_ma_df_b,last_price_df_b,on='name')\n",
    "    \n",
    "    g = last_ma_df_a\n",
    "    h = last_ma_df_b\n",
    "    \n",
    "    a = pd.merge(c,g, on='name')\n",
    "    b = pd.merge(d,h, on='name')\n",
    "    \n",
    "    a['price_diff']=a['price_y']/a['price_x']\n",
    "    b['price_diff']=b['price_y']/b['price_x']\n",
    "    #g['volume_z'] = last_price_df_a['volume']\n",
    "    a = a[['name','code_x','close_x','close_y','ma60_x','ma60_y','ma120_x','ma120_y','price_x','price_y','date_x','volume_y','price_diff']]\n",
    "    b = b[['name','code_x','close_x','close_y','ma60_x','ma60_y','ma120_x','ma120_y','price_x','price_y','date_x','volume_y','price_diff']]\n",
    "    \n",
    "    for i in datelist:\n",
    "        t = pd.Timestamp(i)\n",
    "        first_df = a.loc[a['date_x'] == t]             ##  표준화 dataframe \n",
    "        second_df = b.loc[b['date_x'] == t] \n",
    "        strdate = t.strftime('%Y-%m-%d')\n",
    "        first_df =  first_df.sort_values([\"price_diff\"],ascending=True)\n",
    "        second_df = second_df.sort_values([\"price_diff\"],ascending=True)\n",
    "        first_df.to_excel(path_total_a+strdate+'.xlsx')  ##  표준화 dataframe 중 ma120 < 0.1 and close > ma60 > ma120 (from 2019.01.01)\n",
    "        second_df.to_excel(path_total_b+strdate+'.xlsx')  ##  표준화 dataframe 중 ma120 < 0.1 and close > ma60 > ma120 (from 2008.01.01) \n",
    "        \n",
    "search_stock(name,select_start_a,select_start_b)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  샘플로 간략하게  검색하여  종가 > ma120  일일 비교  하여  관심 종목 추출_9  total_a(1년분) ,total_b(11년분) 추출 및  공통종목을 추출\n",
    "\n",
    "\n",
    "from mod1 import *\n",
    "#import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "#from pandas.core.common import SettingWithCopyWarning\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
    "\n",
    "path = 'd:\\\\test\\\\close_ma120_'\n",
    "path_total = 'd:\\\\test\\\\total_'\n",
    "path_total_a = 'd:\\\\test\\\\total_a_'\n",
    "path_total_b = 'd:\\\\test\\\\total_b_'\n",
    "path_total_c = 'd:\\\\test\\\\total_c_'\n",
    "path_total_f = 'd:\\\\test\\\\total_filter_'\n",
    "\n",
    "#df = all_stock('2019-10-10')\n",
    "#df = df['Name']\n",
    "#name = df.to_list()\n",
    "    \n",
    "name = ['hrs','디엔에프','푸드나무','화성밸브','미래생명자원','웹케시']\n",
    "\n",
    "select_start_a = '2019-01-01'\n",
    "select_start_b = '2008-01-01'\n",
    "\n",
    "select_query = \"select * from market where Name='hrs' and Date >= '2019-10-01' \"\n",
    "df3 = pd.read_sql(select_query, engine)\n",
    "\n",
    "df3 = df3['Date']\n",
    "datelist = df3.to_list()\n",
    "    \n",
    "def search_stock(name,select_start):   \n",
    "    print(name)\n",
    "    print(select_start)\n",
    "    pure_df = pd.DataFrame()\n",
    "    df2 = pd.DataFrame() \n",
    "    for i in name:\n",
    "        #print(i)\n",
    "        df=select_stock(i,select_start)\n",
    "        #print(df)\n",
    "        pure_df = pure_df.append(df)\n",
    "        ma(df)\n",
    "\n",
    "        source = MinMaxScaler()\n",
    "        data = source.fit_transform(df[['close','ma60','ma120','volume']].values)\n",
    "        df1 = pd.DataFrame(data)\n",
    "        df1['name']=i\n",
    "        df1.columns=['close','ma60','ma120','volume','name']\n",
    "        df1[['date','code']] = df[['date','code']]\n",
    "        #print(df1)\n",
    "        df2 = df2.append(df1)\n",
    "\n",
    "    pure_df.columns = map(str.lower, pure_df.columns) ## \n",
    "\n",
    "    last_df = df2.loc[df2['date'] == datelist[-1]]\n",
    "    last_close_df = last_df[last_df['close'] < 0.1]\n",
    "    last_ma_df = last_df[last_df['ma120'] < 0.1]\n",
    "    a_df = last_ma_df[last_ma_df['close'] > last_ma_df['ma60']] \n",
    "    last_ma_df = a_df[a_df['ma60'] > a_df['ma120']]\n",
    "    last_price_df = pure_df.loc[pure_df['date'] == datelist[-1]]\n",
    "    \n",
    "    for i in datelist:\n",
    "        first_df = df2.loc[df2['date'] == i]\n",
    "        first_price_df = pure_df.loc[pure_df['date'] == i]\n",
    "        one_close_df = pd.merge(first_df,last_close_df,on='code')\n",
    "        one_df = pd.merge(first_df,last_ma_df,on='code')\n",
    "        reset_close_df = last_close_df.reset_index()\n",
    "        reset_ma_df = last_ma_df.reset_index()\n",
    "        one_close_df['code']= reset_close_df['code']\n",
    "        one_df['code']= reset_ma_df['code']\n",
    "        close_df = pd.merge(first_price_df[['close','code']],one_close_df,on='code')\n",
    "        ma_df = pd.merge(first_price_df[['close','code']],one_df,on='code')        \n",
    "        two_close_df = pd.merge(last_price_df[['close','code','volume']],close_df,on='code')\n",
    "        two_df = pd.merge(last_price_df[['close','code','volume']],ma_df,on='code')\n",
    "        two_close_df.columns= ['price_y','code', 'volume_z','price_x', 'close_x', 'ma60_x', 'ma120_x', 'volume_x','name_x', 'date_x', 'close_y', 'ma60_y', 'ma120_y', 'volume_y','name_y', 'date_y']\n",
    "        two_df.columns= ['price_y','code', 'volume_z','price_x', 'close_x', 'ma60_x', 'ma120_x', 'volume_x','name_x', 'date_x', 'close_y', 'ma60_y', 'ma120_y', 'volume_y','name_y', 'date_y']\n",
    "\n",
    "        price_df = two_close_df[['name_x','code','close_x','close_y','ma60_x','ma60_y','ma120_x','ma120_y','price_x','price_y','date_x','volume_z']]\n",
    "        ma120_df = two_df[['name_x','code','close_x','close_y','ma60_x','ma60_y','ma120_x','ma120_y','price_x','price_y','date_x','volume_z']]\n",
    "        price_df['price_diff']=price_df['price_y']/price_df['price_x']\n",
    "        ma120_df['price_diff']=ma120_df['price_y']/ma120_df['price_x']\n",
    "        price_df =  price_df.sort_values([\"price_diff\"],ascending=True)\n",
    "        ma120_df =  ma120_df.sort_values([\"price_diff\"],ascending=True)\n",
    "        second_df =  first_df.sort_values([\"ma120\"],ascending=True)\n",
    "        #ma120_df['price_x']=first_price_df['close'].values\n",
    "        #ma120_df['price_y']=last_price_df['close'].values\n",
    "        strdate = i.strftime('%Y-%m-%d')\n",
    "       \n",
    "        if select_start == select_start_a:\n",
    "            ma120_df.to_excel(path_total_a+strdate+'.xlsx')\n",
    "            price_df.to_excel(path_total_c+strdate+'.xlsx')\n",
    "        else:\n",
    "            ma120_df.to_excel(path_total_b+strdate+'.xlsx')\n",
    "            second_df.to_excel(path+strdate+'.xlsx')\n",
    "\n",
    "def total_ab_intersection( ):\n",
    "    for i in datelist:\n",
    "        strdate = i.strftime('%Y-%m-%d')\n",
    "        df_a = pd.read_excel(path_total_a+strdate+'.xlsx')\n",
    "        filter_df_a = df_a[df_a['close_y'] < 0.2]\n",
    "        df_b = pd.read_excel(path_total_b+strdate+'.xlsx')\n",
    "        #df_ab = pd.DataFrame()\n",
    "        df_ab = pd.merge(df_a[['name_x']],df_b,on='name_x')\n",
    "        filter_df_ab = pd.merge(filter_df_a[['name_x']],df_b,on='name_x')\n",
    "\n",
    "        total_df = df_ab[['name_x', 'code', 'close_x', 'close_y', 'ma60_x', 'ma60_y', 'ma120_x', 'ma120_y', 'price_x', 'price_y', 'date_x','volume_z', 'price_diff']]\n",
    "        filter_total_df = filter_df_ab[['name_x', 'code', 'close_x', 'close_y', 'ma60_x', 'ma60_y', 'ma120_x', 'ma120_y', 'price_x', 'price_y', 'date_x','volume_z', 'price_diff']]\n",
    "        total_df.to_excel(path_total+strdate+'.xlsx')\n",
    "        filter_total_df.to_excel(path_total_f+strdate+'.xlsx') \n",
    "            \n",
    "            \n",
    "#search_stock(name,select_start_b)\n",
    "total_ab_intersection( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##  관심종목에서 종가 비교하기\n",
    "\n",
    "from mod1 import *\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "\n",
    "path = 'd:\\\\stockdata\\\\close_ma120\\\\close_ma120_'\n",
    "\n",
    "back_date=1\n",
    "choice_date='2019-10-18'\n",
    "\n",
    "df = pd.read_excel(path+choice_date+'.xlsx')\n",
    "df = df['name']\n",
    "name = df.to_list()\n",
    "\n",
    "df1 = pd.DataFrame()\n",
    "diff_df = pd.DataFrame()\n",
    "for i in name:\n",
    "    #print(i)\n",
    "    df=select_stock(i,'2019-01-01')\n",
    "    df1 = df1.append(df)\n",
    "\n",
    "last = len(df1[df1['Name'] == name[0]])-1\n",
    "price_startday_df = df1[df1.index == (last-back_date)]\n",
    "price_today_df = df1[df1.index == last]\n",
    "\n",
    "diff_df = pd.merge(price_startday_df[['Name','Close']],price_today_df[['Name','Close']],on='Name')\n",
    "diff_df.columns=['name','price_startday','price_today']\n",
    "diff_df['diff']=diff_df['price_today']/diff_df['price_startday']\n",
    "\n",
    "price_up = diff_df[diff_df['diff'] > 1]\n",
    "price_down = diff_df[diff_df['diff'] < 1]\n",
    "price_sum=len(price_up)+len(price_down)\n",
    "print('price_up = {}'.format(len(price_up)))\n",
    "print('price_down = {}'.format(len(price_down)))\n",
    "    \n",
    "print('win_rate={}%'.format((len(price_up)/price_sum)*100))\n",
    "\n",
    "display((price_up.sort_values([\"diff\"],ascending=False).head(10)))\n",
    "display(price_down.sort_values(['diff']).head(10))\n",
    "display(diff_df.describe())\n",
    "\n",
    "#sort_df = diff_df.sort_values([\"diff\"],ascending=False)  ##  상승, 하락 을  순서별로 정렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mod1 import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "\n",
    "path = 'd:\\\\stockdata\\\\close_ma120\\\\close_ma120_'\n",
    "path_total = 'd:\\\\stockdata\\\\close_ma120\\\\total_'\n",
    "\n",
    "df = all_stock('2019-10-10')\n",
    "df = df['Name']\n",
    "name = df.to_list()\n",
    "\n",
    "pure_df = pd.DataFrame()\n",
    "df2 = pd.DataFrame()\n",
    "for i in name:\n",
    "    #print(i)\n",
    "    df=select_stock(i,'2008-01-01')\n",
    "    pure_df = pure_df.append(df)\n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close','ma60','ma120','volume']].values)\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1['name']=i\n",
    "    df1.columns=['close','ma60','ma120','volume','name']\n",
    "    df1[['date','code']] = df[['date','code']]\n",
    "    #print(df1)\n",
    "    df2 = df2.append(df1)\n",
    "\n",
    "pure_df.columns = map(str.lower, pure_df.columns) ## \n",
    " \n",
    "select_query = \"select * from market where Name='hrs' and Date >= '2019-10-01' and Date < '2019-11-01' \"\n",
    "df3 = pd.read_sql(select_query, engine)\n",
    "\n",
    "df3 = df3['Date']\n",
    "datelist = df3.to_list()\n",
    "\n",
    "last_df = df2.loc[df2['date'] == datelist[-1]]\n",
    "last_df = last_df[last_df['ma120'] < 0.1]\n",
    "last_price_df = pure_df.loc[pure_df['date'] == datelist[-1]]\n",
    "\n",
    "for i in datelist:\n",
    "    first_df = df2.loc[df2['date'] == i]\n",
    "    first_price_df = pure_df.loc[pure_df['date'] == i]\n",
    "    one_df = pd.merge(first_df,last_df,on='code')\n",
    "    reset_index_df = last_df.reset_index()\n",
    "    one_df['code']= reset_index_df['code']\n",
    "    ma_df = pd.merge(first_price_df[['close','code']],one_df,on='code')\n",
    "    two_df = pd.merge(last_price_df[['close','code']],ma_df,on='code')\n",
    "    two_df.columns= ['price_y','code', 'price_x', 'close_x', 'ma60_x', 'ma120_x', 'volume_x','name_x', 'date_x', 'close_y', 'ma60_y', 'ma120_y', 'volume_y','name_y', 'date_y']\n",
    "    ma120_df = two_df[['name_x','code','close_x','close_y','ma60_x','ma60_y','ma120_x','ma120_y','price_x','price_y','date_x']]\n",
    "    ma120_df['price_diff']=ma120_df['price_y']/ma120_df['price_x']\n",
    "    ma120_df =  ma120_df.sort_values([\"price_diff\"],ascending=False)\n",
    "    second_df =  first_df.sort_values([\"ma120\"],ascending=False)\n",
    "    #ma120_df['price_x']=first_price_df['close'].values\n",
    "    #ma120_df['price_y']=last_price_df['close'].values\n",
    "    strdate = i.strftime('%Y-%m-%d')\n",
    "    second_df.to_excel(path+strdate+'.xlsx')\n",
    "    ma120_df.to_excel(path_total+strdate+'.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  관심종목  ma120 일선 비교하기\n",
    "\n",
    "from mod1 import *\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "\n",
    "path = 'd:\\\\stockdata\\\\close_ma120\\\\close_ma120_'\n",
    "\n",
    "back_date=1\n",
    "choice_date='2019-10-25'\n",
    "\n",
    "df = pd.read_excel(path+choice_date+'.xlsx')\n",
    "df = df['name']\n",
    "name = df.to_list()\n",
    "\n",
    "df1 = pd.DataFrame()\n",
    "diff_df = pd.DataFrame()\n",
    "ma120_df2 = pd.DataFrame()\n",
    "for i in name:\n",
    "    #print(i)\n",
    "    df=select_stock(i,'2010-01-01')\n",
    "    df1 = df1.append(df)    \n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close','ma120','volume']].values)\n",
    "    ma120_df1 = pd.DataFrame(data)\n",
    "    ma120_df1['Name']=i\n",
    "    ma120_df1.columns=['close','ma120','volume','name',]\n",
    "    ma120_df1['date'] = df['date']\n",
    "    #print(df1)\n",
    "    ma120_df2 = ma120_df2.append(ma120_df1)\n",
    "    \n",
    "\n",
    "last = len(ma120_df2[ma120_df2['name'] == name[0]])-1\n",
    "startday_df = ma120_df2[ma120_df2.index == (last-back_date)]\n",
    "#yesterday_df = df2[df2.index == (last-1)]\n",
    "today_df = ma120_df2[ma120_df2.index == last]\n",
    "\n",
    "ma120_diff_df = pd.merge(startday_df[['name','ma120']],today_df[['name','ma120']],on='name')\n",
    "ma120_diff_df.columns=['name','startday','today']\n",
    "ma120_diff_df['diff']=ma120_diff_df['today']/ma120_diff_df['startday']\n",
    "\n",
    "ma120_up = ma120_diff_df[ma120_diff_df['diff'] > 1]\n",
    "ma120_down = ma120_diff_df[ma120_diff_df['diff'] < 1]\n",
    "ma120_sum=len(ma120_up)+len(ma120_down)\n",
    "print('ma120_up = {}'.format(len(ma120_up)))\n",
    "print('ma120_down = {}'.format(len(ma120_down)))\n",
    "    \n",
    "print('win_rate={}%'.format((len(ma120_up)/ma120_sum)*100))\n",
    "\n",
    "display((ma120_up.sort_values([\"diff\"],ascending=False).head(10)))\n",
    "display(ma120_down.sort_values(['diff']).head(10))\n",
    "display(ma120_diff_df.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  관심종목  종가, ma120 일선별로   상세히 비교 하기\n",
    "\n",
    "from mod1 import *\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "\n",
    "path = 'd:\\\\stockdata\\\\close_ma120\\\\close_ma120_'\n",
    "path_total = 'd:\\\\stockdata\\\\close_ma120\\\\total_'\n",
    "\n",
    "back_date=1\n",
    "choice_date='2019-10-25'\n",
    "\n",
    "df = pd.read_excel(path+choice_date+'.xlsx')\n",
    "df = df['name']\n",
    "name = df.to_list()\n",
    "\n",
    "df1 = pd.DataFrame()\n",
    "diff_df = pd.DataFrame()\n",
    "ma120_df2 = pd.DataFrame()\n",
    "for i in name:\n",
    "    #print(i)\n",
    "    df=select_stock(i,'2010-01-01')\n",
    "    df1 = df1.append(df)    \n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close','ma120','volume']].values)\n",
    "    ma120_df1 = pd.DataFrame(data)\n",
    "    ma120_df1['Name']=i\n",
    "    ma120_df1.columns=['close','ma120','volume','name',]\n",
    "    ma120_df1['date'] = df['date']\n",
    "    #print(df1)\n",
    "    ma120_df2 = ma120_df2.append(ma120_df1)\n",
    "    \n",
    "\n",
    "last = len(ma120_df2[ma120_df2['name'] == name[0]])-1\n",
    "ma120_startday_df = ma120_df2[ma120_df2.index == (last-back_date)]\n",
    "ma120_today_df = ma120_df2[ma120_df2.index == last]\n",
    "price_startday_df = df1[df1.index == (last-back_date)]\n",
    "price_today_df = df1[df1.index == last]\n",
    "\n",
    "ma120_diff_df = pd.merge(ma120_startday_df[['name','ma120']],ma120_today_df[['name','ma120']],on='name')\n",
    "ma120_diff_df.columns=['name','ma120_startday','ma120_today']\n",
    "ma120_diff_df['ma120_diff']=ma120_diff_df['ma120_today']/ma120_diff_df['ma120_startday']\n",
    "\n",
    "diff_df = pd.merge(price_startday_df[['Name','Close']],price_today_df[['Name','Close']],on='Name')\n",
    "diff_df.columns=['name','price_startday','price_today']\n",
    "diff_df['price_diff']=diff_df['price_today']/diff_df['price_startday']\n",
    "\n",
    "ma120_up = ma120_diff_df[ma120_diff_df['ma120_diff'] > 1]\n",
    "ma120_down = ma120_diff_df[ma120_diff_df['ma120_diff'] < 1]\n",
    "ma120_sum=len(ma120_up)+len(ma120_down)\n",
    "\n",
    "price_up = diff_df[diff_df['price_diff'] > 1]\n",
    "price_down = diff_df[diff_df['price_diff'] < 1]\n",
    "price_sum=len(price_up)+len(price_down)\n",
    "\n",
    "print('ma120_up = {}'.format(len(ma120_up)))\n",
    "print('ma120_down = {}'.format(len(ma120_down)))\n",
    "    \n",
    "print('win_rate={}%'.format((len(ma120_up)/ma120_sum)*100))\n",
    "\n",
    "display((ma120_up.sort_values([\"ma120_diff\"],ascending=False).head(10)))\n",
    "display(ma120_down.sort_values(['ma120_diff']).head(10))\n",
    "display(ma120_diff_df.describe())\n",
    "\n",
    "print('price_up = {}'.format(len(price_up)))\n",
    "print('price_down = {}'.format(len(price_down)))\n",
    "    \n",
    "print('win_rate={}%'.format((len(price_up)/price_sum)*100))\n",
    "\n",
    "display((price_up.sort_values([\"price_diff\"],ascending=False).head(10)))\n",
    "display(price_down.sort_values(['price_diff']).head(10))\n",
    "display(diff_df.describe())\n",
    "\n",
    "total_df = pd.merge(ma120_diff_df,diff_df,on='name')\n",
    "total_df = total_df.sort_values([\"price_diff\"],ascending=False)\n",
    "total_df.to_excel(path_total+choice_date+'.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  관심종목  종가, ma120 일선별로 상세히 비교 하기 _ back_date 자동계산 및 Volume 추가\n",
    "\n",
    "from mod1 import *\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "\n",
    "path = 'd:\\\\stockdata\\\\close_ma120\\\\close_ma120_'\n",
    "path_total = 'd:\\\\stockdata\\\\close_ma120\\\\total_'\n",
    "\n",
    "choice_date='2019-10-11'\n",
    "select_query = \"select count(*) from market_good where Name='hrs' and Date > \"\n",
    "var = select_query +\"'\"+choice_date+\"'\" \n",
    "df = pd.read_sql(var, engine)\n",
    "count = df.values.tolist()\n",
    "back_date = count[0][0]\n",
    "\n",
    "df = pd.read_excel(path+choice_date+'.xlsx')\n",
    "df = df['name']\n",
    "name = df.to_list()\n",
    "\n",
    "df1 = pd.DataFrame()\n",
    "diff_df = pd.DataFrame()\n",
    "ma120_df2 = pd.DataFrame()\n",
    "for i in name:\n",
    "    #print(i)\n",
    "    df=select_stock(i,'2010-01-01')\n",
    "    df1 = df1.append(df)    \n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close','ma120','volume']].values)\n",
    "    ma120_df1 = pd.DataFrame(data)\n",
    "    ma120_df1['Name']=i\n",
    "    ma120_df1.columns=['close','ma120','volume','name',]\n",
    "    ma120_df1['date'] = df['date']\n",
    "    #print(df1)\n",
    "    ma120_df2 = ma120_df2.append(ma120_df1)\n",
    "    \n",
    "\n",
    "last = len(ma120_df2[ma120_df2['name'] == name[0]])-1\n",
    "ma120_startday_df = ma120_df2[ma120_df2.index == (last-back_date)]\n",
    "ma120_today_df = ma120_df2[ma120_df2.index == last]\n",
    "price_startday_df = df1[df1.index == (last-back_date)]\n",
    "price_today_df = df1[df1.index == last]\n",
    "\n",
    "ma120_diff_df = pd.merge(ma120_startday_df[['name','ma120']],ma120_today_df[['name','ma120']],on='name')\n",
    "ma120_diff_df.columns=['name','ma120_startday','ma120_today']\n",
    "ma120_diff_df['ma120_diff']=ma120_diff_df['ma120_today']/ma120_diff_df['ma120_startday']\n",
    "\n",
    "diff_df = pd.merge(price_startday_df[['Name','Close','Volume']],price_today_df[['Name','Close','Volume']],on='Name')\n",
    "diff_df.columns=['name','price_startday','volume_startday','price_today','volume_today']\n",
    "diff_df['price_diff']=diff_df['price_today']/diff_df['price_startday']\n",
    "\n",
    "ma120_up = ma120_diff_df[ma120_diff_df['ma120_diff'] > 1]\n",
    "ma120_down = ma120_diff_df[ma120_diff_df['ma120_diff'] < 1]\n",
    "ma120_sum=len(ma120_up)+len(ma120_down)\n",
    "\n",
    "price_up = diff_df[diff_df['price_diff'] > 1]\n",
    "price_down = diff_df[diff_df['price_diff'] < 1]\n",
    "price_sum=len(price_up)+len(price_down)\n",
    "\n",
    "print('ma120_up = {}'.format(len(ma120_up)))\n",
    "print('ma120_down = {}'.format(len(ma120_down)))\n",
    "    \n",
    "print('win_rate={}%'.format((len(ma120_up)/ma120_sum)*100))\n",
    "\n",
    "display((ma120_up.sort_values([\"ma120_diff\"],ascending=False).head(10)))\n",
    "display(ma120_down.sort_values(['ma120_diff']).head(10))\n",
    "display(ma120_diff_df.describe())\n",
    "\n",
    "print('price_up = {}'.format(len(price_up)))\n",
    "print('price_down = {}'.format(len(price_down)))\n",
    "    \n",
    "print('win_rate={}%'.format((len(price_up)/price_sum)*100))\n",
    "\n",
    "display((price_up.sort_values([\"price_diff\"],ascending=False).head(10)))\n",
    "display(price_down.sort_values(['price_diff']).head(10))\n",
    "display(diff_df.describe())\n",
    "\n",
    "total_df = pd.merge(ma120_diff_df,diff_df,on='name')\n",
    "total_df  = total_df[['name','ma120_startday','ma120_today','ma120_diff','price_startday','price_today','volume_startday','volume_today','price_diff']]\n",
    "total_df = total_df.sort_values([\"price_diff\"],ascending=False)\n",
    "total_df.to_excel(path_total+choice_date+'.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##  전종목  종가 > ma120  일일 비교 하여  종목 pick 하고 pick한 종목의  종가를  비교분석\n",
    "\n",
    "from mod1 import *\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "\n",
    "\n",
    "path = 'd:\\\\stockdata\\\\close_ma120\\\\close_ma120_'\n",
    "back_date=1\n",
    "choice_date='2019-10-11'\n",
    "\n",
    "all_df = all_stock(choice_date)\n",
    "all_name_df = all_df['Name']\n",
    "\n",
    "all_name = all_name_df.to_list()\n",
    "\n",
    "all_df2 = pd.DataFrame()\n",
    "for i in all_name:\n",
    "    #print(i)\n",
    "    all_df=select_stock(i,'2010-01-01')\n",
    "    ma(all_df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(all_df[['close','ma120','volume']].values)\n",
    "    all_df1 = pd.DataFrame(data)\n",
    "    all_df1['Name']=i\n",
    "    all_df1.columns=['close','ma120','volume','name',]\n",
    "    all_df1['date'] = all_df['date']\n",
    "    #print(df1)\n",
    "    all_df2 = all_df2.append(all_df1)\n",
    "    \n",
    "\n",
    "last = len(all_df2[all_df2['name'] == all_name[0]])-1\n",
    "all_today_df = all_df2[all_df2.index == last]\n",
    "\n",
    "ma120_df = all_today_df[all_today_df['close'] > all_today_df['ma120']]\n",
    "\n",
    "today = str(ma120_df.iloc[0,4])\n",
    "ma120_df.to_excel(path+today+'.xlsx', encoding='utf-8')\n",
    "\n",
    "pick_df = pd.read_excel(path+choice_date+'.xlsx')\n",
    "pick_df = pick_df['name']\n",
    "pick_name = pick_df.to_list()\n",
    "\n",
    "pick_df1 = pd.DataFrame()\n",
    "diff_df = pd.DataFrame()\n",
    "for i in pick_name:\n",
    "    #print(i)\n",
    "    pick_df=select_stock(i,'2019-01-01')\n",
    "    pick_df1 = pick_df1.append(pick_df)\n",
    "\n",
    "last = len(pick_df1[pick_df1['Name'] == pick_name[0]])-1\n",
    "startday_df = pick_df1[pick_df1.index == (last-back_date)]\n",
    "today_df = pick_df1[pick_df1.index == last]\n",
    "\n",
    "diff_df = pd.merge(startday_df[['Name','Close']],today_df[['Name','Close']],on='Name')\n",
    "diff_df.columns=['name','startday','today']\n",
    "diff_df['diff']=diff_df['today']/diff_df['startday']\n",
    "\n",
    "up = diff_df[diff_df['diff'] > 1]\n",
    "down = diff_df[diff_df['diff'] < 1]\n",
    "sum=len(up)+len(down)\n",
    "print('up = {}'.format(len(up)))\n",
    "print('down = {}'.format(len(down)))\n",
    "    \n",
    "print('win_rate={}%'.format((len(up)/sum)*100))\n",
    "\n",
    "display((up.sort_values([\"diff\"],ascending=False).head(10)))\n",
    "display(down.sort_values(['diff']).head(10))\n",
    "display(diff_df.describe())\n",
    "\n",
    "#kk = datetime.now()-datetime(2019,10,13)\n",
    "#print(kk.days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##  전종목  종가, ma120 일선 비교하기\n",
    "\n",
    "from mod1 import *\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "\n",
    "path = 'd:\\\\stockdata\\\\close_ma120\\\\close_ma120_'\n",
    "path_total = 'd:\\\\stockdata\\\\close_ma120\\\\all_'\n",
    "\n",
    "back_date=5\n",
    "choice_date='2019-10-11'\n",
    "\n",
    "df = all_stock(choice_date)\n",
    "#df.columns=['date', 'code', 'name', 'open', 'high', 'low', 'volume', 'close']\n",
    "df.columns = map(str.lower, df.columns)\n",
    "df = df['name']\n",
    "name = df.to_list()\n",
    "\n",
    "df1 = pd.DataFrame()\n",
    "diff_df = pd.DataFrame()\n",
    "ma120_df2 = pd.DataFrame()\n",
    "for i in name:\n",
    "    #print(i)\n",
    "    df=select_stock(i,'2010-01-01')\n",
    "    df1 = df1.append(df)    \n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close','ma120','volume']].values)\n",
    "    ma120_df1 = pd.DataFrame(data)\n",
    "    ma120_df1['Name']=i\n",
    "    ma120_df1.columns=['close','ma120','volume','name',]\n",
    "    ma120_df1['date'] = df['date']\n",
    "    #print(df1)\n",
    "    ma120_df2 = ma120_df2.append(ma120_df1)\n",
    "    \n",
    "ma120_df2['event_date'] = pd.to_datetime(ma120_df2['date'])\n",
    "df1['event_date'] = pd.to_datetime(df1['Date'])\n",
    "day = str((datetime.now()-timedelta(3)).date())\n",
    "da = str((datetime.now()-timedelta(2)).date())\n",
    "ma120_startday_df = ma120_df2.loc[ma120_df2['event_date'] == day]\n",
    "ma120_today_df = ma120_df2.loc[ma120_df2['event_date'] == da]\n",
    "price_startday_df = df1.loc[df1['event_date'] == day]\n",
    "price_today_df = df1.loc[df1['event_date'] == da]\n",
    "\n",
    "ma120_diff_df = pd.merge(ma120_startday_df[['name','ma120']],ma120_today_df[['name','ma120']],on='name')\n",
    "ma120_diff_df.columns=['name','ma120_startday','ma120_today']\n",
    "ma120_diff_df['ma120_diff']=ma120_diff_df['ma120_today']/ma120_diff_df['ma120_startday']\n",
    "\n",
    "diff_df = pd.merge(price_startday_df[['Name','Close']],price_today_df[['Name','Close']],on='Name')\n",
    "diff_df.columns=['name','price_startday','price_today']\n",
    "diff_df['price_diff']=diff_df['price_today']/diff_df['price_startday']\n",
    "\n",
    "ma120_up = ma120_diff_df[ma120_diff_df['ma120_diff'] > 1]\n",
    "ma120_down = ma120_diff_df[ma120_diff_df['ma120_diff'] < 1]\n",
    "ma120_sum=len(ma120_up)+len(ma120_down)\n",
    "\n",
    "price_up = diff_df[diff_df['price_diff'] > 1]\n",
    "price_down = diff_df[diff_df['price_diff'] < 1]\n",
    "price_sum=len(price_up)+len(price_down)\n",
    "\n",
    "print('ma120_up = {}'.format(len(ma120_up)))\n",
    "print('ma120_down = {}'.format(len(ma120_down)))\n",
    "    \n",
    "print('win_rate={}%'.format((len(ma120_up)/ma120_sum)*100))\n",
    "\n",
    "display((ma120_up.sort_values([\"ma120_diff\"],ascending=False).head(10)))\n",
    "display(ma120_down.sort_values(['ma120_diff']).head(10))\n",
    "display(ma120_diff_df.describe())\n",
    "\n",
    "print('price_up = {}'.format(len(price_up)))\n",
    "print('price_down = {}'.format(len(price_down)))\n",
    "    \n",
    "print('win_rate={}%'.format((len(price_up)/price_sum)*100))\n",
    "\n",
    "display((price_up.sort_values([\"price_diff\"],ascending=False).head(10)))\n",
    "display(price_down.sort_values(['price_diff']).head(10))\n",
    "display(diff_df.describe())\n",
    "\n",
    "total_df = pd.merge(ma120_diff_df,diff_df,on='name')\n",
    "total_df = total_df.sort_values([\"price_diff\"],ascending=False)\n",
    "total_df.to_excel(path_total+choice_date+'.xlsx')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###  관심종목 ma60, ma120, cci 그래프 생성\n",
    "\n",
    "from mod1 import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "\n",
    "def close_ma(df,select1,select2,select3):\n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close',select1,select2,select3]].values)\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1.columns=['close',select1,select2,select3]\n",
    "    df1 = df1.set_index(df['date'])\n",
    "    df1.plot(figsize=(16,4))\n",
    "    plt.title(df['name'][0])\n",
    "    plt.show()\n",
    "\n",
    "path = 'd:\\\\stockdata\\\\close_ma120\\\\close_ma120_'\n",
    "path_total = 'd:\\\\stockdata\\\\close_ma120\\\\total_'\n",
    "\n",
    "choice_date = '2019-10-01'\n",
    "df = pd.read_excel(path_total+choice_date+'.xlsx')\n",
    "df = df['name']\n",
    "name = df.to_list()\n",
    "\n",
    "#name=['hrs','손오공']\n",
    "\n",
    "pure_df = pd.DataFrame()\n",
    "df2 = pd.DataFrame()\n",
    "cci_df = pd.DataFrame()\n",
    "for i in name:\n",
    "    #print(i)\n",
    "    df=select_stock(i,'2010-01-01')\n",
    "    cci_df[['open','high','low','volume','close']] = df[['Open','High','Low','Volume','Close']].astype(float) #  TA-Lib로 평균을 구하려면 실수로 만들어야 함\n",
    "    period = 120\n",
    "    cci_df['cci'] = ta.CCI(cci_df, timeperiod=period)\n",
    "    df['cci'] = cci_df['cci']\n",
    "    close_ma(df,'cci','ma60','ma120')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
