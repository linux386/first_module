{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mod1 import *\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior( )\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = select_stock('오공','2019-01-01')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abcd(trend, skip_loop = 4, ma = 7):\n",
    "    ma = pd.Series(trend).rolling(ma).mean().values\n",
    "    x = []\n",
    "    for a in range(ma.shape[0]):\n",
    "        for b in range(a, ma.shape[0], skip_loop):\n",
    "            for c in range(b, ma.shape[0], skip_loop):\n",
    "                for d in range(c, ma.shape[0], skip_loop):\n",
    "                    print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abcd(df['Close'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abcd(trend, skip_loop = 4, ma = 7):\n",
    "    ma = pd.Series(trend).rolling(ma).mean().values\n",
    "    x = []\n",
    "    for a in range(ma.shape[0]):\n",
    "        for b in range(a, ma.shape[0], skip_loop):\n",
    "            for c in range(b, ma.shape[0], skip_loop):\n",
    "                for d in range(c, ma.shape[0], skip_loop):\n",
    "                    if ma[b] > ma[a] and \\\n",
    "                    (ma[c] < ma[b] and ma[c] > ma[a]) \\\n",
    "                    and ma[d] > ma[b]:\n",
    "                        x.append([a,b,c,d])\n",
    "    x_np = np.array(x)\n",
    "    ac = x_np[:,0].tolist() + x_np[:,2].tolist()\n",
    "    bd = x_np[:,1].tolist() + x_np[:,3].tolist()\n",
    "    ac_set = set(ac)\n",
    "    bd_set = set(bd)\n",
    "    signal = np.zeros(len(trend))\n",
    "    buy = list(ac_set - bd_set)\n",
    "    sell = list(list(bd_set - ac_set))\n",
    "    signal[buy] = 1.0\n",
    "    signal[sell] = -1.0\n",
    "    return signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "signal = abcd(df['Close'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buy_stock(\n",
    "    real_movement,\n",
    "    signal,\n",
    "    initial_money = 1000000,\n",
    "    max_buy = 1,\n",
    "    max_sell = 1,\n",
    "):\n",
    "    \"\"\"\n",
    "    real_movement = actual movement in the real world\n",
    "    delay = how much interval you want to delay to change our decision from buy to sell, vice versa\n",
    "    initial_state = 1 is buy, 0 is sell\n",
    "    initial_money = 10000, ignore what kind of currency\n",
    "    max_buy = max quantity for share to buy\n",
    "    max_sell = max quantity for share to sell\n",
    "    \"\"\"\n",
    "    starting_money = initial_money\n",
    "    states_sell = []\n",
    "    states_buy = []\n",
    "    states_money = []\n",
    "    current_inventory = 0\n",
    "    \n",
    "    def buy(i, initial_money, current_inventory):\n",
    "        shares = initial_money // real_movement[i]\n",
    "        if shares < 1:\n",
    "            print(\n",
    "                'day %d: total balances %f, not enough money to buy a unit price %f'\n",
    "                % (i, initial_money, real_movement[i])\n",
    "            )\n",
    "        else:\n",
    "            if shares > max_buy:\n",
    "                buy_units = max_buy\n",
    "            else:\n",
    "                buy_units = shares\n",
    "            initial_money -= buy_units * real_movement[i]\n",
    "            current_inventory += buy_units\n",
    "            print(\n",
    "                'day %d: buy %d units at price %f, total balance %f'\n",
    "                % (i, buy_units, buy_units * real_movement[i], initial_money)\n",
    "            )\n",
    "            states_buy.append(0)\n",
    "        return initial_money, current_inventory\n",
    "    \n",
    "    for i in range(real_movement.shape[0]):\n",
    "        state = signal[i]\n",
    "        if state == 1:\n",
    "            initial_money, current_inventory = buy(\n",
    "                i, initial_money, current_inventory\n",
    "            )\n",
    "            states_buy.append(i)\n",
    "        elif state == -1:\n",
    "            if current_inventory == 0:\n",
    "                    print('day %d: cannot sell anything, inventory 0' % (i))\n",
    "            else:\n",
    "                if current_inventory > max_sell:\n",
    "                    sell_units = max_sell\n",
    "                else:\n",
    "                    sell_units = current_inventory\n",
    "                current_inventory -= sell_units\n",
    "                total_sell = sell_units * real_movement[i]\n",
    "                initial_money += total_sell\n",
    "                try:\n",
    "                    invest = (\n",
    "                        (real_movement[i] - real_movement[states_buy[-1]])\n",
    "                        / real_movement[states_buy[-1]]\n",
    "                    ) * 100\n",
    "                except:\n",
    "                    invest = 0\n",
    "                print(\n",
    "                    'day %d, sell %d units at price %f, investment %f %%, total balance %f,'\n",
    "                    % (i, sell_units, total_sell, invest, initial_money)\n",
    "                )\n",
    "            states_sell.append(i)\n",
    "        states_money.append(initial_money)\n",
    "            \n",
    "    invest = ((initial_money - starting_money) / starting_money) * 100\n",
    "    total_gains = initial_money - starting_money\n",
    "    return states_buy, states_sell, total_gains, invest, states_money"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_buy, states_sell, total_gains, invest, states_money = buy_stock(df.Close, signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (15,5))\n",
    "plt.plot(close, color='r', lw=2.)\n",
    "plt.plot(close, '^', markersize=10, color='m', label = 'buying signal', markevery = states_buy)\n",
    "plt.plot(close, 'v', markersize=10, color='k', label = 'selling signal', markevery = states_sell)\n",
    "plt.title('total gains %f, total investment %f%%'%(total_gains, invest))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.loc[' 2020-01'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backtrader "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 주식Data를 select_stock로 불러서 백테스트할때"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##  20일 이동 평균선 추세매매 (20MA > Close : Buy,  20MA < Close : Sell)\n",
    "\n",
    "from mod1 import *\n",
    "import datetime\n",
    "import backtrader as bt\n",
    "\n",
    "# Create a subclass of Strategy to define the indicators and logic\n",
    "class Momentum(bt.Strategy):\n",
    "    # list of parameters which are configurable for the strategy\n",
    "    params = dict(\n",
    "        pfast=10,  # period for the fast moving average\n",
    "        pslow=20  # period for the slow moving average\n",
    "    )\n",
    "\n",
    "    def __init__(self):\n",
    "        self.dataclose = self.datas[0].close\n",
    "        self.smaSlow = bt.ind.SimpleMovingAverage(period=self.p.pslow)\n",
    "        self.smaFast = bt.ind.SimpleMovingAverage(period=self.p.pfast)\n",
    "        self.order = None\n",
    "\n",
    "    def log(self, txt, dt=None):\n",
    "        ''' Logging function fot this strategy'''\n",
    "        dt = dt or self.datas[0].datetime.date(0)\n",
    "        print('%s, %s' % (dt.isoformat(), txt))\n",
    "\n",
    "    def notify_order(self, order):\n",
    "        # 1. If order is submitted/accepted, do nothing\n",
    "        if order.status in [order.Submitted, order.Accepted]:\n",
    "            return\n",
    "        # 2. If order is buy/sell executed, report price executed\n",
    "        if order.status in [order.Completed]:\n",
    "            if order.isbuy():\n",
    "                self.log('BUY EXECUTED, Price: {0:8.2f}, Size: {1:8.2f} Cost: {2:8.2f}, Comm: {3:8.2f}'.format(\n",
    "                    order.executed.price,\n",
    "                    order.executed.size,\n",
    "                    order.executed.value,\n",
    "                    order.executed.comm))\n",
    "\n",
    "                self.buyprice = order.executed.price\n",
    "                self.buycomm = order.executed.comm\n",
    "            else:\n",
    "                self.log('SELL EXECUTED, {0:8.2f}, Size: {1:8.2f} Cost: {2:8.2f}, Comm{3:8.2f}'.format(\n",
    "                    order.executed.price,\n",
    "                    order.executed.size,\n",
    "                    order.executed.value,\n",
    "                    order.executed.comm))\n",
    "\n",
    "            self.bar_executed = len(self)  # when was trade executed\n",
    "        # 3. If order is canceled/margin/rejected, report order canceled\n",
    "        elif order.status in [order.Canceled, order.Margin, order.Rejected]:\n",
    "            self.log('Order Canceled/Margin/Rejected')\n",
    "\n",
    "        self.order = None\n",
    "\n",
    "    def next(self):\n",
    "        cash = self.broker.get_cash()\n",
    "        value = self.broker.get_value()\n",
    "        size = int(cash / self.data.close[0])\n",
    "        # Order가 Pending인지 확인, 그렇다면 다시 주문할 수 없음\n",
    "        if self.order:\n",
    "            return\n",
    "\n",
    "        if not self.position:  # not in the market\n",
    "            if self.smaSlow < self.data.close[0]:\n",
    "                self.order = self.buy(size=size)\n",
    "\n",
    "        elif self.getposition().size > 0: #in the market\n",
    "            if self.smaSlow > self.data.close[0]:\n",
    "                self.order = self.sell(size=self.getposition().size)\n",
    "\n",
    "def run(args=None):\n",
    "    cerebro = bt.Cerebro()  # create a \"Cerebro\" engine instance\n",
    "    cerebro.broker.setcash(1000000) #초기자금\n",
    "\n",
    "    df = select_stock('삼성전자','2019-01-01')\n",
    "    df = df.iloc[:246]\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Date\"])  ###  아주 중요!! pandas.core.series.Series DATA를 datatime object numpy로 돌려줌\n",
    "    df = df.set_index(df['Date'])\n",
    "    data = bt.feeds.PandasData(dataname=df, open='Open',close='Close')\n",
    "\n",
    "    cerebro.adddata(data) #데이터 삽입\n",
    "    cerebro.addstrategy(Momentum) #전략적용\n",
    "    print('Starting Portfolio Value: %.2f' % cerebro.broker.getvalue())\n",
    "    cerebro.run() #수행\n",
    "    print('Final Portfolio Value: %.2f' % cerebro.broker.getvalue())\n",
    "    cerebro.plot() #plot\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  20일 이동 평균선 역추세매매 (20MA > Close : Sell,  20MA < Close : Buy)\n",
    "\n",
    "from mod1 import *\n",
    "import datetime\n",
    "import backtrader as bt\n",
    "\n",
    "# Create a subclass of Strategy to define the indicators and logic\n",
    "class Momentum(bt.Strategy):\n",
    "    # list of parameters which are configurable for the strategy\n",
    "    params = dict(\n",
    "        pfast=10,  # period for the fast moving average\n",
    "        pslow=20  # period for the slow moving average\n",
    "    )\n",
    "\n",
    "    def __init__(self):\n",
    "        self.dataclose = self.datas[0].close\n",
    "        self.smaSlow = bt.ind.SimpleMovingAverage(period=self.p.pslow)\n",
    "        self.smaFast = bt.ind.SimpleMovingAverage(period=self.p.pfast)\n",
    "        self.order = None\n",
    "\n",
    "    def log(self, txt, dt=None):\n",
    "        ''' Logging function fot this strategy'''\n",
    "        dt = dt or self.datas[0].datetime.date(0)\n",
    "        print('%s, %s' % (dt.isoformat(), txt))\n",
    "\n",
    "    def notify_order(self, order):\n",
    "        # 1. If order is submitted/accepted, do nothing\n",
    "        if order.status in [order.Submitted, order.Accepted]:\n",
    "            return\n",
    "        # 2. If order is buy/sell executed, report price executed\n",
    "        if order.status in [order.Completed]:\n",
    "            if order.isbuy():\n",
    "                self.log('BUY EXECUTED, Price: {0:8.2f}, Size: {1:8.2f} Cost: {2:8.2f}, Comm: {3:8.2f}'.format(\n",
    "                    order.executed.price,\n",
    "                    order.executed.size,\n",
    "                    order.executed.value,\n",
    "                    order.executed.comm))\n",
    "\n",
    "                self.buyprice = order.executed.price\n",
    "                self.buycomm = order.executed.comm\n",
    "            else:\n",
    "                self.log('SELL EXECUTED, {0:8.2f}, Size: {1:8.2f} Cost: {2:8.2f}, Comm{3:8.2f}'.format(\n",
    "                    order.executed.price,\n",
    "                    order.executed.size,\n",
    "                    order.executed.value,\n",
    "                    order.executed.comm))\n",
    "\n",
    "            self.bar_executed = len(self)  # when was trade executed\n",
    "        # 3. If order is canceled/margin/rejected, report order canceled\n",
    "        elif order.status in [order.Canceled, order.Margin, order.Rejected]:\n",
    "            self.log('Order Canceled/Margin/Rejected')\n",
    "\n",
    "        self.order = None\n",
    "\n",
    "    def next(self):\n",
    "        cash = self.broker.get_cash()\n",
    "        value = self.broker.get_value()\n",
    "        size = int(cash / self.data.close[0])\n",
    "        # Order가 Pending인지 확인, 그렇다면 다시 주문할 수 없음\n",
    "        if self.order:\n",
    "            return\n",
    "\n",
    "        if not self.position:  # not in the market\n",
    "            if self.smaSlow > self.data.close[0]:\n",
    "                self.order = self.buy(size=size)\n",
    "\n",
    "        elif self.getposition().size > 0: #in the market\n",
    "            if self.smaSlow < self.data.close[0]:\n",
    "                self.order = self.sell(size=self.getposition().size)\n",
    "                \n",
    "def run(args=None):\n",
    "    cerebro = bt.Cerebro()  # create a \"Cerebro\" engine instance\n",
    "    cerebro.broker.setcash(1000000) #초기자금\n",
    "\n",
    "    df = select_stock('삼성전자','2019-01-01')\n",
    "    df = df.iloc[:246]\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Date\"])  ###  아주 중요!! pandas.core.series.Series DATA를 datatime object numpy로 돌려줌\n",
    "    df = df.set_index(df['Date'])\n",
    "    data = bt.feeds.PandasData(dataname=df, open='Open',close='Close')\n",
    "\n",
    "    cerebro.adddata(data) #데이터 삽입\n",
    "    cerebro.addstrategy(Momentum) #전략적용\n",
    "    print('Starting Portfolio Value: %.2f' % cerebro.broker.getvalue())\n",
    "    cerebro.run() #수행\n",
    "    print('Final Portfolio Value: %.2f' % cerebro.broker.getvalue())\n",
    "    cerebro.plot() #plot\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 주식Data를 text로 불러서 백테스트할때"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import backtrader as bt\n",
    "\n",
    "\n",
    "# Create a subclass of Strategy to define the indicators and logic\n",
    "\n",
    "class SmaCross(bt.Strategy):\n",
    "    # list of parameters which are configurable for the strategy\n",
    "    params = dict(\n",
    "        pfast=10,  # period for the fast moving average\n",
    "        pslow=30   # period for the slow moving average\n",
    "    )\n",
    "\n",
    "    def __init__(self):\n",
    "        sma1 = bt.ind.SMA(period=self.p.pfast)  # fast moving average\n",
    "        sma2 = bt.ind.SMA(period=self.p.pslow)  # slow moving average\n",
    "        self.crossover = bt.ind.CrossOver(sma1, sma2)  # crossover signal\n",
    "\n",
    "    def next(self):\n",
    "        if not self.position:  # not in the market\n",
    "            if self.crossover > 0:  # if fast crosses slow to the upside\n",
    "                self.buy()  # enter long\n",
    "\n",
    "        elif self.crossover < 0:  # in the market & cross to the downside\n",
    "            self.close()  # close long position\n",
    "\n",
    "\n",
    "cerebro = bt.Cerebro()  # create a \"Cerebro\" engine instance\n",
    "\n",
    "# Create a data feed\n",
    "#homepath = os.getenv('c:\\\\Users\\\\kkang\\notebook\\\\Git\\\\first_module')\n",
    "datapath = ('./orcl-1995-2014.txt')\n",
    "\n",
    "data = bt.feeds.YahooFinanceCSVData(\n",
    "    dataname=datapath,\n",
    "    fromdate=datetime.datetime(2000,1,1),\n",
    "    todate = datetime.datetime(2000,12,31),\n",
    "    reverse=False)\n",
    "\n",
    "cerebro.adddata(data)  # Add the data feed\n",
    "\n",
    "cerebro.addstrategy(SmaCross)  # Add the trading strategy\n",
    "cerebro.run()  # run it all\n",
    "cerebro.plot(style='candlestick')  # and plot it with a single command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  기간동안 낙폭 과대종목 검색\n",
    "\n",
    "import time\n",
    "from  mod1 import *\n",
    "\n",
    "start = time.time()  # 시작 시간 저장\n",
    "\n",
    "def all_stock_period(date1, date2='2021-01-01'):\n",
    "    select_query = \"select * from market_good where Date >=  \"\n",
    "    var = select_query +\"'\"+date1+\"'\"  +\" \"+ 'and Date <=' + \"'\"+date2+\"'\"\n",
    "    df = pd.read_sql(var, engine)\n",
    "    return df\n",
    "\n",
    "\n",
    "df = all_stock_period('2020-02-20','2020-03-25')\n",
    "df_uniq = df['Name'].unique()\n",
    "df_uniq_list=df_uniq.tolist()\n",
    "\n",
    "min_data = []\n",
    "for x in df_uniq_list:\n",
    "    min_value = min(df[df['Name']== x ].Close)\n",
    "    min_data.append(min_value)\n",
    "\n",
    "min_close = pd.DataFrame(min_data)\n",
    "\n",
    "df_a=pd.DataFrame(df_uniq)\n",
    "\n",
    "\n",
    "df_first=pd.DataFrame()\n",
    "df_first['Name']=df_a[0]\n",
    "df_first['Close']=min_close[0]\n",
    "df_to = all_stock('2020-05-21')\n",
    "df_last=df_to[['Name','Close']]\n",
    "df = pd.merge(df_first,df_last,on='Name')\n",
    "\n",
    "df['diff']=df['Close_y']/df['Close_x']\n",
    "df.head()\n",
    "\n",
    "close_diff_df =  df.sort_values([\"diff\"],ascending=True)\n",
    "close_diff_df.head()\n",
    "\n",
    "close_diff_df.to_excel(\"d:\\\\b_9.xlsx\")\n",
    "print(\"time :\", time.time() - start)  # 현재시각 - 시작시간 = 실행 시간"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## 개별종목분석\n",
    "\n",
    "from mod1 import *\n",
    "\n",
    "def close_ma_vol(df,select1,select2,select3):\n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close',select1,select2,select3]].values)\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1.columns=['close',select1,select2,select3]\n",
    "    df1 = df1.set_index(df['date'])\n",
    "    df1.plot(figsize=(16,4))\n",
    "    plt.title(df['name'][0])\n",
    "    plt.grid(True)\n",
    "    plt.show()    \n",
    "\n",
    "name=['디엔에프','모트렉스','푸드나무','상보','아난티','손오공','한컴위드']\n",
    "\n",
    "for i in name:\n",
    "    df = select_stock(i,'2018-01-01')\n",
    "    close_ma_vol(df,'ma60','ma120','volume')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##  거래량 증가 관심종목 분석\n",
    "from mod1 import *\n",
    "\n",
    "def volume_group_analysis(path_volume,select_day):\n",
    "    select_day = '2020-04-27'\n",
    "    date = '2020-01-01'\n",
    "    name = pd.read_excel(path_volume+select_day+'.xlsx', encoding='utf-8',index_col=0)\n",
    "    name_all = name['Name']\n",
    "    name_all = name_all.to_list()\n",
    "    name = name[:5]\n",
    "\n",
    "    for i in name_all:\n",
    "        select_query = \"select Date,Volume,Close from market where Name= \"\n",
    "        date_query = \"Date > \"\n",
    "        var = select_query +\"'\"+i+\"'\"+\" \"+\"&&\"+\" \"+date_query+\"'\"+date+\"'\" \n",
    "        df = pd.read_sql(var, engine)\n",
    "        df[['Volume','Close']] = df[['Volume','Close']].astype(float) #  TA-Lib로 평균을 구하려면 실수로 만들어야 함\n",
    "        df.columns=df.columns.str.lower()\n",
    "\n",
    "        talib_ma120 = ta.MA(df, timeperiod=20)\n",
    "        df['ma20'] = talib_ma120\n",
    "\n",
    "        source = MinMaxScaler()\n",
    "        data = source.fit_transform(df[['close','volume','ma20']].values)\n",
    "        df1 = pd.DataFrame(data)\n",
    "        df1.columns=['close','volume','ma20']\n",
    "        df1 = df1.set_index(df['date'])\n",
    "        df1.plot(figsize=(16,2))\n",
    "        plt.title(i)\n",
    "        plt.show()\n",
    "               \n",
    "volume_group_analysis(path_price,'2020-04-28')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##  가격 증가 관심종목 분석\n",
    "\n",
    "from mod1 import *\n",
    "\n",
    "def price_group_analysis(path_price,select_day):\n",
    "    #select_day = '2020-04-27'\n",
    "    date = '2020-01-01'\n",
    "    name = pd.read_excel(path_volume+select_day+'.xlsx', encoding='utf-8',index_col=0)\n",
    "    name_all = name['Name']\n",
    "    name_all = name_all.to_list()\n",
    "    name = name[:5]\n",
    "\n",
    "    for i in name_all:\n",
    "        select_query = \"select Date,Volume,Close from market where Name= \"\n",
    "        date_query = \"Date > \"\n",
    "        var = select_query +\"'\"+i+\"'\"+\" \"+\"&&\"+\" \"+date_query+\"'\"+date+\"'\" \n",
    "        df = pd.read_sql(var, engine)\n",
    "        df[['Volume','Close']] = df[['Volume','Close']].astype(float) #  TA-Lib로 평균을 구하려면 실수로 만들어야 함\n",
    "        df.columns=df.columns.str.lower()\n",
    "\n",
    "        talib_ma120 = ta.MA(df, timeperiod=20)\n",
    "        df['ma20'] = talib_ma120\n",
    "\n",
    "        source = MinMaxScaler()\n",
    "        data = source.fit_transform(df[['close','volume','ma20']].values)\n",
    "        df1 = pd.DataFrame(data)\n",
    "        df1.columns=['close','volume','ma20']\n",
    "        df1 = df1.set_index(df['date'])\n",
    "        df1.plot(figsize=(16,2))\n",
    "        plt.title(i)\n",
    "        plt.show()\n",
    "\n",
    "price_group_analysis(path_price,'2020-05-27')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# stock_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "###  Keras_LSTM_Stock_Prediction#1\n",
    "\n",
    "from mod1 import *\n",
    "import math\n",
    "import tensorflow as tf\n",
    "\n",
    "df = select_stock('hrs','2020-01-01')\n",
    "df=df[['Open','High','Close']]\n",
    "\n",
    "df['High'] = df['High'] / 100000\n",
    "df['Open'] = df['Open'] / 100000\n",
    "df['Close'] = df['Close'] / 100000\n",
    "df.head(5)\n",
    "\n",
    "window = 5\n",
    "amount_of_features = len(df.columns)\n",
    "data = df.values #pd.DataFrame(stock)\n",
    "sequence_length = window + 1\n",
    "result = []\n",
    "\n",
    "for index in range(len(data) - sequence_length):\n",
    "    result.append(data[index: index + sequence_length])\n",
    "\n",
    "result = np.array(result)\n",
    "\n",
    "\n",
    "\n",
    "row = round(0.9 * result.shape[0])\n",
    "train = result[:int(row), :]\n",
    "x_train = train[:, :-1]\n",
    "y_train = train[:, -1][:,-1]\n",
    "x_test = result[int(row):, :-1]\n",
    "y_test = result[int(row):, -1][:,-1]\n",
    "\n",
    "#x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], amount_of_features))\n",
    "#x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], amount_of_features))  \n",
    "\n",
    "print(\"x_train\", x_train.shape)\n",
    "print(\"y_train\", y_train.shape)\n",
    "print(\"X_test\", x_test.shape)\n",
    "print(\"y_test\", y_test.shape)\n",
    "\n",
    "\n",
    "d = 0.2\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.LSTM(128, input_shape=(window, 3), return_sequences=True))\n",
    "model.add(tf.keras.layers.Dropout(d))\n",
    "model.add(tf.keras.layers.LSTM(64, input_shape=(window, 3), return_sequences=False))\n",
    "model.add(tf.keras.layers.Dropout(d))\n",
    "model.add(tf.keras.layers.Dense(16,kernel_initializer=\"uniform\",activation='relu'))        \n",
    "model.add(tf.keras.layers.Dense(1,kernel_initializer=\"uniform\",activation='relu'))\n",
    "model.compile(loss='mse',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train,y_train,batch_size=10,epochs=100,validation_split=0.1,verbose=0)\n",
    "\n",
    "trainScore = model.evaluate(x_train, y_train, verbose=0)\n",
    "print('Train Score: %.2f MSE (%.2f RMSE)' % (trainScore[0], math.sqrt(trainScore[0])))\n",
    "\n",
    "testScore = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test Score: %.2f MSE (%.2f RMSE)' % (testScore[0], math.sqrt(testScore[0])))\n",
    "\n",
    "# print(X_test[-1])\n",
    "diff=[]\n",
    "ratio=[]\n",
    "p = model.predict(x_test)\n",
    "for u in range(len(y_test)):\n",
    "    pr = p[u][0]\n",
    "    ratio.append((y_test[u]/pr)-1)\n",
    "    diff.append(abs(y_test[u]- pr))\n",
    "    #print(u, y_test[u], pr, (y_test[u]/pr)-1, abs(y_test[u]- pr))\n",
    "\n",
    "plt.plot(p,color='red', label='prediction')\n",
    "plt.plot(y_test,color='blue', label='y_test')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "###  Keras_LSTM_Stock_Prediction#2\n",
    "\n",
    "\n",
    "from mod1 import *\n",
    "import math\n",
    "import tensorflow as tf\n",
    "\n",
    "df = select_stock('hrs','2020-01-01')\n",
    "df=df[['Open','High','Close']]\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "window = 5\n",
    "amount_of_features = len(df.columns)\n",
    "data = df.values #pd.DataFrame(stock)\n",
    "data = scaler.fit_transform(data)\n",
    "sequence_length = window + 1\n",
    "result = []\n",
    "\n",
    "for index in range(len(data) - sequence_length):\n",
    "    result.append(data[index: index + sequence_length])\n",
    "                  \n",
    "result = np.array(result)\n",
    "\n",
    "row = round(0.9 * result.shape[0])\n",
    "train = result[:int(row), :]\n",
    "\n",
    "x_train = train[:, :-1]\n",
    "y_train = train[:, -1][:,-1]\n",
    "x_test = result[int(row):, :-1]\n",
    "y_test = result[int(row):, -1][:,-1]\n",
    "\n",
    "print(\"x_train\", x_train.shape)\n",
    "print(\"y_train\", y_train.shape)\n",
    "print(\"x_test\", x_test.shape)\n",
    "print(\"y_test\", y_test.shape)\n",
    "\n",
    "d = 0.2\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.LSTM(128, input_shape=(window, 3), return_sequences=True))\n",
    "model.add(tf.keras.layers.Dropout(d))\n",
    "model.add(tf.keras.layers.LSTM(64, input_shape=(window, 3), return_sequences=False))\n",
    "model.add(tf.keras.layers.Dropout(d))\n",
    "model.add(tf.keras.layers.Dense(16,kernel_initializer=\"uniform\",activation='relu'))        \n",
    "model.add(tf.keras.layers.Dense(1,kernel_initializer=\"uniform\",activation='relu'))\n",
    "model.compile(loss='mse',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train,y_train,batch_size=10,epochs=500,verbose=0)\n",
    "model.evaluate(x_train, y_train)\n",
    "\n",
    "pred = model.predict(x_test) \n",
    "#pred = [[0.69005],[0.61538],[0.60407],[0.63575],[0.62443]]  ## 테스트용으로 종가 5일치를 역순으로 \n",
    "scale= MinMaxScaler()\n",
    "scale.min_, scale.scale_=scaler.min_[2], scaler.scale_[2]   ##  Open열[0],High열[1] ~ Close열은 [4]\n",
    "pred = scale.inverse_transform(pred)\n",
    "print(pred)\n",
    "\n",
    "true = y_test.reshape(-1,1)\n",
    "true = scale.inverse_transform(true)\n",
    "print(true)\n",
    "\n",
    "plt.plot(pred,color='red', label='prediction')\n",
    "plt.plot(true,color='blue', label='y_test')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model Save - MinMaxScaler.fit \n",
    "\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "sns.set()\n",
    "tf.compat.v1.random.set_random_seed(1234)\n",
    "\n",
    "tf.random.set_seed(777)  # reproducibility\n",
    "\n",
    "df = select_stock('hrs','2020-01-01')\n",
    "df = df[['Open','High','Low','Volume','Close']]\n",
    "xy = df.values\n",
    "\n",
    "test_min = np.min(xy, 0)\n",
    "test_max = np.max(xy, 0)\n",
    "test_denom = test_max - test_min\n",
    "\n",
    "\n",
    "seq_length = 5\n",
    "data_dim = 5\n",
    "hidden_dim = 10\n",
    "output_dim = 1\n",
    "learning_rate = 0.01\n",
    "iterations = 9000\n",
    "\n",
    "minmax = MinMaxScaler().fit(df.astype('float64')) # Close index\n",
    "dataset = minmax.transform(df.astype('float64')) # Close index\n",
    "\n",
    "train_size = int(len(dataset) * 0.7)\n",
    "train_set = dataset[0:train_size]\n",
    "test_set = dataset[train_size-seq_length:]  # Index from [train_size - seq_leng\n",
    "\n",
    "# build datasets\n",
    "def build_dataset(time_series, seq_length):\n",
    "    dataX = []\n",
    "    dataY = []\n",
    "    for i in range(0, len(time_series) - seq_length):\n",
    "        _x = time_series[i:i + seq_length, :]\n",
    "        _y = time_series[i + seq_length, [-1]]  # Next close price\n",
    "        #print(_x, \"->\", _y)\n",
    "        dataX.append(_x)\n",
    "        dataY.append(_y)\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "trainX, trainY = build_dataset(train_set, seq_length)\n",
    "testX, testY = build_dataset(test_set, seq_length)\n",
    "\n",
    "print(\"trainX\", trainX.shape)\n",
    "print(\"trainY\", trainX.shape)\n",
    "print(\"testX\", testX.shape)\n",
    "print(\"testY\", testY.shape)\n",
    "\n",
    "\n",
    "d = 0.2\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.LSTM(128, input_shape=(5, 5), return_sequences=True))\n",
    "model.add(tf.keras.layers.Dropout(d))\n",
    "model.add(tf.keras.layers.LSTM(64, input_shape=(5, 5), return_sequences=False))\n",
    "model.add(tf.keras.layers.Dropout(d))\n",
    "model.add(tf.keras.layers.Dense(16,kernel_initializer=\"uniform\",activation='relu'))        \n",
    "model.add(tf.keras.layers.Dense(1,kernel_initializer=\"uniform\",activation='relu'))\n",
    "model.compile(loss='mse',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "model.fit(trainX, trainY,batch_size=10,epochs=100,validation_split=0.1,verbose=0)\n",
    "\n",
    "model.evaluate(trainX, trainY)\n",
    "\n",
    "pred = model.predict(testX) \n",
    "#pred = [[0.69005],[0.61538],[0.60407],[0.63575],[0.62443]]  ## 테스트용으로 종가 5일치를 역순으로 \n",
    "scale= MinMaxScaler()\n",
    "scale.min_, scale.scale_=minmax.min_[4], minmax.scale_[4]   ##  Open열[0],High열[1] ~ Close열은 [4]\n",
    "pred = scale.inverse_transform(pred)\n",
    "print(pred)\n",
    "\n",
    "true = testY.reshape(-1,1)\n",
    "true = scale.inverse_transform(true)\n",
    "print(true)\n",
    "\n",
    "plt.plot(pred,color='red', label='prediction')\n",
    "plt.plot(true,color='blue', label='y_test')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "This script shows how to predict stock prices using a basic RNN\n",
    "'''\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "tf.random.set_seed(777) \n",
    "\n",
    "df = select_stock('hrs','2020-01-01')\n",
    "df = df[['Open','High','Low','Volume','Close']]\n",
    "xy = df.values\n",
    "\n",
    "\n",
    "# train Parameters\n",
    "seq_length = 7\n",
    "data_dim = 5\n",
    "hidden_dim = 10\n",
    "output_dim = 1\n",
    "learning_rate = 0.01\n",
    "iterations = 1000\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "dataset = scaler.fit_transform(xy)\n",
    "\n",
    "# train/test split\n",
    "train_size = int(len(dataset) * 0.7)\n",
    "pre_train_set = dataset[0:train_size]\n",
    "pre_test_set = dataset[train_size - seq_length:]  # Index from [train_size - seq_length] to utilize past sequence\n",
    "\n",
    "#최종 7 rows 다음날 Price Predict 입력 data\n",
    "last_X = scaler.fit_transform((xy[-seq_length:,:]))\n",
    "\n",
    "\n",
    "# build datasets\n",
    "def build_dataset(time_series, seq_length):\n",
    "    dataX = []\n",
    "    dataY = []\n",
    "    for i in range(0, len(time_series) - seq_length):\n",
    "        _x = time_series[i:i + seq_length, :]\n",
    "        _y = time_series[i + seq_length, [-1]]  # Next close price\n",
    "        #print(_x, \"->\", _y)\n",
    "        dataX.append(_x)\n",
    "        dataY.append(_y)\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "trainx, trainy = build_dataset(pre_train_set, seq_length)\n",
    "print(\"#\"*100)\n",
    "testx, testy = build_dataset(pre_test_set, seq_length)\n",
    "\n",
    "d = 0.2\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.LSTM(128, input_shape=(5, 5), return_sequences=True))\n",
    "model.add(tf.keras.layers.Dropout(d))\n",
    "model.add(tf.keras.layers.LSTM(64, input_shape=(5, 5), return_sequences=False))\n",
    "model.add(tf.keras.layers.Dropout(d))\n",
    "model.add(tf.keras.layers.Dense(16,kernel_initializer=\"uniform\",activation='relu'))        \n",
    "model.add(tf.keras.layers.Dense(1,kernel_initializer=\"uniform\",activation='relu'))\n",
    "model.compile(loss='mse',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "model.fit(trainX, trainY,batch_size=10,epochs=100,validation_split=0.1,verbose=0)\n",
    "\n",
    "trainScore = model.evaluate(trainX, trainY, verbose=1)\n",
    "print('Train Score: %.2f MSE (%.2f RMSE)' % (trainScore[0], math.sqrt(trainScore[0])))\n",
    "\n",
    "testScore = model.evaluate(testX, testY, verbose=0)\n",
    "print('Test Score: %.2f MSE (%.2f RMSE)' % (testScore[0], math.sqrt(testScore[0])))\n",
    "\n",
    "# print(X_test[-1])\n",
    "diff=[]\n",
    "ratio=[]\n",
    "predict=[]\n",
    "p = model.predict(testX)\n",
    "for u in range(len(testY)):\n",
    "    pr = p[u][0]\n",
    "    ratio.append((testY[u]/pr)-1)\n",
    "    diff.append(abs(testY[u]- pr))\n",
    "    predict.append(pr)\n",
    "    #print(u, y_test[u], pr, (y_test[u]/pr)-1, abs(y_test[u]- pr))\n",
    "\n",
    "plt.plot(p,color='red', label='prediction')\n",
    "plt.plot(testY,color='blue', label='testY')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Third"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mod1 import *\n",
    "import tensorflow as tf\n",
    "\n",
    "df = select_stock('hrs','2010-01-01')\n",
    "# Line 9 to 17 is for preprocessing and saving the dataset downloaded from yahoo website\n",
    "# It is not necessary to run these codes if you are using provided dataset in repo.\n",
    "# If you want to use your own dataset downloaded from yahoo then first run these with commented rest.\n",
    "# After that you can run as usual provided.\n",
    "\n",
    "# df = df.drop(['Date'],axis=1)\n",
    "# for col in df:\n",
    "#     for i,item in enumerate(df[col]):\n",
    "#         if item=='null':\n",
    "#             df[col][i] = np.nan\n",
    "# df = df.dropna(inplace=False)\n",
    "# for col in df:\n",
    "#     print(df[col].isnull().sum())\n",
    "# df.to_csv('yah.csv',index=False)\n",
    "\n",
    "df = df.drop(['Date','Code','Name','Volume'],axis=1)\n",
    "\n",
    "\n",
    "df_train = df[:1059]\n",
    "df_test = df[1059:]\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(df_train.drop(['Close'],axis=1).values)\n",
    "y_train = scaler.fit_transform(df_train['Close'].values.reshape(-1, 1))\n",
    "\n",
    "\n",
    "X_test = scaler.fit_transform(df_test.drop(['Close'],axis=1).values)\n",
    "y_test = scaler.fit_transform(df_test['Close'].values.reshape(-1, 1))\n",
    "#y_test = df_test['Close'].as_matrix()\n",
    "print(X_train.shape)\n",
    "print(np.max(y_test),np.max(y_train),np.min(y_test),np.min(y_train))\n",
    "\n",
    "def denormalize(df,norm_data):\n",
    "    df = df['Close'].values.reshape(-1,1)\n",
    "    norm_data = norm_data.reshape(-1,1)\n",
    "    scl = MinMaxScaler()\n",
    "    a = scl.fit_transform(df)\n",
    "    new = scl.inverse_transform(norm_data)\n",
    "    return new\n",
    "\n",
    "def neural_net_model(X_data,input_dim):\n",
    "    W_1 = tf.Variable(tf.random_uniform([input_dim,10]))\n",
    "    b_1 = tf.Variable(tf.zeros([10]))\n",
    "    layer_1 = tf.add(tf.matmul(X_data,W_1), b_1)\n",
    "    layer_1 = tf.nn.tanh(layer_1)\n",
    "\n",
    "    W_2 = tf.Variable(tf.random_uniform([10,10]))\n",
    "    b_2 = tf.Variable(tf.zeros([10]))\n",
    "    layer_2 = tf.add(tf.matmul(layer_1,W_2), b_2)\n",
    "    layer_2 = tf.nn.tanh(layer_2)\n",
    "\n",
    "    W_O = tf.Variable(tf.random_uniform([10,1]))\n",
    "    b_O = tf.Variable(tf.zeros([1]))\n",
    "    output = tf.add(tf.matmul(layer_2,W_O), b_O)\n",
    "\n",
    "    return output,W_O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_t = denormalize(df_train,y_train)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "plt.xlabel('Days')\n",
    "plt.ylabel('Stock Value HRS')\n",
    "plt.title('HRS Stock Index Prediction')\n",
    "ax.plot(range(len(y_train)), y_t,label='Original')\n",
    "plt.ion()\n",
    "\n",
    "\n",
    "d = 0.2\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.LSTM(128, input_shape=(1, 3), return_sequences=True))\n",
    "model.add(tf.keras.layers.Dropout(d))\n",
    "model.add(tf.keras.layers.LSTM(64, input_shape=(1, 3), return_sequences=False))\n",
    "model.add(tf.keras.layers.Dropout(d))\n",
    "model.add(tf.keras.layers.Dense(16,kernel_initializer=\"uniform\",activation='relu'))        \n",
    "model.add(tf.keras.layers.Dense(1,kernel_initializer=\"uniform\",activation='relu'))\n",
    "model.compile(loss='mse',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train,batch_size=10,epochs=100,validation_split=0.1,verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Close'].values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aaa(norm_data):\n",
    "    norm_data = norm_data.reshape(-1,1)\n",
    "    scl = MinMaxScaler()\n",
    "    new = scl.inverse_transform(norm_data)\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##  Tensorflow 1.0\n",
    "\n",
    "from mod1 import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior( )\n",
    "\n",
    "df = select_stock('hrs','2010-01-01')\n",
    "# Line 9 to 17 is for preprocessing and saving the dataset downloaded from yahoo website\n",
    "# It is not necessary to run these codes if you are using provided dataset in repo.\n",
    "# If you want to use your own dataset downloaded from yahoo then first run these with commented rest.\n",
    "# After that you can run as usual provided.\n",
    "\n",
    "# df = df.drop(['Date'],axis=1)\n",
    "# for col in df:\n",
    "#     for i,item in enumerate(df[col]):\n",
    "#         if item=='null':\n",
    "#             df[col][i] = np.nan\n",
    "# df = df.dropna(inplace=False)\n",
    "# for col in df:\n",
    "#     print(df[col].isnull().sum())\n",
    "# df.to_csv('yah.csv',index=False)\n",
    "\n",
    "df = df.drop(['Date','Code','Name','Volume'],axis=1)\n",
    "\n",
    "\n",
    "df_train = df[:1059]\n",
    "df_test = df[1059:]\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(df_train.drop(['Close'],axis=1).values)\n",
    "y_train = scaler.fit_transform(df_train['Close'].values.reshape(-1, 1))\n",
    "\n",
    "\n",
    "X_test = scaler.fit_transform(df_test.drop(['Close'],axis=1).values)\n",
    "y_test = scaler.fit_transform(df_test['Close'].values.reshape(-1, 1))\n",
    "#y_test = df_test['Close'].as_matrix()\n",
    "print(X_train.shape)\n",
    "print(np.max(y_test),np.max(y_train),np.min(y_test),np.min(y_train))\n",
    "\n",
    "\n",
    "def denormalize(df,norm_data):\n",
    "    df = df['Close'].values.reshape(-1,1)\n",
    "    norm_data = norm_data.reshape(-1,1)\n",
    "    scl = MinMaxScaler()\n",
    "    a = scl.fit_transform(df)\n",
    "    new = scl.inverse_transform(norm_data)\n",
    "    return new\n",
    "\n",
    "def neural_net_model(X_data,input_dim):\n",
    "    W_1 = tf.Variable(tf.random_uniform([input_dim,10]))\n",
    "    b_1 = tf.Variable(tf.zeros([10]))\n",
    "    layer_1 = tf.add(tf.matmul(X_data,W_1), b_1)\n",
    "    layer_1 = tf.nn.tanh(layer_1)\n",
    "\n",
    "    W_2 = tf.Variable(tf.random_uniform([10,10]))\n",
    "    b_2 = tf.Variable(tf.zeros([10]))\n",
    "    layer_2 = tf.add(tf.matmul(layer_1,W_2), b_2)\n",
    "    layer_2 = tf.nn.tanh(layer_2)\n",
    "\n",
    "    W_O = tf.Variable(tf.random_uniform([10,1]))\n",
    "    b_O = tf.Variable(tf.zeros([1]))\n",
    "    output = tf.add(tf.matmul(layer_2,W_O), b_O)\n",
    "\n",
    "    return output,W_O\n",
    "\n",
    "xs = tf.placeholder(\"float\")\n",
    "ys = tf.placeholder(\"float\")\n",
    "\n",
    "output,W_O = neural_net_model(xs,3)\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(output-ys))\n",
    "train = tf.train.AdamOptimizer(0.001).minimize(cost)\n",
    "\n",
    "correct_pred = tf.argmax(output, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred,tf.float32))\n",
    "\n",
    "c_t = []\n",
    "c_test = []\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    saver = tf.train.Saver()\n",
    "    y_t = denormalize(df_train,y_train)\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    plt.xlabel('Days')\n",
    "    plt.ylabel('Stock Value HRS')\n",
    "    plt.title('HRS Stock Index Prediction')\n",
    "    ax.plot(range(len(y_train)), y_t,label='Original')\n",
    "    plt.ion()\n",
    "\n",
    "    #saver.restore(sess,'yahoo_dataset.ckpt')\n",
    "    for i in range(100):\n",
    "        #sess.run([cost,train],feed_dict={xs:X_train, ys:y_train})\n",
    "        for j in range(X_train.shape[0]):\n",
    "            sess.run([cost,train],feed_dict={xs:X_train[j,:].reshape(1,3), ys:y_train[j]})\n",
    "\n",
    "        try:\n",
    "            ax.lines.remove(lines[0])\n",
    "        except Exception:\n",
    "            pass\n",
    "        pred = sess.run(output, feed_dict={xs:X_train})\n",
    "        pred = denormalize(df_train,pred)\n",
    "        plt.plot(range(len(y_train)), pred,'r-',label='Prediction')\n",
    "        plt.legend(loc='best')\n",
    "        plt.pause(0.1)\n",
    "\n",
    "        c_t.append(sess.run(cost, feed_dict={xs:X_train,ys:y_train}))\n",
    "        c_test.append(sess.run(cost, feed_dict={xs:X_test,ys:y_test}))\n",
    "        print('Epoch :',i,'Cost :',c_t[i])\n",
    "\n",
    "    pred = sess.run(output, feed_dict={xs:X_test})\n",
    "    for i in range(y_test.shape[0]):\n",
    "        print('Original :',y_test[i],'Predicted :',pred[i])\n",
    "\n",
    "    #plt.plot(range(50),c_t)\n",
    "    #plt.plot(range(50),c_test)\n",
    "    #plt.show()\n",
    "\n",
    "    print('Cost :',sess.run(cost, feed_dict={xs:X_test,ys:y_test}))\n",
    "    y_test = denormalize(df_test,y_test)\n",
    "    pred = denormalize(df_test,pred)\n",
    "    plt.plot(range(y_test.shape[0]),y_test,label=\"Original Data\")\n",
    "    plt.plot(range(y_test.shape[0]),pred,label=\"Predicted Data\")\n",
    "    plt.legend(loc='best')\n",
    "    \"\"\"plt.ylabel('Stock Value')\n",
    "    plt.xlabel('Days')\n",
    "    plt.title('Stock Market Nifty')\"\"\"\n",
    "    plt.show()\n",
    "    if input('Save model ? [Y/N]') == 'Y':\n",
    "        import os\n",
    "        saver.save(sess, os.getcwd() + '/yahoo_dataset.ckpt')\n",
    "        print('Model Saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Super Trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mod1 import *\n",
    "\n",
    "df = select_stock('한국알콜','2020-01-01')\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "@author: techietrader\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd  \n",
    "\n",
    "def ATR(df,n): #df is the DataFrame, n is the period 7,14 ,etc\n",
    "    df['H-L']=abs(df['High']-df['Low'])\n",
    "    df['H-PC']=abs(df['High']-df['Close'].shift(1))\n",
    "    df['L-PC']=abs(df['Low']-df['Close'].shift(1))\n",
    "    df['TR']=df[['H-L','H-PC','L-PC']].max(axis=1)\n",
    "    df['ATR']=np.nan\n",
    "    df.at[n-1,'ATR']=df['TR'][:n-1].mean() #.ix is deprecated from pandas version- 0.19\n",
    "    for i in range(n,len(df)):\n",
    "        df['ATR'][i]=(df['ATR'][i-1]*(n-1)+ df['TR'][i])/n\n",
    "    return df\n",
    "     \n",
    "\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "@author: techietrader\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd  \n",
    "\n",
    "\n",
    "#SuperTrend\n",
    "def ST(df,f,n): #df is the dataframe, n is the period, f is the factor; f=3, n=7 are commonly used.\n",
    "    #Calculation of ATR\n",
    "    df['H-L']=abs(df['High']-df['Low'])\n",
    "    df['H-PC']=abs(df['High']-df['Close'].shift(1))\n",
    "    df['L-PC']=abs(df['Low']-df['Close'].shift(1))\n",
    "    df['TR']=df[['H-L','H-PC','L-PC']].max(axis=1)\n",
    "    df['ATR']=np.nan\n",
    "    df.at[n-1,'ATR']=df['TR'][:n-1].mean() #.ix is deprecated from pandas verion- 0.19\n",
    "    for i in range(n,len(df)):\n",
    "        df['ATR'][i]=(df['ATR'][i-1]*(n-1)+ df['TR'][i])/n\n",
    "\n",
    "    #Calculation of SuperTrend\n",
    "    df['Upper Basic']=(df['High']+df['Low'])/2+(f*df['ATR'])\n",
    "    df['Lower Basic']=(df['High']+df['Low'])/2-(f*df['ATR'])\n",
    "    df['Upper Band']=df['Upper Basic']\n",
    "    df['Lower Band']=df['Lower Basic']\n",
    "    for i in range(n,len(df)):\n",
    "        if df['Close'][i-1]<=df['Upper Band'][i-1]:\n",
    "            df['Upper Band'][i]=min(df['Upper Basic'][i],df['Upper Band'][i-1])\n",
    "        else:\n",
    "            df['Upper Band'][i]=df['Upper Basic'][i]    \n",
    "    for i in range(n,len(df)):\n",
    "        if df['Close'][i-1]>=df['Lower Band'][i-1]:\n",
    "            df['Lower Band'][i]=max(df['Lower Basic'][i],df['Lower Band'][i-1])\n",
    "        else:\n",
    "            df['Lower Band'][i]=df['Lower Basic'][i]   \n",
    "    df['SuperTrend']=np.nan\n",
    "    for i in df['SuperTrend']:\n",
    "        if df['Close'][n-1]<=df['Upper Band'][n-1]:\n",
    "            df['SuperTrend'][n-1]=df['Upper Band'][n-1]\n",
    "        elif df['Close'][n-1]>df['Upper Band'][i]:\n",
    "            df['SuperTrend'][n-1]=df['Lower Band'][n-1]\n",
    "    for i in range(n,len(df)):\n",
    "        if df['SuperTrend'][i-1]==df['Upper Band'][i-1] and df['Close'][i]<=df['Upper Band'][i]:\n",
    "            df['SuperTrend'][i]=df['Upper Band'][i]\n",
    "        elif  df['SuperTrend'][i-1]==df['Upper Band'][i-1] and df['Close'][i]>=df['Upper Band'][i]:\n",
    "            df['SuperTrend'][i]=df['Lower Band'][i]\n",
    "        elif df['SuperTrend'][i-1]==df['Lower Band'][i-1] and df['Close'][i]>=df['Lower Band'][i]:\n",
    "            df['SuperTrend'][i]=df['Lower Band'][i]\n",
    "        elif df['SuperTrend'][i-1]==df['Lower Band'][i-1] and df['Close'][i]<=df['Lower Band'][i]:\n",
    "            df['SuperTrend'][i]=df['Upper Band'][i]\n",
    "    return df\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SuperST(stockdata,estim,multiplier = 7):\n",
    "    #first we need next row value\n",
    "    df_prev = estim[['finaluband','finallband','supert']].join(stockdata[['close']]).shift(1)\n",
    "    # name colums as it was in paramas\n",
    "    df_prev.columns = ['prevfinaluband', 'prevfinallband', 'prevsupertrend', 'prevclose']\n",
    "    # working matrix parmas with shifed values w/o NaN in ATR\n",
    "    df = stockdata.dropna().join(df_prev).fillna(0)\n",
    "\n",
    "    #calulate vectors \n",
    "    upperbasicband = ((df.high+df.low)/2 + (multiplier * df.atr))\n",
    "    lowerbasicband = ((df.high+df.low)/2 - (multiplier * df.atr))\n",
    "    # np.where is a vector version of if\n",
    "    upperband = np.where((upperbasicband < df.prevfinaluband) | (df.prevclose > df.prevfinaluband),\n",
    "                        upperbasicband,df.prevfinaluband)\n",
    "    lowerband = np.where ((lowerbasicband > df.prevfinallband) | (df.prevclose < df.prevfinallband),\n",
    "                         lowerbasicband,df.prevfinallband)\n",
    "\n",
    "    supertrend = np.where (df.prevsupertrend == df.prevfinaluband,\n",
    "                             np.where(df.close <= upperband,\n",
    "                                      upperband,lowerband),\n",
    "                          np.where(df.prevsupertrend == df.prevfinallband,\n",
    "                                      np.where(df.close >= lowerband,\n",
    "                                              lowerband,upperband),\n",
    "                                    np.zeros_like(lowerband)))\n",
    "\n",
    "\n",
    "    return upperbasicband.to_frame('uband').assign( \n",
    "                    lband = lowerbasicband).assign(\n",
    "                    finaluband = upperband).assign(\n",
    "                    finallband = lowerband).assign(\n",
    "                    supert = supertrend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#df = pd.read_excel('d:\\\\stockdata\\\\vote_stock\\\\detect_stock_with_price_2020-05-18.xlsx')\n",
    "df = pd.read_excel('d:\\\\b_9.xlsx')\n",
    "df=df['Name'].iloc[300:400]\n",
    "#name = df.values.tolist() ## numpy to list\n",
    "name = df.to_list()  \n",
    "\n",
    "#name = ['SGA솔루션즈','한국전자인증','SGA','케이사인','한컴위드']\n",
    "\n",
    "for i in name:\n",
    "    df = select_stock(i,'2020-01-01')\n",
    "    ST(df,3,7)\n",
    "    df = df.set_index(df['Date'])\n",
    "    df[['Close','SuperTrend']].plot(figsize=(16,4))\n",
    "    plt.title(i)\n",
    "    plt.grid(True)\n",
    "    plt.show()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "name = '원익홀딩스'\n",
    "df = select_stock(name,'2017-01-01')\n",
    "ST(df,3,7)\n",
    "df = df.set_index(df['Date'])\n",
    "df[['Close','SuperTrend']].plot(figsize=(16,4))\n",
    "plt.title(name)\n",
    "plt.grid(True)\n",
    "plt.show()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#df = pd.read_excel('d:\\\\stockdata\\\\vote_stock\\\\detect_stock_with_price_2020-05-18.xlsx')\n",
    "#df = pd.read_excel('d:\\\\high.xlsx')\n",
    "#df = df['Name'].unique()\n",
    "#name = df.values.tolist() ## numpy to list\n",
    "#name = df.tolist()  \n",
    "\n",
    "name = ['모트렉스','원익홀딩스','오공','동국산업','링네트','이씨에스','한국단자']\n",
    "\n",
    "for i in name:\n",
    "    df = select_stock(i,'2019-01-01')\n",
    "    df['V']=df['Volume']\n",
    "    ST(df,3,7)\n",
    "    df = df.set_index(df['Date'])\n",
    "    df[['Close','SuperTrend']].plot(figsize=(16,4))\n",
    "    plt.title(i)\n",
    "    plt.grid(True)\n",
    "    plt.show()    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = select_stock('hrs','2020-05-01')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = \"select * from kospi where Date > '2018-01-01'\"\n",
    "df = pd.read_sql(var, engine)\n",
    "\n",
    "\n",
    "ST(df,3,7)\n",
    "df = df.set_index(df['Date'])\n",
    "df[['Close','SuperTrend']].plot(figsize=(16,4))\n",
    "plt.title('kospi')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = \"select * from kospi where Date > '2019-06-01'\"\n",
    "df = pd.read_sql(var, engine)\n",
    "\n",
    "\n",
    "ST(df,3,7)\n",
    "df = df.set_index(df['Date'])\n",
    "df[['Close','SuperTrend']].plot(figsize=(16,4))\n",
    "plt.title('kospi')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mod1 import *\n",
    "import matplotlib.gridspec as gridspec\n",
    "import mplfinance as mpf\n",
    "\n",
    "\n",
    "df = select_stock('hrs', '2020-01-01')\n",
    "\n",
    "ohlc = df[['Date','Open', 'High', 'Low', 'Close','Volume']]\n",
    "ohlc['Date'] = pd.to_datetime(ohlc['Date'])\n",
    "ohlc = ohlc.set_index('Date')\n",
    "ohlc.index.name = 'Date'\n",
    "\n",
    "mpf.plot(ohlc,figratio=(15,8),type='candle',mav=(5),volume=True,style='charles')  ### 3,6,9일 이동평균선 그리고 거래량"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이타 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mod1 import *\n",
    "\n",
    "df = select_stock('hrs','2020-01-01')\n",
    "df = df[['Open','High','Low','Volume','Close']]\n",
    "print(df.head())\n",
    "\n",
    "# 결과확인을 위해 소수 출력 옵션 변경 소수 첫째자리까지\n",
    "np.set_printoptions(formatter={'float_kind': lambda x: \"{0:0.5f}\".format(x)}) \n",
    "\n",
    "data = df.values\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "data_a =scaler.fit_transform(data)               ## 전처리 \n",
    "print(data_a[:5])\n",
    "\n",
    "data_b = scaler.inverse_transform(data_a)        ## 전체 복원\n",
    "print(data_b[:5])\n",
    "\n",
    "data_c = scaler.inverse_transform(data_a)[:, [0]] ##  Open열만 복원,  Close열은 [4]\n",
    "data_c[:5]\n",
    "\n",
    "### 주식 예측값 배열이 생성 되었을때 실제 Close와 비교하기\n",
    "\n",
    "#pred = model.predict(test_X) \n",
    "pred = [[0.69005],[0.61538],[0.60407],[0.63575],[0.62443]]  ## 테스트용으로 종가 5일치를 역순으로 \n",
    "scale= MinMaxScaler()\n",
    "scale.min_, scale.scale_=scaler.min_[4], scaler.scale_[4]   ##  Open열[0],High열[1] ~ Close열은 [4]\n",
    "data_d = scale.inverse_transform(pred)\n",
    "print(data_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "print(np.__version__) # 1.16.4\n",
    "\n",
    "# 결과확인을 위해 소수 출력 옵션 변경\n",
    "np.set_printoptions(formatter={'float_kind': lambda x: \"{0:0.1f}\".format(x)}) \n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "t1 =  np.array([\n",
    "                    [ 1,    1000],\n",
    "                    [ 5,   10000],\n",
    "                    [10,  100000],\n",
    "               ])\n",
    "t2 =  np.array([\n",
    "                    [  2,    100],\n",
    "                    [ 15,  20000],\n",
    "                    [100, 300000],\n",
    "               ])\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "scaler.fit(t1)\n",
    "print(scaler.n_samples_seen_, scaler.data_min_, scaler.data_max_, scaler.feature_range)\n",
    "# > 3 [1.0 1000.0] [10.0 100000.0] (0, 1)\n",
    "\n",
    "scaler.partial_fit(t2) # 추가 피팅\n",
    "print(scaler.n_samples_seen_, scaler.data_min_, scaler.data_max_, scaler.feature_range)\n",
    "# > 6 [1.0 100.0] [100.0 300000.0] (0, 1)\n",
    "\n",
    "t2_prinme = scaler.transform(t2)\n",
    "# array([[0.0, 0.0],\n",
    "#        [0.1, 0.1],\n",
    "#        [1.0, 1.0]])\n",
    "print(t2_prinme)\n",
    "\n",
    "t2_prime_prime = scaler.inverse_transform(t2_prinme)\n",
    "#  array([[  2.0,    100.0],\n",
    "#         [ 15.0,  20000.0],\n",
    "#         [100.0, 300000.0]])\n",
    "print(t2_prime_prime)\n",
    "\n",
    "\n",
    "### https://m.blog.naver.com/PostView.nhn?blogId=wideeyed&logNo=221614354947&proxyReferer=https:%2F%2Fwww.google.com%2F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## np.reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  reshape(-1)의 의미  : 가변적이다\n",
    "\n",
    "x = np.arange(12)\n",
    "print(x)\n",
    "\n",
    "print(x.reshape(-1,1))  ## 행,열중 열이  1열이므로 12행이된다\n",
    "print(x.reshape(-1,2))  ## 열이 2열이므로 6행이 된다\n",
    "\n",
    "print(x.reshape(1,-1))  ## 행,열중 행이 1행이므로 열이 12열이 된다\n",
    "print(x.reshape(2,-1))  ## 행,열중 행이 2행이므로 열이 6열이 된다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 년중 특정요일 날짜 추출하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def allsundays(year):\n",
    "    return pd.date_range(start=str(year), end=str(year+1),freq='W-SUN').strftime('%Y-%m-%d').tolist()\n",
    "\n",
    "allsundays(2020)[:5]  # First 5 Sundays of 2020\n",
    "# ['01/01/2017', '01/08/2017', '01/15/2017', '01/22/2017', '01/29/2017']\n",
    "\n",
    "\n",
    "https://rfriend.tistory.com/503"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date, timedelta\n",
    "\n",
    "def allsundays(year):\n",
    "   d = date(year, 1, 1)                    # January 1st\n",
    "   d += timedelta(days = 6 - d.weekday())  # First Sunday\n",
    "   while d.year == year:\n",
    "      yield d\n",
    "      d += timedelta(days = 7)\n",
    "\n",
    "sunday=[]    \n",
    "for d in allsundays(2020):\n",
    "   sunday.append(d)\n",
    "\n",
    "sunday[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 월봉, 주봉 DataFrame 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  stock 자료 항목을 월봉, 주봉  DataFrame 으로 변환하기\n",
    "\n",
    "from mod1 import *\n",
    "\n",
    "df = select_market('kospi','2020-01-01')\n",
    "#df = df.set_index('Date')\n",
    "#df.index=pd.to_datetime(df.index)\n",
    "#df = df.reset_index()\n",
    "df['Date']=pd.to_datetime(df['Date'])\n",
    "#months = [g for n, g in df.groupby(pd.Grouper(key='Date',freq='M'))]  ##   월별\n",
    "months = [g for n, g in df.groupby(pd.Grouper(key='Date',freq='W'))]  ##   주별\n",
    "columns = ['date','open', 'high', 'low', 'close', 'volume']\n",
    "rows = []\n",
    "\n",
    "for i in range(len(months)):\n",
    "    rows.append(months[i].iloc[-1]['Date'])\n",
    "    rows.append(months[i].iloc[0][\"Open\"])\n",
    "    rows.append(max(months[i]['High']))\n",
    "    rows.append(min(months[i]['Low']))\n",
    "    rows.append(months[i].iloc[-1]['Close'])\n",
    "    rows.append(sum(months[i]['Volume']))\n",
    "\n",
    "arr = np.array(rows)\n",
    "arr1 = arr.reshape(len(months),6)\n",
    "df = pd.DataFrame(data=arr1, columns=columns)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mod1 import *\n",
    "\n",
    "today = datetime.now().strftime('%Y-%m-%d')\n",
    "today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
