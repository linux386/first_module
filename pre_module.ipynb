{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  ##  일봉,주봉,월봉 데이터 생성\n",
    "\n",
    "from mod1 import *\n",
    "\n",
    "def day_week_month_data(market='일야', start_day = '2020-01-01',period ='month'):\n",
    "    if market=='kospi' or market=='kosdaq':\n",
    "        df = select_market(market,start_day)\n",
    "    else :\n",
    "        df = select_stock(market,start_day)\n",
    "    df['Date']=pd.to_datetime(df['Date'])\n",
    "    months = [g for n, g in df.groupby(pd.Grouper(key='Date',freq='M'))]  ##   월별\n",
    "    weeks = [g for n, g in df.groupby(pd.Grouper(key='Date',freq='W'))]  ##   주별\n",
    "    columns = ['Date','Open', 'High', 'Low', 'Close', 'Volume']\n",
    "    rows = []    \n",
    "\n",
    "    if period == 'day':\n",
    "        \n",
    "        df=df[['Date','Open', 'High', 'Low','Close', 'Volume']]\n",
    "        df.columns=columns\n",
    "        #df = df.set_index(df['date'])\n",
    "        return df\n",
    "    \n",
    "    elif period == 'month':\n",
    "        period = months\n",
    "        \n",
    "    elif period == 'week':\n",
    "        period = weeks\n",
    "        \n",
    "    for i in range(len(period)):\n",
    "        rows.append(period[i].iloc[-1]['Date'])\n",
    "        rows.append(period[i].iloc[0][\"Open\"])\n",
    "        rows.append(max(period[i]['High']))\n",
    "        rows.append(min(period[i]['Low']))\n",
    "        rows.append(period[i].iloc[-1]['Close'])\n",
    "        rows.append(sum(period[i]['Volume']))\n",
    "        \n",
    "    arr = np.array(rows)\n",
    "    arr1 = arr.reshape(len(period),6)\n",
    "    df = pd.DataFrame(data=arr1, columns=columns)\n",
    "    df = df.set_index(df['Date'])\n",
    "    df.rename(columns = {'Date' : 'Date1'}, inplace = True)\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  일봉,주봉,월봉에서  연속으로 하락한 종목을 순서대로 정렬\n",
    "\n",
    "\n",
    "from mod1 import *\n",
    "\n",
    "def day_week_month_data(market='일야', start_day = '2020-01-01',period ='month'):\n",
    "    if market=='kospi' or market=='kosdaq':\n",
    "        df = select_market(market,start_day)\n",
    "    else :\n",
    "        df = select_stock(market,start_day)\n",
    "    df['Date']=pd.to_datetime(df['Date'])\n",
    "    months = [g for n, g in df.groupby(pd.Grouper(key='Date',freq='M'))]  ##   월별\n",
    "    weeks = [g for n, g in df.groupby(pd.Grouper(key='Date',freq='W'))]  ##   주별\n",
    "    columns = ['Date','Open', 'High', 'Low', 'Close', 'Volume']\n",
    "    rows = []    \n",
    "\n",
    "    if period == 'day':\n",
    "        \n",
    "        df=df[['Date','Open', 'High', 'Low','Close', 'Volume']]\n",
    "        df.columns=columns\n",
    "        #df = df.set_index(df['date'])\n",
    "        return df\n",
    "    \n",
    "    elif period == 'month':\n",
    "        period = months\n",
    "        \n",
    "    elif period == 'week':\n",
    "        period = weeks\n",
    "        \n",
    "    for i in range(len(period)):\n",
    "        rows.append(period[i].iloc[-1]['Date'])\n",
    "        rows.append(period[i].iloc[0][\"Open\"])\n",
    "        rows.append(max(period[i]['High']))\n",
    "        rows.append(min(period[i]['Low']))\n",
    "        rows.append(period[i].iloc[-1]['Close'])\n",
    "        rows.append(sum(period[i]['Volume']))\n",
    "        \n",
    "    arr = np.array(rows)\n",
    "    arr1 = arr.reshape(len(period),6)\n",
    "    df = pd.DataFrame(data=arr1, columns=columns)\n",
    "    df = df.set_index(df['Date'])\n",
    "    df.rename(columns = {'Date' : 'Date1'}, inplace = True)\n",
    "    return df \n",
    "\n",
    "def depress(period):\n",
    "    today = datetime.now().strftime('%Y-%m-%d')\n",
    "    path_depress = 'd:\\\\stockdata\\\\depress\\\\depress_'\n",
    "    if period=='month':\n",
    "        start_day='2019-01-01'\n",
    "        \n",
    "    elif period=='week' :\n",
    "        start_day='2020-01-01'\n",
    "        \n",
    "    else :\n",
    "        start_day='2020-05-01'\n",
    "        \n",
    "    df = all_stock('2020-06-15')\n",
    "    df = df['Name']\n",
    "    name = df.to_list()\n",
    "\n",
    "    #name=['일야','hrs','디지털대성']\n",
    "    count = 0\n",
    "    depress=[]\n",
    "    for i in name:\n",
    "        df = day_week_month_data(market=i,start_day=start_day,period=period)\n",
    "        df['yesterday']=df.Close.shift(1)\n",
    "        df['minus']=(df['Close']-df['yesterday']) < 0\n",
    "        df1 = df.sort_values(by=['Date'], axis=0, ascending=False,ignore_index=True )\n",
    "        minus = df1.minus.values\n",
    "\n",
    "        for i in minus:\n",
    "            if i == True:\n",
    "                count += 1\n",
    "\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        #print(count)\n",
    "        depress.append(count)\n",
    "        count=0\n",
    "\n",
    "\n",
    "    df2= pd.DataFrame()\n",
    "    df2['name']=name\n",
    "    df2['count']=depress\n",
    "    df3 = df2.sort_values(by=['count'], axis=0, ascending=False,ignore_index=True )\n",
    "    if period=='month':\n",
    "        df3 = df3.iloc[:100]\n",
    "    elif period=='week':\n",
    "        df3 = df3.iloc[:200]\n",
    "    elif period=='day':\n",
    "        df3 = df3.iloc[:300]\n",
    "    #else:\n",
    "       # break\n",
    "    df3.to_excel(path_depress+today+'_'+period+'.xlsx')\n",
    "    #return df3\n",
    "\n",
    "\n",
    "three_period=['day','week','month']\n",
    "for i in three_period:\n",
    "    depress(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  일봉상 연속으로 하락한 종목을 순서대로 정렬\n",
    "\n",
    "from mod1 import *\n",
    "\n",
    "df = all_stock('2020-06-12')\n",
    "df = df['Name']\n",
    "name = df.to_list()\n",
    "\n",
    "count = 0\n",
    "depress=[]\n",
    "for i in name:\n",
    "    df = select_stock(i,'2020-05-01')\n",
    "    df['yesterday']=df.Close.shift(1)\n",
    "    df['minus']=(df['Close']-df['yesterday']) < 0\n",
    "    df1 = df.sort_values(by=['Date'], axis=0, ascending=False,ignore_index=True )\n",
    "    minus = df1.minus.values\n",
    "\n",
    "    for i in minus:\n",
    "        \n",
    "\n",
    "        if i == True:\n",
    "            count += 1\n",
    "\n",
    "        else:\n",
    "            \n",
    "            break\n",
    "        \n",
    "    print(count)\n",
    "    depress.append(count)\n",
    "    count=0\n",
    "\n",
    "\n",
    "df2= pd.DataFrame()\n",
    "df2['name']=name\n",
    "df2['count']=depress\n",
    "df3 = df2.sort_values(by=['count'], axis=0, ascending=False,ignore_index=True )\n",
    "df3.to_excel('d:\\depress_day.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###  기간동안 종목별 종가중 최대값 \n",
    "\n",
    "from  mod1 import *\n",
    "\n",
    "def all_stock_period(date1, date2='2021-01-01'):\n",
    "    select_query = \"select * from market_good where Date >=  \"\n",
    "    var = select_query +\"'\"+date1+\"'\"  +\" \"+ 'and Date <=' + \"'\"+date2+\"'\"\n",
    "    df = pd.read_sql(var, engine)\n",
    "    return df\n",
    "\n",
    "df = all_stock_period('2020-03-05','2020-03-10')\n",
    "\n",
    "max(df[df['Code']=='000547'].Close) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  기간동안 낙폭 과대종목 검색 (기간동안 최저점에서 현재가 비교)_1\n",
    "\n",
    "\n",
    "from  mod1 import *\n",
    "\n",
    "def all_stock_period(date1, date2='2021-01-01'):\n",
    "    select_query = \"select * from market_good where Date >=  \"\n",
    "    var = select_query +\"'\"+date1+\"'\"  +\" \"+ 'and Date <=' + \"'\"+date2+\"'\"\n",
    "    df = pd.read_sql(var, engine)\n",
    "    return df\n",
    "\n",
    "\n",
    "df = all_stock_period('2020-02-20','2020-03-25')\n",
    "df_uniq = df['Name'].unique()\n",
    "df_uniq_list=df_uniq.tolist()\n",
    "\n",
    "min_data = []\n",
    "for x in df_uniq_list:\n",
    "    min_value = min(df[df['Name']== x ].Close)\n",
    "    min_data.append(min_value)\n",
    "\n",
    "min_close = pd.DataFrame(min_data)\n",
    "\n",
    "df_a=pd.DataFrame(df_uniq)\n",
    "\n",
    "\n",
    "df_first=pd.DataFrame()\n",
    "df_first['Name']=df_a[0]\n",
    "df_first['Close']=min_close[0]\n",
    "df_to = all_stock('2020-07-28')\n",
    "df_last=df_to[['Name','Close']]\n",
    "df = pd.merge(df_first,df_last,on='Name')\n",
    "\n",
    "df['diff']=df['Close_y']/df['Close_x']\n",
    "df.head()\n",
    "\n",
    "close_diff_df =  df.sort_values([\"diff\"],ascending=True)\n",
    "close_diff_df.head()\n",
    "\n",
    "close_diff_df.to_excel(\"f:\\\\b_1.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  기간동안 낙폭 과대종목 검색 (기간동안 최저점에서 현재가 비교)_2\n",
    "\n",
    "import time\n",
    "from  mod1 import *\n",
    "\n",
    "start = time.time()  # 시작 시간 저장\n",
    "\n",
    "today = datetime.now().strftime('%Y-%m-%d')\n",
    "current=today\n",
    "def all_stock_period(date1, date2='2021-01-01'):\n",
    "    select_query = \"select * from market_good where Date >=  \"\n",
    "    var = select_query +\"'\"+date1+\"'\"  +\" \"+ 'and Date <=' + \"'\"+date2+\"'\"\n",
    "    df = pd.read_sql(var, engine)\n",
    "    return df\n",
    "\n",
    "df = all_stock_period('2020-02-19','2020-03-25')\n",
    "df_start=pd.DataFrame()\n",
    "name = df['Name'].unique()\n",
    "\n",
    "df = df.set_index('Name')\n",
    "\n",
    "min_list=[ ]\n",
    "for i in name:\n",
    "    min_close  = min(df.loc[i].Close)\n",
    "    min_list.append(min_close)\n",
    "\n",
    "df_start=pd.DataFrame(name)\n",
    "df_start['Name']=pd.DataFrame(name)\n",
    "df_start['Close']=pd.DataFrame(min_list)\n",
    "df_start=df_start[['Name','Close']]\n",
    "df1 = all_stock(current)\n",
    "df1_last = df1[['Name','Close']]\n",
    "\n",
    "df2 = pd.merge(df_start, df1_last, on=\"Name\")\n",
    "df2['diff']=df2['Close_y']/df2['Close_x']\n",
    "df2 = df2.sort_values(by=['diff'], ascending='True')\n",
    "\n",
    "df2.to_excel('f:\\\\down_'+current+'.xlsx')\n",
    "print(\"time :\", time.time() - start)  # 현재시각 - 시작시간 = 실행 시간"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## _1 기간동안 낙폭 과대종목 검색 (기간동안 최저점에서 현재가 비교)_2\n",
    "\n",
    "import time\n",
    "from  mod1 import *\n",
    "\n",
    "start = time.time()  # 시작 시간 저장\n",
    "today = datetime.now().strftime('%Y-%m-%d')\n",
    "df = select_stock('아스트','2019-01-01')\n",
    "how = {'Open': 'first', 'High': 'max', 'Low': 'min', 'Close': 'last', 'Volume': 'sum'}\n",
    "def resample_df(df, freq, how):\n",
    "    df['Date'] = df['Date'].astype('datetime64[ns]')\n",
    "    df = df.set_index('Date')\n",
    "    df = df[['Open','High','Low','Close','Volume']]\n",
    "    #how = {'Open': 'first', 'High': 'max', 'Low': 'min', 'Close': 'last', 'Volume': 'sum'}\n",
    "    if freq != 'd' and len(df) > 0:\n",
    "        if freq == 'm':\n",
    "            df = df.resample('M').apply(how)\n",
    "            #df.index = df.index.strftime('%Y%m')\n",
    "        elif freq == 'y':\n",
    "            df = df.resample('Y').apply(how)\n",
    "            #df.index = df.index.strftime('%Y')\n",
    "        else:\n",
    "            print(\"choose a freq parameter in ('m', 'y', 'd')\")\n",
    "            raise RuntimeError\n",
    "    return df\n",
    "\n",
    "df = resample_df(df,'m',how)    \n",
    "print(df.head())\n",
    "print(\"time :\", time.time() - start)  # 현재시각 - 시작시간 = 실행 시간"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## _2기간동안 낙폭 과대종목 검색 (기간동안 최저점에서 현재가 비교)_2\n",
    "\n",
    "import time\n",
    "from  mod1 import *\n",
    "\n",
    "start = time.time()  # 시작 시간 저장\n",
    "today = datetime.now().strftime('%Y-%m-%d')\n",
    "df = select_stock('아스트','2019-01-01')\n",
    "\n",
    "df1=pd.DataFrame()\n",
    "\n",
    "df1[['Date','Close']] = df[['Date','Close']]\n",
    "\n",
    "df1['Date'] = df1['Date'].astype('datetime64[ns]')\n",
    "\n",
    " \n",
    "\n",
    "df1 = df1.set_index('Date')\n",
    "\n",
    "df_week = df1.resample('W').mean()\n",
    "\n",
    "df_month = df1.resample('M').mean()\n",
    "\n",
    "print(df_month.head())\n",
    "\n",
    "print(\"time :\", time.time() - start)  # 현재시각 - 시작시간 = 실행 시간"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  기간동안 낙폭 과대종목 검색\n",
    "\n",
    "from mod1 import *\n",
    "today = datetime.now().strftime('%Y-%m-%d')\n",
    "current=today\n",
    "\n",
    "df_from = all_stock('2020-03-05')\n",
    "df_to = all_stock(current)\n",
    "df_first=df_from[['Name','Close']]\n",
    "df_last=df_to[['Name','Close']]\n",
    "df = pd.merge(df_first,df_last,on='Name')\n",
    "\n",
    "df['diff']=df['Close_y']/df['Close_x']\n",
    "df.head()\n",
    "\n",
    "close_diff_df =  df.sort_values([\"diff\"],ascending=True)\n",
    "close_diff_df.head()\n",
    "\n",
    "close_diff_df.to_excel('d:\\\\down_'+current+'.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 월봉 만들기\n",
    "\n",
    "df = select_stock('아스트','2019-01-01')\n",
    "how = {'Open': 'first', 'High': 'max', 'Low': 'min', 'Close': 'last', 'Volume': 'sum'}\n",
    "def resample_df(df, freq, how):\n",
    "    df['Date'] = df['Date'].astype('datetime64[ns]')\n",
    "    df = df.set_index('Date')\n",
    "    df = df[['Open','High','Low','Close','Volume']]\n",
    "    #how = {'Open': 'first', 'High': 'max', 'Low': 'min', 'Close': 'last', 'Volume': 'sum'}\n",
    "    if freq != 'd' and len(df) > 0:\n",
    "        if freq == 'm':\n",
    "            df = df.resample('M').apply(how)\n",
    "            #df.index = df.index.strftime('%Y%m')\n",
    "        elif freq == 'y':\n",
    "            df = df.resample('Y').apply(how)\n",
    "            #df.index = df.index.strftime('%Y')\n",
    "        else:\n",
    "            print(\"choose a freq parameter in ('m', 'y', 'd')\")\n",
    "            raise RuntimeError\n",
    "    return df\n",
    "\n",
    "df = resample_df(df,'m',how)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 9 elements, new values have 1 elements",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-86-7768276fa6d6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'current_Close'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'current_Close'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'current_Close'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\envs\\kkang\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__setattr__\u001b[1;34m(self, name, value)\u001b[0m\n\u001b[0;32m   5285\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5286\u001b[0m             \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5287\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5288\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5289\u001b[0m             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\properties.pyx\u001b[0m in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\envs\\kkang\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_set_axis\u001b[1;34m(self, axis, labels)\u001b[0m\n\u001b[0;32m    659\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    660\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_set_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 661\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    662\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    663\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\envs\\kkang\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mset_axis\u001b[1;34m(self, axis, new_labels)\u001b[0m\n\u001b[0;32m    176\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnew_len\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mold_len\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m             raise ValueError(\n\u001b[1;32m--> 178\u001b[1;33m                 \u001b[1;34mf\"Length mismatch: Expected axis has {old_len} elements, new \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    179\u001b[0m                 \u001b[1;34mf\"values have {new_len} elements\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m             )\n",
      "\u001b[1;31mValueError\u001b[0m: Length mismatch: Expected axis has 9 elements, new values have 1 elements"
     ]
    }
   ],
   "source": [
    "##  기간동안 종목 가격 변화 \n",
    "\n",
    "from  mod1 import *\n",
    "\n",
    "price_path = 'f:/stockdata/vote_stock/detect_stock_with_price_'\n",
    "volume_path = 'f:/stockdata/vote_stock/detect_stock_with_volume_'\n",
    "\n",
    "df = pd.read_excel(volume_path+'2019-01-03.xlsx', index_col=0)\n",
    "\n",
    "data = pd.DataFrame()\n",
    "for x in df['Name']:\n",
    "    current = select_stock(x,'2020-07-20')\n",
    "    data = data.append(current['Close'])\n",
    "\n",
    "data = data.reset_index(drop=True)\n",
    "data.columns=['current_Close']\n",
    "\n",
    "df['current_Close']=data['current_Close']\n",
    "df['diff']=df['current_Close'] / df['today_Close']\n",
    "\n",
    "df = df.sort_values(['diff'], ascending=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## datetime.date  -> pd.to_datetime \n",
    "\n",
    "#!/usr/bin/env python3\n",
    "# coding: utf-8\n",
    "\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "# create a datetime data object\n",
    "d_time = datetime.date(2010, 11, 12)\n",
    "\n",
    "# create a pandas Timestamp object\n",
    "t_stamp = pd.to_datetime('2010/11/12')\n",
    "\n",
    "# cast `datetime_timestamp` as Timestamp object and compare\n",
    "d_time2t_stamp = pd.to_datetime(d_time)\n",
    "\n",
    "# print to double check\n",
    "print(d_time)\n",
    "print(t_stamp)\n",
    "print(d_time2t_stamp)\n",
    "\n",
    "# since the conversion succeds this prints `True`\n",
    "print(d_time2t_stamp == t_stamp)\n",
    "\n",
    "\n",
    "## sample \n",
    "t = pd.Timestamp('2013-12-25 00:00:00')\n",
    "\n",
    "t.date()\n",
    "#datetime.date(2013, 12, 25)\n",
    "\n",
    "t.date() == datetime.date(2013, 12, 25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import FinanceDataReader as fdr\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime as dt\n",
    "from datetime import datetime,timedelta\n",
    "from urllib.request import urlopen\n",
    "import sqlalchemy \n",
    "import pymysql\n",
    "import talib.abstract as ta\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "from matplotlib import font_manager, rc\n",
    "font_name = font_manager.FontProperties(fname=\"c:/Windows/Fonts/malgun.ttf\").get_name()\n",
    "rc('font', family=font_name)\n",
    "\n",
    "now = dt.datetime.today().strftime('%Y-%m-%d')\n",
    "engine = sqlalchemy.create_engine('mysql+pymysql://kkang:leaf2027@localhost/stock?charset=utf8',encoding='utf-8')\n",
    "conn = pymysql.connect(host = 'localhost', user = 'kkang', password = 'leaf2027' ,db = 'stock')\n",
    "curs = conn.cursor()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataBase 입출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  코스피, 코드닥 지수 Database에 입력\n",
    "\n",
    "from mod1 import *\n",
    "def market_index_to_database(startday, lastday='20251231', market='코스피'):\n",
    "\n",
    "    df = get_index_ohlcv_by_date(startday, lastday, market)\n",
    "\n",
    "    df.index.names = ['Date']\n",
    "    df.columns  = ('Open','High','Low','Close','Volume')\n",
    "    if market == '코스피':\n",
    "        df['Market']='kospi'\n",
    "        df.to_sql(name='kospi', con=engine, if_exists='append')\n",
    "    elif market == '코스닥':\n",
    "        df['Market']='kosdaq'\n",
    "        df.to_sql(name='kosdaq', con=engine, if_exists='append')\n",
    "    #df.to_excel('d:\\\\kospi.xlsx')\n",
    "market_index_to_database(\"20200731\",'20251231','코스피')\n",
    "market_index_to_database(\"20200731\",'20251231','코스닥')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## def get_stock_price_from_fdr(end_date=now):  코스피,코스닥 전체종목 입력\n",
    "        \n",
    "file_name = input('파일이름을 입력하세요:')\n",
    "toward = input('저장 방식을 입력하세요 : sample: excel, sql ')\n",
    "start_date = input(\"시작날자를 입려하세요 : sample: '2015-01-01'\")\n",
    "table_name = input(\"table명을 입력하세요 : sample: market\")\n",
    "data=pd.read_excel('d:\\\\'+ file_name)\n",
    "   \n",
    "code_list = data['종목코드'].tolist()\n",
    "code_list = [str(item).zfill(6) for item in code_list]\n",
    "name_list = data['종목명'].tolist()\n",
    "\n",
    "# 코스피 상장종목 전체\n",
    "stock_dic = dict(list(zip(code_list,name_list)))\n",
    "\n",
    "for code in sorted(stock_dic.keys()):\n",
    "    df  = fdr.DataReader(code,start_date,now)\n",
    "    print(code,stock_dic[code])\n",
    "    df['Code'],df['Name'] = code,stock_dic[code]\n",
    "    df = df[['Code','Name','Open','High','Low','Volume','Close']]\n",
    "    if toward == 'excel':\n",
    "        df.to_excel('d:\\\\data_set\\\\kospi\\\\'+ stock_dic[code] +'.xlsx',engine = 'xlsxwriter')\n",
    "    elif toward == 'sql':\n",
    "        df.to_sql(name=table_name, con=engine, if_exists='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "주식 Code를 입력하세요204990\n",
      "주식이름을 입력하세요코썬바이오\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#### 신규종목 \n",
    "## insert mysql 개별 주식\n",
    "\n",
    "Code = input('주식 Code를 입력하세요')\n",
    "Name = input('주식이름을 입력하세요')\n",
    "\n",
    "df = fdr.DataReader(Code, '1995')\n",
    "#df.to_excel('d:\\\\'+Code+'.xlsx', encoding='UTF-8')\n",
    "\n",
    "#df = pd.read_excel('d:\\\\'+Code+'.xlsx')\n",
    "df['Code']= Code\n",
    "df['Name']= Name\n",
    "\n",
    "df = df[['Code','Name','Open', 'High', 'Low', 'Volume','Close']]\n",
    "df = df.reset_index().rename(columns={'index':'Date'})\n",
    "\n",
    "df.to_sql(name='market', con=engine, if_exists='append', index = False)\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#### 기존에 액면분할시 가격조정 안된 기존 data가 있을때\n",
    "## insert mysql 개별 주식\n",
    "\n",
    "\n",
    "Code = input('주식 Code를 입력하세요')\n",
    "Name = input('주식이름을 입력하세요')\n",
    "\n",
    "query = \"delete from  market where Code = \"+\"'\"+Code+\"'\"\n",
    "\n",
    "curs.execute(query)\n",
    "conn.commit()\n",
    "\n",
    "\n",
    "df = fdr.DataReader(Code, '1995')\n",
    "#df.to_excel('d:\\\\'+Code+'.xlsx', encoding='UTF-8')\n",
    "\n",
    "#df = pd.read_excel('d:\\\\'+Code+'.xlsx')\n",
    "df['Code']= Code\n",
    "df['Name']= Name\n",
    "\n",
    "df = df[['Code','Name','Open', 'High', 'Low', 'Volume','Close']]\n",
    "df = df.reset_index().rename(columns={'index':'Date'})\n",
    "\n",
    "df.to_sql(name='market', con=engine, if_exists='append', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "query = \"select distinct Name from market\"\n",
    "\n",
    "df = pd.read_sql(query,con=engine)\n",
    "df.to_excel('f:\\\\aa.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## def excel_to_mysql():\n",
    "\n",
    "file_name = input('파일이름을 입력하세요:')\n",
    "        \n",
    "df=pd.read_excel('d:\\\\'+ file_name)\n",
    "if file_name=='kpi200.xlsx':\n",
    "    df.columns=['Date','kpi200','거래량']\n",
    "    table_name = 'kpi200'\n",
    "    #df = df.set_index('Date')\n",
    "elif file_name=='moneytrend.xlsx':\n",
    "    table_name = 'moneytrend'\n",
    "    df.columns=['Date', '고객예탁금', '신용잔고','주식형펀드','혼합형펀드','채권형펀드']\n",
    "    #df = df.set_index('Date')\n",
    "elif file_name=='kospi_sector.xlsx':\n",
    "    table_name = 'kospi_sector'\n",
    "    df.columns=['Date', 'sectorName', 'changeRate', 'first', 'second']\n",
    "elif file_name=='kosdaq_sector.xlsx':\n",
    "    table_name = 'kosdaq_sector'\n",
    "    df.columns=['Date', 'sectorName', 'changeRate', 'first', 'second']\n",
    "else:\n",
    "    print('\\n file_name error\\n')\n",
    "    \n",
    "df.to_sql(name=table_name, con=engine, if_exists='append', index = False)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  코스피 , 코스닥 누락데이터 입력\n",
    "\n",
    "from mod1 import *\n",
    "\n",
    "kospi_df = pd.read_sql(\"select Date from kospi order by Date desc limit 1\", engine)\n",
    "kospi_df = str(kospi_df['Date'])\n",
    "kospi_date = kospi_df[5:15]\n",
    "\n",
    "kosdaq_df = pd.read_sql(\"select Date from kosdaq order by Date desc limit 1\", engine)\n",
    "kosdaq_df = str(kosdaq_df['Date'])\n",
    "kosdaq_date = kosdaq_df[5:15]\n",
    "\n",
    "\n",
    "start_kospi = datetime.strptime(kospi_date , \"%Y-%m-%d\")\n",
    "kospi_date= (start_kospi + timedelta(days=1)).strftime('%Y%m%d')\n",
    "\n",
    "start_kosdaq = datetime.strptime(kosdaq_date , \"%Y-%m-%d\")\n",
    "kosdaq_date= (start_kosdaq + timedelta(days=1)).strftime('%Y%m%d')\n",
    "\n",
    "\n",
    "df_kospi = get_index_ohlcv_by_date(kospi_date, \"20250228\", \"코스피\")\n",
    "df_kospi.index.names = ['Date']\n",
    "df_kospi.columns  = ('Open','High','Low','Close','Volume')\n",
    "df_kospi['Market']='kospi'\n",
    "df_kospi.to_sql(name='kospi', con=engine, if_exists='append')\n",
    "\n",
    "\n",
    "df_kosdaq = get_index_ohlcv_by_date(kosdaq_date, \"20250228\", \"코스닥\")\n",
    "df_kosdaq.index.names = ['Date']\n",
    "df_kosdaq.columns  = ('Open','High','Low','Close','Volume')\n",
    "df_kosdaq['Market']='kosdaq'\n",
    "df_kosdaq.to_sql(name='kosdaq', con=engine, if_exists='append')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Excel to mysql\n",
    "\n",
    "import FinanceDataReader as fdr\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "from  datetime import datetime\n",
    "\n",
    "engine = sqlalchemy.create_engine('mysql+pymysql://kkang:leaf2027@localhost/stock?charset=utf8',encoding='utf-8')\n",
    "\n",
    "date = input('원하는 날짜를 입력하세요 ')\n",
    "path = 'd:\\\\stockdata\\\\관리종목\\\\'+date+'.xlsx'\n",
    "\n",
    "df = pd.read_excel(path)\n",
    "\n",
    "df.to_sql(name='badstock', con=engine, if_exists='append', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Mysql to Excel\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "connect = create_engine('mysql+pymysql://kkang:leaf2027@localhost/stock?charset=utf8',encoding='utf-8')\n",
    "df = pd.read_sql(\"SELECT distinct Name,Code from market where date = '2019-09-05'\", connect)\n",
    "\n",
    "df.to_excel('d:\\\\sql_market.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### kospi, kosdaq  지수 DB 입력  version_1\n",
    "\n",
    "from mod1 import *\n",
    "\n",
    "df_kospi  = get_index_kospi_ohlcv_by_date(\"20200113\",\"20200120\", \"코스피\")\n",
    "df_kospi.index.names = ['Date']\n",
    "df_kospi.columns  = ('Open','High','Low','Close','Volume')\n",
    "df_kospi['Market']='kospi'\n",
    "df_kospi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### kospi, kosdaq  지수 DB 입력  version_2\n",
    "\n",
    "from mod1 import *\n",
    "\n",
    "df_kospi  = get_index_ohlcv_by_date(\"20200410\",\"20210410\", \"코스피\")\n",
    "df_kospi.index.names = ['Date']\n",
    "df_kospi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### kospi, kosdaq  지수 DB 입력  version_2\n",
    "\n",
    "from mod1 import *\n",
    "\n",
    "df_kospi  = get_index_ohlcv_by_date(\"20200413\",\"20210410\", \"코스피\")\n",
    "df_kospi.index.names = ['Date']\n",
    "df_kospi.columns  = ('Open','High','Low','Close','Volume')\n",
    "df_kospi['Market']='kospi'\n",
    "df_kospi.to_sql(name='kospi', con=engine, if_exists='append')\n",
    "\n",
    "df_kosdaq = get_index_ohlcv_by_date(\"20200413\",\"20210410\", \"코스닥\")\n",
    "df_kosdaq.index.names = ['Date']\n",
    "df_kosdaq.columns  = ('Open','High','Low','Close','Volume')\n",
    "df_kosdaq['Market']='kosdaq'\n",
    "df_kosdaq.to_sql(name='kosdaq', con=engine, if_exists='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### kospi, kosdaq  지수 DB 입력 version_3\n",
    "\n",
    "from mod1 import *\n",
    "\n",
    "kospi_df = pd.read_sql(\"select Date from kospi order by Date desc limit 1\", engine)\n",
    "kospi_df = str(kospi_df['Date'])\n",
    "kospi_date = kospi_df[5:15]\n",
    "\n",
    "kosdaq_df = pd.read_sql(\"select Date from kosdaq order by Date desc limit 1\", engine)\n",
    "kosdaq_df = str(kosdaq_df['Date'])\n",
    "kosdaq_date = kosdaq_df[5:15]\n",
    "\n",
    "\n",
    "start_kospi = datetime.strptime(kospi_date , \"%Y-%m-%d\")\n",
    "kospi_date= (start_kospi + timedelta(days=1)).strftime('%Y%m%d')\n",
    "\n",
    "start_kosdaq = datetime.strptime(kosdaq_date , \"%Y-%m-%d\")\n",
    "kosdaq_date= (start_kosdaq + timedelta(days=1)).strftime('%Y%m%d')\n",
    "\n",
    "\n",
    "df_kospi = get_index_ohlcv_by_date(kospi_date, \"20250228\", \"코스피\")\n",
    "df_kospi.index.names = ['Date']\n",
    "df_kospi.columns  = ('Open','High','Low','Close','Volume')\n",
    "df_kospi['Market']='kospi'\n",
    "df_kospi.to_sql(name='kospi', con=engine, if_exists='append')\n",
    "\n",
    "df_kosdaq = get_index_ohlcv_by_date(kosdaq_date, \"20250228\", \"코스피\")\n",
    "df_kosdaq.index.names = ['Date']\n",
    "df_kosdaq.columns  = ('Open','High','Low','Close','Volume')\n",
    "df_kosdaq['Market']='kosdaq'\n",
    "df_kosdaq.to_sql(name='kosdaq', con=engine, if_exists='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "###  선물크롤링하여 맨처음 DB에 future table생성할때\n",
    "\n",
    "# 2019-09-11 수정  mysql future table에서 최종 날짜를 확인해서 그뒤날부터 insert \n",
    "# 기존 daum 주식 사이트 : ajax 방식으로 변경으로 인해 이를 반영한 코드를 수정.\n",
    "# pip install fake-useragent 설치 후 실행 가능\n",
    "\n",
    "import io\n",
    "import json\n",
    "import sys\n",
    "import pandas as pd\n",
    "import sqlalchemy \n",
    "import urllib.request as req\n",
    "from datetime import datetime\n",
    "from fake_useragent import UserAgent\n",
    "\n",
    "engine = sqlalchemy.create_engine('mysql+pymysql://kkang:leaf2027@localhost/stock?charset=utf8',encoding='utf-8')\n",
    "\n",
    "\n",
    "# Fake Header 정보\n",
    "ua = UserAgent()\n",
    "\n",
    "# 헤더 선언\n",
    "headers = {\n",
    "    'User-Agent': ua.ie,\n",
    "    'referer': 'http://finance.daum.net/domestic/futures'\n",
    "}\n",
    "\n",
    "\n",
    "url = \"http://finance.daum.net/api/future/KR4101Q30005/days?pagination=true&page=1\"\n",
    "res = req.urlopen(req.Request(url, headers=headers)).read().decode('utf-8')\n",
    "\n",
    "df1 = pd.DataFrame()\n",
    "for i in range(1,7):\n",
    "    # 다음 주식 요청 URL\n",
    "    url = \"http://finance.daum.net/api/future/KR4101Q30005/days?pagination=true&page=\"+str(i)\n",
    "\n",
    "    res = req.urlopen(req.Request(url, headers=headers)).read().decode('utf-8')\n",
    "    \n",
    "    rank_json = json.loads(res)['data']\n",
    "    \n",
    "    df = pd.DataFrame(rank_json)\n",
    "    df1 = df1.append(df,ignore_index=True)\n",
    "    \n",
    "df2 = df1[['date','tradePrice','change', 'changePrice','changeRate','unsettledVolume','foreignSettlement', 'institutionSettlement', 'privateSettlement']]\n",
    "df2.columns=('Date','Future','change','가격변동','등락률','미결제약정','외국인','기관','개인')\n",
    "df2['Date'] = pd.to_datetime(df2['Date']).dt.date\n",
    "#df2['Date'] = pd.to_datetime(df2['Date']).apply(lambda x: x.date())\n",
    "#df2['Date'] = pd.to_datetime(df2['Date'], format = '%Y-%m-%d') # yyyy-mm-dd hh:mm:ss -> yyyy-mm-dd (속성은그대로 보여주는 형식만 변경)\n",
    "df2 =df2[['Date','Future','미결제약정','외국인','기관','개인']]\n",
    "#df2 = df2[df2.Date > until_date]\n",
    "df2.to_sql(name='future', con=engine, if_exists='append', index = False)\n",
    "df2 = df2.set_index('Date')\n",
    "df2.to_excel('d:\\\\future.xlsx',encoding='utf-8')\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2019-01-28 수정\n",
    "# 기존 daum 주식 사이트 : ajax 방식으로 변경으로 인해 이를 반영한 코드를 수정.\n",
    "# pip install fake-useragent 설치 후 실행 가능\n",
    "import time\n",
    "import io\n",
    "import json\n",
    "import sys\n",
    "import pandas as pd\n",
    "import urllib.request as req\n",
    "\n",
    "from fake_useragent import UserAgent\n",
    "\n",
    "start = time.time()  # 시작 시간 저장\n",
    "\n",
    "#sys.stdout = io.TextIOWrapper(sys.stdout.detach(), encoding='utf-8')\n",
    "#sys.stderr = io.TextIOWrapper(sys.stderr.detach(), encoding='utf-8')\n",
    "\n",
    "# Fake Header 정보\n",
    "ua = UserAgent()\n",
    "\n",
    "# 헤더 선언\n",
    "headers = {\n",
    "    'User-Agent': ua.ie,\n",
    "    'referer': 'http://finance.daum.net/domestic/all_stocks'\n",
    "}\n",
    "\n",
    "# 다음 주식 요청 URL\n",
    "kospi_sector_url = \"http://finance.daum.net/api/quotes/sectors?fieldName=&order=&perPage=&market=KOSPI&page=&changes=UPPER_LIMIT%2CRISE%2CEVEN%2CFALL%2CLOWER_LIMIT\"\n",
    "kosdaq_sector_url = \"http://finance.daum.net/api/quotes/sectors?fieldName=&order=&perPage=&market=KOSDAQ&page=&changes=UPPER_LIMIT%2CRISE%2CEVEN%2CFALL%2CLOWER_LIMI\"\n",
    "\n",
    "# 요청\n",
    "kospi_sector_res = req.urlopen(req.Request(kospi_sector_url, headers=headers)).read().decode('utf-8')\n",
    "kosdaq_sector_res = req.urlopen(req.Request(kosdaq_sector_url, headers=headers)).read().decode('utf-8')\n",
    "# 응답 데이터 확인(Json Data)\n",
    "# print('res', res)\n",
    "\n",
    "# 응답 데이터 str -> json 변환 및 data 값 저장\n",
    "kospi_sector = json.loads(kospi_sector_res)['data']\n",
    "kosdaq_sector = json.loads(kosdaq_sector_res)['data']\n",
    "# 중간 확인\n",
    "#print('중간 확인 : ', rank_json, '\\n')\n",
    "\n",
    "#for elm in rank_json:\n",
    "    # print(type(elm)) #Type 확인\n",
    "    #print('순위 : {}, 금액 : {}, 회사명 : {}'.format(elm['rank'], elm['tradePrice'], elm['name']), )\n",
    "\n",
    "kospi_sector_df = pd.DataFrame(kospi_sector)\n",
    "kosdaq_sector_df = pd.DataFrame(kosdaq_sector)\n",
    "\n",
    "kospi_name=[]\n",
    "kosdaq_name=[]\n",
    "\n",
    "for i in range(len(kospi_sector_df.index)):\n",
    "    stock_name = [kospi_sector_df['includedStocks'][i][0]['name'],kospi_sector_df['includedStocks'][i][1]['name']]\n",
    "    kospi_name.append(stock_name)\n",
    "kospi_name_df=pd.DataFrame(kospi_name)\n",
    "\n",
    "kospi_sector_df = kospi_sector_df[['date','sectorName','change','changeRate']]\n",
    "kospi_sector_df['changeRate'] = kospi_sector_df['changeRate']*100\n",
    "\n",
    "kospi_sector_df = kospi_sector_df.sort_values(['change','changeRate'], ascending=[False,False])\n",
    "\n",
    "for i in range(len(kosdaq_sector_df.index)):\n",
    "    stock_name = [kosdaq_sector_df['includedStocks'][i][0]['name'],kosdaq_sector_df['includedStocks'][i][1]['name']]\n",
    "    kosdaq_name.append(stock_name)\n",
    "kosdaq_name_df=pd.DataFrame(kosdaq_name)\n",
    "\n",
    "kosdaq_sector_df = kosdaq_sector_df[['date','sectorName','change','changeRate']]\n",
    "kosdaq_sector_df['changeRate'] = kosdaq_sector_df['changeRate']*100\n",
    "\n",
    "\n",
    "kospi_sector_df = kospi_sector_df.join(kospi_name_df)\n",
    "kosdaq_sector_df = kosdaq_sector_df.join(kosdaq_name_df)\n",
    "\n",
    "kospi_sector_df.columns=('date', 'sectorName', 'change', 'changeRate', 'first', 'second')\n",
    "kosdaq_sector_df.columns=('date', 'sectorName', 'change', 'changeRate', 'first', 'second')\n",
    "\n",
    "kosdaq_sector_df = kosdaq_sector_df.sort_values(['change','changeRate'], ascending=[False,False])\n",
    "\n",
    "#display(kospi_sector_df.set_index('date')) \n",
    "#display(kosdaq_sector_df.set_index('date')) \n",
    "\n",
    "\n",
    "##########  업종별시세 column중에 changeRate 'FALL' data를 일관되게 -수치로 바꾸는 code\n",
    " \n",
    "kospi = kospi_sector_df.set_index('change')  ##  index롤 분류하기위한 indeㅌing\n",
    "kosdaq = kosdaq_sector_df.set_index('change')  ##  index롤 분류하기위한 indeㅌing\n",
    "\n",
    "for i in [kospi,kosdaq]:\n",
    "    cols = i.index.difference(['RISE'])      ## cols는 DateFrame이 아닌 change값이 FALL을 가리키는 객체\n",
    "    b = i.loc[cols]\n",
    "    b['changeRate']=i.loc[cols]['changeRate'].mul(-1)\n",
    "    i.loc[cols]=b        ## a change 값이 FALL인 행을 chageRate값을 -로 바꾼 b로 치환   \n",
    "\n",
    "kospi_sector = kospi.set_index('date')\n",
    "kosdaq_sector = kosdaq.set_index('date')\n",
    "kospi_df =  kospi_sector.sort_values([\"changeRate\"],ascending=False)\n",
    "kosdaq_df =  kosdaq_sector.sort_values([\"changeRate\"],ascending=False)\n",
    "\n",
    "\n",
    "kospi_df.to_sql(name='kospi_sector', con=engine, if_exists='append')\n",
    "kosdaq_df.to_sql(name='kosdaq_seotor', con=engine, if_exists='append')\n",
    "print(\"time :\", time.time() - start)  # 현재시각 - 시작시간 = 실행 시간"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kosdaq_sector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###  선물 DB Update할때\n",
    "\n",
    "# 2019-09-11 수정  mysql future table에서 최종 날짜를 확인해서 그뒤날부터 insert \n",
    "# 기존 daum 주식 사이트 : ajax 방식으로 변경으로 인해 이를 반영한 코드를 수정.\n",
    "# pip ainstall fake-useragent 설치 후 실행 가능\n",
    "\n",
    "import io\n",
    "import json\n",
    "import sys\n",
    "import pandas as pd\n",
    "import sqlalchemy \n",
    "import urllib.request as req\n",
    "from datetime import datetime\n",
    "from fake_useragent import UserAgent\n",
    "\n",
    "from datetime import datetime\n",
    "from fake_useragent import UserAgent\n",
    "\n",
    "engine = sqlalchemy.create_engine('mysql+pymysql://kkang:leaf2027@localhost/stock?charset=utf8',encoding='utf-8')\n",
    "future_df = pd.read_sql(\"select Date from future order by Date desc limit 1\", engine)\n",
    "future_df = str(future_df['Date'])\n",
    "until_date = future_df[5:15]\n",
    "\n",
    "year = until_date.split('-')[0]\n",
    "mm = until_date.split('-')[1]\n",
    "dd = until_date.split('-')[2]\n",
    "#year=year[2:]\n",
    "until_date = year+'-'+mm+'-'+dd\n",
    "until_date = datetime.strptime(until_date, '%Y-%m-%d').date() ## str 을  datetime.date로 type 변경\n",
    "\n",
    "# Fake Header 정보\n",
    "ua = UserAgent()\n",
    "\n",
    "# 헤더 선언\n",
    "headers = {\n",
    "    'User-Agent': ua.ie,\n",
    "    'referer': 'http://finance.daum.net/domestic/futures'\n",
    "}\n",
    "\n",
    "\n",
    "url = \"http://finance.daum.net/api/future/KR4101Q60002/days?pagination=true&page=1\"  #KR4011PC002 \"선물 코스피 200지수 12월물\" 코드는 구글검색이용\n",
    "res = req.urlopen(req.Request(url, headers=headers)).read().decode('utf-8')\n",
    "\n",
    "df1 = pd.DataFrame()\n",
    "for i in range(1,3):\n",
    "    # 다음 주식 요청 URL\n",
    "    url = \"http://finance.daum.net/api/future/KR4101Q60002/days?pagination=true&page=\"+str(i)\n",
    "\n",
    "    res = req.urlopen(req.Request(url, headers=headers)).read().decode('utf-8')\n",
    "    \n",
    "    rank_json = json.loads(res)['data']\n",
    "    \n",
    "    df = pd.DataFrame(rank_json)\n",
    "    df1 = df1.append(df,ignore_index=True)\n",
    "df2 = df1[['date','tradePrice','change', 'changePrice','changeRate','unsettledVolume','foreignSettlement', 'institutionSettlement', 'privateSettlement']]\n",
    "df2.columns=('Date','Future','change','가격변동','등락률','미결제약정','외국인','기관','개인')\n",
    "df2['Date'] = pd.to_datetime(df2['Date']).dt.date\n",
    "#df2['Date'] = pd.to_datetime(df2['Date']).apply(lambda x: x.date())\n",
    "#df2['Date'] = pd.to_datetime(df2['Date'], format = '%Y-%m-%d') # yyyy-mm-dd hh:mm:ss -> yyyy-mm-dd (속성은그대로 보여주는 형식만 변경)\n",
    "df2 =df2[['Date','Future','미결제약정','외국인','기관','개인']]\n",
    "df2 = df2[df2.Date > until_date]\n",
    "df2.to_sql(name='future', con=engine, if_exists='append', index = False)\n",
    "df2 = df2.set_index('Date')\n",
    "df2.to_excel('d:\\\\future.xlsx',encoding='utf-8')\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matplotlib를 사용한 Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## 선물  베이시스 graph ( One_graph)\n",
    "## def future_trend_graph():\n",
    "   \n",
    "\n",
    "#query = \"select * from future where Date > '2019-06-13'\"+\"'\"+date+\"'\"\n",
    "query = \"select * from basis where Date > '2019-06-13'\"\n",
    "\n",
    "\n",
    "name=['kpi200','Future']\n",
    "#name=['미결제약정']\n",
    "\n",
    "tuple_name=tuple(name)\n",
    "df1 = pd.DataFrame()\n",
    "    \n",
    "df = pd.read_sql(query ,engine)\n",
    "\n",
    "#df.columns=['Date','kpi200','Close']\n",
    "df = df.set_index('Date')\n",
    "df1=df[name]\n",
    "\n",
    "plt.figure(figsize=(16,4))    \n",
    "for i in range(len(name)):\n",
    "    plt.plot(df1[name[i]]/df1[name[i]].loc[df.index[0]]*100, label=name[i])\n",
    "        \n",
    "#plt.legend(loc=0)\n",
    "plt.legend(loc=0)\n",
    "plt.grid(True,color='0.7',linestyle=':',linewidth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## 선물  베이시스 graph ( One_graph)\n",
    "## def future_trend_graph():\n",
    "   \n",
    "\n",
    "#query = \"select * from future where Date > '2019-06-13'\"+\"'\"+date+\"'\"\n",
    "query = \"select * from future where Date > '2019-06-13'\"\n",
    "\n",
    "\n",
    "name=['Close', '미결제약정', '외국인', '기관', '개인']\n",
    "#name=['미결제약정']\n",
    "\n",
    "tuple_name=tuple(name)\n",
    "df1 = pd.DataFrame()\n",
    "    \n",
    "df = pd.read_sql(query ,engine)\n",
    "\n",
    "df.columns=['Date', 'Close', '미결제약정', '외국인', '기관', '개인']\n",
    "df = df.set_index('Date')\n",
    "df1=df[name]\n",
    "\n",
    "plt.figure(figsize=(16,4))    \n",
    "for i in range(len(name)):\n",
    "    plt.plot(df1[name[i]]/df1[name[i]].loc[df.index[0]]*100)\n",
    "        \n",
    "#plt.legend(loc=0)\n",
    "plt.legend(name)\n",
    "plt.grid(True,color='0.7',linestyle=':',linewidth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## 선물 graph ( One_graph)\n",
    "## def future_trend_graph():\n",
    "    \n",
    "#name = input(\"항목을 입력하세요: 선택항목: 'kpi200', '거래량', '고객예탁금', '신용잔고', '주식형펀드', '혼합형펀드', '채권형펀드'\").split()\n",
    "#date = input(\"날짜를 입력하세요 sample: '2019-01-10':\")\n",
    "    \n",
    "    \n",
    "#query = \"select * from future where Date > '2019-06-13'\"+\"'\"+date+\"'\"\n",
    "query = \"select * from future where Date > '2019-06-13'\"\n",
    "\n",
    "\n",
    "name=['Close', '미결제약정', '외국인', '기관', '개인']\n",
    "#name=['미결제약정']\n",
    "\n",
    "tuple_name=tuple(name)\n",
    "df1 = pd.DataFrame()\n",
    "    \n",
    "df = pd.read_sql(query ,engine)\n",
    "\n",
    "df.columns=['Date', 'Close', '미결제약정', '외국인', '기관', '개인']\n",
    "df = df.set_index('Date')\n",
    "df1=df[name]\n",
    "\n",
    "plt.figure(figsize=(16,4))    \n",
    "for i in range(len(name)):\n",
    "    plt.plot(df1[name[i]]/df1[name[i]].loc[df.index[0]]*100)\n",
    "        \n",
    "plt.legend(name,loc=0)\n",
    "plt.grid(True,color='0.7',linestyle=':',linewidth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## 선물 graph ( Multi_graph)\n",
    "## def future_trend_graph():\n",
    " \n",
    "#name = input(\"항목을 입력하세요: 선택항목: 'kpi200', '거래량', '고객예탁금', '신용잔고', '주식형펀드', '혼합형펀드', '채권형펀드'\").split()\n",
    "#date = input(\"날짜를 입력하세요 sample: '2019-01-10':\")\n",
    "    \n",
    "#query = \"select * from future where Date > '2019-06-13'\"+\"'\"+date+\"'\"\n",
    "query = \"select * from future where Date > '2019-06-11'\"\n",
    "\n",
    "\n",
    "name=['Close', '미결제약정', '외국인', '기관', '개인']\n",
    "name1=['Close','미결제약정']\n",
    "name2=['외국인', '기관', '개인']\n",
    "\n",
    "#tuple_name=tuple(name)\n",
    "df1 = pd.DataFrame()\n",
    "    \n",
    "df = pd.read_sql(query ,engine)\n",
    "\n",
    "df.columns=['Date', 'Close', '미결제약정', '외국인', '기관', '개인']\n",
    "df = df.set_index('Date')\n",
    "df1=df[name]\n",
    "\n",
    "plt.figure(figsize=(16,4))    \n",
    "for i in range(len(name1)):\n",
    "    #plt.subplot(2,2,i+1)\n",
    "    plt.plot(df1[name1[i]]/df1[name1[i]].loc[df.index[0]]*100,color=colors[i])\n",
    "    \n",
    "plt.legend(loc=0)\n",
    "plt.grid(True,color='0.7',linestyle=':',linewidth=1)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(16,4)) \n",
    "for i in range(len(name2)):\n",
    "    plt.subplot(2,2,i+1)\n",
    "    plt.plot(df1[name2[i]]/df1[name2[i]].loc[df.index[0]]*100,color=colors[i])\n",
    "    \n",
    "    plt.legend(loc=0)\n",
    "    plt.grid(True,color='0.7',linestyle=':',linewidth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Close and Volume graph 표준화\n",
    "\n",
    "import FinanceDataReader as fdr\n",
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "engine = sqlalchemy.create_engine('mysql+pymysql://kkang:leaf2027@localhost/stock?charset=utf8',encoding='utf-8')\n",
    "\n",
    "select_query = \"select Date,Volume,Close from market where Name= \"\n",
    "date_query = \"Date > \"\n",
    "\n",
    "def choice(select):\n",
    "    name = '화천기계'\n",
    "    date = '2019-01-01'\n",
    "    if select == 1:\n",
    "        name = input('주식이름을 입력하세요 : ')\n",
    "        date = input('날짜를 입력하세요: ')\n",
    "        var = select_query +\"'\"+name+\"'\"+\" \"+\"&&\"+\" \"+date_query+\"'\"+date+\"'\" \n",
    "        return var\n",
    "    elif select == 2:\n",
    "        var = select_query +\"'\"+name+\"'\"+\" \"+\"&&\"+\" \"+date_query+\"'\"+date+\"'\" \n",
    "        return var\n",
    "\n",
    "select = input('select 1 or 2: ')\n",
    "select = int(select)\n",
    "\n",
    "df = pd.read_sql(choice(select), engine)\n",
    "\n",
    "source = MinMaxScaler()\n",
    "data = source.fit_transform(df[['Close','Volume']].values.astype(float))\n",
    "df1 = pd.DataFrame(data)\n",
    "df1.columns=['Close','Volume']\n",
    "df1 = df1.set_index(df['Date'])\n",
    "df1.plot(figsize=(16,4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Close and Volume graph 표준화 _ 2  종목을 list로 설정\n",
    "\n",
    "import FinanceDataReader as fdr\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "engine = sqlalchemy.create_engine('mysql+pymysql://kkang:leaf2027@localhost/stock?charset=utf8',encoding='utf-8')\n",
    "\n",
    "select_query = \"select Date,Volume,Close from market where Name= \"\n",
    "date_query = \"Date > \"\n",
    "\n",
    "df = pd.read_excel('d:\\\\detect_stock_with_volume.xlsx')\n",
    "df=df['Name']\n",
    "#name = df.values.tolist() ## numpy to list\n",
    "name = df.to_list()              ## DataFrame to list\n",
    "date = '2019-01-01'\n",
    "for i in name:\n",
    "    var = select_query +\"'\"+i+\"'\"+\" \"+\"&&\"+\" \"+date_query+\"'\"+date+\"'\" \n",
    "    df = pd.read_sql(var, engine)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['Close','Volume']].values.astype(float))\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1.columns=['Close','Volume']\n",
    "    df1 = df1.set_index(df['Date'])\n",
    "    df1.plot(figsize=(16,2))\n",
    "    plt.title(i)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Close and Volume graph 표준화-3  이동평균선 포함\n",
    "\n",
    "import talib.abstract as ta\n",
    "import FinanceDataReader as fdr\n",
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "engine = sqlalchemy.create_engine('mysql+pymysql://kkang:leaf2027@localhost/stock?charset=utf8',encoding='utf-8')\n",
    "\n",
    "select_query = \"select * from market where Name= \"\n",
    "date_query = \"Date > \"\n",
    "\n",
    "def choice(select):\n",
    "    name = 'hrs'\n",
    "    date = '2010-01-01'\n",
    "    if select == 1:\n",
    "        name = input('주식이름을 입력하세요 : ')\n",
    "        date = input('날짜를 입력하세요: ')\n",
    "        var = select_query +\"'\"+name+\"'\"+\" \"+\"&&\"+\" \"+date_query+\"'\"+date+\"'\" \n",
    "        return var\n",
    "    elif select == 2:\n",
    "        var = select_query +\"'\"+name+\"'\"+\" \"+\"&&\"+\" \"+date_query+\"'\"+date+\"'\" \n",
    "        return var\n",
    "\n",
    "select = input('select 1 or 2: ')\n",
    "select = int(select)\n",
    "\n",
    "df = pd.read_sql(choice(select), engine)\n",
    "df[['Open','High','Low','Volume','Close']] = df[['Open','High','Low','Volume','Close']].astype(float) #  TA-Lib로 평균을 구하려면 실수로 만들어야 함\n",
    "df.columns=df.columns.str.lower()\n",
    "\n",
    "talib_ma5 = ta.MA(df, timeperiod=5)\n",
    "df['ma5'] = talib_ma5\n",
    "\n",
    "talib_ma120 = ta.MA(df, timeperiod=120)\n",
    "df['ma120'] = talib_ma120\n",
    "\n",
    "source = MinMaxScaler()\n",
    "data = source.fit_transform(df[['close','volume','ma120']].values)\n",
    "df1 = pd.DataFrame(data)\n",
    "df1.columns=['close','ma120','volume']\n",
    "df1 = df1.set_index(df['date'])\n",
    "df1.plot(figsize=(16,4))\n",
    "\n",
    "choice(select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Close and Volume and MA graph 표준화-3  주식 DataFrame에서   종가, 거래걍, 이동평균선을 graph로 그리는 함수 \n",
    "\n",
    "def close_vol_ma(DataFrame,select):\n",
    "\n",
    "    df = DataFrame\n",
    "    df.columns=df.columns.str.lower()\n",
    "    df[['volume','close']] = df[['volume','close']].astype(float) #  TA-Lib로 평균을 구하려면 실수로 만들어야 함\n",
    "\n",
    "    talib_ma5 = ta.MA(df, timeperiod=5)\n",
    "    df['ma5'] = talib_ma5\n",
    "    \n",
    "    talib_ma10 = ta.MA(df, timeperiod=10)\n",
    "    df['ma10'] = talib_ma10    \n",
    "\n",
    "    talib_ma15 = ta.MA(df, timeperiod=15)\n",
    "    df['ma15'] = talib_ma15\n",
    "\n",
    "    talib_ma20 = ta.MA(df, timeperiod=20)\n",
    "    df['ma20'] = talib_ma20\n",
    "    \n",
    "    talib_ma30 = ta.MA(df, timeperiod=30)\n",
    "    df['ma30'] = talib_ma30    \n",
    "    \n",
    "    talib_ma60 = ta.MA(df, timeperiod=60)\n",
    "    df['ma60'] = talib_ma60    \n",
    "    \n",
    "    talib_ma120 = ta.MA(df, timeperiod=120)\n",
    "    df['ma120'] = talib_ma120    \n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close',select,'volume']].values)\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1.columns=['close',select,'volume']\n",
    "    df1 = df1.set_index(df['date'])\n",
    "    df1.plot(figsize=(16,4))\n",
    "close_vol_ma(df,select='ma20')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## def stock_select_with_Volume_Close():\n",
    "    \n",
    "yesterday = input(\"어제날짜를 입력하세요 : sample: '2019-02-07 00:00:00'  \") \n",
    "today = input(\"오늘날짜를 입력하세요 : sample: '2019-02-07 00:00:00'  \")\n",
    "    \n",
    "select_query = \"select * from market where Date >=\"\n",
    "volume_query = \"&& Volume >  500000\"\n",
    "    \n",
    "var = select_query +\"'\"+yesterday+\"'\"+ volume_query\n",
    "df = pd.read_sql(var ,engine)\n",
    "\n",
    "df1 = df[df['Date'].astype(str) == yesterday]\n",
    "df1 = df1[['Name','Volume','Close']]\n",
    "df1.columns = ['Name','yester_Volume','yester_Close']\n",
    "#display(df1)\n",
    "\n",
    "df2 = df[df['Date'].astype(str) == today]\n",
    "df2 = df2[['Name','Volume','Close']]\n",
    "df2.columns = ['Name','today_Volume','today_Close']\n",
    "#display(df2)\n",
    "\n",
    "df3 = pd.merge(df1,df2,on='Name')\n",
    "df3['Close']=df3['today_Close']/df3['yester_Close']\n",
    "df3['Volume']=df3['today_Volume']/df3['yester_Volume']\n",
    "df3 = df3.sort_values(by=['Volume','Close'],ascending=False)\n",
    "df3 = df3.reset_index(drop=True)\n",
    "df3 = df3[:10]\n",
    "df4 = df3.sort_values(by=['Close','Volume'],ascending=False)\n",
    "df4 = df4.reset_index(drop=True)\n",
    "df4 = df4[:10]\n",
    "display(df3)\n",
    "display(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## def stock_price_graph():\n",
    "    \n",
    "name = input('주식이름을 입력하세요:').split()\n",
    "date = input(\"날짜를 입력하세요 sample: '2019-01-10': \")\n",
    "\n",
    "select_query = \"select Date,Close from market where Name= \"\n",
    "date_query =  \"Date >\"\n",
    "\n",
    "tuple_name=tuple(name)\n",
    "df1 = pd.DataFrame()\n",
    "\n",
    "for x in tuple_name:\n",
    "    var = select_query +\"'\"+x+\"'\"+\" \"+\"&&\"+\" \"+date_query+\"'\"+date+\"'\"\n",
    "    df = pd.read_sql(var ,engine) \n",
    "    df.columns=['Date',x]\n",
    "    if df1.empty:\n",
    "        df1 = df\n",
    "    else:\n",
    "        df1 = pd.merge (df,df1,on='Date')\n",
    "df1=df1.set_index('Date')\n",
    "    \n",
    "plt.figure(figsize=(12,5))\n",
    "    \n",
    "for i in range(len(name)):\n",
    "    plt.plot(df1[name[i]]/df1[name[i]].loc[df['Date'][0]]*100)\n",
    "        \n",
    "plt.legend(loc=0)\n",
    "plt.grid(True,color='0.7',linestyle=':',linewidth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def stock_price_graph():  여러개 입력가능\n",
    "    \n",
    "## def stock_price_graph():\n",
    "    \n",
    "name = input('주식이름을 입력하세요:').split(',')\n",
    "date = input(\"날짜를 입력하세요 sample: '2019-01-10':\")\n",
    "        \n",
    "select_query = \"select Date,Close from market where Name= \"\n",
    "date_query = \"Date > \"\n",
    "    \n",
    "\n",
    "tuple_name=tuple(name)\n",
    "df1 = pd.DataFrame()\n",
    "    \n",
    "for x in tuple_name:\n",
    "    var = select_query +\"'\"+x+\"'\"+\" \"+\"&&\"+\" \"+date_query+\"'\"+date+\"'\"\n",
    "    df = pd.read_sql(var ,engine)\n",
    "    df.columns=['Date',x]\n",
    "    if df1.empty:\n",
    "        df1 = df\n",
    "    else:\n",
    "        df1 = pd.merge (df,df1,on='Date')\n",
    "df1=df1.set_index('Date')\n",
    "    \n",
    "plt.figure(figsize=(12,5))\n",
    "    \n",
    "for i in range(len(name)):\n",
    "    plt.plot(df1[name[i]]/df1[name[i]].loc[df['Date'][0]]*100)\n",
    "        \n",
    "plt.legend(name,loc=0)\n",
    "plt.grid(True,color='0.7',linestyle=':',linewidth=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def stock_price_graph():  여러개 입력가능\n",
    "    \n",
    "## def stock_price_graph():\n",
    "    \n",
    "name = input('주식이름을 입력하세요:').split(',')\n",
    "date = input(\"날짜를 입력하세요 sample: '2019-01-10':\")\n",
    "        \n",
    "select_query = \"select Date,Close from market where Name= \"\n",
    "date_query = \"Date > \"\n",
    "    \n",
    "\n",
    "tuple_name=tuple(name)\n",
    "df1 = pd.DataFrame()\n",
    "    \n",
    "for x in tuple_name:\n",
    "    var = select_query +\"'\"+x+\"'\"+\" \"+\"&&\"+\" \"+date_query+\"'\"+date+\"'\"\n",
    "    df = pd.read_sql(var ,engine)\n",
    "    df.columns=['Date',x]\n",
    "    if df1.empty:\n",
    "        df1 = df\n",
    "    else:\n",
    "        df1 = pd.merge (df,df1,on='Date')\n",
    "df1=df1.set_index('Date')\n",
    "    \n",
    "plt.figure(figsize=(12,5))\n",
    "    \n",
    "for i in range(len(name)):\n",
    "    plt.plot(df1[name[i]]/df1[name[i]].loc[df['Date'][0]]*100)\n",
    "        \n",
    "plt.legend(name,loc=0)\n",
    "plt.grid(True,color='0.7',linestyle=':',linewidth=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def stock_volume and price_graph():  여러개 입력가능\n",
    "\n",
    "import io\n",
    "import json\n",
    "import sys\n",
    "from fake_useragent import UserAgent\n",
    "import FinanceDataReader as fdr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime as dt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from datetime import datetime,timedelta\n",
    "from urllib.request import urlopen\n",
    "import urllib.request as req\n",
    "import sqlalchemy \n",
    "import pymysql\n",
    "import talib.abstract as ta\n",
    "from talib import RSI, BBANDS\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "from matplotlib import font_manager, rc\n",
    "plt.rcParams.update({'figure.max_open_warning': 0})\n",
    "font_name = font_manager.FontProperties(fname=\"c:/Windows/Fonts/malgun.ttf\").get_name()\n",
    "rc('font', family=font_name)\n",
    "\n",
    "today = datetime.now()\n",
    "real_yesterday = (today-timedelta(1)).strftime('%Y-%m-%d')\n",
    "real_today = today.strftime('%Y-%m-%d')\n",
    "date_list = ['2008-01-01','2013-01-01','2018-01-01','2019-01-01']\n",
    "\n",
    "now = dt.datetime.today().strftime('%Y-%m-%d')\n",
    "engine = sqlalchemy.create_engine('mysql+pymysql://kkang:leaf2027@localhost/stock?charset=utf8',encoding='utf-8')\n",
    "conn = pymysql.connect(host = 'localhost', user = 'kkang', password = 'leaf2027' ,db = 'stock')\n",
    "curs = conn.cursor()\n",
    "\n",
    "path_price = 'd:\\\\stockdata\\\\vote_stock\\\\detect_stock_with_price_'\n",
    "path_volume = 'd:\\\\stockdata\\\\vote_stock\\\\detect_stock_with_volume_'\n",
    "path = 'd:\\\\stockdata\\\\close_ma120\\\\close_ma120_'\n",
    "path_total = 'd:\\\\stockdata\\\\close_ma120\\\\total_'\n",
    "path_total_f = 'd:\\\\stockdata\\\\close_ma120\\\\total_filter_'\n",
    "path_total_a = 'd:\\\\stockdata\\\\close_ma120\\\\total_a_'\n",
    "path_total_b = 'd:\\\\stockdata\\\\close_ma120\\\\total_b_'\n",
    "path_total_c = 'd:\\\\stockdata\\\\close_ma120\\\\total_c_'\n",
    "\n",
    "def select_market(name,date):\n",
    "    select_query = \"select * from \"\n",
    "    date_query = \" where Date > \"    \n",
    "    var = select_query + name + date_query+\"'\"+date+\"'\" \n",
    "    df = pd.read_sql(var, engine)\n",
    "    return df\n",
    "\n",
    "def min_max(df,select):\n",
    "    ma(df)\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close',select,'volume']].values)\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1.columns=['close',select,'volume']\n",
    "    df1 = df1.set_index(df['date'])\n",
    "    return df1\n",
    "\n",
    "def ma(DataFrame):\n",
    "    df = DataFrame\n",
    "    df.columns=df.columns.str.lower()\n",
    "    df[['volume','close']] = df[['volume','close']].astype(float) #  TA-Lib로 평균을 구하려면 실수로 만들어야 함\n",
    "\n",
    "    talib_ma5 = ta.MA(df, timeperiod=5)\n",
    "    df['ma5'] = talib_ma5\n",
    "    \n",
    "    talib_ma10 = ta.MA(df, timeperiod=10)\n",
    "    df['ma10'] = talib_ma10    \n",
    "\n",
    "    talib_ma15 = ta.MA(df, timeperiod=15)\n",
    "    df['ma15'] = talib_ma15\n",
    "\n",
    "    talib_ma20 = ta.MA(df, timeperiod=20)\n",
    "    df['ma20'] = talib_ma20\n",
    "    \n",
    "    talib_ma30 = ta.MA(df, timeperiod=30)\n",
    "    df['ma30'] = talib_ma30    \n",
    "    \n",
    "    talib_ma60 = ta.MA(df, timeperiod=60)\n",
    "    df['ma60'] = talib_ma60    \n",
    "    \n",
    "    talib_ma120 = ta.MA(df, timeperiod=120)\n",
    "    df['ma120'] = talib_ma120  \n",
    "\n",
    "    \n",
    "def market_ma(df,select1,select2):\n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close',select1,select2]].values)\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1.columns=['close',select1,select2]\n",
    "    df1 = df1.set_index(df['date'])\n",
    "    df1.plot(figsize=(16,4))\n",
    "    plt.title(df['market'][0])\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def get_graph(choice=1):\n",
    "    graph_name_list=['stock','money', 'program','future']\n",
    "    date='2018-01-01'\n",
    "    future_date='2019-12-11'  ##  선물마감 하루전\n",
    "    if choice == 1:\n",
    "        df = select_market('kospi','2015-01-01')\n",
    "        market_ma(df,'ma60','ma120')\n",
    "        df = select_market('kosdaq','2015-01-01')\n",
    "        market_ma(df,'ma60','ma120')\n",
    "      \n",
    "        kpi200_df = pd.read_sql(\"select Date from kpi200 order by Date desc limit 2\", engine)\n",
    "        yesterday = str(kpi200_df['Date'][1])\n",
    "        today = str(kpi200_df['Date'][0])\n",
    "        \n",
    "      \n",
    "        for i in graph_name_list:\n",
    "            if i == 'stock' :\n",
    "                name = pd.read_excel(path_volume+today+'.xlsx', encoding='utf-8')\n",
    "                name_all = name['Name']\n",
    "                name_all = name_all.to_list()\n",
    "                \n",
    "                name = name['Name']\n",
    "                name = name[0:2]\n",
    "                name = name.to_list()\n",
    "                print(name)\n",
    "\n",
    "                select_query = \"select Date,Volume,Close from market where Name= \"\n",
    "                date_query = \"Date > \"\n",
    "\n",
    "\n",
    "                tuple_name=tuple(name)\n",
    "                df1 = pd.DataFrame()\n",
    "\n",
    "                for x in tuple_name:\n",
    "                    var = select_query +\"'\"+x+\"'\"+\" \"+\"&&\"+\" \"+date_query+\"'\"+date+\"'\"\n",
    "                    df = pd.read_sql(var ,engine)\n",
    "                    df.columns=['Date',x+'거래량',x]\n",
    "                    if df1.empty:\n",
    "                        df1 = df\n",
    "                    else:\n",
    "                        df1 = pd.merge (df,df1,on='Date')\n",
    "                df1=df1.set_index('Date')\n",
    "                size = len(df1.index)\n",
    "\n",
    "\n",
    "                plt.figure(figsize=(16,4)) \n",
    "                for i in range(len(name)):\n",
    "                    plt.plot(df1[name[i]]/df1[name[i]].loc[df['Date'][0]]*100,label=name[i])\n",
    "                    plt.legend(loc=0)\n",
    "                    plt.grid(True,color='0.7',linestyle=':',linewidth=1)\n",
    "\n",
    "                plt.figure(figsize=(16,4))\n",
    "                for i in range(len(name)):\n",
    "                    volume_average = df1[name[i]+'거래량'].sum(axis=0)/size\n",
    "                    plt.plot(df1[name[i]+'거래량']/volume_average, label=name[i])\n",
    "                    #plt.plot(df1[name[i]+'거래량']/df1[name[i]+'거래량'].loc[df['Date'][0]]*100, label =[name[i]+'거래량'] )\n",
    "                    plt.legend(loc=0)\n",
    "                    plt.grid(True,color='0.7',linestyle=':',linewidth=1)  \n",
    "\n",
    "get_graph(choice=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## def money_trend_graph():\n",
    "    \n",
    "name = input(\"항목을 입력하세요: 선택항목: 'kpi200', '거래량', '고객예탁금', '신용잔고', '주식형펀드', '혼합형펀드', '채권형펀드'\").split()\n",
    "date = input(\"날짜를 입력하세요 sample: '2019-01-10':\")\n",
    "    \n",
    "query = \"select * from kpi_with_money where Date >\"+\"'\"+date+\"'\"\n",
    "    \n",
    "tuple_name=tuple(name)\n",
    "df1 = pd.DataFrame()\n",
    "    \n",
    "df = pd.read_sql(query ,engine)\n",
    "\n",
    "df.columns=['Date','kpi200', '거래량', '고객예탁금', '신용잔고', '주식형펀드', '혼합형펀드', '채권형펀드']\n",
    "df = df.set_index('Date')\n",
    "df1=df[name]\n",
    "\n",
    "\n",
    "for i in range(len(name)):\n",
    "    plt.plot(df1[name[i]]/df1[name[i]].loc[df.index[0]]*100)\n",
    "        \n",
    "plt.legend(loc=0)\n",
    "plt.grid(True,color='0.7',linestyle=':',linewidth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## def money_trend_graph():\n",
    "    \n",
    "name = input(\"항목을 입력하세요: 선택항목: 'kpi200', '거래량', '고객예탁금', '신용잔고', '주식형펀드', '혼합형펀드', '채권형펀드'\").split()\n",
    "date = input(\"날짜를 입력하세요 sample: '2019-01-10':\")\n",
    "    \n",
    "query = \"select * from kpi_with_money where Date >\"+\"'\"+date+\"'\"\n",
    "    \n",
    "tuple_name=tuple(name)\n",
    "df1 = pd.DataFrame()\n",
    "    \n",
    "df = pd.read_sql(query ,engine)\n",
    "\n",
    "df.columns=['Date','kpi200', '거래량', '고객예탁금', '신용잔고', '주식형펀드', '혼합형펀드', '채권형펀드']\n",
    "df = df.set_index('Date')\n",
    "df1=df[name]\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "for i in range(len(name)):\n",
    "    plt.plot(df1[name[i]]/df1[name[i]].loc[df.index[0]]*100)\n",
    "        \n",
    "plt.legend(loc=0)\n",
    "plt.grid(True,color='0.7',linestyle=':',linewidth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## def money_trend_graph():  integrate graph\n",
    "    \n",
    "name = input(\"항목을 입력하세요: 선택항목: 'kpi200', '거래량', '고객예탁금', '신용잔고', '주식형펀드', '혼합형펀드', '채권형펀드'\").split()\n",
    "date = input(\"날짜를 입력하세요 sample: '2019-01-10':\")\n",
    "    \n",
    "query = \"select * from kpi_with_money where Date >\"+\"'\"+date+\"'\"\n",
    "    \n",
    "tuple_name=tuple(name)\n",
    "df1 = pd.DataFrame()\n",
    "    \n",
    "df = pd.read_sql(query ,engine)\n",
    "\n",
    "df.columns=['Date','kpi200', '거래량', '고객예탁금', '신용잔고', '주식형펀드', '혼합형펀드', '채권형펀드']\n",
    "df = df.set_index('Date')\n",
    "df1=df[name]\n",
    "\n",
    "plt.figure(figsize=(16,4))\n",
    "colors = ['red','green','blue','pink','gray']\n",
    "for i in range(len(name)):\n",
    "    plt.subplot(2,2,i+1)\n",
    "    plt.plot(df1[name[i]]/df1[name[i]].loc[df.index[0]]*100,color=colors[i])\n",
    "    \n",
    "    plt.legend(loc=0)\n",
    "    plt.grid(True,color='0.7',linestyle=':',linewidth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 엑셀에서 종목별로 다양한 graph 출력\n",
    "\n",
    "from mod1 import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "\n",
    "def close_ma(df,select1,select2):\n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close',select1,select2]].values)\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1.columns=['close',select1,select2]\n",
    "    df1 = df1.set_index(df['date'])\n",
    "    df1.plot(figsize=(16,4))\n",
    "    plt.title(df['name'][0])\n",
    "    plt.show()\n",
    "\n",
    "def close_ma_vol(df,select1,select2,select3):\n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close',select1,select2,select3]].values)\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1.columns=['close',select1,select2,select3]\n",
    "    df1 = df1.set_index(df['date'])\n",
    "    df1.plot(figsize=(16,4))\n",
    "    plt.title(df['name'][0])\n",
    "    plt.show()    \n",
    "    \n",
    "    \n",
    "path = 'd:\\\\stockdata\\\\close_ma120\\\\close_ma120_'\n",
    "path_total_f = 'd:\\\\stockdata\\\\close_ma120\\\\total_filter_'\n",
    "\n",
    "choice_date='2019-10-01'\n",
    "#df = pd.read_excel(path_total_f+choice_date+'.xlsx')\n",
    "df = pd.read_excel('d:\\\\stockdata\\\\close_ma120\\\\2019_10\\\\total_2019-10-01.xlsx')\n",
    "name_df = df['name']\n",
    "name = name_df.to_list()\n",
    "#name=['hrs','디엔에프','푸드나무','에스퓨얼셀']\n",
    "\n",
    "for i in name:\n",
    "    df = select_stock(i, '2019-10-01')\n",
    "    #close_ma_vol(df,'ma60','ma120','volume')\n",
    "    close_ma(df,'ma5','ma10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## analysis graph (rsi, obv, ma60, ma120, volume)\n",
    "\n",
    "from mod1 import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "\n",
    "def close_ma(df,select1,select2):\n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close',select1,select2]].values)\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1.columns=['close',select1,select2]\n",
    "    df1 = df1.set_index(df['date'])\n",
    "    df1.iloc[14:].plot(grid=True,figsize=(16,4));\n",
    "    plt.title(df['name'][0])\n",
    "    plt.show()\n",
    "\n",
    "def close_ma_vol(df,select1,select2,select3):\n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close',select1,select2,select3]].values)\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1.columns=['close',select1,select2,select3]\n",
    "    df1 = df1.set_index(df['date'])\n",
    "    df1.iloc[14:].plot(grid=True,figsize=(16,4));\n",
    "    plt.title(df['name'][0])\n",
    "    plt.show()    \n",
    "    \n",
    "def rsi(df):\n",
    "    df = df.set_index('date')\n",
    "    talib_rsi = ta.RSI(df, timeperiod=14)\n",
    "    talib_rsi.iloc[14:].plot( grid=True,figsize=(16,4))\n",
    "    plt.fill_between(df.index,y1=30, y2=70, color='#adccff', alpha='0.3')\n",
    "    plt.show()\n",
    "    \n",
    "def obv(df):\n",
    "    df = df.set_index('date')\n",
    "    real = ta.OBV(df)\n",
    "    real.iloc[14:].plot( y=['volume'], grid=True,figsize=(16,4));\n",
    "    plt.show()\n",
    "    \n",
    "name = ['서원','hrs']   \n",
    "for i in name:\n",
    "    df = select_stock(i,'2016-04-01')\n",
    "    close_ma(df,'ma60','ma120')\n",
    "    rsi(df)\n",
    "    obv(df)\n",
    "    close_ma_vol(df,'ma60','ma120','volume')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Crawling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 상장회사 종가확인\n",
    "# 브라우저 실행\n",
    "from selenium import webdriver\n",
    "driver = webdriver.Chrome('C:/Users/kkang/selenium/chromedriver.exe')\n",
    "\n",
    "# 상장회사검색\n",
    "driver.get('http://marketdata.krx.co.kr/mdi#document=040602')\n",
    "\n",
    "# 다운로드 버튼을 클릭\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "button = driver.find_element(By.XPATH, '//button[text()=\"Excel\"]')\n",
    "button.click()\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "# 다운로드 폴더로 이동\n",
    "folder = 'c:\\\\Users\\\\kkang\\\\Downloads'\n",
    "os.chdir(folder)\n",
    "\n",
    "# 파일 다운로드까지 대기 (1초씩 최대 30회)\n",
    "fname = 'data.xls'\n",
    "for _ in range(30):\n",
    "    if os.path.exists(fname):\n",
    "        break\n",
    "    time.sleep(1)\n",
    "\n",
    "# 파일명 바꾸기\n",
    "os.rename('data.xls', 'price.xls')\n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 일별 관리종목 추출\n",
    "\n",
    "from  datetime import datetime\n",
    "import pandas as pd\n",
    "import xlsxwriter\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "today = datetime.now()\n",
    "today = today.strftime(\"%Y-%m-%d\")\n",
    "#today=input('입력')\n",
    "#url = 'http://finance.naver.com/sise/investorDealTrendDay.nhn?bizdate=2020601&sosok=&page=1'\n",
    "url = 'https://finance.naver.com/sise/management.nhn'\n",
    "source = urlopen(url).read()   # 지정한 페이지에서 코드 읽기\n",
    "source = BeautifulSoup(source, 'lxml')   # 뷰티풀 스프로 태그별로 코드 분류\n",
    "data = []\n",
    "\n",
    "path = 'd:\\\\stockdata\\\\관리종목\\\\'+today+'.xlsx'\n",
    "body = source.find('body')\n",
    "trs = body.find_all('tr')\n",
    "name = []\n",
    "for tr in trs:\n",
    "    tds = tr.find_all('a',{'class':\"tltle\"})\n",
    "    for td in tds:\n",
    "        name.append(td.text.strip())\n",
    "\n",
    "df = pd.DataFrame(name)\n",
    "df['Date']=str(today)\n",
    "df = df.set_index('Date')\n",
    "df.columns=['Name']\n",
    "df.to_excel(path)\n",
    "df = pd.read_excel(path)\n",
    "df.to_sql(name='badstock', con=engine, if_exists='append', index = False)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### pykrx 모듈을 통한 krx 웹 crawling\n",
    "\n",
    "from pykrx.comm.util import dataframe_empty_handler, singleton\n",
    "from pykrx.comm.http import KrxHttp\n",
    "from pandas import DataFrame\n",
    "import pandas as pd\n",
    "from pykrx import stock\n",
    "\n",
    "a = stock.market.ticker._StockFinder()\n",
    "b = stock.market.ticker._StockTicker()\n",
    "df_a = a.read()\n",
    "df_b = b._get_stock_info_listed()\n",
    "df_finder_kosdaq = df_a[df_a['marketName']=='KOSDAQ']\n",
    "df_finder_kospi = df_a[df_a['marketName']=='KOSPI']\n",
    "#display(df_kosdaq.reset_index(drop=True))\n",
    "#display(df_kospi.reset_index(drop=True))\n",
    "\n",
    "df_ticker_kosdaq = df_b[df_b['시장']=='KOSDAQ']\n",
    "df_ticker_kospi = df_b[df_b['시장']=='KOSPI']\n",
    "\n",
    "df_finder_kosdaq.to_excel('d:\\\\find_kosdaq.xlsx')\n",
    "df_finder_kospi.to_excel('d:\\\\find_kospi.xlsx')\n",
    "df_ticker_kosdaq.to_excel('d:\\\\tick_kosdaq.xlsx')\n",
    "df_ticker_kospi.to_excel('d:\\\\tick_kospi.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock Prediction 관련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  상승추세 종목 발굴 _1\n",
    "\n",
    "## market_good table에서 모든 colume 추출\n",
    "def market_stock(date):\n",
    "    select_query = \"select * from market_good where Date >  \"\n",
    "    var = select_query +\"'\"+date+\"'\" \n",
    "    df = pd.read_sql(var, engine)\n",
    "    return df\n",
    "\n",
    "from mod1 import *\n",
    "\n",
    "## 개별종목이름 리스트 생성\n",
    "df = market_stock('2019-01-01')\n",
    "stock_name=df['Name'].drop_duplicates()\n",
    "stock_name = stock_name.tolist()\n",
    "\n",
    "## 종목별로 이동평균선(ma5 ~ ma120)생성\n",
    "ma_df = pd.DataFrame()\n",
    "for name in stock_name:\n",
    "    print(name)\n",
    "    df1 = df[(df['Name'] == name)]\n",
    "    ma(df1)\n",
    "    ma_df=ma_df.append(df1)\n",
    "    \n",
    "#df3.to_excel('d:\\\\good_stock.xlsx')\n",
    "\n",
    "##  현재 today 종가가 ma120일선 위에있는 (상승추세에있는) 종목 추출\n",
    "df1 = ma_df[['date','code','name','close','volume','ma120']]\n",
    "df2 = df1[(df1['date'].astype(str) == '2019-09-30')]\n",
    "df3 = df2[(df2['close'] >= df2['ma120'])]\n",
    "df3\n",
    "\n",
    "## 상승추세종목 리스트 생성\n",
    "good_name=df3['name']\n",
    "good_name = good_name.tolist()\n",
    "\n",
    "## 상승추세 종목 그래프 생성 \n",
    "for i in good_name:\n",
    "    df=select_stock(i,'17-01-01')\n",
    "    df1 = close_vol_ma(df,'ma120')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  상승추세 종목 발굴 _2\n",
    "##  상승추세종목을 표준화하여 세부적으로 추출\n",
    "\n",
    "from mod1 import *\n",
    "\n",
    "## 개별종목이름 리스트 생성\n",
    "all_df = market_stock('2019-01-01')\n",
    "stock_name=all_df['Name'].drop_duplicates()\n",
    "stock_name = stock_name.tolist()\n",
    "\n",
    "## 종목별로 이동평균선(ma5 ~ ma120)생성\n",
    "ma_df = pd.DataFrame()\n",
    "min_max_df = pd.DataFrame()\n",
    "for name in stock_name:\n",
    "    print(name)\n",
    "    all_df1 = all_df[(all_df['Name'] == name)]\n",
    "    ma(all_df1)\n",
    "    ma_df=ma_df.append(all_df1)\n",
    "    \n",
    "#df3.to_excel('d:\\\\good_stock.xlsx')\n",
    "\n",
    "##  현재 today 종가가 ma120일선 위에있는 (상승추세에있는) 종목 추출\n",
    "first_df1 = ma_df[['date','code','name','close','volume','ma120']]\n",
    "first_df2 = first_df1[(first_df1['date'].astype(str) == '2019-09-30')]\n",
    "first_df3 = first_df2[(first_df2['close'] >= first_df2['ma120'])]\n",
    "first_df3\n",
    "\n",
    "## 상승추세종목 리스트 생성\n",
    "good_name=first_df3['name']\n",
    "good_name = good_name.tolist()\n",
    "\n",
    "## 상승추세종목별로 표준화 (MinMaxSchalr)생성\n",
    "good_stock_df = pd.DataFrame()\n",
    "min_max_df = pd.DataFrame()\n",
    "for name in good_name:\n",
    "    print(name)\n",
    "    good_df1 = select_stock(name,'2019-01-01')\n",
    "    good_stock_df=good_stock_df.append(good_df1)\n",
    "    min_max_df1 = min_max(good_df1,'ma120')\n",
    "    min_max_df=min_max_df.append(min_max_df1)\n",
    "\n",
    "good_stock_df1 = good_stock_df.set_index('Date')\n",
    "min_max_df[['code','name']]=good_stock_df1[['Code','Name']]\n",
    "\n",
    "second_df1 = min_max_df\n",
    "second_df2 = second_df1[(second_df1.index.astype(str) == real_yesterday)]\n",
    "second_df3 = second_df2[(second_df2['close'] <= 0.3) & (second_df2['ma120'] <=0.3)]\n",
    "second_df3\n",
    "\n",
    "## 표준화로 선별한 상승추세종목 리스트 생성\n",
    "min_max_name=second_df3['name']\n",
    "min_max_name = min_max_name.tolist()\n",
    "\n",
    "## 표준화로 선별한 추세 종목 그래프 생성 \n",
    "for i in min_max_name:\n",
    "    all_df=select_stock(i,'17-01-01')\n",
    "    all_df1 = close_vol_ma(all_df,'ma120')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  상승추세 종목 발굴 _3\n",
    "##  상승추세종목을 표준화 함수를 통합하여  속도 향상\n",
    "\n",
    "from mod1 import *\n",
    "\n",
    "all_df = market_stock('2019-10-01')\n",
    "stock_name=all_df['Name'].drop_duplicates()\n",
    "stock_name = stock_name.tolist()\n",
    "\n",
    "## 상승추세종목별로 표준화 (MinMaxSchalr)생성\n",
    "good_stock_df = pd.DataFrame()\n",
    "min_max_df = pd.DataFrame()\n",
    "\n",
    "for name in stock_name:\n",
    "    print(name)\n",
    "    good_df1 = select_stock(name,'2017-01-01')\n",
    "    min_max_df1 = min_max(good_df1,'ma120')\n",
    "    good_stock_df=good_stock_df.append(good_df1)\n",
    "    min_max_df=min_max_df.append(min_max_df1)\n",
    "\n",
    " \n",
    "good_stock_df1 = good_stock_df.set_index('date')\n",
    "min_max_df[['code','name']]=good_stock_df1[['code','name']]\n",
    " \n",
    "second_df1 = min_max_df\n",
    "second_df2 = second_df1[(second_df1.index.astype(str) == '2019-10-02')]\n",
    "second_df3 = second_df2[(second_df2['close'] <= 0.05)]\n",
    "second_df3\n",
    "\n",
    "## 표준화로 선별한 상승추세종목 리스트 생성\n",
    "min_max_name=second_df3['name']\n",
    "min_max_name = min_max_name.tolist()\n",
    "\n",
    "## 표준화로 선별한 추세 종목 그래프 생성 \n",
    "for i in min_max_name:\n",
    "    all_df=select_stock(i,'17-01-01')\n",
    "    all_df1 = close_vol_ma(all_df,'ma120')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Stock Prediction 30 days\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from tqdm import tqdm\n",
    "sns.set()\n",
    "tf.set_random_seed(777)  # reproducibility\n",
    "tf.reset_default_graph()\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter('ignore')\n",
    "\n",
    "import sqlalchemy\n",
    "\n",
    "engine = sqlalchemy.create_engine('mysql+pymysql://kkang:leaf2027@localhost/stock?charset=utf8',encoding='utf-8')\n",
    "var =\"select * from market where Name='HRS' and  Date > '2019-01-01'\" \n",
    "df = pd.read_sql(var ,engine)\n",
    "df.head()\n",
    "\n",
    "minmax = MinMaxScaler().fit(df.iloc[:, 7:].astype('float32')) # Close index\n",
    "df_log = minmax.transform(df.iloc[:, 7:].astype('float32')) # Close index\n",
    "df_log = pd.DataFrame(df_log)\n",
    "df_log.head()\n",
    "\n",
    "simulation_size = 10\n",
    "num_layers = 1\n",
    "size_layer = 128\n",
    "timestamp = 5\n",
    "epoch = 300\n",
    "dropout_rate = 0.8\n",
    "test_size = 30\n",
    "learning_rate = 0.01\n",
    "\n",
    "df_train = df_log\n",
    "df.shape, df_train.shape\n",
    "\n",
    "class Model:\n",
    "    def __init__(\n",
    "        self,\n",
    "        learning_rate,\n",
    "        num_layers,\n",
    "        size,\n",
    "        size_layer,\n",
    "        output_size,\n",
    "        forget_bias = 0.1,\n",
    "    ):\n",
    "        def lstm_cell(size_layer):\n",
    "            return tf.nn.rnn_cell.LSTMCell(size_layer, state_is_tuple = False)\n",
    "\n",
    "        rnn_cells = tf.nn.rnn_cell.MultiRNNCell(\n",
    "            [lstm_cell(size_layer) for _ in range(num_layers)],\n",
    "            state_is_tuple = False,\n",
    "        )\n",
    "        self.X = tf.placeholder(tf.float32, (None, None, size))\n",
    "        self.Y = tf.placeholder(tf.float32, (None, output_size))\n",
    "        drop = tf.contrib.rnn.DropoutWrapper(\n",
    "            rnn_cells, output_keep_prob = forget_bias\n",
    "        )\n",
    "        self.hidden_layer = tf.placeholder(\n",
    "            tf.float32, (None, num_layers * 2 * size_layer)\n",
    "        )\n",
    "        self.outputs, self.last_state = tf.nn.dynamic_rnn(\n",
    "            drop, self.X, initial_state = self.hidden_layer, dtype = tf.float32\n",
    "        )\n",
    "        self.logits = tf.layers.dense(self.outputs[-1], output_size)\n",
    "        self.cost = tf.reduce_mean(tf.square(self.Y - self.logits))\n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate).minimize(\n",
    "            self.cost\n",
    "        )\n",
    "        \n",
    "def calculate_accuracy(real, predict):\n",
    "    real = np.array(real) + 1\n",
    "    predict = np.array(predict) + 1\n",
    "    percentage = 1 - np.sqrt(np.mean(np.square((real - predict) / real)))\n",
    "    return percentage * 100\n",
    "\n",
    "def anchor(signal, weight):\n",
    "    buffer = []\n",
    "    last = signal[0]\n",
    "    for i in signal:\n",
    "        smoothed_val = last * weight + (1 - weight) * i\n",
    "        buffer.append(smoothed_val)\n",
    "        last = smoothed_val\n",
    "    return buffer\n",
    "\n",
    "def forecast():\n",
    "    tf.reset_default_graph()\n",
    "    modelnn = Model(\n",
    "        learning_rate, num_layers, df_log.shape[1], size_layer, df_log.shape[1], dropout_rate\n",
    "    )\n",
    "    sess = tf.InteractiveSession()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    date_ori = pd.to_datetime(df.iloc[:, 0]).tolist()\n",
    "\n",
    "    pbar = tqdm(range(epoch), desc = 'train loop')\n",
    "    for i in pbar:\n",
    "        init_value = np.zeros((1, num_layers * 2 * size_layer))\n",
    "        total_loss, total_acc = [], []\n",
    "        for k in range(0, df_train.shape[0] - 1, timestamp):\n",
    "            index = min(k + timestamp, df_train.shape[0] - 1)\n",
    "            batch_x = np.expand_dims(\n",
    "                df_train.iloc[k : index, :].values, axis = 0\n",
    "            )\n",
    "            batch_y = df_train.iloc[k + 1 : index + 1, :].values\n",
    "            logits, last_state, _, loss = sess.run(\n",
    "                [modelnn.logits, modelnn.last_state, modelnn.optimizer, modelnn.cost],\n",
    "                feed_dict = {\n",
    "                    modelnn.X: batch_x,\n",
    "                    modelnn.Y: batch_y,\n",
    "                    modelnn.hidden_layer: init_value,\n",
    "                },\n",
    "            )        \n",
    "            init_value = last_state\n",
    "            total_loss.append(loss)\n",
    "            total_acc.append(calculate_accuracy(batch_y[:, 0], logits[:, 0]))\n",
    "        pbar.set_postfix(cost = np.mean(total_loss), acc = np.mean(total_acc))\n",
    "    \n",
    "    future_day = test_size\n",
    "\n",
    "    output_predict = np.zeros((df_train.shape[0] + future_day, df_train.shape[1]))\n",
    "    output_predict[0] = df_train.iloc[0]\n",
    "    upper_b = (df_train.shape[0] // timestamp) * timestamp\n",
    "    init_value = np.zeros((1, num_layers * 2 * size_layer))\n",
    "\n",
    "    for k in range(0, (df_train.shape[0] // timestamp) * timestamp, timestamp):\n",
    "        out_logits, last_state = sess.run(\n",
    "            [modelnn.logits, modelnn.last_state],\n",
    "            feed_dict = {\n",
    "                modelnn.X: np.expand_dims(\n",
    "                    df_train.iloc[k : k + timestamp], axis = 0\n",
    "                ),\n",
    "                modelnn.hidden_layer: init_value,\n",
    "            },\n",
    "        )\n",
    "        init_value = last_state\n",
    "        output_predict[k + 1 : k + timestamp + 1] = out_logits\n",
    "\n",
    "    if upper_b != df_train.shape[0]:\n",
    "        out_logits, last_state = sess.run(\n",
    "            [modelnn.logits, modelnn.last_state],\n",
    "            feed_dict = {\n",
    "                modelnn.X: np.expand_dims(df_train.iloc[upper_b:], axis = 0),\n",
    "                modelnn.hidden_layer: init_value,\n",
    "            },\n",
    "        )\n",
    "        output_predict[upper_b + 1 : df_train.shape[0] + 1] = out_logits\n",
    "        future_day -= 1\n",
    "        date_ori.append(date_ori[-1] + timedelta(days = 1))\n",
    "\n",
    "    init_value = last_state\n",
    "    \n",
    "    for i in range(future_day):\n",
    "        o = output_predict[-future_day - timestamp + i:-future_day + i]\n",
    "        out_logits, last_state = sess.run(\n",
    "            [modelnn.logits, modelnn.last_state],\n",
    "            feed_dict = {\n",
    "                modelnn.X: np.expand_dims(o, axis = 0),\n",
    "                modelnn.hidden_layer: init_value,\n",
    "            },\n",
    "        )\n",
    "        init_value = last_state\n",
    "        output_predict[-future_day + i] = out_logits[-1]\n",
    "        date_ori.append(date_ori[-1] + timedelta(days = 1))\n",
    "    \n",
    "    output_predict = minmax.inverse_transform(output_predict)\n",
    "    deep_future = anchor(output_predict[:, 0], 0.4)\n",
    "    \n",
    "    return deep_future\n",
    "\n",
    "results = []\n",
    "for i in range(simulation_size):\n",
    "    print('simulation %d'%(i + 1))\n",
    "    results.append(forecast())\n",
    "    \n",
    "date_ori = pd.to_datetime(df.iloc[:, 0]).tolist()\n",
    "for i in range(test_size):\n",
    "    date_ori.append(date_ori[-1] + timedelta(days = 1))\n",
    "date_ori = pd.Series(date_ori).dt.strftime(date_format = '%Y-%m-%d').tolist()\n",
    "date_ori[-5:]\n",
    "\n",
    "accepted_results = []\n",
    "for r in results:\n",
    "    if (np.array(r[-test_size:]) < np.min(df['Close'])).sum() == 0 and \\\n",
    "    (np.array(r[-test_size:]) > np.max(df['Close']) * 2).sum() == 0:\n",
    "        accepted_results.append(r)\n",
    "len(accepted_results)\n",
    "\n",
    "accuracies = [calculate_accuracy(df['Close'].values, r[:-test_size]) for r in accepted_results]\n",
    "\n",
    "plt.figure(figsize = (15, 5))\n",
    "for no, r in enumerate(accepted_results):\n",
    "    plt.plot(r, label = 'forecast %d'%(no + 1))\n",
    "plt.plot(df['Close'], label = 'true trend', c = 'black')\n",
    "plt.legend()\n",
    "plt.title('average accuracy: %.4f'%(np.mean(accuracies)))\n",
    "\n",
    "x_range_future = np.arange(len(results[0]))\n",
    "plt.xticks(x_range_future[::30], date_ori[::30])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## MinMaxScaller() 변조및 복조\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "connect = create_engine('mysql+pymysql://kkang:leaf2027@localhost/stock?charset=utf8',encoding='utf-8')\n",
    "df = pd.read_sql(\"SELECT * from market where Code = '036640' and date > '2019-08-05'\", connect)\n",
    "\n",
    "df = df[['Open', 'High', 'Low', 'Volume', 'Close']]\n",
    "\n",
    "dataset = df.values\n",
    "\n",
    "source = MinMaxScaler() # default is 0,1\n",
    "dataset = source.fit_transform(dataset) ### MinMaxScaler 변조\n",
    "\n",
    "display(dataset)\n",
    "print('='*100)\n",
    "\n",
    "source.inverse_transform(dataset) ### MinMaxScaler 복조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## 이동 평균선\n",
    "\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "file = 'd:\\\\hrs.xlsx'\n",
    "\n",
    "connect = create_engine('mysql+pymysql://kkang:leaf2027@localhost/stock?charset=utf8',encoding='utf-8')\n",
    "df = pd.read_sql(\"SELECT * from market where Name = 'hrs' && Date > '2019-01-05'\", connect)\n",
    "\n",
    "volume_average_5 = df['Volume'].rolling(window=5,min_periods=1).mean()\n",
    "volume_average_10 = df['Volume'].rolling(window=10,min_periods=1).mean()\n",
    "volume_average_20 = df['Volume'].rolling(window=20,min_periods=1).mean()\n",
    "volume_average_60 = df['Volume'].rolling(window=60,min_periods=1).mean()\n",
    "volume_average_120 = df['Volume'].rolling(window=120,min_periods=1).mean()\n",
    "\n",
    "close_average_5 = df['Close'].rolling(window=5,min_periods=1).mean()\n",
    "close_average_10 = df['Close'].rolling(window=10,min_periods=1).mean()\n",
    "close_average_20 = df['Close'].rolling(window=20,min_periods=1).mean()\n",
    "close_average_60 = df['Close'].rolling(window=60,min_periods=1).mean()\n",
    "close_average_120 = df['Close'].rolling(window=120,min_periods=1).mean()\n",
    "\n",
    "df.insert(len(df.columns), \"Vol_MA5\", volume_average_5)\n",
    "df.insert(len(df.columns), \"Vol_MA10\", volume_average_10)\n",
    "df.insert(len(df.columns), \"Vol_MA20\", volume_average_20)\n",
    "df.insert(len(df.columns), \"Vol_MA60\", volume_average_60)\n",
    "df.insert(len(df.columns), \"Vol_MA120\", volume_average_120)\n",
    "\n",
    "df.insert(len(df.columns), \"Close_MA5\", close_average_5)\n",
    "df.insert(len(df.columns), \"Close_MA10\", close_average_10)\n",
    "df.insert(len(df.columns), \"Close_MA20\", close_average_20)\n",
    "df.insert(len(df.columns), \"Close_MA60\", close_average_60)\n",
    "df.insert(len(df.columns), \"Close_MA120\", close_average_120)\n",
    "\n",
    "df1 = df[['Date','Name','Close','Volume','Vol_MA5','Vol_MA10','Vol_MA20','Vol_MA60','Vol_MA120']]\n",
    "#df1.to_excel(file)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###  RSI\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "import talib.abstract as ta # talib.abstract는 Series나 numpy가 아닌 DataFrame도 대입가능\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import pandas_datareader.data as web\n",
    "import numpy as np\n",
    "from talib import RSI, BBANDS\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "file = 'd:\\\\hrs.xlsx'\n",
    "connect = create_engine('mysql+pymysql://kkang:leaf2027@localhost/stock?charset=utf8',encoding='utf-8')\n",
    "df = pd.read_sql(\"SELECT * from market where Name = 'hrs' && Date > '2019-01-05'\", connect)\n",
    "display(df.head())\n",
    "\n",
    "df = df.set_index('Date')\n",
    "df.columns = df.columns.str.lower()\n",
    "df[['open','high','low','volume','close']] = df[['open','high','low','volume','close']].astype(float)\n",
    "#df = df[['open','high','low','volume','close']]\n",
    "display(df.head())\n",
    "\n",
    "ta_ma5 = ta.MA(df,timeperiod=5 )\n",
    "display(ta_ma5.head())\n",
    "\n",
    "close = df['close'].values\n",
    "up, mid, low = BBANDS(close, timeperiod=20, nbdevup=2, nbdevdn=2, matype=0)\n",
    "df['BB_up']=up\n",
    "df['BB_mid']=mid\n",
    "df['BB_low']=low\n",
    "\n",
    "rsi = RSI(close, timeperiod=14)\n",
    "print(\"RSI (first 10 elements)\\n\", rsi[14:24])\n",
    "df['RSI']=rsi\n",
    "display(df['RSI'].head())\n",
    "\n",
    "up, mid, low = BBANDS(close, timeperiod=20, nbdevup=2, nbdevdn=2, matype=0)\n",
    "bbp = (df['close'] - low) / (up - low)\n",
    "df['BBP']=bbp\n",
    "display(bbp.head())\n",
    "\n",
    "index=df.index\n",
    "max_holding = 100\n",
    "\n",
    "holdings = pd.DataFrame(index=df.index, data={'Holdings': np.array([np.nan] * index.shape[0])})\n",
    "holdings.loc[((df['RSI'] < 30) & (df['BBP'] < 0)), 'Holdings'] = max_holding\n",
    "holdings.loc[((df['RSI'] > 70) & (df['BBP'] > 1)), 'Holdings'] = 0\n",
    "holdings.ffill(inplace=True)\n",
    "holdings.fillna(0, inplace=True)\n",
    "\n",
    "holdings['Order'] = holdings.diff()\n",
    "holdings.dropna(inplace=True)\n",
    "\n",
    "fig, (ax0, ax1, ax2) = plt.subplots(3, 1, sharex=True, figsize=(12, 8))\n",
    "ax0.plot(index, df['close'], label='Close')\n",
    "ax0.set_xlabel('Date')\n",
    "ax0.set_ylabel('close')\n",
    "ax0.grid()\n",
    "\n",
    "for day, holding in holdings.iterrows():\n",
    "    order = holding['Order']\n",
    "    if order > 0:\n",
    "        ax0.scatter(x=day, y=df.loc[day, 'close'], color='green')\n",
    "    elif order < 0:\n",
    "        ax0.scatter(x=day, y=df.loc[day, 'close'], color='red')\n",
    "\n",
    "ax1.plot(index, df['RSI'], label='RSI')\n",
    "ax1.fill_between(index, y1=30, y2=70, color='#adccff', alpha='0.3')\n",
    "ax1.set_xlabel('Date')\n",
    "ax1.set_ylabel('RSI')\n",
    "ax1.grid()\n",
    "\n",
    "ax2.plot(index, df['BB_up'], label='BB_up')\n",
    "ax2.plot(index, df['close'], label='AdjClose')\n",
    "ax2.plot(index, df['BB_low'], label='BB_low')\n",
    "ax2.fill_between(index, y1=df['BB_low'], y2=df['BB_up'], color='#adccff', alpha='0.3')\n",
    "ax2.set_xlabel('Date')\n",
    "ax2.set_ylabel('Bollinger Bands')\n",
    "ax2.grid()\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  ta-lib 이동평균선 그래프 출력\n",
    "\n",
    "import talib.abstract as ta\n",
    "import FinanceDataReader as fdr\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime as dt\n",
    "from datetime import datetime,timedelta\n",
    "from urllib.request import urlopen\n",
    "import sqlalchemy \n",
    "import pymysql\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "from matplotlib import font_manager, rc\n",
    "font_name = font_manager.FontProperties(fname=\"c:/Windows/Fonts/malgun.ttf\").get_name()\n",
    "rc('font', family=font_name)\n",
    "\n",
    "now = dt.datetime.today().strftime('%Y-%m-%d')\n",
    "engine = sqlalchemy.create_engine('mysql+pymysql://kkang:leaf2027@localhost/stock?charset=utf8',encoding='utf-8')\n",
    "\n",
    "\n",
    "df = pd.read_sql(\"SELECT * from market where Code = '036640' and date > '2019-01-05'\", engine)\n",
    "df = df.set_index('Date')\n",
    "df[['Open','High','Low','Volume','Close']] = df[['Open','High','Low','Volume','Close']].astype(float) #  TA-Lib로 평균을 구하려면 실수로 만들어야 함\n",
    "df.columns=df.columns.str.lower()\n",
    "\n",
    "talib_ma5 = ta.MA(df, timeperiod=5)\n",
    "df['ma5'] = talib_ma5\n",
    "\n",
    "talib_ma10 = ta.MA(df, timeperiod=10)\n",
    "df['ma10'] = talib_ma10\n",
    "\n",
    "talib_ma20 = ta.MA(df, timeperiod=20)\n",
    "df['ma20'] = talib_ma20\n",
    "\n",
    "talib_ma60 = ta.MA(df, timeperiod=60)\n",
    "df['ma60'] = talib_ma60\n",
    "\n",
    "talib_ma120 = ta.MA(df, timeperiod=120)\n",
    "df['ma120'] = talib_ma120\n",
    "\n",
    "display(df.iloc[120:].head())\n",
    "\n",
    "plt.figure(figsize=(16,4))\n",
    "plt.plot(df['ma5'],label='ma5')\n",
    "plt.plot(df['ma10'],label='ma10')\n",
    "plt.plot(df['ma20'],label='ma20')\n",
    "plt.plot(df['ma60'],label='ma60')\n",
    "plt.plot(df['ma120'],label='ma120')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  이동평균선  데이타베이스  일괄입력\n",
    "import time\n",
    "import talib.abstract as ta\n",
    "import FinanceDataReader as fdr\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime as dt\n",
    "from datetime import datetime,timedelta\n",
    "from urllib.request import urlopen\n",
    "import sqlalchemy \n",
    "import pymysql\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "from matplotlib import font_manager, rc\n",
    "font_name = font_manager.FontProperties(fname=\"c:/Windows/Fonts/malgun.ttf\").get_name()\n",
    "rc('font', family=font_name)\n",
    "\n",
    "now = dt.datetime.today().strftime('%Y-%m-%d')\n",
    "engine = sqlalchemy.create_engine('mysql+pymysql://kkang:leaf2027@localhost/stock?charset=utf8',encoding='utf-8')\n",
    "\n",
    "df = pd.read_sql(\"SELECT distinct Name from market \", engine)\n",
    "df = df.set_index('Name')\n",
    "name = df.index\n",
    "for i in range(len(name)):\n",
    "    df = pd.read_sql(\"SELECT * from market where Name =\"+\"'\"+name[i]+\"'\", engine)\n",
    "    line = df.shape[0]   \n",
    "    \n",
    "    df[['Open','High','Low','Volume','Close']] = df[['Open','High','Low','Volume','Close']].astype(float) #  TA-Lib로 평균을 구하려면 실수로 만들어야 함\n",
    "    df.columns=df.columns.str.lower()\n",
    "    #df = df.set_index('date')\n",
    "            \n",
    "    if line >= 120:\n",
    "        talib_ma5 = ta.MA(df, timeperiod=5)\n",
    "        df['ma5'] = talib_ma5\n",
    "\n",
    "        talib_ma10 = ta.MA(df, timeperiod=10)\n",
    "        df['ma10'] = talib_ma10\n",
    "\n",
    "        talib_ma20 = ta.MA(df, timeperiod=20)\n",
    "        df['ma20'] = talib_ma20\n",
    "\n",
    "        talib_ma60 = ta.MA(df, timeperiod=60)\n",
    "        df['ma60'] = talib_ma60\n",
    "\n",
    "        talib_ma120 = ta.MA(df, timeperiod=120)\n",
    "        df['ma120'] = talib_ma120\n",
    "\n",
    "        df_ma = df[['date','code','name','ma5','ma10','ma20','ma60','ma120']].round(2)\n",
    "        df_ma.iloc[:4,3]=df_ma.iloc[4,3]\n",
    "        df_ma.iloc[:9,4]=df_ma.iloc[9,4]\n",
    "        df_ma.iloc[:19,5]=df_ma.iloc[19,5]\n",
    "        df_ma.iloc[:59,6]=df_ma.iloc[59,6]\n",
    "        df_ma.iloc[:119,7]=df_ma.iloc[119,7]        \n",
    "        df_ma.columns=['Date','Code','Name','ma5','ma10','ma20','ma60','ma120']\n",
    "        df_ma.to_sql(name='ma', con=engine, if_exists='append', index = False)  \n",
    "        \n",
    "    elif line >= 60 and line < 120:\n",
    "        talib_ma5 = ta.MA(df, timeperiod=5)\n",
    "        df['ma5'] = talib_ma5\n",
    "        \n",
    "        talib_ma10 = ta.MA(df, timeperiod=10)\n",
    "        df['ma10'] = talib_ma10\n",
    "        \n",
    "        talib_ma20 = ta.MA(df, timeperiod=20)\n",
    "        df['ma20'] = talib_ma20\n",
    "        \n",
    "        talib_ma60 = ta.MA(df, timeperiod=60)\n",
    "        df['ma60'] = talib_ma60\n",
    "        \n",
    "        df_ma = df[['date','code','name','ma5','ma10','ma20','ma60']].round(2)\n",
    "        df_ma.iloc[:4,3]=df_ma.iloc[4,3]\n",
    "        df_ma.iloc[:9,4]=df_ma.iloc[9,4]\n",
    "        df_ma.iloc[:19,5]=df_ma.iloc[19,5]\n",
    "        df_ma.iloc[:59,6]=df_ma.iloc[59,6]        \n",
    "        df_ma.columns=['Date','Code','Name','ma5','ma10','ma20','ma60']\n",
    "        df_ma.to_sql(name='ma', con=engine, if_exists='append', index = False) \n",
    "        \n",
    "    elif line >= 20 and line <60:\n",
    "        talib_ma5 = ta.MA(df, timeperiod=5)\n",
    "        df['ma5'] = talib_ma5\n",
    "        \n",
    "        talib_ma10 = ta.MA(df, timeperiod=10)\n",
    "        df['ma10'] = talib_ma10\n",
    "        \n",
    "        talib_ma20 = ta.MA(df, timeperiod=20)\n",
    "        df['ma20'] = talib_ma20\n",
    "        \n",
    "        df_ma = df[['date','code','name','ma5','ma10','ma20']].round(2)\n",
    "        df_ma.iloc[:4,3]=df_ma.iloc[4,3]\n",
    "        df_ma.iloc[:9,4]=df_ma.iloc[9,4]\n",
    "        df_ma.iloc[:19,5]=df_ma.iloc[19,5]\n",
    "        df_ma.columns=['Date','Code','Name','ma5','ma10','ma20']\n",
    "        df_ma.to_sql(name='ma', con=engine, if_exists='append', index = False)\n",
    "        \n",
    "    elif line >= 10 and line <20:\n",
    "        talib_ma5 = ta.MA(df, timeperiod=5)\n",
    "        df['ma5'] = talib_ma5\n",
    "        \n",
    "        talib_ma10 = ta.MA(df, timeperiod=10)\n",
    "        df['ma10'] = talib_ma10\n",
    "        \n",
    "        df_ma = df[['date','code','name','ma5','ma10']].round(2)\n",
    "        df_ma.iloc[:4,3]=df_ma.iloc[4,3]\n",
    "        df_ma.iloc[:9,4]=df_ma.iloc[9,4] \n",
    "        df_ma.columns=['Date','Code','Name','ma5','ma10']\n",
    "        df_ma.to_sql(name='ma', con=engine, if_exists='append', index = False) \n",
    "        \n",
    "    elif line >= 5 and line <10:\n",
    "        talib_ma5 = ta.MA(df, timeperiod=5)\n",
    "        df['ma5'] = talib_ma5 \n",
    "        \n",
    "        df_ma = df[['date','code','name','ma5']].round(2)\n",
    "        df_ma.iloc[:4,3]=df_ma.iloc[4,3]\n",
    "        df_ma.columns=['Date','Code','Name','ma5']\n",
    "        df_ma.to_sql(name='ma', con=engine, if_exists='append', index = False)\n",
    "        \n",
    "    elif line > 5:\n",
    "        pass\n",
    "  \n",
    "    #df_ma.to_excel('d:\\ma_line.xlsx')\n",
    "    #df_ma.columns=['Date','Code','Name','ma5','ma10','ma20','ma60','ma120']\n",
    "    #df_ma.to_sql(name='ma', con=engine, if_exists='append', index = False)\n",
    "    print(df_ma.head(1))\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 일일 종목선정 project 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## 일일 거래량 50만주이상 주식중 전일 거래량 보다 많은 거래량 top15 종목 \n",
    "\n",
    "import FinanceDataReader as fdr\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime as dt\n",
    "from datetime import datetime,timedelta\n",
    "from urllib.request import urlopen\n",
    "import sqlalchemy \n",
    "import pymysql\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "from matplotlib import font_manager, rc\n",
    "font_name = font_manager.FontProperties(fname=\"c:/Windows/Fonts/malgun.ttf\").get_name()\n",
    "rc('font', family=font_name)\n",
    "\n",
    "today = datetime.now()\n",
    "real_yesterday = (today-timedelta(1)).strftime('%Y-%m-%d')\n",
    "real_today = today.strftime('%Y-%m-%d')\n",
    "\n",
    "now = dt.datetime.today().strftime('%Y-%m-%d')\n",
    "engine = sqlalchemy.create_engine('mysql+pymysql://kkang:leaf2027@localhost/stock?charset=utf8',encoding='utf-8')\n",
    "\n",
    "market_df = pd.read_sql(\"select * from market where Date > '2019-01-01'\", engine)\n",
    "#market_df\n",
    "\n",
    "is_hrs=market_df['Name']=='HRS'\n",
    "hrs_df = market_df[is_hrs]\n",
    "yesterday = str(hrs_df['Date'].iloc[0])\n",
    "today = str(hrs_df['Date'].iloc[1])\n",
    "#print(yesterday)\n",
    "#print(today)\n",
    "\n",
    "#var = \"select * from market where (Date = '2019-01-02' OR Date = '2019-01-03')  and Volume >  500000\"\n",
    "#df = pd.read_sql(var ,engine)\n",
    "#df\n",
    "\n",
    "select_query = \"select * from market where (Date = \"\n",
    "volume_query = \"&& Volume >  500000\"\n",
    "    \n",
    "var = select_query +\"'\"+yesterday+\"'\"+'or Date ='+\"'\"+today+\"'\"+')' + volume_query\n",
    "df = pd.read_sql(var ,engine)\n",
    "\n",
    "#df\n",
    "\n",
    "\n",
    "df1 = df[df['Date'].astype(str) == yesterday]\n",
    "df1 = df1[['Name','Volume','Close']]\n",
    "df1.columns = ['Name','yester_Volume','yester_Close']\n",
    "#display(df1)\n",
    "\n",
    "\n",
    "df2 = df[df['Date'].astype(str) == today]\n",
    "df2 = df2[['Name','Volume','Close']]\n",
    "df2.columns = ['Name','today_Volume','today_Close']\n",
    "#display(df2)\n",
    "\n",
    "df3 = pd.merge(df1,df2,on='Name')\n",
    "df3['Close']=df3['today_Close']/df3['yester_Close']\n",
    "df3['Volume']=df3['today_Volume']/df3['yester_Volume']\n",
    "df3 = df3.sort_values(by=['Volume','Close'],ascending=False)\n",
    "df4 = df3.sort_values(by=['Close','Volume'],ascending=False)\n",
    "df3 = df3.reset_index(drop=True)\n",
    "\n",
    "df3 = df3[:19]\n",
    "df4 = df4.reset_index(drop=True)\n",
    "df4 = df4[:19]\n",
    "df3.to_excel('d:\\\\stockdata\\\\vote_stock\\\\detect_stock_with_volume_'+today+'.xlsx', encoding='utf-8')\n",
    "df4.to_excel('d:\\\\stockdata\\\\vote_stock\\\\detect_stock_with_price_'+today+'.xlsx', encoding='utf-8')        \n",
    "display(df3)\n",
    "display(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## 일일 거래량 50만주이상 주식중 전일 거래량 보다 많은 거래량 top19 종목  for loop 추가 및 화일로 저장\n",
    "\n",
    "import FinanceDataReader as fdr\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime as dt\n",
    "from datetime import datetime,timedelta\n",
    "from urllib.request import urlopen\n",
    "import sqlalchemy \n",
    "import pymysql\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "from matplotlib import font_manager, rc\n",
    "font_name = font_manager.FontProperties(fname=\"c:/Windows/Fonts/malgun.ttf\").get_name()\n",
    "rc('font', family=font_name)\n",
    "\n",
    "today = datetime.now()\n",
    "real_yesterday = (today-timedelta(1)).strftime('%Y-%m-%d')\n",
    "real_today = today.strftime('%Y-%m-%d')\n",
    "\n",
    "now = dt.datetime.today().strftime('%Y-%m-%d')\n",
    "engine = sqlalchemy.create_engine('mysql+pymysql://kkang:leaf2027@localhost/stock?charset=utf8',encoding='utf-8')\n",
    "\n",
    "market_df = pd.read_sql(\"select * from market where Date > '2019-05-01'\", engine)\n",
    "#market_df\n",
    "\n",
    "is_hrs=market_df['Name']=='HRS'\n",
    "hrs_df = market_df[is_hrs]\n",
    "yesterday = str(hrs_df['Date'].iloc[0])\n",
    "today = str(hrs_df['Date'].iloc[1])\n",
    "count = hrs_df.shape[0]\n",
    "#for i in range(hrs_df['Date'].shape[0]):\n",
    "for i in range(count):\n",
    "    yesterday = str(hrs_df['Date'].iloc[i])\n",
    "    today = str(hrs_df['Date'].iloc[i+1])\n",
    "    print('y:{}'.format(yesterday))\n",
    "    print('t:{}'.format(today))\n",
    "    select_query = \"select * from market where (Date = \"\n",
    "    volume_query = \"&& Volume >  500000\"\n",
    "    \n",
    "    var = select_query +\"'\"+yesterday+\"'\"+'or Date ='+\"'\"+today+\"'\"+')' + volume_query\n",
    "    df = pd.read_sql(var ,engine)\n",
    "\n",
    "    #df\n",
    "\n",
    "\n",
    "    df1 = df[df['Date'].astype(str) == yesterday]\n",
    "    df1 = df1[['Name','Volume','Close']]\n",
    "    df1.columns = ['Name','yester_Volume','yester_Close']\n",
    "    #display(df1)\n",
    "\n",
    "\n",
    "    df2 = df[df['Date'].astype(str) == today]\n",
    "    df2 = df2[['Name','Volume','Close']]\n",
    "    df2.columns = ['Name','today_Volume','today_Close']\n",
    "    #display(df2)\n",
    "\n",
    "    df3 = pd.merge(df1,df2,on='Name')\n",
    "    df3['Close']=df3['today_Close']/df3['yester_Close']\n",
    "    df3['Volume']=df3['today_Volume']/df3['yester_Volume']\n",
    "    df3 = df3.sort_values(by=['Volume','Close'],ascending=False)\n",
    "    df4 = df3.sort_values(by=['Close','Volume'],ascending=False)\n",
    "    df3 = df3.reset_index(drop=True)\n",
    "\n",
    "    df3 = df3[:19]\n",
    "    df4 = df4.reset_index(drop=True)\n",
    "    df4 = df4[:19]\n",
    "    df3.to_excel('d:\\\\stockdata\\\\vote_stock\\\\detect_stock_with_volume_'+today+'.xlsx', encoding='utf-8')\n",
    "    df4.to_excel('d:\\\\stockdata\\\\vote_stock\\\\detect_stock_with_price_'+today+'.xlsx', encoding='utf-8')        \n",
    "    display(df3)\n",
    "    display(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  전종목 검색하여  종가 > ma120  일일 비교  하여  관심 종목 추출_1\n",
    "\n",
    "from mod1 import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "\n",
    "\n",
    "path = 'd:\\\\stockdata\\\\close_ma120\\\\close_ma120_'\n",
    "\n",
    "df = all_stock('2019-10-10')\n",
    "df = df['Name']\n",
    "\n",
    "name = df.to_list()\n",
    "\n",
    "df2 = pd.DataFrame()\n",
    "for i in name:\n",
    "    #print(i)\n",
    "    df=select_stock(i,'2010-01-01')\n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close','ma120','volume']].values)\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1['Name']=i\n",
    "    df1.columns=['close','ma120','volume','name',]\n",
    "    df1['date'] = df['date']\n",
    "    #print(df1)\n",
    "    df2 = df2.append(df1)\n",
    "    \n",
    "\n",
    "last = len(df2[df2['name'] == name[0]])-1\n",
    "today_df = df2[df2.index == last]\n",
    "\n",
    "ma120_df = today_df[today_df['close'] > today_df['ma120']]\n",
    "ma120_df = ma120_df.sort_values(['ma120'])\n",
    "\n",
    "today = str(ma120_df.iloc[0,4])\n",
    "ma120_df.to_excel(path+today+'.xlsx', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  전종목 검색하여  종가 > ma120  일일 비교  하여  관심 종목 추출_2  날짜를 지정하여 검색 가능\n",
    "\n",
    "from mod1 import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "\n",
    "choice_date='2019-10-22'\n",
    "path = 'd:\\\\stockdata\\\\close_ma120\\\\close_ma120_'\n",
    "\n",
    "df = all_stock('2019-10-10')\n",
    "df = df['Name']\n",
    "\n",
    "name = df.to_list()\n",
    "\n",
    "df2 = pd.DataFrame()\n",
    "for i in name:\n",
    "    #print(i)\n",
    "    df=select_stock(i,'2010-01-01')\n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close','ma120','volume']].values)\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1['Name']=i\n",
    "    df1.columns=['close','ma120','volume','name',]\n",
    "    df1['date'] = df['date']\n",
    "    #print(df1)\n",
    "    df2 = df2.append(df1)\n",
    "    \n",
    "\n",
    "select_query = \"select count(*) from market_good where Name='hrs' and Date > \"\n",
    "var = select_query +\"'\"+choice_date+\"'\" \n",
    "sql_df = pd.read_sql(var, engine)\n",
    "count = sql_df.values.tolist()\n",
    "back_date = count[0][0]\n",
    "back_date\n",
    "today_df = df2.loc[df2['date'] == (today_df['date'].values[0]-timedelta(back_date))]\n",
    "\n",
    "ma120_df = today_df[today_df['close'] > today_df['ma120']]\n",
    "ma120_df = ma120_df.sort_values(['ma120'])\n",
    "\n",
    "ma120_df.to_excel(path+choice_date+'.xlsx', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  전종목 검색하여  종가 > ma120  일일 비교  하여  관심 종목 추출_3  한달단위로 추출\n",
    "\n",
    "from mod1 import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "\n",
    "path = 'd:\\\\stockdata\\\\close_ma120\\\\close_ma120_'\n",
    "\n",
    "df = all_stock('2019-10-10')\n",
    "df = df['Name']\n",
    "\n",
    "name = df.to_list()\n",
    "\n",
    "df2 = pd.DataFrame()\n",
    "for i in name:\n",
    "    #print(i)\n",
    "    df=select_stock(i,'2010-01-01')\n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close','ma60','ma120','volume']].values)\n",
    "    df1 = pd.DataFrame(data)\n",
    "\n",
    "    df1['Name']=i\n",
    "    df1.columns=['close','ma60','ma120','volume','name',]\n",
    "    df1['date'] = df['date']\n",
    "\n",
    "    #print(df1)\n",
    "    df2 = df2.append(df1)\n",
    "\n",
    "select_query = \"select * from market where Name='hrs' and Date >= '2019-10-01' and Date < '2019-11-01' \"\n",
    "df3 = pd.read_sql(select_query, engine)\n",
    "\n",
    "df3 = df3['Date']\n",
    "datelist = df3.to_list()\n",
    "\n",
    "for i in datelist:\n",
    "    choice_df = df2.loc[df2['date'] == i]\n",
    "    strdate = i.strftime('%Y-%m-%d')\n",
    "    ma120_df = choice_df[choice_df['close'] > choice_df['ma120']]\n",
    "    ma120_df = ma120_df.sort_values(['ma120'])\n",
    "    ma120_df.to_excel(path+strdate+'.xlsx')\n",
    "    #print(today_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  전종목 검색하여  종가 > ma120  일일 비교  하여  관심 종목 추출_4  한달단위로  close_ma120, total 동시 추출\n",
    "\n",
    "from mod1 import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "\n",
    "path = 'd:\\\\stockdata\\\\close_ma120\\\\close_ma120_'\n",
    "path_total = 'd:\\\\stockdata\\\\close_ma120\\\\total_'\n",
    "\n",
    "df = all_stock('2019-10-10')\n",
    "df = df['Name']\n",
    "name = df.to_list()\n",
    "\n",
    "pure_df = pd.DataFrame()\n",
    "df2 = pd.DataFrame()\n",
    "\n",
    "for i in name:\n",
    "    #print(i)\n",
    "    df=select_stock(i,'2008-01-01')\n",
    "    pure_df = pure_df.append(df)\n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close','ma60','ma120','volume']].values)\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1['name']=i\n",
    "    df1.columns=['close','ma60','ma120','volume','name']\n",
    "    df1['date'] = df['date']\n",
    "    #print(df1)\n",
    "    df2 = df2.append(df1)\n",
    "\n",
    "pure_df.columns = map(str.lower, pure_df.columns) ## \n",
    "\n",
    "select_query = \"select * from market where Name='hrs' and Date >= '2019-10-01' \"\n",
    "df3 = pd.read_sql(select_query, engine)\n",
    "\n",
    "df3 = df3['Date']\n",
    "datelist = df3.to_list()\n",
    "\n",
    "last_df = df2.loc[df2['date'] == datelist[-1]]\n",
    "last_df = last_df[last_df['ma120'] < 0.1]\n",
    "last_price_df = pure_df.loc[pure_df['date'] == datelist[-1]]\n",
    "\n",
    "for i in datelist:\n",
    "    first_df = df2.loc[df2['date'] == i]\n",
    "    first_price_df = pure_df.loc[pure_df['date'] == i]\n",
    "    ma120_df = pd.merge(first_df,last_df,on='name')\n",
    "    ma_df = pd.merge(first_price_df[['close','name']],ma120_df,on='name')\n",
    "    ma120_df = pd.merge(last_price_df[['close','volume','name']],ma_df,on='name')\n",
    "    ma120_df.columns= ['price_y','volume_z', 'name', 'price_x', 'close_x', 'ma60_x', 'ma120_x','volume_x', 'date_x', 'close_y', 'ma60_y', 'ma120_y', 'volume_y', 'date_y']\n",
    "    ma120_df = ma120_df[['name','close_x','close_y','ma60_x','ma60_y','ma120_x','ma120_y','price_x','price_y','volume_z','date_x']]\n",
    "    ma120_df['price_diff']=ma120_df['price_y']/ma120_df['price_x']\n",
    "    ma120_df =  ma120_df.sort_values([\"price_diff\"],ascending=False)\n",
    "    second_df =  first_df.sort_values([\"ma120\"],ascending=False)\n",
    "    #ma120_df['price_x']=first_price_df['close'].values\n",
    "    #ma120_df['price_y']=last_price_df['close'].values\n",
    "    strdate = i.strftime('%Y-%m-%d')\n",
    "    second_df.to_excel(path+strdate+'.xlsx')\n",
    "    ma120_df.to_excel(path_total+strdate+'.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  전종목 검색하여  종가 > ma120  일일 비교  하여  관심 종목 추출_5  한달단위로  close_ma120, total 동시 추출(1년분)\n",
    "\n",
    "from mod1 import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
    "\n",
    "path = 'd:\\\\stockdata\\\\close_ma120\\\\close_ma120_'\n",
    "path_total = 'd:\\\\stockdata\\\\close_ma120\\\\total_'\n",
    "path_total_a = 'd:\\\\stockdata\\\\close_ma120\\\\total_a_'\n",
    "path_total_b = 'd:\\\\stockdata\\\\close_ma120\\\\total_b_'\n",
    "\n",
    "df = all_stock('2019-10-10')\n",
    "df = df['Name']\n",
    "name = df.to_list()\n",
    "\n",
    "pure_df = pd.DataFrame()\n",
    "df2 = pd.DataFrame()\n",
    "\n",
    "for i in name:\n",
    "    #print(i)\n",
    "    df=select_stock(i,'2019-01-01')\n",
    "    pure_df = pure_df.append(df)\n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close','ma60','ma120','volume']].values)\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1['name']=i\n",
    "    df1.columns=['close','ma60','ma120','volume','name']\n",
    "    df1[['date','code']] = df[['date','code']]\n",
    "\n",
    "    #print(df1)\n",
    "    df2 = df2.append(df1)\n",
    "\n",
    "pure_df.columns = map(str.lower, pure_df.columns) ## \n",
    "\n",
    "select_query = \"select * from market where Name='hrs' and Date >= '2019-10-01' \"\n",
    "df3 = pd.read_sql(select_query, engine)\n",
    "\n",
    "df3 = df3['Date']\n",
    "datelist = df3.to_list()\n",
    "\n",
    "last_df = df2.loc[df2['date'] == datelist[-1]]\n",
    "last_df = last_df[last_df['ma120'] < 0.1]\n",
    "a_df = last_df[last_df['close'] > last_df['ma60']] \n",
    "last_df = a_df[a_df['ma60'] > a_df['ma120']]\n",
    "last_price_df = pure_df.loc[pure_df['date'] == datelist[-1]]\n",
    "\n",
    "for i in datelist:\n",
    "    first_df = df2.loc[df2['date'] == i]\n",
    "    first_price_df = pure_df.loc[pure_df['date'] == i]\n",
    "    one_df = pd.merge(first_df,last_df,on='code')\n",
    "    reset_index_df = last_df.reset_index()\n",
    "    one_df['code']= reset_index_df['code']\n",
    "    ma_df = pd.merge(first_price_df[['close','code']],one_df,on='code')\n",
    "    two_df = pd.merge(last_price_df[['close','code','volume']],ma_df,on='code')\n",
    "    two_df.columns= ['price_y','code', 'volume_z','price_x', 'close_x', 'ma60_x', 'ma120_x', 'volume_x','name_x', 'date_x', 'close_y', 'ma60_y', 'ma120_y', 'volume_y','name_y', 'date_y']\n",
    "\n",
    "    ma120_df = two_df[['name_x','code','close_x','close_y','ma60_x','ma60_y','ma120_x','ma120_y','price_x','price_y','date_x','volume_z']]\n",
    "    ma120_df['price_diff']=ma120_df['price_y']/ma120_df['price_x']\n",
    "    ma120_df =  ma120_df.sort_values([\"price_diff\"],ascending=False)\n",
    "    #second_df =  first_df.sort_values([\"ma120\"],ascending=False)\n",
    "\n",
    "    strdate = i.strftime('%Y-%m-%d')\n",
    "    #second_df.to_excel(path+strdate+'.xlsx')\n",
    "    ma120_df.to_excel(path_total_a+strdate+'.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  전종목 검색하여  종가 > ma120  일일 비교  하여  관심 종목 추출_6  한달단위로  close_ma120, total 동시 추출(11년분)\n",
    "\n",
    "from mod1 import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
    "\n",
    "path = 'd:\\\\stockdata\\\\close_ma120\\\\close_ma120_'\n",
    "path_total = 'd:\\\\stockdata\\\\close_ma120\\\\total_'\n",
    "path_total_a = 'd:\\\\stockdata\\\\close_ma120\\\\total_a_'\n",
    "path_total_b = 'd:\\\\stockdata\\\\close_ma120\\\\total_b_'\n",
    "\n",
    "df = all_stock('2019-10-10')\n",
    "df = df['Name']\n",
    "name = df.to_list()\n",
    "\n",
    "pure_df = pd.DataFrame()\n",
    "df2 = pd.DataFrame()\n",
    "\n",
    "for i in name:\n",
    "    #print(i)\n",
    "    df=select_stock(i,'2008-01-01')\n",
    "    pure_df = pure_df.append(df)\n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close','ma60','ma120','volume']].values)\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1['name']=i\n",
    "    df1.columns=['close','ma60','ma120','volume','name']\n",
    "    df1[['date','code']] = df[['date','code']]\n",
    "\n",
    "    #print(df1)\n",
    "    df2 = df2.append(df1)\n",
    "\n",
    "pure_df.columns = map(str.lower, pure_df.columns) ## \n",
    "\n",
    "select_query = \"select * from market where Name='hrs' and Date >= '2019-10-01' \"\n",
    "df3 = pd.read_sql(select_query, engine)\n",
    "\n",
    "df3 = df3['Date']\n",
    "datelist = df3.to_list()\n",
    "\n",
    "last_df = df2.loc[df2['date'] == datelist[-1]]\n",
    "last_df = last_df[last_df['ma120'] < 0.1]\n",
    "a_df = last_df[last_df['close'] > last_df['ma60']] \n",
    "last_df = a_df[a_df['ma60'] > a_df['ma120']]\n",
    "last_price_df = pure_df.loc[pure_df['date'] == datelist[-1]]\n",
    "\n",
    "for i in datelist:\n",
    "    first_df = df2.loc[df2['date'] == i]\n",
    "    first_price_df = pure_df.loc[pure_df['date'] == i]\n",
    "    one_df = pd.merge(first_df,last_df,on='code')\n",
    "    reset_index_df = last_df.reset_index()\n",
    "    one_df['code']= reset_index_df['code']\n",
    "    ma_df = pd.merge(first_price_df[['close','code']],one_df,on='code')\n",
    "    two_df = pd.merge(last_price_df[['close','code','volume']],ma_df,on='code')\n",
    "    two_df.columns= ['price_y','code', 'volume_z','price_x', 'close_x', 'ma60_x', 'ma120_x', 'volume_x','name_x', 'date_x', 'close_y', 'ma60_y', 'ma120_y', 'volume_y','name_y', 'date_y']\n",
    "\n",
    "    ma120_df = two_df[['name_x','code','close_x','close_y','ma60_x','ma60_y','ma120_x','ma120_y','price_x','price_y','date_x','volume_z']]\n",
    "    ma120_df['price_diff']=ma120_df['price_y']/ma120_df['price_x']\n",
    "    ma120_df =  ma120_df.sort_values([\"price_diff\"],ascending=False)\n",
    "    second_df =  first_df.sort_values([\"ma120\"],ascending=False)\n",
    "\n",
    "    strdate = i.strftime('%Y-%m-%d')\n",
    "    second_df.to_excel(path+strdate+'.xlsx')\n",
    "    ma120_df.to_excel(path_total_b+strdate+'.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  전종목 검색하여  종가 > ma120  일일 비교  하여  관심 종목 추출_7  한달단위로  close_ma120, total (1년분),close_ma120, total (11년분) 동시 추출\n",
    "\n",
    "from mod1 import *\n",
    "#import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "#from pandas.core.common import SettingWithCopyWarning\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
    "\n",
    "path = 'd:\\\\stockdata\\\\close_ma120\\\\close_ma120_'\n",
    "path_total = 'd:\\\\test\\\\total_'\n",
    "path_total_a = 'd:\\\\test\\\\total_a_'\n",
    "path_total_b = 'd:\\\\test\\\\total_b_'\n",
    "\n",
    "#df = all_stock('2019-10-10')\n",
    "#df = df['Name']\n",
    "#name = df.to_list()\n",
    "    \n",
    "name = ['필룩스','MP한강','금호전기','나이벡']\n",
    "\n",
    "select_start_a = '2019-01-01'\n",
    "select_start_b = '2008-01-01'\n",
    "    \n",
    "def search_stock(name,select_start):   \n",
    "    print(name)\n",
    "    print(select_start)\n",
    "    pure_df = pd.DataFrame()\n",
    "    df2 = pd.DataFrame() \n",
    "    for i in name:\n",
    "        #print(i)\n",
    "        df=select_stock(i,select_start)\n",
    "        #print(df)\n",
    "        pure_df = pure_df.append(df)\n",
    "        ma(df)\n",
    "\n",
    "        source = MinMaxScaler()\n",
    "        data = source.fit_transform(df[['close','ma60','ma120','volume']].values)\n",
    "        df1 = pd.DataFrame(data)\n",
    "        df1['name']=i\n",
    "        df1.columns=['close','ma60','ma120','volume','name']\n",
    "        df1[['date','code']] = df[['date','code']]\n",
    "        #print(df1)\n",
    "        df2 = df2.append(df1)\n",
    "\n",
    "    pure_df.columns = map(str.lower, pure_df.columns) ## \n",
    "\n",
    "    select_query = \"select * from market where Name='hrs' and Date >= '2019-10-01' \"\n",
    "    df3 = pd.read_sql(select_query, engine)\n",
    "\n",
    "    df3 = df3['Date']\n",
    "    datelist = df3.to_list()\n",
    "\n",
    "    last_df = df2.loc[df2['date'] == datelist[-1]]\n",
    "    last_df = last_df[last_df['ma120'] < 0.1]\n",
    "    a_df = last_df[last_df['close'] > last_df['ma60']] \n",
    "    last_df = a_df[a_df['ma60'] > a_df['ma120']]\n",
    "    last_price_df = pure_df.loc[pure_df['date'] == datelist[-1]]\n",
    "\n",
    "    for i in datelist:\n",
    "        first_df = df2.loc[df2['date'] == i]\n",
    "        first_price_df = pure_df.loc[pure_df['date'] == i]\n",
    "        one_df = pd.merge(first_df,last_df,on='code')\n",
    "        reset_index_df = last_df.reset_index()\n",
    "        one_df['code']= reset_index_df['code']\n",
    "        ma_df = pd.merge(first_price_df[['close','code']],one_df,on='code')\n",
    "        two_df = pd.merge(last_price_df[['close','code']],ma_df,on='code')\n",
    "        two_df.columns= ['price_y','code', 'price_x', 'close_x', 'ma60_x', 'ma120_x', 'volume_x','name_x', 'date_x', 'close_y', 'ma60_y', 'ma120_y', 'volume_y','name_y', 'date_y']\n",
    "        ma120_df = two_df[['name_x','code','close_x','close_y','ma60_x','ma60_y','ma120_x','ma120_y','price_x','price_y','date_x']]\n",
    "        ma120_df['price_diff']=ma120_df['price_y']/ma120_df['price_x']\n",
    "        ma120_df =  ma120_df.sort_values([\"price_diff\"],ascending=False)\n",
    "        second_df =  first_df.sort_values([\"ma120\"],ascending=False)\n",
    "        #ma120_df['price_x']=first_price_df['close'].values\n",
    "        #ma120_df['price_y']=last_price_df['close'].values\n",
    "        strdate = i.strftime('%Y-%m-%d')\n",
    "        #second_df.to_excel(path+strdate+'.xlsx')\n",
    "        if select_start == select_start_a:\n",
    "            ma120_df.to_excel(path_total_a+strdate+'.xlsx')\n",
    "        else:\n",
    "            ma120_df.to_excel(path_total_b+strdate+'.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  전종목 검색하여  종가 > ma120  일일 비교  하여  관심 종목 추출_8  total_a(1년분) ,total_b(11년분) 의 공통종목을 추출\n",
    "\n",
    "from mod1 import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
    "\n",
    "path = 'd:\\\\stockdata\\\\close_ma120\\\\close_ma120_'\n",
    "path_total = 'd:\\\\stockdata\\\\close_ma120\\\\total_'\n",
    "path_total_a = 'd:\\\\stockdata\\\\close_ma120\\\\total_a_'\n",
    "path_total_b = 'd:\\\\stockdata\\\\close_ma120\\\\total_b_'\n",
    "\n",
    "select_query = \"select * from market where Name='hrs' and Date >= '2019-10-01' \"\n",
    "df3 = pd.read_sql(select_query, engine)\n",
    "\n",
    "df3 = df3['Date']\n",
    "datelist = df3.to_list()\n",
    "\n",
    "for i in datelist:\n",
    "    strdate = i.strftime('%Y-%m-%d')\n",
    "    df_a = pd.read_excel(path_total_a+strdate+'.xlsx')\n",
    "    df_b = pd.read_excel(path_total_b+strdate+'.xlsx')\n",
    "    #df_ab = pd.DataFrame()\n",
    "    df_ab = pd.merge(df_a[['name_x']],df_b,on='name_x')\n",
    "    \n",
    "    total_df = df_ab[['name_x', 'code', 'close_x', 'close_y', 'ma60_x', 'ma60_y', 'ma120_x', 'ma120_y', 'price_x', 'price_y', 'date_x','volume_z', 'price_diff']]\n",
    "    total_df.to_excel(path_total+strdate+'.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  전종목 검색하여  종가 > ma120  일일 비교  하여  관심 종목 추출_9  total_a(1년분) ,total_b(11년분) 추출 및  공통종목을 추출\n",
    "\n",
    "from mod1 import *\n",
    "#import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "#from pandas.core.common import SettingWithCopyWarning\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
    "\n",
    "path = 'd:\\\\stockdata\\\\close_ma120\\\\close_ma120_'\n",
    "path_total = 'd:\\\\stockdata\\\\close_ma120\\\\total_'\n",
    "path_total_f = 'd:\\\\stockdata\\\\close_ma120\\\\total_filter_'\n",
    "path_total_a = 'd:\\\\stockdata\\\\close_ma120\\\\total_a_'\n",
    "path_total_b = 'd:\\\\stockdata\\\\close_ma120\\\\total_b_'\n",
    "path_total_c = 'd:\\\\stockdata\\\\close_ma120\\\\total_c_'\n",
    "\n",
    "\n",
    "df = all_stock('2019-10-10')\n",
    "df = df['Name']\n",
    "name = df.to_list()\n",
    "    \n",
    "select_start_a = '2019-01-01'\n",
    "select_start_b = '2008-01-01'\n",
    "\n",
    "select_query = \"select * from market where Name='hrs' and Date >= '2019-10-01' \"\n",
    "df3 = pd.read_sql(select_query, engine)\n",
    "\n",
    "df3 = df3['Date']\n",
    "datelist = df3.to_list()\n",
    "    \n",
    "def search_stock(name,select_start):   \n",
    "    print(name)\n",
    "    print(select_start)\n",
    "    pure_df = pd.DataFrame()\n",
    "    df2 = pd.DataFrame() \n",
    "    for i in name:\n",
    "        #print(i)\n",
    "        df=select_stock(i,select_start)\n",
    "        #print(df)\n",
    "        pure_df = pure_df.append(df)\n",
    "        ma(df)\n",
    "\n",
    "        source = MinMaxScaler()\n",
    "        data = source.fit_transform(df[['close','ma60','ma120','volume']].values)\n",
    "        df1 = pd.DataFrame(data)\n",
    "        df1['name']=i\n",
    "        df1.columns=['close','ma60','ma120','volume','name']\n",
    "        df1[['date','code']] = df[['date','code']]\n",
    "        #print(df1)\n",
    "        df2 = df2.append(df1)\n",
    "\n",
    "    pure_df.columns = map(str.lower, pure_df.columns) ## \n",
    "\n",
    "    last_df = df2.loc[df2['date'] == datelist[-1]]\n",
    "    last_close_df = last_df[last_df['close'] < 0.1]\n",
    "    last_ma_df = last_df[last_df['ma120'] < 0.1]\n",
    "    a_df = last_ma_df[last_ma_df['close'] > last_ma_df['ma60']] \n",
    "    last_ma_df = a_df[a_df['ma60'] > a_df['ma120']]\n",
    "    last_price_df = pure_df.loc[pure_df['date'] == datelist[-1]]\n",
    "    \n",
    "    for i in datelist:\n",
    "        first_df = df2.loc[df2['date'] == i]\n",
    "        first_price_df = pure_df.loc[pure_df['date'] == i]\n",
    "        one_close_df = pd.merge(first_df,last_close_df,on='code')\n",
    "        one_df = pd.merge(first_df,last_ma_df,on='code')\n",
    "        reset_close_df = last_close_df.reset_index()\n",
    "        reset_ma_df = last_ma_df.reset_index()\n",
    "        one_close_df['code']= reset_close_df['code']\n",
    "        one_df['code']= reset_ma_df['code']\n",
    "        close_df = pd.merge(first_price_df[['close','code']],one_close_df,on='code')\n",
    "        ma_df = pd.merge(first_price_df[['close','code']],one_df,on='code')        \n",
    "        two_close_df = pd.merge(last_price_df[['close','code','volume']],close_df,on='code')\n",
    "        two_df = pd.merge(last_price_df[['close','code','volume']],ma_df,on='code')\n",
    "        two_close_df.columns= ['price_y','code', 'volume_z','price_x', 'close_x', 'ma60_x', 'ma120_x', 'volume_x','name_x', 'date_x', 'close_y', 'ma60_y', 'ma120_y', 'volume_y','name_y', 'date_y']\n",
    "        two_df.columns= ['price_y','code', 'volume_z','price_x', 'close_x', 'ma60_x', 'ma120_x', 'volume_x','name_x', 'date_x', 'close_y', 'ma60_y', 'ma120_y', 'volume_y','name_y', 'date_y']\n",
    "\n",
    "        price_df = two_close_df[['name_x','code','close_x','close_y','ma60_x','ma60_y','ma120_x','ma120_y','price_x','price_y','date_x','volume_z']]\n",
    "        ma120_df = two_df[['name_x','code','close_x','close_y','ma60_x','ma60_y','ma120_x','ma120_y','price_x','price_y','date_x','volume_z']]\n",
    "        price_df['price_diff']=price_df['price_y']/price_df['price_x']\n",
    "        ma120_df['price_diff']=ma120_df['price_y']/ma120_df['price_x']\n",
    "        price_df =  price_df.sort_values([\"price_diff\"],ascending=True)\n",
    "        ma120_df =  ma120_df.sort_values([\"price_diff\"],ascending=True)\n",
    "        second_df =  first_df.sort_values([\"ma120\"],ascending=True)\n",
    "        #ma120_df['price_x']=first_price_df['close'].values\n",
    "        #ma120_df['price_y']=last_price_df['close'].values\n",
    "        strdate = i.strftime('%Y-%m-%d')\n",
    "       \n",
    "        if select_start == select_start_a:\n",
    "            ma120_df.to_excel(path_total_a+strdate+'.xlsx')\n",
    "            price_df.to_excel(path_total_c+strdate+'.xlsx')\n",
    "        else:\n",
    "            ma120_df.to_excel(path_total_b+strdate+'.xlsx')\n",
    "            second_df.to_excel(path+strdate+'.xlsx')\n",
    "            \n",
    "def total_ab_intersection( ):\n",
    "    for i in datelist:\n",
    "        strdate = i.strftime('%Y-%m-%d')\n",
    "        df_a = pd.read_excel(path_total_a+strdate+'.xlsx')\n",
    "        filter_df_a = df_a[df_a['close_y'] < 0.2]\n",
    "        df_b = pd.read_excel(path_total_b+strdate+'.xlsx')\n",
    "        #df_ab = pd.DataFrame()\n",
    "        df_ab = pd.merge(df_a[['name_x']],df_b,on='name_x')\n",
    "        filter_df_ab = pd.merge(filter_df_a[['name_x']],df_b,on='name_x')\n",
    "\n",
    "        total_df = df_ab[['name_x', 'code', 'close_x', 'close_y', 'ma60_x', 'ma60_y', 'ma120_x', 'ma120_y', 'price_x', 'price_y', 'date_x','volume_z', 'price_diff']]\n",
    "        filter_total_df = filter_df_ab[['name_x', 'code', 'close_x', 'close_y', 'ma60_x', 'ma60_y', 'ma120_x', 'ma120_y', 'price_x', 'price_y', 'date_x','volume_z', 'price_diff']]\n",
    "        total_df.to_excel(path_total+strdate+'.xlsx')\n",
    "        filter_total_df.to_excel(path_total_f+strdate+'.xlsx') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  전종목 검색하여  종가 > ma120  일일 비교  하여  관심 종목 추출_9  total_a(1년분) ,total_b(11년분) 추출 및  공통종목을 추출 another method\n",
    "\n",
    "from mod1 import *\n",
    "#import pandas as pd\n",
    "\n",
    "path = 'd:\\\\test\\\\close_ma120_'\n",
    "path_total = 'd:\\\\test\\\\total_'\n",
    "path_total_a = 'd:\\\\test\\\\total_a_'\n",
    "path_total_b = 'd:\\\\test\\\\total_b_'\n",
    "path_total_c = 'd:\\\\test\\\\total_c_'\n",
    "\n",
    "#df = all_stock('2019-10-10')\n",
    "#df = df['Name']\n",
    "#name = df.to_list()\n",
    "    \n",
    "name = ['HRS','디엔에프','푸드나무','화성밸브','미래생명자원','웹케시']\n",
    "\n",
    "select_start_a = '2019-01-01'\n",
    "select_start_b = '2008-01-01'\n",
    "\n",
    "select_query = \"select * from market where Name='hrs' and Date >= '2019-10-01' \"\n",
    "df3 = pd.read_sql(select_query, engine)\n",
    "\n",
    "df3 = df3['Date']\n",
    "datelist = df3.to_list()\n",
    "    \n",
    "def search_stock(name,select_start_a,select_start_b):   \n",
    "    #print(name)\n",
    "    #print(select_start)\n",
    "    pure_df_a = pd.DataFrame()\n",
    "    df2_a = pd.DataFrame() \n",
    "    pure_df_b = pd.DataFrame()\n",
    "    df2_b = pd.DataFrame() \n",
    "    for i in name:\n",
    "        #print(i)\n",
    "        df_a=select_stock(i,select_start_a)\n",
    "        df_b=select_stock(i,select_start_b)\n",
    "        #print(df)\n",
    "        pure_df_a = pure_df_a.append(df_a)\n",
    "        pure_df_b = pure_df_b.append(df_b)\n",
    "        ma(df_a)\n",
    "        ma(df_b)\n",
    "\n",
    "        source = MinMaxScaler()\n",
    "        data_a = source.fit_transform(df_a[['close','ma60','ma120','volume']].values)\n",
    "        data_b = source.fit_transform(df_b[['close','ma60','ma120','volume']].values)\n",
    "        df1_a = pd.DataFrame(data_a)\n",
    "        df1_b = pd.DataFrame(data_b)\n",
    "        df1_a['name']=i\n",
    "        df1_b['name']=i\n",
    "        df1_a.columns=['close','ma60','ma120','volume','name']\n",
    "        df1_b.columns=['close','ma60','ma120','volume','name']\n",
    "        df1_a[['date','code','price']] = df_a[['date','code','close']]\n",
    "        df1_b[['date','code','price']] = df_b[['date','code','close']]\n",
    "        df2_a = df2_a.append(df1_a)\n",
    "        df2_b = df2_b.append(df1_b)        \n",
    "        \n",
    "    pure_df_a.columns = map(str.lower, pure_df_a.columns) ## \n",
    "    pure_df_b.columns = map(str.lower, pure_df_a.columns) ##\n",
    "    \n",
    "    pure_df_a = pure_df_a[['name','close','volume','date']]\n",
    "    pure_df_b = pure_df_b[['name','close','volume','date']]\n",
    "        \n",
    "    choice_day = pd.Timestamp('2019-09-30 00:00:00')\n",
    "    c = df2_a[df2_a['date']>choice_day]\n",
    "    d = df2_b[df2_b['date']>choice_day]\n",
    "    e = pure_df_a[pure_df_a['date']>choice_day]\n",
    "    f = pure_df_b[pure_df_b['date']>choice_day]\n",
    "    \n",
    "    last_df_a = c.loc[c['date'] == datelist[-1]]\n",
    "    last_close_df_a = last_df_a[last_df_a['close'] < 0.1]\n",
    "    last_ma_df_a = last_df_a[last_df_a['ma120'] < 0.1]\n",
    "    a_df_a = last_ma_df_a[last_ma_df_a['close'] > last_ma_df_a['ma60']] \n",
    "    last_ma_df_a = a_df_a[a_df_a['ma60'] > a_df_a['ma120']]\n",
    "    last_price_df_a = e.loc[e['date'] == datelist[-1]]\n",
    "    last_price_df_a = last_price_df_a[['name','volume']]\n",
    "    last_ma_df_a  = pd.merge(last_ma_df_a,last_price_df_a,on='name')\n",
    "\n",
    "    last_df_b = d.loc[d['date'] == datelist[-1]]\n",
    "    last_close_df_b = last_df_b[last_df_b['close'] < 0.1]\n",
    "    last_ma_df_b = last_df_b[last_df_b['ma120'] < 0.1]\n",
    "    a_df_b = last_ma_df_b[last_ma_df_b['close'] > last_ma_df_b['ma60']] \n",
    "    last_ma_df_b = a_df_b[a_df_b['ma60'] > a_df_b['ma120']]\n",
    "    last_price_df_b = f.loc[f['date'] == datelist[-1]]\n",
    "    last_price_df_b = last_price_df_b[['name','volume']]\n",
    "    last_ma_df_b  = pd.merge(last_ma_df_b,last_price_df_b,on='name')\n",
    "    \n",
    "    g = last_ma_df_a\n",
    "    h = last_ma_df_b\n",
    "    \n",
    "    a = pd.merge(c,g, on='name')\n",
    "    b = pd.merge(d,h, on='name')\n",
    "    \n",
    "    a['price_diff']=a['price_y']/a['price_x']\n",
    "    b['price_diff']=b['price_y']/b['price_x']\n",
    "    #g['volume_z'] = last_price_df_a['volume']\n",
    "    a = a[['name','code_x','close_x','close_y','ma60_x','ma60_y','ma120_x','ma120_y','price_x','price_y','date_x','volume_y','price_diff']]\n",
    "    b = b[['name','code_x','close_x','close_y','ma60_x','ma60_y','ma120_x','ma120_y','price_x','price_y','date_x','volume_y','price_diff']]\n",
    "    \n",
    "    for i in datelist:\n",
    "        t = pd.Timestamp(i)\n",
    "        first_df = a.loc[a['date_x'] == t]             ##  표준화 dataframe \n",
    "        second_df = b.loc[b['date_x'] == t] \n",
    "        strdate = t.strftime('%Y-%m-%d')\n",
    "        first_df =  first_df.sort_values([\"price_diff\"],ascending=True)\n",
    "        second_df = second_df.sort_values([\"price_diff\"],ascending=True)\n",
    "        first_df.to_excel(path_total_a+strdate+'.xlsx')  ##  표준화 dataframe 중 ma120 < 0.1 and close > ma60 > ma120 (from 2019.01.01)\n",
    "        second_df.to_excel(path_total_b+strdate+'.xlsx')  ##  표준화 dataframe 중 ma120 < 0.1 and close > ma60 > ma120 (from 2008.01.01) \n",
    "        \n",
    "search_stock(name,select_start_a,select_start_b)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  샘플로 간략하게  검색하여  종가 > ma120  일일 비교  하여  관심 종목 추출_9  total_a(1년분) ,total_b(11년분) 추출 및  공통종목을 추출\n",
    "\n",
    "\n",
    "from mod1 import *\n",
    "#import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "#from pandas.core.common import SettingWithCopyWarning\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
    "\n",
    "path = 'd:\\\\test\\\\close_ma120_'\n",
    "path_total = 'd:\\\\test\\\\total_'\n",
    "path_total_a = 'd:\\\\test\\\\total_a_'\n",
    "path_total_b = 'd:\\\\test\\\\total_b_'\n",
    "path_total_c = 'd:\\\\test\\\\total_c_'\n",
    "path_total_f = 'd:\\\\test\\\\total_filter_'\n",
    "\n",
    "#df = all_stock('2019-10-10')\n",
    "#df = df['Name']\n",
    "#name = df.to_list()\n",
    "    \n",
    "name = ['hrs','디엔에프','푸드나무','화성밸브','미래생명자원','웹케시']\n",
    "\n",
    "select_start_a = '2019-01-01'\n",
    "select_start_b = '2008-01-01'\n",
    "\n",
    "select_query = \"select * from market where Name='hrs' and Date >= '2019-10-01' \"\n",
    "df3 = pd.read_sql(select_query, engine)\n",
    "\n",
    "df3 = df3['Date']\n",
    "datelist = df3.to_list()\n",
    "    \n",
    "def search_stock(name,select_start):   \n",
    "    print(name)\n",
    "    print(select_start)\n",
    "    pure_df = pd.DataFrame()\n",
    "    df2 = pd.DataFrame() \n",
    "    for i in name:\n",
    "        #print(i)\n",
    "        df=select_stock(i,select_start)\n",
    "        #print(df)\n",
    "        pure_df = pure_df.append(df)\n",
    "        ma(df)\n",
    "\n",
    "        source = MinMaxScaler()\n",
    "        data = source.fit_transform(df[['close','ma60','ma120','volume']].values)\n",
    "        df1 = pd.DataFrame(data)\n",
    "        df1['name']=i\n",
    "        df1.columns=['close','ma60','ma120','volume','name']\n",
    "        df1[['date','code']] = df[['date','code']]\n",
    "        #print(df1)\n",
    "        df2 = df2.append(df1)\n",
    "\n",
    "    pure_df.columns = map(str.lower, pure_df.columns) ## \n",
    "\n",
    "    last_df = df2.loc[df2['date'] == datelist[-1]]\n",
    "    last_close_df = last_df[last_df['close'] < 0.1]\n",
    "    last_ma_df = last_df[last_df['ma120'] < 0.1]\n",
    "    a_df = last_ma_df[last_ma_df['close'] > last_ma_df['ma60']] \n",
    "    last_ma_df = a_df[a_df['ma60'] > a_df['ma120']]\n",
    "    last_price_df = pure_df.loc[pure_df['date'] == datelist[-1]]\n",
    "    \n",
    "    for i in datelist:\n",
    "        first_df = df2.loc[df2['date'] == i]\n",
    "        first_price_df = pure_df.loc[pure_df['date'] == i]\n",
    "        one_close_df = pd.merge(first_df,last_close_df,on='code')\n",
    "        one_df = pd.merge(first_df,last_ma_df,on='code')\n",
    "        reset_close_df = last_close_df.reset_index()\n",
    "        reset_ma_df = last_ma_df.reset_index()\n",
    "        one_close_df['code']= reset_close_df['code']\n",
    "        one_df['code']= reset_ma_df['code']\n",
    "        close_df = pd.merge(first_price_df[['close','code']],one_close_df,on='code')\n",
    "        ma_df = pd.merge(first_price_df[['close','code']],one_df,on='code')        \n",
    "        two_close_df = pd.merge(last_price_df[['close','code','volume']],close_df,on='code')\n",
    "        two_df = pd.merge(last_price_df[['close','code','volume']],ma_df,on='code')\n",
    "        two_close_df.columns= ['price_y','code', 'volume_z','price_x', 'close_x', 'ma60_x', 'ma120_x', 'volume_x','name_x', 'date_x', 'close_y', 'ma60_y', 'ma120_y', 'volume_y','name_y', 'date_y']\n",
    "        two_df.columns= ['price_y','code', 'volume_z','price_x', 'close_x', 'ma60_x', 'ma120_x', 'volume_x','name_x', 'date_x', 'close_y', 'ma60_y', 'ma120_y', 'volume_y','name_y', 'date_y']\n",
    "\n",
    "        price_df = two_close_df[['name_x','code','close_x','close_y','ma60_x','ma60_y','ma120_x','ma120_y','price_x','price_y','date_x','volume_z']]\n",
    "        ma120_df = two_df[['name_x','code','close_x','close_y','ma60_x','ma60_y','ma120_x','ma120_y','price_x','price_y','date_x','volume_z']]\n",
    "        price_df['price_diff']=price_df['price_y']/price_df['price_x']\n",
    "        ma120_df['price_diff']=ma120_df['price_y']/ma120_df['price_x']\n",
    "        price_df =  price_df.sort_values([\"price_diff\"],ascending=True)\n",
    "        ma120_df =  ma120_df.sort_values([\"price_diff\"],ascending=True)\n",
    "        second_df =  first_df.sort_values([\"ma120\"],ascending=True)\n",
    "        #ma120_df['price_x']=first_price_df['close'].values\n",
    "        #ma120_df['price_y']=last_price_df['close'].values\n",
    "        strdate = i.strftime('%Y-%m-%d')\n",
    "       \n",
    "        if select_start == select_start_a:\n",
    "            ma120_df.to_excel(path_total_a+strdate+'.xlsx')\n",
    "            price_df.to_excel(path_total_c+strdate+'.xlsx')\n",
    "        else:\n",
    "            ma120_df.to_excel(path_total_b+strdate+'.xlsx')\n",
    "            second_df.to_excel(path+strdate+'.xlsx')\n",
    "\n",
    "def total_ab_intersection( ):\n",
    "    for i in datelist:\n",
    "        strdate = i.strftime('%Y-%m-%d')\n",
    "        df_a = pd.read_excel(path_total_a+strdate+'.xlsx')\n",
    "        filter_df_a = df_a[df_a['close_y'] < 0.2]\n",
    "        df_b = pd.read_excel(path_total_b+strdate+'.xlsx')\n",
    "        #df_ab = pd.DataFrame()\n",
    "        df_ab = pd.merge(df_a[['name_x']],df_b,on='name_x')\n",
    "        filter_df_ab = pd.merge(filter_df_a[['name_x']],df_b,on='name_x')\n",
    "\n",
    "        total_df = df_ab[['name_x', 'code', 'close_x', 'close_y', 'ma60_x', 'ma60_y', 'ma120_x', 'ma120_y', 'price_x', 'price_y', 'date_x','volume_z', 'price_diff']]\n",
    "        filter_total_df = filter_df_ab[['name_x', 'code', 'close_x', 'close_y', 'ma60_x', 'ma60_y', 'ma120_x', 'ma120_y', 'price_x', 'price_y', 'date_x','volume_z', 'price_diff']]\n",
    "        total_df.to_excel(path_total+strdate+'.xlsx')\n",
    "        filter_total_df.to_excel(path_total_f+strdate+'.xlsx') \n",
    "            \n",
    "            \n",
    "#search_stock(name,select_start_b)\n",
    "total_ab_intersection( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##  관심종목에서 종가 비교하기\n",
    "\n",
    "from mod1 import *\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "\n",
    "path = 'd:\\\\stockdata\\\\close_ma120\\\\close_ma120_'\n",
    "\n",
    "back_date=1\n",
    "choice_date='2019-10-18'\n",
    "\n",
    "df = pd.read_excel(path+choice_date+'.xlsx')\n",
    "df = df['name']\n",
    "name = df.to_list()\n",
    "\n",
    "df1 = pd.DataFrame()\n",
    "diff_df = pd.DataFrame()\n",
    "for i in name:\n",
    "    #print(i)\n",
    "    df=select_stock(i,'2019-01-01')\n",
    "    df1 = df1.append(df)\n",
    "\n",
    "last = len(df1[df1['Name'] == name[0]])-1\n",
    "price_startday_df = df1[df1.index == (last-back_date)]\n",
    "price_today_df = df1[df1.index == last]\n",
    "\n",
    "diff_df = pd.merge(price_startday_df[['Name','Close']],price_today_df[['Name','Close']],on='Name')\n",
    "diff_df.columns=['name','price_startday','price_today']\n",
    "diff_df['diff']=diff_df['price_today']/diff_df['price_startday']\n",
    "\n",
    "price_up = diff_df[diff_df['diff'] > 1]\n",
    "price_down = diff_df[diff_df['diff'] < 1]\n",
    "price_sum=len(price_up)+len(price_down)\n",
    "print('price_up = {}'.format(len(price_up)))\n",
    "print('price_down = {}'.format(len(price_down)))\n",
    "    \n",
    "print('win_rate={}%'.format((len(price_up)/price_sum)*100))\n",
    "\n",
    "display((price_up.sort_values([\"diff\"],ascending=False).head(10)))\n",
    "display(price_down.sort_values(['diff']).head(10))\n",
    "display(diff_df.describe())\n",
    "\n",
    "#sort_df = diff_df.sort_values([\"diff\"],ascending=False)  ##  상승, 하락 을  순서별로 정렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mod1 import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "\n",
    "path = 'd:\\\\stockdata\\\\close_ma120\\\\close_ma120_'\n",
    "path_total = 'd:\\\\stockdata\\\\close_ma120\\\\total_'\n",
    "\n",
    "df = all_stock('2019-10-10')\n",
    "df = df['Name']\n",
    "name = df.to_list()\n",
    "\n",
    "pure_df = pd.DataFrame()\n",
    "df2 = pd.DataFrame()\n",
    "for i in name:\n",
    "    #print(i)\n",
    "    df=select_stock(i,'2008-01-01')\n",
    "    pure_df = pure_df.append(df)\n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close','ma60','ma120','volume']].values)\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1['name']=i\n",
    "    df1.columns=['close','ma60','ma120','volume','name']\n",
    "    df1[['date','code']] = df[['date','code']]\n",
    "    #print(df1)\n",
    "    df2 = df2.append(df1)\n",
    "\n",
    "pure_df.columns = map(str.lower, pure_df.columns) ## \n",
    " \n",
    "select_query = \"select * from market where Name='hrs' and Date >= '2019-10-01' and Date < '2019-11-01' \"\n",
    "df3 = pd.read_sql(select_query, engine)\n",
    "\n",
    "df3 = df3['Date']\n",
    "datelist = df3.to_list()\n",
    "\n",
    "last_df = df2.loc[df2['date'] == datelist[-1]]\n",
    "last_df = last_df[last_df['ma120'] < 0.1]\n",
    "last_price_df = pure_df.loc[pure_df['date'] == datelist[-1]]\n",
    "\n",
    "for i in datelist:\n",
    "    first_df = df2.loc[df2['date'] == i]\n",
    "    first_price_df = pure_df.loc[pure_df['date'] == i]\n",
    "    one_df = pd.merge(first_df,last_df,on='code')\n",
    "    reset_index_df = last_df.reset_index()\n",
    "    one_df['code']= reset_index_df['code']\n",
    "    ma_df = pd.merge(first_price_df[['close','code']],one_df,on='code')\n",
    "    two_df = pd.merge(last_price_df[['close','code']],ma_df,on='code')\n",
    "    two_df.columns= ['price_y','code', 'price_x', 'close_x', 'ma60_x', 'ma120_x', 'volume_x','name_x', 'date_x', 'close_y', 'ma60_y', 'ma120_y', 'volume_y','name_y', 'date_y']\n",
    "    ma120_df = two_df[['name_x','code','close_x','close_y','ma60_x','ma60_y','ma120_x','ma120_y','price_x','price_y','date_x']]\n",
    "    ma120_df['price_diff']=ma120_df['price_y']/ma120_df['price_x']\n",
    "    ma120_df =  ma120_df.sort_values([\"price_diff\"],ascending=False)\n",
    "    second_df =  first_df.sort_values([\"ma120\"],ascending=False)\n",
    "    #ma120_df['price_x']=first_price_df['close'].values\n",
    "    #ma120_df['price_y']=last_price_df['close'].values\n",
    "    strdate = i.strftime('%Y-%m-%d')\n",
    "    second_df.to_excel(path+strdate+'.xlsx')\n",
    "    ma120_df.to_excel(path_total+strdate+'.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  관심종목  ma120 일선 비교하기\n",
    "\n",
    "from mod1 import *\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "\n",
    "path = 'd:\\\\stockdata\\\\close_ma120\\\\close_ma120_'\n",
    "\n",
    "back_date=1\n",
    "choice_date='2019-10-25'\n",
    "\n",
    "df = pd.read_excel(path+choice_date+'.xlsx')\n",
    "df = df['name']\n",
    "name = df.to_list()\n",
    "\n",
    "df1 = pd.DataFrame()\n",
    "diff_df = pd.DataFrame()\n",
    "ma120_df2 = pd.DataFrame()\n",
    "for i in name:\n",
    "    #print(i)\n",
    "    df=select_stock(i,'2010-01-01')\n",
    "    df1 = df1.append(df)    \n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close','ma120','volume']].values)\n",
    "    ma120_df1 = pd.DataFrame(data)\n",
    "    ma120_df1['Name']=i\n",
    "    ma120_df1.columns=['close','ma120','volume','name',]\n",
    "    ma120_df1['date'] = df['date']\n",
    "    #print(df1)\n",
    "    ma120_df2 = ma120_df2.append(ma120_df1)\n",
    "    \n",
    "\n",
    "last = len(ma120_df2[ma120_df2['name'] == name[0]])-1\n",
    "startday_df = ma120_df2[ma120_df2.index == (last-back_date)]\n",
    "#yesterday_df = df2[df2.index == (last-1)]\n",
    "today_df = ma120_df2[ma120_df2.index == last]\n",
    "\n",
    "ma120_diff_df = pd.merge(startday_df[['name','ma120']],today_df[['name','ma120']],on='name')\n",
    "ma120_diff_df.columns=['name','startday','today']\n",
    "ma120_diff_df['diff']=ma120_diff_df['today']/ma120_diff_df['startday']\n",
    "\n",
    "ma120_up = ma120_diff_df[ma120_diff_df['diff'] > 1]\n",
    "ma120_down = ma120_diff_df[ma120_diff_df['diff'] < 1]\n",
    "ma120_sum=len(ma120_up)+len(ma120_down)\n",
    "print('ma120_up = {}'.format(len(ma120_up)))\n",
    "print('ma120_down = {}'.format(len(ma120_down)))\n",
    "    \n",
    "print('win_rate={}%'.format((len(ma120_up)/ma120_sum)*100))\n",
    "\n",
    "display((ma120_up.sort_values([\"diff\"],ascending=False).head(10)))\n",
    "display(ma120_down.sort_values(['diff']).head(10))\n",
    "display(ma120_diff_df.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  관심종목  종가, ma120 일선별로   상세히 비교 하기\n",
    "\n",
    "from mod1 import *\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "\n",
    "path = 'd:\\\\stockdata\\\\close_ma120\\\\close_ma120_'\n",
    "path_total = 'd:\\\\stockdata\\\\close_ma120\\\\total_'\n",
    "\n",
    "back_date=1\n",
    "choice_date='2019-10-25'\n",
    "\n",
    "df = pd.read_excel(path+choice_date+'.xlsx')\n",
    "df = df['name']\n",
    "name = df.to_list()\n",
    "\n",
    "df1 = pd.DataFrame()\n",
    "diff_df = pd.DataFrame()\n",
    "ma120_df2 = pd.DataFrame()\n",
    "for i in name:\n",
    "    #print(i)\n",
    "    df=select_stock(i,'2010-01-01')\n",
    "    df1 = df1.append(df)    \n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close','ma120','volume']].values)\n",
    "    ma120_df1 = pd.DataFrame(data)\n",
    "    ma120_df1['Name']=i\n",
    "    ma120_df1.columns=['close','ma120','volume','name',]\n",
    "    ma120_df1['date'] = df['date']\n",
    "    #print(df1)\n",
    "    ma120_df2 = ma120_df2.append(ma120_df1)\n",
    "    \n",
    "\n",
    "last = len(ma120_df2[ma120_df2['name'] == name[0]])-1\n",
    "ma120_startday_df = ma120_df2[ma120_df2.index == (last-back_date)]\n",
    "ma120_today_df = ma120_df2[ma120_df2.index == last]\n",
    "price_startday_df = df1[df1.index == (last-back_date)]\n",
    "price_today_df = df1[df1.index == last]\n",
    "\n",
    "ma120_diff_df = pd.merge(ma120_startday_df[['name','ma120']],ma120_today_df[['name','ma120']],on='name')\n",
    "ma120_diff_df.columns=['name','ma120_startday','ma120_today']\n",
    "ma120_diff_df['ma120_diff']=ma120_diff_df['ma120_today']/ma120_diff_df['ma120_startday']\n",
    "\n",
    "diff_df = pd.merge(price_startday_df[['Name','Close']],price_today_df[['Name','Close']],on='Name')\n",
    "diff_df.columns=['name','price_startday','price_today']\n",
    "diff_df['price_diff']=diff_df['price_today']/diff_df['price_startday']\n",
    "\n",
    "ma120_up = ma120_diff_df[ma120_diff_df['ma120_diff'] > 1]\n",
    "ma120_down = ma120_diff_df[ma120_diff_df['ma120_diff'] < 1]\n",
    "ma120_sum=len(ma120_up)+len(ma120_down)\n",
    "\n",
    "price_up = diff_df[diff_df['price_diff'] > 1]\n",
    "price_down = diff_df[diff_df['price_diff'] < 1]\n",
    "price_sum=len(price_up)+len(price_down)\n",
    "\n",
    "print('ma120_up = {}'.format(len(ma120_up)))\n",
    "print('ma120_down = {}'.format(len(ma120_down)))\n",
    "    \n",
    "print('win_rate={}%'.format((len(ma120_up)/ma120_sum)*100))\n",
    "\n",
    "display((ma120_up.sort_values([\"ma120_diff\"],ascending=False).head(10)))\n",
    "display(ma120_down.sort_values(['ma120_diff']).head(10))\n",
    "display(ma120_diff_df.describe())\n",
    "\n",
    "print('price_up = {}'.format(len(price_up)))\n",
    "print('price_down = {}'.format(len(price_down)))\n",
    "    \n",
    "print('win_rate={}%'.format((len(price_up)/price_sum)*100))\n",
    "\n",
    "display((price_up.sort_values([\"price_diff\"],ascending=False).head(10)))\n",
    "display(price_down.sort_values(['price_diff']).head(10))\n",
    "display(diff_df.describe())\n",
    "\n",
    "total_df = pd.merge(ma120_diff_df,diff_df,on='name')\n",
    "total_df = total_df.sort_values([\"price_diff\"],ascending=False)\n",
    "total_df.to_excel(path_total+choice_date+'.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  관심종목  종가, ma120 일선별로 상세히 비교 하기 _ back_date 자동계산 및 Volume 추가\n",
    "\n",
    "from mod1 import *\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "\n",
    "path = 'd:\\\\stockdata\\\\close_ma120\\\\close_ma120_'\n",
    "path_total = 'd:\\\\stockdata\\\\close_ma120\\\\total_'\n",
    "\n",
    "choice_date='2019-10-11'\n",
    "select_query = \"select count(*) from market_good where Name='hrs' and Date > \"\n",
    "var = select_query +\"'\"+choice_date+\"'\" \n",
    "df = pd.read_sql(var, engine)\n",
    "count = df.values.tolist()\n",
    "back_date = count[0][0]\n",
    "\n",
    "df = pd.read_excel(path+choice_date+'.xlsx')\n",
    "df = df['name']\n",
    "name = df.to_list()\n",
    "\n",
    "df1 = pd.DataFrame()\n",
    "diff_df = pd.DataFrame()\n",
    "ma120_df2 = pd.DataFrame()\n",
    "for i in name:\n",
    "    #print(i)\n",
    "    df=select_stock(i,'2010-01-01')\n",
    "    df1 = df1.append(df)    \n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close','ma120','volume']].values)\n",
    "    ma120_df1 = pd.DataFrame(data)\n",
    "    ma120_df1['Name']=i\n",
    "    ma120_df1.columns=['close','ma120','volume','name',]\n",
    "    ma120_df1['date'] = df['date']\n",
    "    #print(df1)\n",
    "    ma120_df2 = ma120_df2.append(ma120_df1)\n",
    "    \n",
    "\n",
    "last = len(ma120_df2[ma120_df2['name'] == name[0]])-1\n",
    "ma120_startday_df = ma120_df2[ma120_df2.index == (last-back_date)]\n",
    "ma120_today_df = ma120_df2[ma120_df2.index == last]\n",
    "price_startday_df = df1[df1.index == (last-back_date)]\n",
    "price_today_df = df1[df1.index == last]\n",
    "\n",
    "ma120_diff_df = pd.merge(ma120_startday_df[['name','ma120']],ma120_today_df[['name','ma120']],on='name')\n",
    "ma120_diff_df.columns=['name','ma120_startday','ma120_today']\n",
    "ma120_diff_df['ma120_diff']=ma120_diff_df['ma120_today']/ma120_diff_df['ma120_startday']\n",
    "\n",
    "diff_df = pd.merge(price_startday_df[['Name','Close','Volume']],price_today_df[['Name','Close','Volume']],on='Name')\n",
    "diff_df.columns=['name','price_startday','volume_startday','price_today','volume_today']\n",
    "diff_df['price_diff']=diff_df['price_today']/diff_df['price_startday']\n",
    "\n",
    "ma120_up = ma120_diff_df[ma120_diff_df['ma120_diff'] > 1]\n",
    "ma120_down = ma120_diff_df[ma120_diff_df['ma120_diff'] < 1]\n",
    "ma120_sum=len(ma120_up)+len(ma120_down)\n",
    "\n",
    "price_up = diff_df[diff_df['price_diff'] > 1]\n",
    "price_down = diff_df[diff_df['price_diff'] < 1]\n",
    "price_sum=len(price_up)+len(price_down)\n",
    "\n",
    "print('ma120_up = {}'.format(len(ma120_up)))\n",
    "print('ma120_down = {}'.format(len(ma120_down)))\n",
    "    \n",
    "print('win_rate={}%'.format((len(ma120_up)/ma120_sum)*100))\n",
    "\n",
    "display((ma120_up.sort_values([\"ma120_diff\"],ascending=False).head(10)))\n",
    "display(ma120_down.sort_values(['ma120_diff']).head(10))\n",
    "display(ma120_diff_df.describe())\n",
    "\n",
    "print('price_up = {}'.format(len(price_up)))\n",
    "print('price_down = {}'.format(len(price_down)))\n",
    "    \n",
    "print('win_rate={}%'.format((len(price_up)/price_sum)*100))\n",
    "\n",
    "display((price_up.sort_values([\"price_diff\"],ascending=False).head(10)))\n",
    "display(price_down.sort_values(['price_diff']).head(10))\n",
    "display(diff_df.describe())\n",
    "\n",
    "total_df = pd.merge(ma120_diff_df,diff_df,on='name')\n",
    "total_df  = total_df[['name','ma120_startday','ma120_today','ma120_diff','price_startday','price_today','volume_startday','volume_today','price_diff']]\n",
    "total_df = total_df.sort_values([\"price_diff\"],ascending=False)\n",
    "total_df.to_excel(path_total+choice_date+'.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##  전종목  종가 > ma120  일일 비교 하여  종목 pick 하고 pick한 종목의  종가를  비교분석\n",
    "\n",
    "from mod1 import *\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "\n",
    "\n",
    "path = 'd:\\\\stockdata\\\\close_ma120\\\\close_ma120_'\n",
    "back_date=1\n",
    "choice_date='2019-10-11'\n",
    "\n",
    "all_df = all_stock(choice_date)\n",
    "all_name_df = all_df['Name']\n",
    "\n",
    "all_name = all_name_df.to_list()\n",
    "\n",
    "all_df2 = pd.DataFrame()\n",
    "for i in all_name:\n",
    "    #print(i)\n",
    "    all_df=select_stock(i,'2010-01-01')\n",
    "    ma(all_df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(all_df[['close','ma120','volume']].values)\n",
    "    all_df1 = pd.DataFrame(data)\n",
    "    all_df1['Name']=i\n",
    "    all_df1.columns=['close','ma120','volume','name',]\n",
    "    all_df1['date'] = all_df['date']\n",
    "    #print(df1)\n",
    "    all_df2 = all_df2.append(all_df1)\n",
    "    \n",
    "\n",
    "last = len(all_df2[all_df2['name'] == all_name[0]])-1\n",
    "all_today_df = all_df2[all_df2.index == last]\n",
    "\n",
    "ma120_df = all_today_df[all_today_df['close'] > all_today_df['ma120']]\n",
    "\n",
    "today = str(ma120_df.iloc[0,4])\n",
    "ma120_df.to_excel(path+today+'.xlsx', encoding='utf-8')\n",
    "\n",
    "pick_df = pd.read_excel(path+choice_date+'.xlsx')\n",
    "pick_df = pick_df['name']\n",
    "pick_name = pick_df.to_list()\n",
    "\n",
    "pick_df1 = pd.DataFrame()\n",
    "diff_df = pd.DataFrame()\n",
    "for i in pick_name:\n",
    "    #print(i)\n",
    "    pick_df=select_stock(i,'2019-01-01')\n",
    "    pick_df1 = pick_df1.append(pick_df)\n",
    "\n",
    "last = len(pick_df1[pick_df1['Name'] == pick_name[0]])-1\n",
    "startday_df = pick_df1[pick_df1.index == (last-back_date)]\n",
    "today_df = pick_df1[pick_df1.index == last]\n",
    "\n",
    "diff_df = pd.merge(startday_df[['Name','Close']],today_df[['Name','Close']],on='Name')\n",
    "diff_df.columns=['name','startday','today']\n",
    "diff_df['diff']=diff_df['today']/diff_df['startday']\n",
    "\n",
    "up = diff_df[diff_df['diff'] > 1]\n",
    "down = diff_df[diff_df['diff'] < 1]\n",
    "sum=len(up)+len(down)\n",
    "print('up = {}'.format(len(up)))\n",
    "print('down = {}'.format(len(down)))\n",
    "    \n",
    "print('win_rate={}%'.format((len(up)/sum)*100))\n",
    "\n",
    "display((up.sort_values([\"diff\"],ascending=False).head(10)))\n",
    "display(down.sort_values(['diff']).head(10))\n",
    "display(diff_df.describe())\n",
    "\n",
    "#kk = datetime.now()-datetime(2019,10,13)\n",
    "#print(kk.days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##  전종목  종가, ma120 일선 비교하기\n",
    "\n",
    "from mod1 import *\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "\n",
    "path = 'd:\\\\stockdata\\\\close_ma120\\\\close_ma120_'\n",
    "path_total = 'd:\\\\stockdata\\\\close_ma120\\\\all_'\n",
    "\n",
    "back_date=5\n",
    "choice_date='2019-10-11'\n",
    "\n",
    "df = all_stock(choice_date)\n",
    "#df.columns=['date', 'code', 'name', 'open', 'high', 'low', 'volume', 'close']\n",
    "df.columns = map(str.lower, df.columns)\n",
    "df = df['name']\n",
    "name = df.to_list()\n",
    "\n",
    "df1 = pd.DataFrame()\n",
    "diff_df = pd.DataFrame()\n",
    "ma120_df2 = pd.DataFrame()\n",
    "for i in name:\n",
    "    #print(i)\n",
    "    df=select_stock(i,'2010-01-01')\n",
    "    df1 = df1.append(df)    \n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close','ma120','volume']].values)\n",
    "    ma120_df1 = pd.DataFrame(data)\n",
    "    ma120_df1['Name']=i\n",
    "    ma120_df1.columns=['close','ma120','volume','name',]\n",
    "    ma120_df1['date'] = df['date']\n",
    "    #print(df1)\n",
    "    ma120_df2 = ma120_df2.append(ma120_df1)\n",
    "    \n",
    "ma120_df2['event_date'] = pd.to_datetime(ma120_df2['date'])\n",
    "df1['event_date'] = pd.to_datetime(df1['Date'])\n",
    "day = str((datetime.now()-timedelta(3)).date())\n",
    "da = str((datetime.now()-timedelta(2)).date())\n",
    "ma120_startday_df = ma120_df2.loc[ma120_df2['event_date'] == day]\n",
    "ma120_today_df = ma120_df2.loc[ma120_df2['event_date'] == da]\n",
    "price_startday_df = df1.loc[df1['event_date'] == day]\n",
    "price_today_df = df1.loc[df1['event_date'] == da]\n",
    "\n",
    "ma120_diff_df = pd.merge(ma120_startday_df[['name','ma120']],ma120_today_df[['name','ma120']],on='name')\n",
    "ma120_diff_df.columns=['name','ma120_startday','ma120_today']\n",
    "ma120_diff_df['ma120_diff']=ma120_diff_df['ma120_today']/ma120_diff_df['ma120_startday']\n",
    "\n",
    "diff_df = pd.merge(price_startday_df[['Name','Close']],price_today_df[['Name','Close']],on='Name')\n",
    "diff_df.columns=['name','price_startday','price_today']\n",
    "diff_df['price_diff']=diff_df['price_today']/diff_df['price_startday']\n",
    "\n",
    "ma120_up = ma120_diff_df[ma120_diff_df['ma120_diff'] > 1]\n",
    "ma120_down = ma120_diff_df[ma120_diff_df['ma120_diff'] < 1]\n",
    "ma120_sum=len(ma120_up)+len(ma120_down)\n",
    "\n",
    "price_up = diff_df[diff_df['price_diff'] > 1]\n",
    "price_down = diff_df[diff_df['price_diff'] < 1]\n",
    "price_sum=len(price_up)+len(price_down)\n",
    "\n",
    "print('ma120_up = {}'.format(len(ma120_up)))\n",
    "print('ma120_down = {}'.format(len(ma120_down)))\n",
    "    \n",
    "print('win_rate={}%'.format((len(ma120_up)/ma120_sum)*100))\n",
    "\n",
    "display((ma120_up.sort_values([\"ma120_diff\"],ascending=False).head(10)))\n",
    "display(ma120_down.sort_values(['ma120_diff']).head(10))\n",
    "display(ma120_diff_df.describe())\n",
    "\n",
    "print('price_up = {}'.format(len(price_up)))\n",
    "print('price_down = {}'.format(len(price_down)))\n",
    "    \n",
    "print('win_rate={}%'.format((len(price_up)/price_sum)*100))\n",
    "\n",
    "display((price_up.sort_values([\"price_diff\"],ascending=False).head(10)))\n",
    "display(price_down.sort_values(['price_diff']).head(10))\n",
    "display(diff_df.describe())\n",
    "\n",
    "total_df = pd.merge(ma120_diff_df,diff_df,on='name')\n",
    "total_df = total_df.sort_values([\"price_diff\"],ascending=False)\n",
    "total_df.to_excel(path_total+choice_date+'.xlsx')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###  관심종목 ma60, ma120, cci 그래프 생성\n",
    "\n",
    "from mod1 import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "\n",
    "def close_ma(df,select1,select2,select3):\n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close',select1,select2,select3]].values)\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1.columns=['close',select1,select2,select3]\n",
    "    df1 = df1.set_index(df['date'])\n",
    "    df1.plot(figsize=(16,4))\n",
    "    plt.title(df['name'][0])\n",
    "    plt.show()\n",
    "\n",
    "path = 'd:\\\\stockdata\\\\close_ma120\\\\close_ma120_'\n",
    "path_total = 'd:\\\\stockdata\\\\close_ma120\\\\total_'\n",
    "\n",
    "choice_date = '2019-10-01'\n",
    "df = pd.read_excel(path_total+choice_date+'.xlsx')\n",
    "df = df['name']\n",
    "name = df.to_list()\n",
    "\n",
    "#name=['hrs','손오공']\n",
    "\n",
    "pure_df = pd.DataFrame()\n",
    "df2 = pd.DataFrame()\n",
    "cci_df = pd.DataFrame()\n",
    "for i in name:\n",
    "    #print(i)\n",
    "    df=select_stock(i,'2010-01-01')\n",
    "    cci_df[['open','high','low','volume','close']] = df[['Open','High','Low','Volume','Close']].astype(float) #  TA-Lib로 평균을 구하려면 실수로 만들어야 함\n",
    "    period = 120\n",
    "    cci_df['cci'] = ta.CCI(cci_df, timeperiod=period)\n",
    "    df['cci'] = cci_df['cci']\n",
    "    close_ma(df,'cci','ma60','ma120')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
