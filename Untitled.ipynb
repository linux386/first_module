{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "5900*1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mod1 import *\n",
    "df = select_stock('부광약품','2018-01-01')\n",
    "df.columns=df.columns.str.lower()\n",
    "df[['open','high','low','volume','close']] = df[['open','high','low','volume','close']].astype(float) #  TA-Lib로 평균을 구하려면 실수로 만들어야 함\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['high','close']].plot(figsize=(12,6),grid=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tr'] = ta.TRANGE(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['atr2'] = df['tr'].rolling(10).mean()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mod1 import *\n",
    "df1 = select_stock('hrs','2018-01-01')\n",
    "df1.columns=df1.columns.str.lower()\n",
    "df1[['open','high','low','volume','close']] = df1[['open','high','low','volume','close']].astype(float) #  TA-Lib로 평균을 구하려면 실수로 만들어야 함\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['atr2'] = df1['volume'].rolling(10).mean()\n",
    "df1.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mod1 import * \n",
    "data = select_stock('부광약품','2018-01-01')\n",
    "\n",
    "\n",
    "PP = pd.Series((data['High'] + data['Low'] + data['Close']) / 3)  \n",
    "R1 = pd.Series(2 * PP - data['Low'])  \n",
    "S1 = pd.Series(2 * PP - data['High'])  \n",
    "R2 = pd.Series(PP + data['High'] - data['Low'])  \n",
    "S2 = pd.Series(PP - data['High'] + data['Low'])  \n",
    "R3 = pd.Series(data['High'] + 2 * (PP - data['Low']))  \n",
    "S3 = pd.Series(data['Low'] - 2 * (data['High'] - PP))  \n",
    "psr = {'PP':PP, 'R1':R1, 'S1':S1, 'R2':R2, 'S2':S2, 'R3':R3, 'S3':S3}  \n",
    "PSR = pd.DataFrame(psr)  \n",
    "data= data.join(PSR)  \n",
    "\n",
    "# plot the data\n",
    "#pd.concat([data['Close'],PP,R1,S1,R2,S2,R3,S3],axis=1).plot(figsize=(12,9),grid=True)\n",
    "pd.concat([data['Close'],PP],axis=1).plot(figsize=(12,6),grid=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mod1 import * \n",
    "data = select_stock('hrs','2018-01-01')\n",
    "\n",
    "\n",
    "PP = pd.Series((data['High'] + data['Low'] + data['Close']) / 3)  \n",
    "R1 = pd.Series(2 * PP - data['Low'])  \n",
    "S1 = pd.Series(2 * PP - data['High'])  \n",
    "R2 = pd.Series(PP + data['High'] - data['Low'])  \n",
    "S2 = pd.Series(PP - data['High'] + data['Low'])  \n",
    "R3 = pd.Series(data['High'] + 2 * (PP - data['Low']))  \n",
    "S3 = pd.Series(data['Low'] - 2 * (data['High'] - PP))  \n",
    "psr = {'PP':PP, 'R1':R1, 'S1':S1, 'R2':R2, 'S2':S2, 'R3':R3, 'S3':S3}  \n",
    "PSR = pd.DataFrame(psr)  \n",
    "data= data.join(PSR)  \n",
    "\n",
    "# plot the data\n",
    "pd.concat([data['Close'],PP,R1,S1,R2,S2,R3,S3],axis=1).plot(figsize=(12,9),grid=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  기간동안 낙폭 과대종목 검색\n",
    "\n",
    "from mod1 import *\n",
    "\n",
    "df_from = all_stock('2020-04-3')\n",
    "df_to = all_stock('2020-04-06')\n",
    "df_first=df_from[['Name','Close']]\n",
    "df_last=df_to[['Name','Close']]\n",
    "df = pd.merge(df_first,df_last,on='Name')\n",
    "\n",
    "df['diff']=df['Close_y']/df['Close_x']\n",
    "df.head()\n",
    "\n",
    "close_diff_df =  df.sort_values([\"diff\"],ascending=True)\n",
    "close_diff_df.head()\n",
    "\n",
    "close_diff_df.to_excel(\"d:\\\\b_1.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time : 18.12507677078247\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from  mod1 import *\n",
    "\n",
    "start = time.time()  # 시작 시간 저장\n",
    "\n",
    "def all_stock_period(date1, date2='2021-01-01'):\n",
    "    select_query = \"select * from market_good where Date >=  \"\n",
    "    var = select_query +\"'\"+date1+\"'\"  +\" \"+ 'and Date <=' + \"'\"+date2+\"'\"\n",
    "    df = pd.read_sql(var, engine)\n",
    "    return df\n",
    "\n",
    "\n",
    "df = all_stock_period('2020-02-20','2020-03-25')\n",
    "df_uniq = df['Name'].unique()\n",
    "df_uniq_list=df_uniq.tolist()\n",
    "\n",
    "min_data = []\n",
    "for x in df_uniq_list:\n",
    "    min_value = min(df[df['Name']== x ].Close)\n",
    "    min_data.append(min_value)\n",
    "\n",
    "min_close = pd.DataFrame(min_data)\n",
    "\n",
    "df_a=pd.DataFrame(df_uniq)\n",
    "\n",
    "\n",
    "df_first=pd.DataFrame()\n",
    "df_first['Name']=df_a[0]\n",
    "df_first['Close']=min_close[0]\n",
    "df_to = all_stock('2020-04-08')\n",
    "df_last=df_to[['Name','Close']]\n",
    "df = pd.merge(df_first,df_last,on='Name')\n",
    "\n",
    "df['diff']=df['Close_y']/df['Close_x']\n",
    "df.head()\n",
    "\n",
    "close_diff_df =  df.sort_values([\"diff\"],ascending=True)\n",
    "close_diff_df.head()\n",
    "\n",
    "close_diff_df.to_excel(\"d:\\\\b_1.xlsx\")\n",
    "print(\"time :\", time.time() - start)  # 현재시각 - 시작시간 = 실행 시간"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  mod1 import *\n",
    "\n",
    "def all_stock_period(date1, date2='2021-01-01'):\n",
    "    select_query = \"select * from market_good where Date >=  \"\n",
    "    var = select_query +\"'\"+date1+\"'\"  +\" \"+ 'and Date <=' + \"'\"+date2+\"'\"\n",
    "    df = pd.read_sql(var, engine)\n",
    "    return df\n",
    "\n",
    "\n",
    "df = all_stock_period('2020-02-20','2020-03-25')\n",
    "df_uniq = df['Name'].unique()\n",
    "df_uniq_list=df_uniq.tolist()\n",
    "\n",
    "min_data = []\n",
    "for x in df_uniq_list:\n",
    "    min_value = min(df[df['Name']== x ].Close)\n",
    "    min_data.append(min_value)\n",
    "\n",
    "min_close = pd.DataFrame(min_data)\n",
    "\n",
    "df_a=pd.DataFrame(df_uniq)\n",
    "\n",
    "\n",
    "df_first=pd.DataFrame()\n",
    "df_first['Name']=df_a[0]\n",
    "df_first['Close']=min_close[0]\n",
    "df_to = all_stock('2020-04-07')\n",
    "df_last=df_to[['Name','Close']]\n",
    "df = pd.merge(df_first,df_last,on='Name')\n",
    "\n",
    "df['diff']=df['Close_y']/df['Close_x']\n",
    "df.head()\n",
    "\n",
    "close_diff_df =  df.sort_values([\"diff\"],ascending=True)\n",
    "close_diff_df.head()\n",
    "\n",
    "close_diff_df.to_excel(\"d:\\\\b_1.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Lengths must match to compare",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-71-55b3f422b0ba>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmin_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mmin_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Code'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mClose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mmin_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmin_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\ops\\common.py\u001b[0m in \u001b[0;36mnew_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[0mother\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mitem_from_zerodim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnew_method\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\ops\\__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    524\u001b[0m         \u001b[0mrvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextract_numpy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    525\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 526\u001b[1;33m         \u001b[0mres_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcomparison_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    527\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    528\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_construct_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mres_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py\u001b[0m in \u001b[0;36mcomparison_op\u001b[1;34m(left, right, op)\u001b[0m\n\u001b[0;32m    232\u001b[0m         \u001b[1;31m#  The ambiguous case is object-dtype.  See GH#27803\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 234\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Lengths must match to compare\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mshould_extension_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Lengths must match to compare"
     ]
    }
   ],
   "source": [
    "min_data = []\n",
    "for x in code:\n",
    "    min_value = min(df[df['Code']== x ].Close)\n",
    "    min_data.append(min_value)\n",
    "\n",
    "a['min'] = pd.DataFrame(min_data)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Code</th>\n",
       "      <th>Name</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-02-20</td>\n",
       "      <td>060310</td>\n",
       "      <td>3S</td>\n",
       "      <td>2865</td>\n",
       "      <td>2885</td>\n",
       "      <td>2790</td>\n",
       "      <td>129466</td>\n",
       "      <td>2865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-02-21</td>\n",
       "      <td>060310</td>\n",
       "      <td>3S</td>\n",
       "      <td>2810</td>\n",
       "      <td>2845</td>\n",
       "      <td>2720</td>\n",
       "      <td>172500</td>\n",
       "      <td>2730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-02-24</td>\n",
       "      <td>060310</td>\n",
       "      <td>3S</td>\n",
       "      <td>2675</td>\n",
       "      <td>2715</td>\n",
       "      <td>2565</td>\n",
       "      <td>133815</td>\n",
       "      <td>2570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-02-25</td>\n",
       "      <td>060310</td>\n",
       "      <td>3S</td>\n",
       "      <td>2590</td>\n",
       "      <td>2750</td>\n",
       "      <td>2575</td>\n",
       "      <td>103511</td>\n",
       "      <td>2740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-02-26</td>\n",
       "      <td>060310</td>\n",
       "      <td>3S</td>\n",
       "      <td>2710</td>\n",
       "      <td>2710</td>\n",
       "      <td>2625</td>\n",
       "      <td>130369</td>\n",
       "      <td>2645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36688</th>\n",
       "      <td>2020-03-09</td>\n",
       "      <td>238490</td>\n",
       "      <td>힘스</td>\n",
       "      <td>19700</td>\n",
       "      <td>20100</td>\n",
       "      <td>18800</td>\n",
       "      <td>68279</td>\n",
       "      <td>19250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36689</th>\n",
       "      <td>2020-03-10</td>\n",
       "      <td>238490</td>\n",
       "      <td>힘스</td>\n",
       "      <td>19100</td>\n",
       "      <td>19500</td>\n",
       "      <td>17900</td>\n",
       "      <td>86842</td>\n",
       "      <td>19450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36690</th>\n",
       "      <td>2020-03-11</td>\n",
       "      <td>238490</td>\n",
       "      <td>힘스</td>\n",
       "      <td>19400</td>\n",
       "      <td>19650</td>\n",
       "      <td>17800</td>\n",
       "      <td>77272</td>\n",
       "      <td>18400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36691</th>\n",
       "      <td>2020-03-12</td>\n",
       "      <td>238490</td>\n",
       "      <td>힘스</td>\n",
       "      <td>17950</td>\n",
       "      <td>18500</td>\n",
       "      <td>16550</td>\n",
       "      <td>104135</td>\n",
       "      <td>16650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36692</th>\n",
       "      <td>2020-03-13</td>\n",
       "      <td>238490</td>\n",
       "      <td>힘스</td>\n",
       "      <td>14800</td>\n",
       "      <td>15800</td>\n",
       "      <td>13250</td>\n",
       "      <td>197648</td>\n",
       "      <td>14800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36693 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date    Code Name   Open   High    Low  Volume  Close\n",
       "0      2020-02-20  060310   3S   2865   2885   2790  129466   2865\n",
       "1      2020-02-21  060310   3S   2810   2845   2720  172500   2730\n",
       "2      2020-02-24  060310   3S   2675   2715   2565  133815   2570\n",
       "3      2020-02-25  060310   3S   2590   2750   2575  103511   2740\n",
       "4      2020-02-26  060310   3S   2710   2710   2625  130369   2645\n",
       "...           ...     ...  ...    ...    ...    ...     ...    ...\n",
       "36688  2020-03-09  238490   힘스  19700  20100  18800   68279  19250\n",
       "36689  2020-03-10  238490   힘스  19100  19500  17900   86842  19450\n",
       "36690  2020-03-11  238490   힘스  19400  19650  17800   77272  18400\n",
       "36691  2020-03-12  238490   힘스  17950  18500  16550  104135  16650\n",
       "36692  2020-03-13  238490   힘스  14800  15800  13250  197648  14800\n",
       "\n",
       "[36693 rows x 8 columns]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2212"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code = df['Code'].unique()\n",
    "len(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        060310\n",
       "1        095570\n",
       "2        068400\n",
       "3        006840\n",
       "4        054620\n",
       "          ...  \n",
       "14617       NaN\n",
       "14618       NaN\n",
       "14619       NaN\n",
       "14620       NaN\n",
       "14621       NaN\n",
       "Name: code, Length: 14622, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['code'] = pd.DataFrame(data = code)\n",
    "df['code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       060310\n",
       "1       095570\n",
       "2       068400\n",
       "3       006840\n",
       "4       054620\n",
       "         ...  \n",
       "2190    000547\n",
       "2191    000545\n",
       "2192    003280\n",
       "2193    037440\n",
       "2194    238490\n",
       "Name: code, Length: 2195, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = df['code'].dropna()\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_data = []\n",
    "for x in code:\n",
    "    min_value = min(df[df['Code']== x ].Close)\n",
    "    min_data.append(min_value)\n",
    "\n",
    "min_close = pd.DataFrame(min_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2190</th>\n",
       "      <td>19950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2191</th>\n",
       "      <td>5780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2192</th>\n",
       "      <td>328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2193</th>\n",
       "      <td>3945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2194</th>\n",
       "      <td>18750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2195 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0\n",
       "0      2390\n",
       "1      4090\n",
       "2      9550\n",
       "3     24050\n",
       "4      9600\n",
       "...     ...\n",
       "2190  19950\n",
       "2191   5780\n",
       "2192    328\n",
       "2193   3945\n",
       "2194  18750\n",
       "\n",
       "[2195 rows x 1 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>060310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>095570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>068400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>006840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>054620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2190</th>\n",
       "      <td>000547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2191</th>\n",
       "      <td>000545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2192</th>\n",
       "      <td>003280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2193</th>\n",
       "      <td>037440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2194</th>\n",
       "      <td>238490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2195 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        code\n",
       "0     060310\n",
       "1     095570\n",
       "2     068400\n",
       "3     006840\n",
       "4     054620\n",
       "...      ...\n",
       "2190  000547\n",
       "2191  000545\n",
       "2192  003280\n",
       "2193  037440\n",
       "2194  238490\n",
       "\n",
       "[2195 rows x 1 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "df['code']=a\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>060310</td>\n",
       "      <td>2390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>095570</td>\n",
       "      <td>4090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>068400</td>\n",
       "      <td>9550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>006840</td>\n",
       "      <td>24050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>054620</td>\n",
       "      <td>9600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2190</th>\n",
       "      <td>000547</td>\n",
       "      <td>19950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2191</th>\n",
       "      <td>000545</td>\n",
       "      <td>5780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2192</th>\n",
       "      <td>003280</td>\n",
       "      <td>328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2193</th>\n",
       "      <td>037440</td>\n",
       "      <td>3945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2194</th>\n",
       "      <td>238490</td>\n",
       "      <td>18750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2195 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        code    min\n",
       "0     060310   2390\n",
       "1     095570   4090\n",
       "2     068400   9550\n",
       "3     006840  24050\n",
       "4     054620   9600\n",
       "...      ...    ...\n",
       "2190  000547  19950\n",
       "2191  000545   5780\n",
       "2192  003280    328\n",
       "2193  037440   3945\n",
       "2194  238490  18750\n",
       "\n",
       "[2195 rows x 2 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['min']=min_close\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'min'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(df[df['Code']=='000547'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3S\n",
      "AJ네트웍스\n",
      "AJ렌터카\n",
      "AK홀딩스\n",
      "APS홀딩스\n",
      "AP시스템\n",
      "AP위성\n",
      "BGF\n",
      "BGF리테일\n",
      "BNK금융지주\n",
      "BYC\n",
      "BYC우\n",
      "CJ\n",
      "CJ CGV\n",
      "CJ ENM\n",
      "CJ대한통운\n",
      "CJ씨푸드\n",
      "CJ씨푸드1우\n",
      "CJ우\n",
      "CJ제일제당\n",
      "CJ제일제당 우\n",
      "CJ프레시웨이\n",
      "CJ헬로\n",
      "CMG제약\n",
      "CNH\n",
      "CS\n",
      "CS홀딩스\n",
      "DB\n",
      "DB금융스팩6호\n",
      "DB금융스팩7호\n",
      "DB금융투자\n",
      "DB손해보험\n",
      "DB하이텍\n",
      "DB하이텍1우\n",
      "DGB금융지주\n",
      "DI동일\n",
      "DMS\n",
      "DRB동일\n",
      "DSC인베스트먼트\n",
      "DSR\n",
      "DSR제강\n",
      "E1\n",
      "EDGC\n",
      "EG\n",
      "F&F\n",
      "GH신소재\n",
      "GKL\n",
      "GRT\n",
      "GS\n",
      "GST\n",
      "GS건설\n",
      "GS글로벌\n",
      "GS리테일\n",
      "GS우\n",
      "GS홈쇼핑\n",
      "GV\n",
      "HB테크놀러지\n",
      "HDC\n",
      "HDC아이콘트롤스\n",
      "HDC현대EP\n",
      "HDC현대산업개발\n",
      "HRS\n",
      "HSD엔진\n",
      "IBKS제10호스팩\n",
      "IBKS제11호스팩\n",
      "IBKS제12호스팩\n",
      "IBKS제6호스팩\n",
      "IBKS제7호스팩\n",
      "IHQ\n",
      "iMBC\n",
      "ISC\n",
      "ITX엠투엠\n",
      "JB금융지주\n",
      "JTC\n",
      "JW생명과학\n",
      "JW신약\n",
      "JW중외제약\n",
      "JW중외제약2우B\n",
      "JW중외제약우\n",
      "JW홀딩스\n",
      "JYP Ent.\n",
      "KBI메탈\n",
      "KB금융\n",
      "KB오토시스\n",
      "KCC\n",
      "KCC건설\n",
      "KCI\n",
      "KCTC\n",
      "KC그린홀딩스\n",
      "KC코트렐\n",
      "KEC\n",
      "KG ETS\n",
      "KG모빌리언스\n",
      "KG이니시스\n",
      "KG케미칼\n",
      "KH바텍\n",
      "KISCO홀딩스\n",
      "KMH\n",
      "KMH하이텍\n",
      "KNN\n",
      "KPX생명과학\n",
      "KPX케미칼\n",
      "KPX홀딩스\n",
      "KR모터스\n",
      "KSS해운\n",
      "KT\n",
      "KT&G\n",
      "KTB투자증권\n",
      "KTcs\n",
      "KTH\n",
      "KTis\n",
      "KT서브마린\n",
      "LF\n",
      "LG\n",
      "LG디스플레이\n",
      "LG상사\n",
      "LG생활건강\n",
      "LG생활건강우\n",
      "LG우\n",
      "LG유플러스\n",
      "LG이노텍\n",
      "LG전자\n",
      "LG전자우\n",
      "LG하우시스\n",
      "LG하우시스우\n",
      "LG화학\n",
      "LG화학우\n",
      "LIG넥스원\n",
      "LS\n",
      "LS네트웍스\n",
      "LS산전\n",
      "LS전선아시아\n",
      "MH에탄올\n",
      "MP한강\n",
      "NAVER\n",
      "NEW\n",
      "NE능률\n",
      "NHN\n",
      "NHN벅스\n",
      "NHN한국사이버결제\n",
      "NH투자증권\n",
      "NH투자증권우\n",
      "NH프라임리츠\n",
      "NICE\n",
      "NICE평가정보\n",
      "NI스틸\n",
      "NPC\n",
      "NPC우\n",
      "OCI\n",
      "PN풍년\n",
      "POSCO\n",
      "RFHIC\n",
      "S&K폴리텍\n",
      "S&TC\n",
      "S&T모티브\n",
      "S&T중공업\n",
      "S&T홀딩스\n",
      "S-Oil\n",
      "S-Oil우\n",
      "SBI인베스트먼트\n",
      "SBI핀테크솔루션즈\n",
      "SBS\n",
      "SBS미디어홀딩스\n",
      "SBS콘텐츠허브\n",
      "SCI평가정보\n",
      "SDN\n",
      "SFA반도체\n",
      "SG\n",
      "SG&G\n",
      "SGA\n",
      "SGA솔루션즈\n",
      "SG세계물산\n",
      "SG충방\n",
      "SH에너지화학\n",
      "SIMPAC\n",
      "SJM\n",
      "SJM홀딩스\n",
      "SK\n",
      "SK4호스팩\n",
      "SK5호스팩\n",
      "SKC\n",
      "SKC 솔믹스\n",
      "SKC코오롱PI\n",
      "SK가스\n",
      "SK네트웍스\n",
      "SK네트웍스우\n",
      "SK디스커버리\n",
      "SK디스커버리우\n",
      "SK디앤디\n",
      "SK머티리얼즈\n",
      "SK바이오랜드\n",
      "SK이노베이션\n",
      "SK이노베이션우\n",
      "SK증권\n",
      "SK증권우\n",
      "SK케미칼\n",
      "SK텔레콤\n",
      "SK하이닉스\n",
      "SM C&C\n",
      "SM Life Design\n",
      "SNK\n",
      "SPC삼립\n",
      "STX\n",
      "STX엔진\n",
      "STX중공업\n",
      "SV인베스트먼트\n",
      "TBH글로벌\n",
      "TCC스틸\n",
      "THE E&M\n",
      "THE MIDONG\n",
      "TJ미디어\n",
      "TPC\n",
      "TS인베스트먼트\n",
      "UCI\n",
      "WI\n",
      "WISCOM\n",
      "W홀딩컴퍼니\n",
      "YBM넷\n",
      "YG PLUS\n",
      "YTN\n",
      "YW\n",
      "가비아\n",
      "가온미디어\n",
      "가온전선\n",
      "강남제비스코\n",
      "강스템바이오텍\n",
      "강원랜드\n",
      "갤럭시아에스엠\n",
      "갤럭시아컴즈\n",
      "게임빌\n",
      "경남스틸\n",
      "경남제약\n",
      "경농\n",
      "경동나비엔\n",
      "경동도시가스\n",
      "경동인베스트\n",
      "경동제약\n",
      "경방\n",
      "경보제약\n",
      "경인양행\n",
      "경인전자\n",
      "경창산업\n",
      "계룡건설\n",
      "계양전기\n",
      "계양전기우\n",
      "고려개발\n",
      "고려산업\n",
      "고려시멘트\n",
      "고려신용정보\n",
      "고려아연\n",
      "고려제강\n",
      "고려제약\n",
      "고영\n",
      "골드퍼시픽\n",
      "골든센츄리\n",
      "골프존\n",
      "골프존뉴딘홀딩스\n",
      "광동제약\n",
      "광림\n",
      "광명전기\n",
      "광전자\n",
      "광주신세계\n",
      "광진실업\n",
      "광진윈텍\n",
      "교보7호스팩\n",
      "교보8호스팩\n",
      "교보9호스팩\n",
      "교보증권\n",
      "구영테크\n",
      "국도화학\n",
      "국동\n",
      "국보디자인\n",
      "국영지앤엠\n",
      "국일신동\n",
      "국일제지\n",
      "국제약품\n",
      "그리티\n",
      "그린케미칼\n",
      "그린플러스\n",
      "극동유화\n",
      "글로벌에스엠\n",
      "글로벌텍스프리\n",
      "글로본\n",
      "글로스퍼랩스\n",
      "금강공업\n",
      "금강공업우\n",
      "금강철강\n",
      "금비\n",
      "금양\n",
      "금호산업\n",
      "금호산업우\n",
      "금호석유\n",
      "금호석유우\n",
      "금호에이치티\n",
      "금호전기\n",
      "금호타이어\n",
      "금화피에스시\n",
      "기가레인\n",
      "기산텔레콤\n",
      "기신정기\n",
      "기아차\n",
      "기업은행\n",
      "까뮤이앤씨\n",
      "까스텔바작\n",
      "깨끗한나라\n",
      "깨끗한나라우\n",
      "나노\n",
      "나노메딕스\n",
      "나노브릭\n",
      "나노스\n",
      "나노신소재\n",
      "나노엔텍\n",
      "나노캠텍\n",
      "나라엠앤디\n",
      "나무가\n",
      "나무기술\n",
      "나스미디어\n",
      "나우IB\n",
      "나이벡\n",
      "나이스디앤비\n",
      "나이스정보통신\n",
      "나인컴플렉스\n",
      "남광토건\n",
      "남선알미늄\n",
      "남선알미우\n",
      "남성\n",
      "남양유업\n",
      "남양유업우\n",
      "남영비비안\n",
      "남해화학\n",
      "남화산업\n",
      "남화토건\n",
      "네스엠\n",
      "네오셈\n",
      "네오오토\n",
      "네오위즈\n",
      "네오위즈홀딩스\n",
      "네오크레마\n",
      "네오티스\n",
      "네오팜\n",
      "네오펙트\n",
      "네이블\n",
      "네이처셀\n",
      "네패스\n",
      "넥센\n",
      "넥센우\n",
      "넥센타이어\n",
      "넥센타이어1우B\n",
      "넥스턴\n",
      "넥스트BT\n",
      "넥스트사이언스\n",
      "넥스트아이\n",
      "넥슨지티\n",
      "넵튠\n",
      "넷게임즈\n",
      "넷마블\n",
      "노랑풍선\n",
      "노루페인트\n",
      "노루페인트우\n",
      "노루홀딩스\n",
      "노루홀딩스우\n",
      "노바렉스\n",
      "노바텍\n",
      "노터스\n",
      "녹십자\n",
      "녹십자랩셀\n",
      "녹십자셀\n",
      "녹십자엠에스\n",
      "녹십자웰빙\n",
      "녹십자홀딩스\n",
      "녹십자홀딩스2우\n",
      "농심\n",
      "농심홀딩스\n",
      "농우바이오\n",
      "누리텔레콤\n",
      "누리플랜\n",
      "뉴로스\n",
      "뉴보텍\n",
      "뉴인텍\n",
      "뉴지랩\n",
      "뉴트리\n",
      "뉴파워프라즈마\n",
      "뉴프라이드\n",
      "뉴프렉스\n",
      "다나와\n",
      "다날\n",
      "다믈멀티미디어\n",
      "다산네트웍스\n",
      "다스코\n",
      "다우기술\n",
      "다우데이타\n",
      "다원시스\n",
      "대교\n",
      "대교우B\n",
      "대구백화점\n",
      "대덕전자\n",
      "대동공업\n",
      "대동금속\n",
      "대동기어\n",
      "대동스틸\n",
      "대동전자\n",
      "대륙제관\n",
      "대림B&Co\n",
      "대림산업\n",
      "대림산업우\n",
      "대림씨엔에스\n",
      "대림제지\n",
      "대림통상\n",
      "대명코퍼레이션\n",
      "대모\n",
      "대보마그네틱\n",
      "대봉엘에스\n",
      "대상\n",
      "대상우\n",
      "대상홀딩스\n",
      "대상홀딩스우\n",
      "대성미생물\n",
      "대성산업\n",
      "대성에너지\n",
      "대성엘텍\n",
      "대성창투\n",
      "대성파인텍\n",
      "대성홀딩스\n",
      "대신밸런스제6호스팩\n",
      "대신밸런스제7호스팩\n",
      "대신정보통신\n",
      "대신증권\n",
      "대신증권2우B\n",
      "대신증권우\n",
      "대아티아이\n",
      "대양금속\n",
      "대양전기공업\n",
      "대양제지\n",
      "대영포장\n",
      "대우건설\n",
      "대우부품\n",
      "대우조선해양\n",
      "대웅\n",
      "대웅제약\n",
      "대원\n",
      "대원강업\n",
      "대원미디어\n",
      "대원산업\n",
      "대원전선\n",
      "대원전선우\n",
      "대원제약\n",
      "대원화성\n",
      "대유\n",
      "대유에이텍\n",
      "대유에이피\n",
      "대유플러스\n",
      "대정화금\n",
      "대주산업\n",
      "대주전자재료\n",
      "대창\n",
      "대창단조\n",
      "대창솔루션\n",
      "대창스틸\n",
      "대한과학\n",
      "대한광통신\n",
      "대한뉴팜\n",
      "대한방직\n",
      "대한약품\n",
      "대한유화\n",
      "대한전선\n",
      "대한제강\n",
      "대한제당\n",
      "대한제당3우B\n",
      "대한제당우\n",
      "대한제분\n",
      "대한항공\n",
      "대한항공우\n",
      "대한해운\n",
      "대한화섬\n",
      "대현\n",
      "대호에이엘\n",
      "대호피앤씨\n",
      "대호피앤씨우\n",
      "대화제약\n",
      "더블유게임즈\n",
      "더존비즈온\n",
      "덕산네오룩스\n",
      "덕산테코피아\n",
      "덕산하이메탈\n",
      "덕성\n",
      "덕성우\n",
      "덕신하우징\n",
      "덕양산업\n",
      "덕우전자\n",
      "데브시스터즈\n",
      "데이타솔루션\n",
      "데일리블록체인\n",
      "덱스터\n",
      "덴티움\n",
      "도이치모터스\n",
      "도화엔지니어링\n",
      "동구바이오제약\n",
      "동국S&C\n",
      "동국산업\n",
      "동국알앤에스\n",
      "동국제강\n",
      "동국제약\n",
      "동남합성\n",
      "동방\n",
      "동방선기\n",
      "동방아그로\n",
      "동부건설\n",
      "동부건설우\n",
      "동부스팩5호\n",
      "동부제철\n",
      "동부제철우\n",
      "동북아12호\n",
      "동북아13호\n",
      "동서\n",
      "동성제약\n",
      "동성코퍼레이션\n",
      "동성화인텍\n",
      "동성화학\n",
      "동신건설\n",
      "동아쏘시오홀딩스\n",
      "동아에스티\n",
      "동아엘텍\n",
      "동아지질\n",
      "동아타이어\n",
      "동아화성\n",
      "동양\n",
      "동양2우B\n",
      "동양3우B\n",
      "동양고속\n",
      "동양물산\n",
      "동양생명\n",
      "동양에스텍\n",
      "동양우\n",
      "동양이엔피\n",
      "동양철관\n",
      "동양파일\n",
      "동양피스톤\n",
      "동양피엔에프\n",
      "동우팜투테이블\n",
      "동운아나텍\n",
      "동원F&B\n",
      "동원개발\n",
      "동원금속\n",
      "동원산업\n",
      "동원수산\n",
      "동원시스템즈\n",
      "동원시스템즈우\n",
      "동일고무벨트\n",
      "동일금속\n",
      "동일기연\n",
      "동일산업\n",
      "동일제강\n",
      "동일철강\n",
      "동진쎄미켐\n",
      "동화기업\n",
      "동화약품\n",
      "두산\n",
      "두산2우B\n",
      "두산건설\n",
      "두산밥캣\n",
      "두산솔루스\n",
      "두산우\n",
      "두산인프라코어\n",
      "두산중공업\n",
      "두산퓨얼셀\n",
      "두올\n",
      "두올산업\n",
      "듀오백\n",
      "드래곤플라이\n",
      "드림시큐리티\n",
      "드림어스컴퍼니\n",
      "드림텍\n",
      "디딤\n",
      "디바이스이엔지\n",
      "디스플레이텍\n",
      "디씨엠\n",
      "디아이\n",
      "디아이씨\n",
      "디아이티\n",
      "디알젬\n",
      "디알텍\n",
      "디앤씨미디어\n",
      "디에스케이\n",
      "디에이치피코리아\n",
      "디에이테크놀로지\n",
      "디에이피\n",
      "디엔에이링크\n",
      "디엔에프\n",
      "디엠티\n",
      "디오\n",
      "디오스텍\n",
      "디와이\n",
      "디와이파워\n",
      "디이엔티\n",
      "디자인\n",
      "디젠스\n",
      "디지아이\n",
      "디지캡\n",
      "디지탈옵틱\n",
      "디지털대성\n",
      "디지틀조선\n",
      "디케이디앤아이\n",
      "디케이락\n",
      "디케이앤디\n",
      "디케이티\n",
      "디티알오토모티브\n",
      "디티앤씨\n",
      "디피씨\n",
      "딜리\n",
      "라닉스\n",
      "라온시큐어\n",
      "라온피플\n",
      "라이브플렉스\n",
      "라이온켐텍\n",
      "라파스\n",
      "락앤락\n",
      "램테크놀러지\n",
      "랩지노믹스\n",
      "러셀\n",
      "레고켐바이오\n",
      "레드캡투어\n",
      "레이\n",
      "레이언스\n",
      "로고스바이오\n",
      "로보로보\n",
      "로보스타\n",
      "로보티즈\n",
      "로스웰\n",
      "로지시스\n",
      "로체시스템즈\n",
      "롯데관광개발\n",
      "롯데리츠\n",
      "롯데손해보험\n",
      "롯데쇼핑\n",
      "롯데정밀화학\n",
      "롯데정보통신\n",
      "롯데제과\n",
      "롯데지주\n",
      "롯데칠성\n",
      "롯데칠성우\n",
      "롯데케미칼\n",
      "롯데푸드\n",
      "롯데하이마트\n",
      "루멘스\n",
      "루미마이크로\n",
      "루트로닉\n",
      "루트로닉3우C\n",
      "룽투코리아\n",
      "리노공업\n",
      "리노스\n",
      "리더스 기술투자\n",
      "리더스코스메틱\n",
      "리드코프\n",
      "리메드\n",
      "린드먼아시아\n",
      "링네트\n",
      "링크제니시스\n",
      "마니커\n",
      "마니커에프앤지\n",
      "마이크로디지탈\n",
      "마이크로컨텍솔\n",
      "마이크로텍\n",
      "마이크로프랜드\n",
      "마크로젠\n",
      "만도\n",
      "만호제강\n",
      "매일유업\n",
      "매일홀딩스\n",
      "매직마이크로\n",
      "매커스\n",
      "맥스로텍\n",
      "맥쿼리인프라\n",
      "맵스리얼티1\n",
      "머큐리\n",
      "멀티캠퍼스\n",
      "메가스터디\n",
      "메가스터디교육\n",
      "메가엠디\n",
      "메디아나\n",
      "메디톡스\n",
      "메디파트너생명공학\n",
      "메디포스트\n",
      "메디프론\n",
      "메리츠금융지주\n",
      "메리츠종금증권\n",
      "메리츠화재\n",
      "메이슨캐피탈\n",
      "메지온\n",
      "메카로\n",
      "메타랩스\n",
      "메타바이오메드\n",
      "멕아이씨에스\n",
      "멜파스\n",
      "명문제약\n",
      "명성티엔에스\n",
      "모나리자\n",
      "모나미\n",
      "모다이노칩\n",
      "모두투어\n",
      "모두투어리츠\n",
      "모바일리더\n",
      "모바일어플라이언스\n",
      "모베이스\n",
      "모베이스전자\n",
      "모비스\n",
      "모아텍\n",
      "모토닉\n",
      "모트렉스\n",
      "모헨즈\n",
      "무림P&P\n",
      "무림SP\n",
      "무림페이퍼\n",
      "무학\n",
      "문배철강\n",
      "미디어젠\n",
      "미래나노텍\n",
      "미래산업\n",
      "미래생명자원\n",
      "미래아이앤지\n",
      "미래에셋대우\n",
      "미래에셋대우스팩2호\n",
      "미래에셋대우스팩3호\n",
      "미래에셋대우스팩4호\n",
      "미래에셋대우우\n",
      "미래에셋벤처투자\n",
      "미래에셋생명\n",
      "미래컴퍼니\n",
      "미래테크놀로지\n",
      "미스터블루\n",
      "미원상사\n",
      "미원에스씨\n",
      "미원홀딩스\n",
      "미원화학\n",
      "미창석유\n",
      "미코\n",
      "미투온\n",
      "민앤지\n",
      "바다로19호\n",
      "바디텍메드\n",
      "바른손\n",
      "바른손이앤에이\n",
      "바른테크놀로지\n",
      "바이넥스\n",
      "바이오니아\n",
      "바이오로그디바이스\n",
      "바이오리더스\n",
      "바이오솔루션\n",
      "바이오스마트\n",
      "바이오제네틱스\n",
      "바이오톡스텍\n",
      "바이온\n",
      "바텍\n",
      "방림\n",
      "배럴\n",
      "백광산업\n",
      "백광소재\n",
      "백금T&A\n",
      "백산\n",
      "버추얼텍\n",
      "버킷스튜디오\n",
      "범양건영\n",
      "베뉴지\n",
      "베셀\n",
      "베스파\n",
      "베트남개발1\n",
      "벽산\n",
      "보광산업\n",
      "보라티알\n",
      "보락\n",
      "보령메디앙스\n",
      "보령제약\n",
      "보성파워텍\n",
      "보해양조\n",
      "본느\n",
      "부광약품\n",
      "부국증권\n",
      "부국증권우\n",
      "부국철강\n",
      "부방\n",
      "부산가스\n",
      "부산산업\n",
      "부산주공\n",
      "부스타\n",
      "뷰웍스\n",
      "브레인콘텐츠\n",
      "브리지텍\n",
      "브이원텍\n",
      "브이티지엠피\n",
      "블러썸엠앤씨\n",
      "블루콤\n",
      "비덴트\n",
      "비디아이\n",
      "비상교육\n",
      "비씨월드제약\n",
      "비아트론\n",
      "비에이치\n",
      "비에이치아이\n",
      "비엠티\n",
      "비즈니스온\n",
      "비츠로셀\n",
      "비츠로테크\n",
      "비트컴퓨터\n",
      "비티원\n",
      "비피도\n",
      "빅솔론\n",
      "빅텍\n",
      "빙그레\n",
      "빛샘전자\n",
      "사람인에이치알\n",
      "사조대림\n",
      "사조동아원\n",
      "사조산업\n",
      "사조씨푸드\n",
      "사조오양\n",
      "삼강엠앤티\n",
      "삼광글라스\n",
      "삼기오토모티브\n",
      "삼륭물산\n",
      "삼목에스폼\n",
      "삼보모터스\n",
      "삼보산업\n",
      "삼보판지\n",
      "삼본전자\n",
      "삼부토건\n",
      "삼성SDI\n",
      "삼성SDI우\n",
      "삼성공조\n",
      "삼성머스트스팩3호\n",
      "삼성물산\n",
      "삼성바이오로직스\n",
      "삼성생명\n",
      "삼성스팩2호\n",
      "삼성에스디에스\n",
      "삼성엔지니어링\n",
      "삼성전기\n",
      "삼성전기우\n",
      "삼성전자\n",
      "삼성전자우\n",
      "삼성제약\n",
      "삼성중공업\n",
      "삼성중공우\n",
      "삼성증권\n",
      "삼성출판사\n",
      "삼성카드\n",
      "삼성화재\n",
      "삼성화재우\n",
      "삼아알미늄\n",
      "삼아제약\n",
      "삼양사\n",
      "삼양사우\n",
      "삼양식품\n",
      "삼양옵틱스\n",
      "삼양통상\n",
      "삼양패키징\n",
      "삼양홀딩스\n",
      "삼양홀딩스우\n",
      "삼영무역\n",
      "삼영엠텍\n",
      "삼영이엔씨\n",
      "삼영전자\n",
      "삼영화학\n",
      "삼원강재\n",
      "삼원테크\n",
      "삼익THK\n",
      "삼익악기\n",
      "삼일\n",
      "삼일기업공사\n",
      "삼일제약\n",
      "삼정펄프\n",
      "삼지전자\n",
      "삼진\n",
      "삼진엘앤디\n",
      "삼진제약\n",
      "삼천당제약\n",
      "삼천리\n",
      "삼천리자전거\n",
      "삼표시멘트\n",
      "삼현철강\n",
      "삼호\n",
      "삼호개발\n",
      "삼화네트웍스\n",
      "삼화왕관\n",
      "삼화전기\n",
      "삼화전자\n",
      "삼화콘덴서\n",
      "삼화페인트\n",
      "상보\n",
      "상상인\n",
      "상상인이안1호스팩\n",
      "상상인이안제2호스팩\n",
      "상상인인더스트리\n",
      "상상인증권\n",
      "상신브레이크\n",
      "상신이디피\n",
      "상신전자\n",
      "상아프론테크\n",
      "상지카일룸\n",
      "새로닉스\n",
      "새론오토모티브\n",
      "샘표\n",
      "샘표식품\n",
      "서린바이오\n",
      "서부T&D\n",
      "서산\n",
      "서암기계공업\n",
      "서연\n",
      "서연이화\n",
      "서연탑메탈\n",
      "서울가스\n",
      "서울리거\n",
      "서울반도체\n",
      "서울식품\n",
      "서울식품우\n",
      "서울옥션\n",
      "서울전자통신\n",
      "서울제약\n",
      "서원\n",
      "서원인텍\n",
      "서전기전\n",
      "서진시스템\n",
      "서진오토모티브\n",
      "서플러스글로벌\n",
      "서한\n",
      "서호전기\n",
      "서흥\n",
      "서희건설\n",
      "선광\n",
      "선데이토즈\n",
      "선도전기\n",
      "선익시스템\n",
      "선진\n",
      "선창산업\n",
      "성광벤드\n",
      "성도이엔지\n",
      "성문전자\n",
      "성문전자우\n",
      "성보화학\n",
      "성신양회\n",
      "성신양회우\n",
      "성안\n",
      "성우전자\n",
      "성우테크론\n",
      "성우하이텍\n",
      "성창기업지주\n",
      "성창오토텍\n",
      "성호전자\n",
      "세경하이테크\n",
      "세기상사\n",
      "세동\n",
      "세명전기\n",
      "세미콘라이트\n",
      "세방\n",
      "세방우\n",
      "세방전지\n",
      "세보엠이씨\n",
      "세아베스틸\n",
      "세아제강\n",
      "세아제강지주\n",
      "세아특수강\n",
      "세아홀딩스\n",
      "세우글로벌\n",
      "세운메디칼\n",
      "세원\n",
      "세원셀론텍\n",
      "세원정공\n",
      "세이브존I&C\n",
      "세종공업\n",
      "세종메디칼\n",
      "세종텔레콤\n",
      "세중\n",
      "세진중공업\n",
      "세진티에스\n",
      "세코닉스\n",
      "세틀뱅크\n",
      "세하\n",
      "세화피앤씨\n",
      "센트랄모텍\n",
      "센트럴바이오\n",
      "셀리드\n",
      "셀리버리\n",
      "셀바스헬스케어\n",
      "셀트리온\n",
      "셀트리온제약\n",
      "셀트리온헬스케어\n",
      "소리바다\n",
      "소프트센\n",
      "소프트센우\n",
      "손오공\n",
      "솔루에타\n",
      "솔본\n",
      "솔브레인\n",
      "솔트웍스\n",
      "송원산업\n",
      "쇼박스\n",
      "수산아이앤티\n",
      "수산중공업\n",
      "수젠텍\n",
      "수출포장\n",
      "슈펙스비앤피\n",
      "슈프리마\n",
      "슈프리마아이디\n",
      "슈프리마에이치큐\n",
      "슈피겐코리아\n",
      "스맥\n",
      "스카이라이프\n",
      "스카이이앤엠\n",
      "스킨앤스킨\n",
      "스타플렉스\n",
      "스튜디오드래곤\n",
      "스페코\n",
      "승일\n",
      "시공테크\n",
      "시그네틱스\n",
      "시너지이노베이션\n",
      "시노펙스\n",
      "시디즈\n",
      "시스웍\n",
      "시큐브\n",
      "신대양제지\n",
      "신도리코\n",
      "신라교역\n",
      "신라섬유\n",
      "신라에스지\n",
      "신라젠\n",
      "신성델타테크\n",
      "신성이엔지\n",
      "신성통상\n",
      "신세계\n",
      "신세계 I&C\n",
      "신세계건설\n",
      "신세계인터내셔날\n",
      "신세계푸드\n",
      "신송홀딩스\n",
      "신신제약\n",
      "신영스팩4호\n",
      "신영스팩5호\n",
      "신영와코루\n",
      "신영증권\n",
      "신영증권우\n",
      "신원\n",
      "신원우\n",
      "신원종합개발\n",
      "신일산업\n",
      "신일제약\n",
      "신진에스엠\n",
      "신풍제약\n",
      "신풍제약우\n",
      "신풍제지\n",
      "신한알파리츠\n",
      "신한제4호스팩\n",
      "신한제5호스팩\n",
      "신한제6호스팩\n",
      "신한지주\n",
      "신화실업\n",
      "신화인터텍\n",
      "신화콘텍\n",
      "신흥\n",
      "신흥에스이씨\n",
      "실리콘웍스\n",
      "심텍\n",
      "심텍홀딩스\n",
      "싸이맥스\n",
      "싸이토젠\n",
      "쌍방울\n",
      "쌍용양회\n",
      "쌍용양회우\n",
      "쌍용정보통신\n",
      "쌍용차\n",
      "써니전자\n",
      "썸에이지\n",
      "쎄노텍\n",
      "쎄니트\n",
      "쎄미시스코\n",
      "쎄트렉아이\n",
      "쎌바이오텍\n",
      "쏠리드\n",
      "씨아이에스\n",
      "씨아이테크\n",
      "씨앤지하이테크\n",
      "씨에스베어링\n",
      "씨에스윈드\n",
      "씨엠에스에듀\n",
      "씨유메디칼\n",
      "씨젠\n",
      "씨케이에이치\n",
      "씨큐브\n",
      "씨트리\n",
      "씨티씨바이오\n",
      "씨티젠\n",
      "씨티케이코스메틱스\n",
      "아가방컴퍼니\n",
      "아나패스\n",
      "아난티\n",
      "아남전자\n",
      "아리온\n",
      "아모그린텍\n",
      "아모레G\n",
      "아모레G우\n",
      "아모레퍼시픽\n",
      "아모레퍼시픽우\n",
      "아모텍\n",
      "아미노로직스\n",
      "아미코젠\n",
      "아바코\n",
      "아바텍\n",
      "아비코전자\n",
      "아세아\n",
      "아세아시멘트\n",
      "아세아제지\n",
      "아세아텍\n",
      "아스타\n",
      "아스트\n",
      "아시아경제\n",
      "아시아나IDT\n",
      "아시아나항공\n",
      "아시아종묘\n",
      "아우딘퓨쳐스\n",
      "아이디스\n",
      "아이디스홀딩스\n",
      "아이마켓코리아\n",
      "아이센스\n",
      "아이스크림에듀\n",
      "아이쓰리시스템\n",
      "아이씨디\n",
      "아이씨케이\n",
      "아이앤씨\n",
      "아이에스동서\n",
      "아이에스이커머스\n",
      "아이에이\n",
      "아이에이네트웍스\n",
      "아이엠\n",
      "아이오케이\n",
      "아이원스\n",
      "아이즈비전\n",
      "아이진\n",
      "아이컴포넌트\n",
      "아이큐어\n",
      "아이크래프트\n",
      "아이텍\n",
      "아이티센\n",
      "아이티엠반도체\n",
      "아주IB투자\n",
      "아주캐피탈\n",
      "아즈텍WB\n",
      "아진산업\n",
      "아진엑스텍\n",
      "아톤\n",
      "아프리카TV\n",
      "안국약품\n",
      "안랩\n",
      "안트로젠\n",
      "알로이스\n",
      "알루코\n",
      "알리코제약\n",
      "알서포트\n",
      "알에스오토메이션\n",
      "알에프세미\n",
      "알에프텍\n",
      "알엔투테크놀로지\n",
      "알테오젠\n",
      "알티캐스트\n",
      "알파홀딩스\n",
      "압타바이오\n",
      "애경산업\n",
      "애경유화\n",
      "애니젠\n",
      "액토즈소프트\n",
      "액트\n",
      "액트로\n",
      "앤디포스\n",
      "앤씨앤\n",
      "앱클론\n",
      "야스\n",
      "양지사\n",
      "어보브반도체\n",
      "에너토크\n",
      "에넥스\n",
      "에버다임\n",
      "에스넷\n",
      "에스디생명공학\n",
      "에스디시스템\n",
      "에스맥\n",
      "에스모\n",
      "에스씨디\n",
      "에스앤씨엔진그룹\n",
      "에스앤에스텍\n",
      "에스에너지\n",
      "에스에스알\n",
      "에스에이엠티\n",
      "에스에이티\n",
      "에스에프에이\n",
      "에스엔유\n",
      "에스엘\n",
      "에스엠\n",
      "에스엠코어\n",
      "에스와이\n",
      "에스원\n",
      "에스제이그룹\n",
      "에스코넥\n",
      "에스텍\n",
      "에스텍파마\n",
      "에스트래픽\n",
      "에스티아이\n",
      "에스티오\n",
      "에스티큐브\n",
      "에스티팜\n",
      "에스폴리텍\n",
      "에스퓨얼셀\n",
      "에스피시스템스\n",
      "에스피지\n",
      "에쎈테크\n",
      "에쓰씨엔지니어링\n",
      "에어부산\n",
      "에이디칩스\n",
      "에이디테크놀로지\n",
      "에이리츠\n",
      "에이블씨엔씨\n",
      "에이비엘바이오\n",
      "에이비프로바이오\n",
      "에이스침대\n",
      "에이스테크\n",
      "에이스토리\n",
      "에이에프더블류\n",
      "에이엔피\n",
      "에이치시티\n",
      "에이치엘비\n",
      "에이치엘비생명과학\n",
      "에이치엘비파워\n",
      "에이치엘사이언스\n",
      "에이치케이\n",
      "에이테크솔루션\n",
      "에이텍\n",
      "에이텍티앤\n",
      "에이티넘인베스트\n",
      "에이티세미콘\n",
      "에이프로젠 H&G\n",
      "에이프로젠 KIC\n",
      "에이프로젠제약\n",
      "에이프론티어\n",
      "에이피티씨\n",
      "에치에프알\n",
      "에코마이스터\n",
      "에코마케팅\n",
      "에코바이오\n",
      "에코캡\n",
      "에코프로\n",
      "에코프로비엠\n",
      "에코플라스틱\n",
      "에프알텍\n",
      "에프앤리퍼블릭\n",
      "에프에스티\n",
      "에프엔씨엔터\n",
      "에프엔에스테크\n",
      "엑사이엔씨\n",
      "엑세스바이오\n",
      "엑셈\n",
      "엑시콘\n",
      "엔바이오니아\n",
      "엔브이에이치코리아\n",
      "엔씨소프트\n",
      "엔에스\n",
      "엔에스쇼핑\n",
      "엔에스엔\n",
      "엔에이치스팩12호\n",
      "엔에이치스팩13호\n",
      "엔에이치스팩14호\n",
      "엔지스테크널러지\n",
      "엔지켐생명과학\n",
      "엔케이\n",
      "엔케이맥스\n",
      "엔케이물산\n",
      "엔터메이트\n",
      "엔텔스\n",
      "엔피케이\n",
      "엘디티\n",
      "엘브이엠씨홀딩스\n",
      "엘비세미콘\n",
      "엘아이에스\n",
      "엘앤씨바이오\n",
      "엘앤에프\n",
      "엘엠에스\n",
      "엘오티베큠\n",
      "엘컴텍\n",
      "엘티씨\n",
      "엠게임\n",
      "엠씨넥스\n",
      "엠아이텍\n",
      "엠에스씨\n",
      "엠에스오토텍\n",
      "엠케이전자\n",
      "엠플러스\n",
      "연우\n",
      "연이정보통신\n",
      "영보화학\n",
      "영신금속\n",
      "영우디에스피\n",
      "영원무역\n",
      "영원무역홀딩스\n",
      "영진약품\n",
      "영풍\n",
      "영풍정밀\n",
      "영풍제지\n",
      "영화금속\n",
      "영화테크\n",
      "영흥철강\n",
      "예림당\n",
      "예선테크\n",
      "예스24\n",
      "예스코홀딩스\n",
      "예스티\n",
      "오가닉티코스메틱\n",
      "오공\n",
      "오디텍\n",
      "오뚜기\n",
      "오로라\n",
      "오르비텍\n",
      "오리엔탈정공\n",
      "오리엔트바이오\n",
      "오리엔트정공\n",
      "오리온\n",
      "오리온홀딩스\n",
      "오리콤\n",
      "오상자이엘\n",
      "오성첨단소재\n",
      "오션브릿지\n",
      "오스코텍\n",
      "오스테오닉\n",
      "오스템\n",
      "오스템임플란트\n",
      "오이솔루션\n",
      "오킨스전자\n",
      "오텍\n",
      "오파스넷\n",
      "오픈베이스\n",
      "올리패스\n",
      "올릭스\n",
      "옴니시스템\n",
      "옴니텔\n",
      "옵트론텍\n",
      "옵티시스\n",
      "옵티팜\n",
      "와이솔\n",
      "와이아이케이\n",
      "와이엔텍\n",
      "와이엠씨\n",
      "와이엠티\n",
      "와이제이엠게임즈\n",
      "와이지-원\n",
      "와이지엔터테인먼트\n",
      "와토스코리아\n",
      "용평리조트\n",
      "우노앤컴퍼니\n",
      "우리금융지주\n",
      "우리기술\n",
      "우리기술투자\n",
      "우리넷\n",
      "우리들제약\n",
      "우리들휴브레인\n",
      "우리로\n",
      "우리바이오\n",
      "우리산업\n",
      "우리산업홀딩스\n",
      "우리손에프앤지\n",
      "우리이앤엘\n",
      "우리조명\n",
      "우리종금\n",
      "우림기계\n",
      "우성사료\n",
      "우수AMS\n",
      "우신시스템\n",
      "우양\n",
      "우원개발\n",
      "우정바이오\n",
      "우주일렉트로\n",
      "우진\n",
      "우진비앤지\n",
      "우진아이엔에스\n",
      "우진플라임\n",
      "웅진\n",
      "웅진씽크빅\n",
      "웅진코웨이\n",
      "원림\n",
      "원익\n",
      "원익IPS\n",
      "원익QnC\n",
      "원익머트리얼즈\n",
      "원익큐브\n",
      "원익홀딩스\n",
      "원일특강\n",
      "원풍\n",
      "원풍물산\n",
      "월덱스\n",
      "웨이브일렉트로\n",
      "웰바이오텍\n",
      "웰크론\n",
      "웰크론강원\n",
      "웰크론한텍\n",
      "웹스\n",
      "웹젠\n",
      "웹케시\n",
      "위니아딤채\n",
      "위닉스\n",
      "위메이드\n",
      "위즈코프\n",
      "위지윅스튜디오\n",
      "위지트\n",
      "윈스\n",
      "윈팩\n",
      "윈하이텍\n",
      "윌링스\n",
      "윌비스\n",
      "윙입푸드\n",
      "유나이티드제약\n",
      "유니드\n",
      "유니맥스글로벌\n",
      "유니셈\n",
      "유니슨\n",
      "유니온\n",
      "유니온머티리얼\n",
      "유니온커뮤니티\n",
      "유니켐\n",
      "유니퀘스트\n",
      "유니크\n",
      "유니테스트\n",
      "유니테크노\n",
      "유니트론텍\n",
      "유라테크\n",
      "유바이오로직스\n",
      "유비벨록스\n",
      "유비케어\n",
      "유비쿼스\n",
      "유비쿼스홀딩스\n",
      "유성기업\n",
      "유성티엔에스\n",
      "유수홀딩스\n",
      "유신\n",
      "유아이엘\n",
      "유안타제3호스팩\n",
      "유안타제4호스팩\n",
      "유안타제5호스팩\n",
      "유안타증권\n",
      "유안타증권우\n",
      "유앤아이\n",
      "유양디앤유\n",
      "유에스티\n",
      "유엔젤\n",
      "유유제약\n",
      "유유제약1우\n",
      "유유제약2우B\n",
      "유진기업\n",
      "유진로봇\n",
      "유진스팩4호\n",
      "유진스팩5호\n",
      "유진테크\n",
      "유진투자증권\n",
      "유티아이\n",
      "유틸렉스\n",
      "유한양행\n",
      "유한양행우\n",
      "유화증권\n",
      "유화증권우\n",
      "육일씨엔에쓰\n",
      "율촌화학\n",
      "율호\n",
      "이건산업\n",
      "이건홀딩스\n",
      "이구산업\n",
      "이그잭스\n",
      "이글루시큐리티\n",
      "이글벳\n",
      "이노메트리\n",
      "이노션\n",
      "이노와이어리스\n",
      "이노와이즈\n",
      "이노인스트루먼트\n",
      "이노테라피\n",
      "이녹스\n",
      "이녹스첨단소재\n",
      "이니텍\n",
      "이더블유케이\n",
      "이라이콤\n",
      "이랜텍\n",
      "이루온\n",
      "이리츠코크렙\n",
      "이마트\n",
      "이미지스\n",
      "이베스트이안스팩1호\n",
      "이베스트투자증권\n",
      "이상네트웍스\n",
      "이수앱지스\n",
      "이수페타시스\n",
      "이수화학\n",
      "이스타코\n",
      "이스트소프트\n",
      "이씨에스\n",
      "이아이디\n",
      "이에스브이\n",
      "이엑스티\n",
      "이엔에프테크놀로지\n",
      "이엘피\n",
      "이엠넷\n",
      "이엠코리아\n",
      "이엠텍\n",
      "이연제약\n",
      "이오테크닉스\n",
      "이원컴포텍\n",
      "이월드\n",
      "이즈미디어\n",
      "이지바이오\n",
      "이지웰페어\n",
      "이지케어텍\n",
      "이크레더블\n",
      "이테크건설\n",
      "이트론\n",
      "이퓨쳐\n",
      "이화공영\n",
      "이화산업\n",
      "이화전기\n",
      "인디에프\n",
      "인바디\n",
      "인베니아\n",
      "인산가\n",
      "인선이엔티\n",
      "인성정보\n",
      "인스코비\n",
      "인지디스플레\n",
      "인지컨트롤스\n",
      "인천도시가스\n",
      "인콘\n",
      "인크로스\n",
      "인탑스\n",
      "인터로조\n",
      "인터엠\n",
      "인터지스\n",
      "인터파크\n",
      "인터파크홀딩스\n",
      "인터플렉스\n",
      "인텍플러스\n",
      "인텔리안테크\n",
      "인트로메딕\n",
      "인트론바이오\n",
      "인팩\n",
      "인포마크\n",
      "인포바인\n",
      "인포뱅크\n",
      "인프라웨어\n",
      "인피니트헬스케어\n",
      "인화정공\n",
      "일동제약\n",
      "일동홀딩스\n",
      "일성건설\n",
      "일성신약\n",
      "일신바이오\n",
      "일신방직\n",
      "일신석재\n",
      "일야\n",
      "일양약품\n",
      "일양약품우\n",
      "일정실업\n",
      "일지테크\n",
      "일진다이아\n",
      "일진디스플\n",
      "일진머티리얼즈\n",
      "일진전기\n",
      "일진파워\n",
      "일진홀딩스\n",
      "잇츠한불\n",
      "잉글우드랩\n",
      "잉크테크\n",
      "자비스\n",
      "자연과환경\n",
      "자이글\n",
      "자이에스앤디\n",
      "자화전자\n",
      "장원테크\n",
      "재영솔루텍\n",
      "전방\n",
      "전진바이오팜\n",
      "전파기지국\n",
      "정다운\n",
      "정산애강\n",
      "정상제이엘에스\n",
      "정원엔시스\n",
      "제너셈\n",
      "제넥신\n",
      "제넨바이오\n",
      "제노레이\n",
      "제노포커스\n",
      "제닉\n",
      "제로투세븐\n",
      "제룡산업\n",
      "제룡전기\n",
      "제우스\n",
      "제이브이엠\n",
      "제이스테판\n",
      "제이스텍\n",
      "제이씨케미칼\n",
      "제이씨현시스템\n",
      "제이에스코퍼레이션\n",
      "제이에스티나\n",
      "제이엔케이히터\n",
      "제이엘케이인스펙션\n",
      "제이엠아이\n",
      "제이엠티\n",
      "제이준코스메틱\n",
      "제이콘텐트리\n",
      "제이티\n",
      "제일기획\n",
      "제일바이오\n",
      "제일약품\n",
      "제일연마\n",
      "제일제강\n",
      "제일테크노스\n",
      "제일파마홀딩스\n",
      "제주반도체\n",
      "제주은행\n",
      "제주항공\n",
      "제테마\n",
      "젬백스\n",
      "젬백스지오\n",
      "조광ILI\n",
      "조광페인트\n",
      "조광피혁\n",
      "조비\n",
      "조선내화\n",
      "조선선재\n",
      "조아제약\n",
      "조이시티\n",
      "조일알미늄\n",
      "조흥\n",
      "종근당\n",
      "종근당바이오\n",
      "종근당홀딩스\n",
      "좋은사람들\n",
      "주성엔지니어링\n",
      "주연테크\n",
      "줌인터넷\n",
      "중앙백신\n",
      "중앙에너비스\n",
      "중앙오션\n",
      "지노믹트리\n",
      "지누스\n",
      "지니뮤직\n",
      "지니언스\n",
      "지니틱스\n",
      "지란지교시큐리티\n",
      "지어소프트\n",
      "지에스이\n",
      "지엔씨에너지\n",
      "지엔코\n",
      "지엘팜텍\n",
      "지엠비코리아\n",
      "지역난방공사\n",
      "지투알\n",
      "지트리비앤티\n",
      "지티지웰니스\n",
      "진도\n",
      "진로발효\n",
      "진매트릭스\n",
      "진바이오텍\n",
      "진성티이씨\n",
      "진양산업\n",
      "진양제약\n",
      "진양폴리\n",
      "진양홀딩스\n",
      "진양화학\n",
      "진에어\n",
      "진원생명과학\n",
      "진흥기업\n",
      "진흥기업2우B\n",
      "진흥기업우B\n",
      "차바이오텍\n",
      "참엔지니어링\n",
      "참좋은여행\n",
      "창해에탄올\n",
      "천보\n",
      "천일고속\n",
      "청담러닝\n",
      "청보산업\n",
      "체리부로\n",
      "체시스\n",
      "초록뱀\n",
      "칩스앤미디어\n",
      "카리스국보\n",
      "카스\n",
      "카카오\n",
      "카페24\n",
      "카프로\n",
      "캐리소프트\n",
      "캐스텍코리아\n",
      "캠시스\n",
      "컬러레이\n",
      "컴투스\n",
      "컴퍼니케이\n",
      "케어랩스\n",
      "케이디켐\n",
      "케이맥\n",
      "케이비17호스팩\n",
      "케이비아이동국실업\n",
      "케이비제11호스팩\n",
      "케이비제18호스팩\n",
      "케이비제19호스팩\n",
      "케이사인\n",
      "케이씨\n",
      "케이씨에스\n",
      "케이씨텍\n",
      "케이씨티\n",
      "케이씨피드\n",
      "케이아이엔엑스\n",
      "케이알피앤이\n",
      "케이에스피\n",
      "케이엔더블유\n",
      "케이엔제이\n",
      "케이엘넷\n",
      "케이엠\n",
      "케이엠더블유\n",
      "케이엠제약\n",
      "케이탑리츠\n",
      "케이프\n",
      "케이피에스\n",
      "케이피에프\n",
      "케이피엠테크\n",
      "케이피티유\n",
      "켐온\n",
      "켐트로닉스\n",
      "켐트로스\n",
      "코닉글로리\n",
      "코데즈컴바인\n",
      "코디\n",
      "코디엠\n",
      "코렌\n",
      "코렌텍\n",
      "코리아나\n",
      "코리아센터\n",
      "코리아써우\n",
      "코리아써키트\n",
      "코리아에셋투자증권\n",
      "코리아에스이\n",
      "코리아에프티\n",
      "코리아오토글라스\n",
      "코리안리\n",
      "코맥스\n",
      "코메론\n",
      "코미코\n",
      "코미팜\n",
      "코세스\n",
      "코센\n",
      "코스맥스\n",
      "코스맥스비티아이\n",
      "코스맥스엔비티\n",
      "코스메카코리아\n",
      "코스모신소재\n",
      "코스모화학\n",
      "코스온\n",
      "코아스\n",
      "코아스템\n",
      "코아시아\n",
      "코엔텍\n",
      "코오롱\n",
      "코오롱글로벌\n",
      "코오롱글로벌우\n",
      "코오롱머티리얼\n",
      "코오롱생명과학\n",
      "코오롱우\n",
      "코오롱인더\n",
      "코오롱인더우\n",
      "코오롱플라스틱\n",
      "코웰패션\n",
      "코위버\n",
      "코윈테크\n",
      "코이즈\n",
      "코콤\n",
      "코텍\n",
      "코프라\n",
      "콜마비앤에이치\n",
      "콤텍시스템\n",
      "쿠쿠홀딩스\n",
      "쿠쿠홈시스\n",
      "큐렉소\n",
      "큐로\n",
      "큐로컴\n",
      "큐로홀딩스\n",
      "큐리언트\n",
      "큐브앤컴퍼니\n",
      "큐브엔터\n",
      "큐에스아이\n",
      "큐캐피탈\n",
      "크라운제과\n",
      "크라운해태홀딩스\n",
      "크라운해태홀딩스우\n",
      "크리스에프앤씨\n",
      "크리스탈\n",
      "크리스탈신소재\n",
      "크린앤사이언스\n",
      "클래시스\n",
      "클리오\n",
      "키네마스터\n",
      "키다리스튜디오\n",
      "키움제5호스팩\n",
      "키움증권\n",
      "키이스트\n",
      "타이거일렉\n",
      "탑엔지니어링\n",
      "태경산업\n",
      "태경화학\n",
      "태광\n",
      "태광산업\n",
      "태림포장\n",
      "태양\n",
      "태양금속\n",
      "태양금속우\n",
      "태영건설\n",
      "태영건설우\n",
      "태웅\n",
      "태웅로직스\n",
      "태원물산\n",
      "태평양물산\n",
      "테고사이언스\n",
      "테라젠이텍스\n",
      "테스\n",
      "테스나\n",
      "테이팩스\n",
      "테크윙\n",
      "텔레칩스\n",
      "텔레필드\n",
      "텔코웨어\n",
      "텔콘RF제약\n",
      "토니모리\n",
      "토박스코리아\n",
      "토비스\n",
      "토탈소프트\n",
      "톱텍\n",
      "투비소프트\n",
      "트루윈\n",
      "특수건설\n",
      "티라유텍\n",
      "티로보틱스\n",
      "티비씨\n",
      "티씨케이\n",
      "티앤알바이오팹\n",
      "티에스이\n",
      "티에이치엔\n",
      "티엘아이\n",
      "티움바이오\n",
      "티웨이항공\n",
      "티웨이홀딩스\n",
      "티케이케미칼\n",
      "티탑스\n",
      "티플랙스\n",
      "티피씨글로벌\n",
      "팅크웨어\n",
      "파라다이스\n",
      "파라텍\n",
      "파루\n",
      "파마리서치프로덕트\n",
      "파멥신\n",
      "파미셀\n",
      "파버나인\n",
      "파세코\n",
      "파수닷컴\n",
      "파워넷\n",
      "파워로직스\n",
      "파이오링크\n",
      "파인디앤씨\n",
      "파인디지털\n",
      "파인테크닉스\n",
      "파인텍\n",
      "파커스\n",
      "파크시스템스\n",
      "파트론\n",
      "판타지오\n",
      "팜스빌\n",
      "팜스코\n",
      "팜스토리\n",
      "패션플랫폼\n",
      "팬스타엔터프라이즈\n",
      "팬엔터테인먼트\n",
      "팬오션\n",
      "팬젠\n",
      "퍼스텍\n",
      "퍼시스\n",
      "펄어비스\n",
      "펌텍코리아\n",
      "페이퍼코리아\n",
      "펩트론\n",
      "평화산업\n",
      "평화정공\n",
      "평화홀딩스\n",
      "포메탈\n",
      "포비스티앤씨\n",
      "포스코 ICT\n",
      "포스코강판\n",
      "포스코엠텍\n",
      "포스코인터내셔널\n",
      "포스코케미칼\n",
      "포시에스\n",
      "포인트엔지니어링\n",
      "푸드나무\n",
      "푸드웰\n",
      "푸른기술\n",
      "푸른저축은행\n",
      "풀무원\n",
      "풍강\n",
      "풍국주정\n",
      "풍산\n",
      "풍산홀딩스\n",
      "퓨쳐스트림네트웍스\n",
      "퓨쳐켐\n",
      "프럼파스트\n",
      "프로스테믹스\n",
      "프로텍\n",
      "프리엠스\n",
      "플랜티넷\n",
      "플레이위드\n",
      "플리토\n",
      "피델릭스\n",
      "피씨디렉트\n",
      "피씨엘\n",
      "피앤씨테크\n",
      "피앤이솔루션\n",
      "피에스엠씨\n",
      "피에스케이\n",
      "피에스케이홀딩스\n",
      "피에스텍\n",
      "피엔티\n",
      "피제이메탈\n",
      "피제이전자\n",
      "필룩스\n",
      "필링크\n",
      "필옵틱스\n",
      "하나금융10호스팩\n",
      "하나금융11호스팩\n",
      "하나금융13호스팩\n",
      "하나금융14호스팩\n",
      "하나금융9호스팩\n",
      "하나금융지주\n",
      "하나니켈1호\n",
      "하나니켈2호\n",
      "하나마이크론\n",
      "하나머스트제6호스팩\n",
      "하나머티리얼즈\n",
      "하나제약\n",
      "하나투어\n",
      "하림\n",
      "하림지주\n",
      "하이골드12호\n",
      "하이골드3호\n",
      "하이골드8호\n",
      "하이로닉\n",
      "하이록코리아\n",
      "하이비젼시스템\n",
      "하이셈\n",
      "하이스틸\n",
      "하이제4호스팩\n",
      "하이즈항공\n",
      "하이텍팜\n",
      "하이트론\n",
      "하이트진로\n",
      "하이트진로2우B\n",
      "하이트진로홀딩스\n",
      "하이트진로홀딩스우\n",
      "하츠\n",
      "한국ANKOR유전\n",
      "한국가구\n",
      "한국가스공사\n",
      "한국경제TV\n",
      "한국공항\n",
      "한국금융지주\n",
      "한국금융지주우\n",
      "한국기업평가\n",
      "한국내화\n",
      "한국단자\n",
      "한국맥널티\n",
      "한국바이오젠\n",
      "한국비엔씨\n",
      "한국석유\n",
      "한국선재\n",
      "한국쉘석유\n",
      "한국아트라스비엑스\n",
      "한국알콜\n",
      "한국유니온제약\n",
      "한국자산신탁\n",
      "한국전력\n",
      "한국전자금융\n",
      "한국전자인증\n",
      "한국전자홀딩스\n",
      "한국정보공학\n",
      "한국정보인증\n",
      "한국정보통신\n",
      "한국제5호스팩\n",
      "한국제6호스팩\n",
      "한국제7호스팩\n",
      "한국제8호스팩\n",
      "한국제지\n",
      "한국조선해양\n",
      "한국종합기술\n",
      "한국주강\n",
      "한국주철관\n",
      "한국철강\n",
      "한국카본\n",
      "한국캐피탈\n",
      "한국컴퓨터\n",
      "한국콜마\n",
      "한국콜마홀딩스\n",
      "한국큐빅\n",
      "한국타이어앤테크놀로지\n",
      "한국테크놀로지\n",
      "한국테크놀로지그룹\n",
      "한국토지신탁\n",
      "한국특수형강\n",
      "한국패러랠\n",
      "한국팩키지\n",
      "한국프랜지\n",
      "한국항공우주\n",
      "한국화장품\n",
      "한국화장품제조\n",
      "한글과컴퓨터\n",
      "한네트\n",
      "한농화성\n",
      "한독\n",
      "한독크린텍\n",
      "한라\n",
      "한라IMS\n",
      "한라홀딩스\n",
      "한미글로벌\n",
      "한미반도체\n",
      "한미사이언스\n",
      "한미약품\n",
      "한빛소프트\n",
      "한샘\n",
      "한섬\n",
      "한성기업\n",
      "한세실업\n",
      "한세엠케이\n",
      "한세예스24홀딩스\n",
      "한솔PNS\n",
      "한솔로지스틱스\n",
      "한솔시큐어\n",
      "한솔씨앤피\n",
      "한솔인티큐브\n",
      "한솔제지\n",
      "한솔케미칼\n",
      "한솔테크닉스\n",
      "한솔홀딩스\n",
      "한솔홈데코\n",
      "한송네오텍\n",
      "한스바이오메드\n",
      "한신공영\n",
      "한신기계\n",
      "한양디지텍\n",
      "한양이엔지\n",
      "한양증권\n",
      "한양증권우\n",
      "한온시스템\n",
      "한올바이오파마\n",
      "한익스프레스\n",
      "한일네트웍스\n",
      "한일단조\n",
      "한일사료\n",
      "한일시멘트\n",
      "한일진공\n",
      "한일철강\n",
      "한일현대시멘트\n",
      "한일홀딩스\n",
      "한일화학\n",
      "한전KPS\n",
      "한전기술\n",
      "한전산업\n",
      "한진\n",
      "한진중공업\n",
      "한진중공업홀딩스\n",
      "한진칼\n",
      "한창\n",
      "한창산업\n",
      "한창제지\n",
      "한컴MDS\n",
      "한컴위드\n",
      "한탑\n",
      "한프\n",
      "한화\n",
      "한화3우B\n",
      "한화갤러리아타임월드\n",
      "한화생명\n",
      "한화손해보험\n",
      "한화시스템\n",
      "한화에스비아이스팩\n",
      "한화에어로스페이스\n",
      "한화에이스스팩4호\n",
      "한화우\n",
      "한화케미칼\n",
      "한화케미칼우\n",
      "한화투자증권\n",
      "한화투자증권우\n",
      "해마로푸드서비스\n",
      "해성디에스\n",
      "해성산업\n",
      "해성옵틱스\n",
      "해태제과식품\n",
      "핸디소프트\n",
      "핸즈코퍼레이션\n",
      "헝셩그룹\n",
      "헬릭스미스\n",
      "현대건설\n",
      "현대건설기계\n",
      "현대건설우\n",
      "현대공업\n",
      "현대그린푸드\n",
      "현대글로비스\n",
      "현대로템\n",
      "현대리바트\n",
      "현대모비스\n",
      "현대미포조선\n",
      "현대바이오\n",
      "현대백화점\n",
      "현대비앤지스틸\n",
      "현대비앤지스틸우\n",
      "현대사료\n",
      "현대상사\n",
      "현대상선\n",
      "현대약품\n",
      "현대에너지솔루션\n",
      "현대에이치씨엔\n",
      "현대엘리베이\n",
      "현대오토에버\n",
      "현대위아\n",
      "현대일렉트릭\n",
      "현대제철\n",
      "현대중공업지주\n",
      "현대차\n",
      "현대차2우B\n",
      "현대차3우B\n",
      "현대차우\n",
      "현대차증권\n",
      "현대코퍼레이션홀딩스\n",
      "현대통신\n",
      "현대해상\n",
      "현대홈쇼핑\n",
      "현성바이탈\n",
      "현우산업\n",
      "현진소재\n",
      "형지I&C\n",
      "형지엘리트\n",
      "혜인\n",
      "호전실업\n",
      "호텔신라\n",
      "호텔신라우\n",
      "홈센타홀딩스\n",
      "홈캐스트\n",
      "화성밸브\n",
      "화성산업\n",
      "화승알앤에이\n",
      "화승엔터프라이즈\n",
      "화승인더\n",
      "화신\n",
      "화신정공\n",
      "화이브라더스코리아\n",
      "화인베스틸\n",
      "화일약품\n",
      "화천기계\n",
      "화천기공\n",
      "환인제약\n",
      "황금에스티\n",
      "효성\n",
      "효성ITX\n",
      "효성오앤비\n",
      "효성중공업\n",
      "효성첨단소재\n",
      "효성티앤씨\n",
      "효성화학\n",
      "후성\n",
      "휘닉스소재\n",
      "휠라코리아\n",
      "휴네시온\n",
      "휴니드\n",
      "휴림로봇\n",
      "휴마시스\n",
      "휴맥스\n",
      "휴맥스홀딩스\n",
      "휴메딕스\n",
      "휴비스\n",
      "휴비츠\n",
      "휴스틸\n",
      "휴온스\n",
      "휴온스글로벌\n",
      "휴젤\n",
      "휴켐스\n",
      "흥구석유\n",
      "흥국\n",
      "흥국에프엔비\n",
      "흥국화재\n",
      "흥국화재2우B\n",
      "흥국화재우\n",
      "흥아해운\n",
      "희림\n",
      "힘스\n"
     ]
    }
   ],
   "source": [
    "for i in a:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'a' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-069f865b262e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'min'\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Name'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mClose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'a' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>060310</td>\n",
       "      <td>060310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>095570</td>\n",
       "      <td>095570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>068400</td>\n",
       "      <td>068400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>006840</td>\n",
       "      <td>006840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>054620</td>\n",
       "      <td>054620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2190</th>\n",
       "      <td>000547</td>\n",
       "      <td>000547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2191</th>\n",
       "      <td>000545</td>\n",
       "      <td>000545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2192</th>\n",
       "      <td>003280</td>\n",
       "      <td>003280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2193</th>\n",
       "      <td>037440</td>\n",
       "      <td>037440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2194</th>\n",
       "      <td>238490</td>\n",
       "      <td>238490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2195 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0    code\n",
       "0     060310  060310\n",
       "1     095570  095570\n",
       "2     068400  068400\n",
       "3     006840  006840\n",
       "4     054620  054620\n",
       "...      ...     ...\n",
       "2190  000547  000547\n",
       "2191  000545  000545\n",
       "2192  003280  003280\n",
       "2193  037440  037440\n",
       "2194  238490  238490\n",
       "\n",
       "[2195 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in name:\n",
    "    df['min']  = min(df[df['Name']==i].Close)\n",
    "    print(df)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from mod1 import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "\n",
    "def close_ma(df,select1,select2):\n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close',select1,select2]].values)\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1.columns=['close',select1,select2]\n",
    "    df1 = df1.set_index(df['date'])\n",
    "    df1.plot(figsize=(16,4))\n",
    "    plt.title(df['name'][0])\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def close_ma_vol(df,select1,select2,select3):\n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close',select1,select2,select3]].values)\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1.columns=['close',select1,select2,select3]\n",
    "    df1 = df1.set_index(df['date'])\n",
    "    df1.plot(figsize=(16,4))\n",
    "    plt.title(df['name'][0])\n",
    "    plt.grid(True)\n",
    "    plt.show()    \n",
    "    \n",
    "def rsi(df):\n",
    "    talib_rsi = ta.RSI(df, timeperiod=14)\n",
    "    df['rsi_14'] = talib_rsi\n",
    "    df = df.set_index(df['date'])\n",
    "    \n",
    "    plt.figure(figsize=(16,4))\n",
    "    plt.plot(df['rsi_14'])\n",
    "    plt.fill_between(df.index,y1=30, y2=70, color='#adccff', alpha='0.3')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('RSI')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "name = ['hrs','한컴위드','손오공']    \n",
    "#name = ['hrs','이노인스트루먼트','한국자산신탁','한국화장품','코리아나','우림기계','아스트','디엔에프','푸드나무','상보','포스코인터내셔널','우주일렉트로','서원','인터파크홀딩스','대양금속','아난티','제룡전기']   \n",
    "for i in name:\n",
    "    df = select_stock(i,'2010-01-01')\n",
    "    close_ma(df,'ma60','ma120')\n",
    "    rsi(df)\n",
    "    close_ma_vol(df,'ma60','ma120','volume')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "df = select_stock('hrs','2010-01-01')\n",
    "\n",
    "close_ma(df,'ma60','ma120')\n",
    "close_ma_vol(df,'ma60','ma120','volume')\n",
    "\n",
    "talib_rsi = ta.RSI(df, timeperiod=14)\n",
    "df['rsi_14'] = talib_rsi\n",
    "display(talib_rsi.head(15))\n",
    "\n",
    "plt.figure(figsize=(16,4))\n",
    "plt.plot(df['rsi_14'])\n",
    "plt.fill_between(df.index,y1=30, y2=70, color='#adccff', alpha='0.3')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('RSI')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mod1 import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "\n",
    "def market_ma(df,select1,select2):\n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close',select1,select2]].values)\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1.columns=['close',select1,select2]\n",
    "    df1 = df1.set_index(df['date'])\n",
    "    df1.plot(figsize=(16,4))\n",
    "    plt.title(df['market'][0])\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def market_ma_vol(df,select1,select2,select3):\n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close',select1,select2,select3]].values)\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1.columns=['close',select1,select2,select3]\n",
    "    df1 = df1.set_index(df['date'])\n",
    "    df1.plot(figsize=(16,4))\n",
    "    plt.title(df['market'][0])\n",
    "    plt.grid(True)\n",
    "    plt.show()    \n",
    "    \n",
    "df = select_market('kospi','2010-01-01')\n",
    "    \n",
    "close_ma(df,'ma60','ma120')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_market(name,date):\n",
    "    select_query = \"select * from \"\n",
    "    date_query = \" where Date > \"    \n",
    "    var = select_query + name + date_query+\"'\"+date+\"'\" \n",
    "    df = pd.read_sql(var, engine)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from mod1 import *\n",
    "df = select_market('kospi','2015-01-01')\n",
    "market_ma(df,'ma60','ma120')\n",
    "df = select_market('kosdaq','2015-01-01')\n",
    "market_ma(df,'ma60','ma120')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mod1 import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "\n",
    "def close_ma(df,select1,select2):\n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close',select1,select2]].values)\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1.columns=['close',select1,select2]\n",
    "    df1 = df1.set_index(df['date'])\n",
    "    df1.plot(figsize=(16,4))\n",
    "    plt.title(df['name'][0])\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def close_ma_vol(df,select1,select2,select3):\n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close',select1,select2,select3]].values)\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1.columns=['close',select1,select2,select3]\n",
    "    df1 = df1.set_index(df['date'])\n",
    "    df1.plot(figsize=(16,4))\n",
    "    plt.title(df['name'][0])\n",
    "    plt.grid(True)\n",
    "    plt.show()    \n",
    "    \n",
    "query = \"select * from kospi where Date > '1995-01-01'\"\n",
    "df = pd.read_sql(query ,engine)\n",
    "\n",
    "close_ma(df,'ma60','ma120')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mod1 import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "\n",
    "def close_ma(df,select1,select2):\n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close',select1,select2]].values)\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1.columns=['close',select1,select2]\n",
    "    df1 = df1.set_index(df['date'])\n",
    "    df1.plot(figsize=(16,4))\n",
    "    plt.title(df['market'][0])\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def close_ma_vol(df,select1,select2,select3):\n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close',select1,select2,select3]].values)\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1.columns=['close',select1,select2,select3]\n",
    "    df1 = df1.set_index(df['date'])\n",
    "    df1.plot(figsize=(16,4))\n",
    "    #plt.title(df['Market'][0])\n",
    "    plt.grid(True)\n",
    "    plt.show()    \n",
    "    \n",
    "query = \"select * from kospi where Date > '2010-01-01'\"\n",
    "df = pd.read_sql(query ,engine)\n",
    "\n",
    "close_ma(df,'ma60','ma120')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mod1 import *\n",
    "from pykrx import stock,website\n",
    "\n",
    "df_kospi  = stock.api.get_index_kospi_ohlcv_by_date(\"19950101\", \"202001050228\", \"코스피\")\n",
    "df_kospi.index.names = ['Date']\n",
    "df_kospi.columns  = ('Open','High','Low','Close','Volume')\n",
    "df_kospi['Market']='kospi'\n",
    "df_kospi.to_sql(name='kospi', con=engine, if_exists='append')\n",
    "\n",
    "df_kosdaq = stock.api.get_index_kosdaq_ohlcv_by_date(\"19960101\", \"20200105\", \"코스닥\")\n",
    "df_kosdaq.index.names = ['Date']\n",
    "df_kosdaq.columns  = ('Open','High','Low','Close','Volume')\n",
    "df_kosdaq'Market']='kosdaq'\n",
    "df_kosdaq.to_sql(name='kosdaq', con=engine, if_exists='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mod1 import *\n",
    "from pykrx import stock,website\n",
    "\n",
    "df  = stock.api.get_index_kospi_ohlcv_by_date(\"19960101\", \"202001050228\", \"코스피\")\n",
    "df.index.names = ['Date']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Name']='kospi'\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df.to_excel('d:\\\\kospi.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mod1 import *\n",
    "\n",
    "\n",
    "df = select_stock('hrs','2019-01-01')\n",
    "df.columns=df.columns.str.lower()\n",
    "df[['volume','close']] = df[['volume','close']].astype(float) #  TA-Lib로 평균을 구하려면 실수로 만들어야 함\n",
    "volume = df['volume'].values.astype('float')\n",
    "sma_vol = talib.SMA(volume, timeperiod=10)\n",
    "df['vol_10'] = sma_vol\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mod1 import *\n",
    "\n",
    "df = select_stock('hrs','2019-01-01')\n",
    "df.columns=df.columns.str.lower()\n",
    "df[['volume','close']] = df[['volume','close']].astype(float) #  TA-Lib로 평균을 구하려면 실수로 만들어야 함\n",
    "sma_vol = ta.SMA(df, timeperiod=10,price='volume')\n",
    "df['vol_10'] = sma_vol\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mod1 import *\n",
    "\n",
    "df = select_stock('hrs','2019-01-01')\n",
    "df.columns=df.columns.str.lower()\n",
    "df[['volume','close']] = df[['volume','close']].astype(float) #  TA-Lib로 평균을 구하려면 실수로 만들어야 함\n",
    "\n",
    "close=ta.MA(df,timeperiod=10)\n",
    "sma = ta.SMA(df, timeperiod=10,price='volume')\n",
    "ema = ta.EMA(df, timeperiod=10,price='volume')\n",
    "plt.plot(close, 'r-')\n",
    "plt.plot(sma, 'b-')\n",
    "plt.plot(ema, 'g-')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for numeric_string in a:\n",
    "    print(numeric_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1,2,3,4,5,5,7,8,9,10,10,2,3,4])\n",
    "desired_array = [int(numeric_string) for numeric_string in row] for row in a]\n",
    "#a = a.astype(np.int64)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=np.random.random(15)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import talib\n",
    "a = a.astype(float)\n",
    "ama=talib.MA(a, timeperiod=5)\n",
    "ama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=a.shape[0]\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sma = ta.SMA(b, timeperiod=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mod1 import *\n",
    "\n",
    "\n",
    "df = select_stock('hrs','2010-01-01')\n",
    "df.columns=df.columns.str.lower()\n",
    "df[['volume','close']] = df[['volume','close']].astype(float) #  TA-Lib로 평균을 구하려면 실수로 만들어야 함\n",
    "\n",
    "close = df['close']\n",
    "\n",
    "sma = ta.SMA(df, timeperiod=120)\n",
    "ema = ta.EMA(df, timeperiod=120)\n",
    "plt.figure(figsize=(16,4))\n",
    "plt.plot(close, 'r-')\n",
    "plt.plot(sma, 'b-')\n",
    "plt.plot(ema, 'g-')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(sma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mod1 import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "import torch.utils.data\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "df = select_stock('hrs','2018-01-01')\n",
    "\n",
    "df['Direction'] = df['Close'].shift(-1)-df['Close']\n",
    "df['Direction'] = df['Direction'].shift(1)\n",
    "\n",
    "#df['shift'][df['shift'] <= 0 ] = 0\n",
    "#df['shift'][df['shift']  > 0 ] = 1\n",
    "# Change type to datetime\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Moving average indicators, short, medium and long term\n",
    "df['SMA10'] = df.Close.rolling(10).mean()\n",
    "df['SMA30'] = df.Close.rolling(30).mean()\n",
    "df['SMA90'] = df.Close.rolling(90).mean()\n",
    "\n",
    "# Exponential moving average \n",
    "df['EWA10'] = df['Close'].ewm(span=10, min_periods=10).mean()\n",
    "df['EWA30'] = df['Close'].ewm(span=30, min_periods=30).mean()\n",
    "df['EWA90'] = df['Close'].ewm(span=90, min_periods=90).mean()\n",
    "\n",
    "# Stochastic Osciallator\n",
    "df['SOI'] = (df['Close'] - df['Low']) / (df['High'] - df['Low'])\n",
    "\n",
    "# 10, 5 and 2 Day Momentum\n",
    "df['Momentum_10'] = df['Close'].diff(10)\n",
    "df['Momentum_5'] = df['Close'].diff(5)\n",
    "df['Momentum_2'] = df['Close'].diff(2)\n",
    "\n",
    "# Standard deviation\n",
    "df['Std_10'] = df['Close'].rolling(10, min_periods=10).std()\n",
    "\n",
    "\n",
    "# Daily variation (High - low)\n",
    "df['Daily_variation'] = (df['High'] - df['Low']) / df['Close']\n",
    "\n",
    "# Day of week\n",
    "df['Day'] = df.Date.dt.dayofweek\n",
    "\n",
    "# Month of year\n",
    "df['Month'] = df.Date.dt.month_name()\n",
    "\n",
    "# Replace day of week number with string in order to make categorical dummy variables\n",
    "df['Day'].replace({0: 'Monday', 1 : 'Tuesday', 2: 'Wednesday', 3 : 'Thursday', 4 : 'Friday'}, inplace=True);\n",
    "\n",
    "# Make dummy variables out of cateorical features \n",
    "df = pd.get_dummies(df);\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  전종목 검색하여  종가 > ma120  일일 비교  하여  관심 종목 추출_9  total_a(1년분) ,total_b(11년분) 추출 및  공통종목을 추출\n",
    "\n",
    "from mod1 import *\n",
    "#import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "#from pandas.core.common import SettingWithCopyWarning\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
    "\n",
    "path = 'd:\\\\stockdata\\\\close_ma120\\\\close_ma120_'\n",
    "path_total = 'd:\\\\stockdata\\\\close_ma120\\\\total_'\n",
    "path_total_f = 'd:\\\\stockdata\\\\close_ma120\\\\total_filter_'\n",
    "path_total_a = 'd:\\\\stockdata\\\\close_ma120\\\\total_a_'\n",
    "path_total_b = 'd:\\\\stockdata\\\\close_ma120\\\\total_b_'\n",
    "path_total_c = 'd:\\\\stockdata\\\\close_ma120\\\\total_c_'\n",
    "\n",
    "\n",
    "df = all_stock('2019-10-10')\n",
    "df = df['Name']\n",
    "name = df.to_list()\n",
    "    \n",
    "select_start_a = '2019-01-01'\n",
    "select_start_b = '2008-01-01'\n",
    "\n",
    "select_query = \"select * from market where Name='hrs' and Date >= '2019-10-01' \"\n",
    "df3 = pd.read_sql(select_query, engine)\n",
    "\n",
    "df3 = df3['Date']\n",
    "datelist = df3.to_list()\n",
    "    \n",
    "def search_stock(name,select_start):   \n",
    "    print(name)\n",
    "    print(select_start)\n",
    "    pure_df = pd.DataFrame()\n",
    "    df2 = pd.DataFrame() \n",
    "    for i in name:\n",
    "        #print(i)\n",
    "        df=select_stock(i,select_start)\n",
    "        #print(df)\n",
    "        pure_df = pure_df.append(df)\n",
    "        ma(df)\n",
    "\n",
    "        source = MinMaxScaler()\n",
    "        data = source.fit_transform(df[['close','ma60','ma120','volume']].values)\n",
    "        df1 = pd.DataFrame(data)\n",
    "        df1['name']=i\n",
    "        df1.columns=['close','ma60','ma120','volume','name']\n",
    "        df1[['date','code']] = df[['date','code']]\n",
    "        #print(df1)\n",
    "        df2 = df2.append(df1)\n",
    "\n",
    "    pure_df.columns = map(str.lower, pure_df.columns) ## \n",
    "\n",
    "    last_df = df2.loc[df2['date'] == datelist[-1]]\n",
    "    last_close_df = last_df[last_df['close'] < 0.1]\n",
    "    last_ma_df = last_df[last_df['ma120'] < 0.1]\n",
    "    a_df = last_ma_df[last_ma_df['close'] > last_ma_df['ma60']] \n",
    "    last_ma_df = a_df[a_df['ma60'] > a_df['ma120']]\n",
    "    last_price_df = pure_df.loc[pure_df['date'] == datelist[-1]]\n",
    "    \n",
    "    for i in datelist:\n",
    "        first_df = df2.loc[df2['date'] == i]\n",
    "        first_price_df = pure_df.loc[pure_df['date'] == i]\n",
    "        one_close_df = pd.merge(first_df,last_close_df,on='code')\n",
    "        one_df = pd.merge(first_df,last_ma_df,on='code')\n",
    "        reset_close_df = last_close_df.reset_index()\n",
    "        reset_ma_df = last_ma_df.reset_index()\n",
    "        one_close_df['code']= reset_close_df['code']\n",
    "        one_df['code']= reset_ma_df['code']\n",
    "        close_df = pd.merge(first_price_df[['close','code']],one_close_df,on='code')\n",
    "        ma_df = pd.merge(first_price_df[['close','code']],one_df,on='code')        \n",
    "        two_close_df = pd.merge(last_price_df[['close','code','volume']],close_df,on='code')\n",
    "        two_df = pd.merge(last_price_df[['close','code','volume']],ma_df,on='code')\n",
    "        two_close_df.columns= ['price_y','code', 'volume_z','price_x', 'close_x', 'ma60_x', 'ma120_x', 'volume_x','name_x', 'date_x', 'close_y', 'ma60_y', 'ma120_y', 'volume_y','name_y', 'date_y']\n",
    "        two_df.columns= ['price_y','code', 'volume_z','price_x', 'close_x', 'ma60_x', 'ma120_x', 'volume_x','name_x', 'date_x', 'close_y', 'ma60_y', 'ma120_y', 'volume_y','name_y', 'date_y']\n",
    "\n",
    "        price_df = two_close_df[['name_x','code','close_x','close_y','ma60_x','ma60_y','ma120_x','ma120_y','price_x','price_y','date_x','volume_z']]\n",
    "        ma120_df = two_df[['name_x','code','close_x','close_y','ma60_x','ma60_y','ma120_x','ma120_y','price_x','price_y','date_x','volume_z']]\n",
    "        price_df['price_diff']=price_df['price_y']/price_df['price_x']\n",
    "        ma120_df['price_diff']=ma120_df['price_y']/ma120_df['price_x']\n",
    "        price_df =  price_df.sort_values([\"price_diff\"],ascending=True)\n",
    "        ma120_df =  ma120_df.sort_values([\"price_diff\"],ascending=True)\n",
    "        second_df =  first_df.sort_values([\"ma120\"],ascending=True)\n",
    "        #ma120_df['price_x']=first_price_df['close'].values\n",
    "        #ma120_df['price_y']=last_price_df['close'].values\n",
    "        strdate = i.strftime('%Y-%m-%d')\n",
    "       \n",
    "        if select_start == select_start_a:\n",
    "            ma120_df.to_excel(path_total_a+strdate+'.xlsx')\n",
    "            price_df.to_excel(path_total_c+strdate+'.xlsx')\n",
    "        else:\n",
    "            ma120_df.to_excel(path_total_b+strdate+'.xlsx')\n",
    "            second_df.to_excel(path+strdate+'.xlsx')\n",
    "            \n",
    "def total_ab_intersection( ):\n",
    "    for i in datelist:\n",
    "        strdate = i.strftime('%Y-%m-%d')\n",
    "        df_a = pd.read_excel(path_total_a+strdate+'.xlsx')\n",
    "        filter_df_a = df_a[df_a['close_y'] < 0.2]\n",
    "        df_b = pd.read_excel(path_total_b+strdate+'.xlsx')\n",
    "        #df_ab = pd.DataFrame()\n",
    "        df_ab = pd.merge(df_a[['name_x']],df_b,on='name_x')\n",
    "        filter_df_ab = pd.merge(filter_df_a[['name_x']],df_b,on='name_x')\n",
    "\n",
    "        total_df = df_ab[['name_x', 'code', 'close_x', 'close_y', 'ma60_x', 'ma60_y', 'ma120_x', 'ma120_y', 'price_x', 'price_y', 'date_x','volume_z', 'price_diff']]\n",
    "        filter_total_df = filter_df_ab[['name_x', 'code', 'close_x', 'close_y', 'ma60_x', 'ma60_y', 'ma120_x', 'ma120_y', 'price_x', 'price_y', 'date_x','volume_z', 'price_diff']]\n",
    "        total_df.to_excel(path_total+strdate+'.xlsx')\n",
    "        filter_total_df.to_excel('filter_'+path_total+strdate+'.xlsx') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  전종목 검색하여  종가 > ma120  일일 비교  하여  관심 종목 추출_9  total_a(1년분) ,total_b(11년분) 추출 및  공통종목을 추출 another method\n",
    "\n",
    "from mod1 import *\n",
    "#import pandas as pd\n",
    "\n",
    "path = 'd:\\\\test\\\\close_ma120_'\n",
    "path_total = 'd:\\\\test\\\\total_'\n",
    "path_total_a = 'd:\\\\test\\\\total_a_'\n",
    "path_total_b = 'd:\\\\test\\\\total_b_'\n",
    "path_total_c = 'd:\\\\test\\\\total_c_'\n",
    "\n",
    "#df = all_stock('2019-10-10')\n",
    "#df = df['Name']\n",
    "#name = df.to_list()\n",
    "    \n",
    "name = ['HRS','디엔에프','푸드나무','에이프로젠제약','포스코엠텍','유니켐','DB','아난티','상보','이에스에이','아스트','모트렉스','이노인스트루먼트','피앤씨테크']\n",
    "\n",
    "select_start_a = '2019-01-01'\n",
    "select_start_b = '2008-01-01'\n",
    "\n",
    "select_query = \"select * from market where Name='hrs' and Date >= '2019-10-01' \"\n",
    "df3 = pd.read_sql(select_query, engine)\n",
    "\n",
    "df3 = df3['Date']\n",
    "datelist = df3.to_list()\n",
    "    \n",
    "def search_stock(name,select_start_a,select_start_b):   \n",
    "    #print(name)\n",
    "    #print(select_start)\n",
    "    pure_df_a = pd.DataFrame()\n",
    "    df2_a = pd.DataFrame() \n",
    "    pure_df_b = pd.DataFrame()\n",
    "    df2_b = pd.DataFrame() \n",
    "    for i in name:\n",
    "        #print(i)\n",
    "        df_a=select_stock(i,select_start_a)\n",
    "        df_b=select_stock(i,select_start_b)\n",
    "        #print(df)\n",
    "        pure_df_a = pure_df_a.append(df_a)\n",
    "        pure_df_b = pure_df_b.append(df_b)\n",
    "        ma(df_a)\n",
    "        ma(df_b)\n",
    "\n",
    "        source = MinMaxScaler()\n",
    "        data_a = source.fit_transform(df_a[['close','ma60','ma120','volume']].values)\n",
    "        data_b = source.fit_transform(df_b[['close','ma60','ma120','volume']].values)\n",
    "        df1_a = pd.DataFrame(data_a)\n",
    "        df1_b = pd.DataFrame(data_b)\n",
    "        df1_a['name']=i\n",
    "        df1_b['name']=i\n",
    "        df1_a.columns=['close','ma60','ma120','volume','name']\n",
    "        df1_b.columns=['close','ma60','ma120','volume','name']\n",
    "        df1_a[['date','code','price']] = df_a[['date','code','close']]\n",
    "        df1_b[['date','code','price']] = df_b[['date','code','close']]\n",
    "        df2_a = df2_a.append(df1_a)\n",
    "        df2_b = df2_b.append(df1_b)        \n",
    "        \n",
    "    pure_df_a.columns = map(str.lower, pure_df_a.columns) ## \n",
    "    pure_df_b.columns = map(str.lower, pure_df_a.columns) ##\n",
    "    \n",
    "    pure_df_a = pure_df_a[['name','close','volume','date']]\n",
    "    pure_df_b = pure_df_b[['name','close','volume','date']]\n",
    "        \n",
    "    choice_day = pd.Timestamp('2019-09-30 00:00:00')\n",
    "    c = df2_a[df2_a['date']>choice_day]\n",
    "    d = df2_b[df2_b['date']>choice_day]\n",
    "    e = pure_df_a[pure_df_a['date']>choice_day]\n",
    "    f = pure_df_b[pure_df_b['date']>choice_day]\n",
    "    \n",
    "    last_df_a = c.loc[c['date'] == datelist[-1]]\n",
    "    last_close_df_a = last_df_a[last_df_a['close'] < 0.1]\n",
    "    last_ma_df_a = last_df_a[last_df_a['ma120'] < 0.1]\n",
    "    a_df_a = last_ma_df_a[last_ma_df_a['close'] > last_ma_df_a['ma60']] \n",
    "    last_ma_df_a = a_df_a[a_df_a['ma60'] > a_df_a['ma120']]\n",
    "    last_price_df_a = e.loc[e['date'] == datelist[-1]]\n",
    "    last_price_df_a = last_price_df_a[['name','volume']]\n",
    "    last_ma_df_a  = pd.merge(last_ma_df_a,last_price_df_a,on='name')\n",
    "\n",
    "    last_df_b = d.loc[d['date'] == datelist[-1]]\n",
    "    last_close_df_b = last_df_b[last_df_b['close'] < 0.1]\n",
    "    last_ma_df_b = last_df_b[last_df_b['ma120'] < 0.1]\n",
    "    a_df_b = last_ma_df_b[last_ma_df_b['close'] > last_ma_df_b['ma60']] \n",
    "    last_ma_df_b = a_df_b[a_df_b['ma60'] > a_df_b['ma120']]\n",
    "    last_price_df_b = f.loc[f['date'] == datelist[-1]]\n",
    "    last_price_df_b = last_price_df_b[['name','volume']]\n",
    "    last_ma_df_b  = pd.merge(last_ma_df_b,last_price_df_b,on='name')\n",
    "    \n",
    "    g = last_ma_df_a\n",
    "    h = last_ma_df_b\n",
    "    \n",
    "    a = pd.merge(c,g, on='name')\n",
    "    b = pd.merge(d,h, on='name')\n",
    "    \n",
    "    a['price_diff']=a['price_y']/a['price_x']\n",
    "    b['price_diff']=b['price_y']/b['price_x']\n",
    "    #g['volume_z'] = last_price_df_a['volume']\n",
    "    a = a[['name','code_x','close_x','close_y','ma60_x','ma60_y','ma120_x','ma120_y','price_x','price_y','date_x','volume_y','price_diff']]\n",
    "    b = b[['name','code_x','close_x','close_y','ma60_x','ma60_y','ma120_x','ma120_y','price_x','price_y','date_x','volume_y','price_diff']]\n",
    "    \n",
    "    for i in datelist:\n",
    "        t = pd.Timestamp(i)\n",
    "        first_df = a.loc[a['date_x'] == t]             ##  표준화 dataframe \n",
    "        second_df = b.loc[b['date_x'] == t] \n",
    "        strdate = t.strftime('%Y-%m-%d')\n",
    "        first_df =  first_df.sort_values([\"price_diff\"],ascending=True)\n",
    "        second_df = second_df.sort_values([\"price_diff\"],ascending=True)\n",
    "        first_df.to_excel(path_total_a+strdate+'.xlsx')  ##  표준화 dataframe 중 ma120 < 0.1 and close > ma60 > ma120 (from 2019.01.01)\n",
    "        second_df.to_excel(path_total_b+strdate+'.xlsx')  ##  표준화 dataframe 중 ma120 < 0.1 and close > ma60 > ma120 (from 2008.01.01) \n",
    "        \n",
    "search_stock(name,select_start_a,select_start_b)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mod1 import *\n",
    "#import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "#from pandas.core.common import SettingWithCopyWarning\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
    "\n",
    "path = 'd:\\\\test\\\\close_ma120_'\n",
    "path_total = 'd:\\\\test\\\\total_'\n",
    "path_total_a = 'd:\\\\test\\\\total_a_'\n",
    "path_total_b = 'd:\\\\test\\\\total_b_'\n",
    "path_total_c = 'd:\\\\test\\\\total_c_'\n",
    "path_total_f = 'd:\\\\test\\\\total_filter_'\n",
    "\n",
    "#df = all_stock('2019-10-10')\n",
    "#df = df['Name']\n",
    "#name = df.to_list()\n",
    "    \n",
    "name = ['hrs','디엔에프','푸드나무','화성밸브','미래생명자원','웹케시']\n",
    "\n",
    "select_start_a = '2019-01-01'\n",
    "select_start_b = '2008-01-01'\n",
    "\n",
    "select_query = \"select * from market where Name='hrs' and Date >= '2019-10-01' \"\n",
    "df3 = pd.read_sql(select_query, engine)\n",
    "\n",
    "df3 = df3['Date']\n",
    "datelist = df3.to_list()\n",
    "    \n",
    "def search_stock(name,select_start):   \n",
    "    print(name)\n",
    "    print(select_start)\n",
    "    pure_df = pd.DataFrame()\n",
    "    df2 = pd.DataFrame() \n",
    "    for i in name:\n",
    "        #print(i)\n",
    "        df=select_stock(i,select_start)\n",
    "        #print(df)\n",
    "        pure_df = pure_df.append(df)\n",
    "        ma(df)\n",
    "\n",
    "        source = MinMaxScaler()\n",
    "        data = source.fit_transform(df[['close','ma60','ma120','volume']].values)\n",
    "        df1 = pd.DataFrame(data)\n",
    "        df1['name']=i\n",
    "        df1.columns=['close','ma60','ma120','volume','name']\n",
    "        df1[['date','code']] = df[['date','code']]\n",
    "        #print(df1)\n",
    "        df2 = df2.append(df1)\n",
    "\n",
    "    pure_df.columns = map(str.lower, pure_df.columns) ## \n",
    "\n",
    "    last_df = df2.loc[df2['date'] == datelist[-1]]\n",
    "    last_close_df = last_df[last_df['close'] < 0.1]\n",
    "    last_ma_df = last_df[last_df['ma120'] < 0.1]\n",
    "    a_df = last_ma_df[last_ma_df['close'] > last_ma_df['ma60']] \n",
    "    last_ma_df = a_df[a_df['ma60'] > a_df['ma120']]\n",
    "    last_price_df = pure_df.loc[pure_df['date'] == datelist[-1]]\n",
    "    \n",
    "    for i in datelist:\n",
    "        first_df = df2.loc[df2['date'] == i]\n",
    "        first_price_df = pure_df.loc[pure_df['date'] == i]\n",
    "        one_close_df = pd.merge(first_df,last_close_df,on='code')\n",
    "        one_df = pd.merge(first_df,last_ma_df,on='code')\n",
    "        reset_close_df = last_close_df.reset_index()\n",
    "        reset_ma_df = last_ma_df.reset_index()\n",
    "        one_close_df['code']= reset_close_df['code']\n",
    "        one_df['code']= reset_ma_df['code']\n",
    "        close_df = pd.merge(first_price_df[['close','code']],one_close_df,on='code')\n",
    "        ma_df = pd.merge(first_price_df[['close','code']],one_df,on='code')        \n",
    "        two_close_df = pd.merge(last_price_df[['close','code','volume']],close_df,on='code')\n",
    "        two_df = pd.merge(last_price_df[['close','code','volume']],ma_df,on='code')\n",
    "        two_close_df.columns= ['price_y','code', 'volume_z','price_x', 'close_x', 'ma60_x', 'ma120_x', 'volume_x','name_x', 'date_x', 'close_y', 'ma60_y', 'ma120_y', 'volume_y','name_y', 'date_y']\n",
    "        two_df.columns= ['price_y','code', 'volume_z','price_x', 'close_x', 'ma60_x', 'ma120_x', 'volume_x','name_x', 'date_x', 'close_y', 'ma60_y', 'ma120_y', 'volume_y','name_y', 'date_y']\n",
    "\n",
    "        price_df = two_close_df[['name_x','code','close_x','close_y','ma60_x','ma60_y','ma120_x','ma120_y','price_x','price_y','date_x','volume_z']]\n",
    "        ma120_df = two_df[['name_x','code','close_x','close_y','ma60_x','ma60_y','ma120_x','ma120_y','price_x','price_y','date_x','volume_z']]\n",
    "        price_df['price_diff']=price_df['price_y']/price_df['price_x']\n",
    "        ma120_df['price_diff']=ma120_df['price_y']/ma120_df['price_x']\n",
    "        price_df =  price_df.sort_values([\"price_diff\"],ascending=True)\n",
    "        ma120_df =  ma120_df.sort_values([\"price_diff\"],ascending=True)\n",
    "        second_df =  first_df.sort_values([\"ma120\"],ascending=True)\n",
    "        #ma120_df['price_x']=first_price_df['close'].values\n",
    "        #ma120_df['price_y']=last_price_df['close'].values\n",
    "        strdate = i.strftime('%Y-%m-%d')\n",
    "       \n",
    "        if select_start == select_start_a:\n",
    "            ma120_df.to_excel(path_total_a+strdate+'.xlsx')\n",
    "            price_df.to_excel(path_total_c+strdate+'.xlsx')\n",
    "        else:\n",
    "            ma120_df.to_excel(path_total_b+strdate+'.xlsx')\n",
    "            second_df.to_excel(path+strdate+'.xlsx')\n",
    "\n",
    "def total_ab_intersection( ):\n",
    "    for i in datelist:\n",
    "        strdate = i.strftime('%Y-%m-%d')\n",
    "        df_a = pd.read_excel(path_total_a+strdate+'.xlsx')\n",
    "        filter_df_a = df_a[df_a['close_y'] < 0.2]\n",
    "        df_b = pd.read_excel(path_total_b+strdate+'.xlsx')\n",
    "        #df_ab = pd.DataFrame()\n",
    "        df_ab = pd.merge(df_a[['name_x']],df_b,on='name_x')\n",
    "        filter_df_ab = pd.merge(filter_df_a[['name_x']],df_b,on='name_x')\n",
    "\n",
    "        total_df = df_ab[['name_x', 'code', 'close_x', 'close_y', 'ma60_x', 'ma60_y', 'ma120_x', 'ma120_y', 'price_x', 'price_y', 'date_x','volume_z', 'price_diff']]\n",
    "        filter_total_df = filter_df_ab[['name_x', 'code', 'close_x', 'close_y', 'ma60_x', 'ma60_y', 'ma120_x', 'ma120_y', 'price_x', 'price_y', 'date_x','volume_z', 'price_diff']]\n",
    "        total_df.to_excel(path_total+strdate+'.xlsx')\n",
    "        filter_total_df.to_excel(path_total_f+strdate+'.xlsx') \n",
    "            \n",
    "            \n",
    "#search_stock(name,select_start_b)\n",
    "total_ab_intersection( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vote_stock volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from mod1 import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "\n",
    "def close_ma(df,select1,select2):\n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close',select1,select2]].values)\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1.columns=['close',select1,select2]\n",
    "    df1 = df1.set_index(df['date'])\n",
    "    df1.plot(figsize=(16,4))\n",
    "    plt.title(df['name'][0])\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def close_ma_vol(df,select1,select2,select3):\n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close',select1,select2,select3]].values)\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1.columns=['close',select1,select2,select3]\n",
    "    df1 = df1.set_index(df['date'])\n",
    "    df1.plot(figsize=(16,4))\n",
    "    plt.title(df['name'][0])\n",
    "    plt.grid(True)\n",
    "    plt.show()    \n",
    "    \n",
    "    \n",
    "path = 'd:\\\\stockdata\\\\close_ma120\\\\close_ma120_'\n",
    "path_total_f = 'd:\\\\stockdata\\\\close_ma120\\\\total_filter_'\n",
    "path_price = 'd:\\\\stockdata\\\\vote_stock\\\\detect_stock_with_price_'\n",
    "path_volume = 'd:\\\\stockdata\\\\vote_stock\\\\detect_stock_with_volume_'\n",
    "\n",
    "choice_date='2020-01-02'\n",
    "df_volume = pd.read_excel(path_volume+choice_date+'.xlsx')\n",
    "name_volume = df_volume['Name']\n",
    "#name = name_volume.to_list()\n",
    "name = ['한국화장품','HRS','디엔에프','푸드나무','에이프로젠제약','포스코엠텍','유니켐','DB','아난티','상보','이에스에이','아스트','모트렉스','이노인스트루먼트','피앤씨테크']\n",
    "\n",
    "\n",
    "for i in name:\n",
    "#for i in name_volume:\n",
    "    #df = select_stock(i,choice_date)\n",
    "    df = select_stock(i, '2018-01-03')\n",
    "    close_ma_vol(df,'ma60','ma120','volume')\n",
    "    #close_ma(df,'ma5','ma20','volume')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykrx.stock.api import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_shorting_status_by_date('20191211','2019125','067390')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykrx.stock import api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vote_stock price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from mod1 import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "\n",
    "def close_ma(df,select1,select2):\n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close',select1,select2]].values)\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1.columns=['close',select1,select2]\n",
    "    df1 = df1.set_index(df['date'])\n",
    "    df1.plot(figsize=(16,4))\n",
    "    plt.title(df['name'][0])\n",
    "    plt.show()\n",
    "\n",
    "def close_ma_vol(df,select1,select2,select3):\n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close',select1,select2,select3]].values)\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1.columns=['close',select1,select2,select3]\n",
    "    df1 = df1.set_index(df['date'])\n",
    "    df1.plot(figsize=(16,4))\n",
    "    plt.title(df['name'][0])\n",
    "    plt.show()    \n",
    "    \n",
    "    \n",
    "path = 'd:\\\\stockdata\\\\close_ma120\\\\close_ma120_'\n",
    "path_total_f = 'd:\\\\stockdata\\\\close_ma120\\\\total_filter_'\n",
    "path_price = 'd:\\\\stockdata\\\\vote_stock\\\\detect_stock_with_price_'\n",
    "path_volume = 'd:\\\\stockdata\\\\vote_stock\\\\detect_stock_with_volume_'\n",
    "\n",
    "choice_date='2020-01-02'\n",
    "df_price = pd.read_excel(path_price+choice_date+'.xlsx')\n",
    "name_price = df_price['Name']\n",
    "#name = name_df.to_list()\n",
    "#name=['hrs','디엔에프','푸드나무','이에스브이']\n",
    "\n",
    "for i in name_price:\n",
    "    #df = select_stock(i,choice_date)\n",
    "    df = select_stock(i, '2010-01-03')\n",
    "    #close_ma_vol(df,'ma60','ma120','volume')\n",
    "    close_ma_vol(df,'ma60','ma120','volume')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# close_ma120 filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from mod1 import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "\n",
    "def close_ma(df,select1,select2):\n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close',select1,select2]].values)\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1.columns=['close',select1,select2]\n",
    "    df1 = df1.set_index(df['date'])\n",
    "    df1.plot(figsize=(16,4))\n",
    "    plt.grid(True)\n",
    "    plt.title(df['name'][0])\n",
    "    plt.show()\n",
    "\n",
    "def close_ma_vol(df,select1,select2,select3):\n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close',select1,select2,select3]].values)\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1.columns=['close',select1,select2,select3]\n",
    "    df1 = df1.set_index(df['date'])\n",
    "    df1.plot(figsize=(16,4))\n",
    "    plt.grid(True)\n",
    "    plt.title(df['name'][0])\n",
    "    plt.show()    \n",
    "    \n",
    "    \n",
    "path = 'd:\\\\stockdata\\\\close_ma120\\\\close_ma120_'\n",
    "path_total_f = 'd:\\\\stockdata\\\\close_ma120\\\\total_filter_'\n",
    "path_total_c = 'd:\\\\stockdata\\\\close_ma120\\\\total_c_'\n",
    "path_total_b = 'd:\\\\stockdata\\\\close_ma120\\\\total_b_'\n",
    "path_price = 'd:\\\\stockdata\\\\vote_stock\\\\detect_stock_with_price_'\n",
    "path_volume = 'd:\\\\stockdata\\\\vote_stock\\\\detect_stock_with_volume_'\n",
    "\n",
    "choice_date='2019-10-01'\n",
    "df = pd.read_excel(path_total_b+choice_date+'.xlsx')\n",
    "name = df['name_x']\n",
    "#name=['hrs','디엔에프','푸드나무','이에스브이']\n",
    "\n",
    "for i in name:\n",
    "    #df = select_stock(i,choice_date)\n",
    "    df = select_stock(i,'2010-01-01')\n",
    "    close_ma(df,'ma60','ma120')\n",
    "    #close_ma(df,'ma10','ma20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from mod1 import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "\n",
    "def close_ma(df,select1,select2):\n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close',select1,select2]].values)\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1.columns=['close',select1,select2]\n",
    "    df1 = df1.set_index(df['date'])\n",
    "    df1.plot(figsize=(16,4))\n",
    "    plt.grid(True)\n",
    "    plt.title(df['name'][0])\n",
    "    plt.show()\n",
    "\n",
    "def close_ma_vol(df,select1,select2,select3):\n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close',select1,select2,select3]].values)\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1.columns=['close',select1,select2,select3]\n",
    "    df1 = df1.set_index(df['date'])\n",
    "    df1.plot(figsize=(16,4))\n",
    "    plt.grid(True)\n",
    "    plt.title(df['name'][0])\n",
    "    plt.show()    \n",
    "    \n",
    "    \n",
    "path = 'd:\\\\stockdata\\\\close_ma120\\\\close_ma120_'\n",
    "path_total_f = 'd:\\\\stockdata\\\\close_ma120\\\\total_filter_'\n",
    "path_total_c = 'd:\\\\stockdata\\\\close_ma120\\\\total_c_'\n",
    "path_total_b = 'd:\\\\stockdata\\\\close_ma120\\\\total_b_'\n",
    "path_price = 'd:\\\\stockdata\\\\vote_stock\\\\detect_stock_with_price_'\n",
    "path_volume = 'd:\\\\stockdata\\\\vote_stock\\\\detect_stock_with_volume_'\n",
    "\n",
    "choice_date='2019-10-01'\n",
    "df = pd.read_excel(path_total_f+choice_date+'.xlsx')\n",
    "name = df['name_x']\n",
    "#name=['hrs','디엔에프','푸드나무','이에스브이']\n",
    "\n",
    "for i in name:\n",
    "    #df = select_stock(i,choice_date)\n",
    "    df = select_stock(i,'2012-12-30')\n",
    "    #close_ma(df,'ma60','ma120')\n",
    "    close_ma_vol(df,'ma60','ma120','volume')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from mod1 import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "\n",
    "def close_ma(df,select1,select2):\n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close',select1,select2]].values)\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1.columns=['close',select1,select2]\n",
    "    df1 = df1.set_index(df['date'])\n",
    "    df1.plot(figsize=(16,4))\n",
    "    plt.title(df['name'][0])\n",
    "    plt.show()\n",
    "\n",
    "path = 'd:\\\\stockdata\\\\close_ma120\\\\close_ma120_'\n",
    "path_total_f = 'd:\\\\stockdata\\\\close_ma120\\\\total_filter_'\n",
    "\n",
    "choice_date='2019-10-01'\n",
    "df = pd.read_excel(path_total_f +choice_date+'.xlsx')\n",
    "#df = df.sort_values([\"close_y\"],ascending=True)\n",
    "name_df = df['name_x']\n",
    "name = name_df.to_list()\n",
    "name.insert(0,'hrs')\n",
    "#name=['hrs','디엔에프','푸드나무','에스퓨얼셀']\n",
    "\n",
    "\n",
    "for i in name:\n",
    "    df = select_stock(i, '2010-01-01')\n",
    "    close_ma(df,'ma60','ma120')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "###  관심종목 ma60, ma120, cci 그래프 생성\n",
    "\n",
    "from mod1 import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "\n",
    "def close_ma(df,select1,select2,select3):\n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close',select1,select2,select3]].values)\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1.columns=['close',select1,select2,select3]\n",
    "    df1 = df1.set_index(df['date'])\n",
    "    df1.plot(figsize=(16,4))\n",
    "    plt.title(df['name'][0])\n",
    "    plt.show()\n",
    "\n",
    "path = 'd:\\\\stockdata\\\\close_ma120\\\\close_ma120_'\n",
    "path_total = 'd:\\\\stockdata\\\\close_ma120\\\\total_'\n",
    "path_total_f = 'd:\\\\stockdata\\\\close_ma120\\\\total_filter_'\n",
    "\n",
    "choice_date='2019-10-01'\n",
    "df = pd.read_excel(path_total_f+choice_date+'.xlsx')\n",
    "name_df = df['name_x']\n",
    "name = name_df.to_list()\n",
    "name.insert(0,'hrs')\n",
    "name=['hrs','디엔에프','푸드나무','에스퓨얼셀','에어부산','HDC아이콘트롤스','유니슨','엔시트론','데일리블록체인']\n",
    "\n",
    "pure_df = pd.DataFrame()\n",
    "df2 = pd.DataFrame()\n",
    "cci_df = pd.DataFrame()\n",
    "for i in name:\n",
    "    #print(i)\n",
    "    df=select_stock(i,'2010-01-01')\n",
    "    cci_df[['open','high','low','volume','close']] = df[['Open','High','Low','Volume','Close']].astype(float) #  TA-Lib로 평균을 구하려면 실수로 만들어야 함\n",
    "    period = 60\n",
    "    cci_df['cci'] = ta.CCI(cci_df, timeperiod=period)\n",
    "    df['cci'] = cci_df['cci']\n",
    "    close_ma(df,'cci','ma60','ma120')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###  관심종목 ma60, ma120, cci 그래프 생성\n",
    "\n",
    "from mod1 import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "\n",
    "def cci_ma2(df,select1,select2,select3):\n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close',select1,select2,select3]].values)\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1.columns=['close',select1,select2,select3]\n",
    "    df1 = df1.set_index(df['date'])\n",
    "    df1.plot(figsize=(16,4))\n",
    "    plt.title(df['name'][0])\n",
    "    plt.show()\n",
    "\n",
    "path = 'd:\\\\stockdata\\\\close_ma120\\\\close_ma120_'\n",
    "path_total = 'd:\\\\stockdata\\\\close_ma120\\\\total_'\n",
    "\n",
    "choice_date = '2019-10-01'\n",
    "df = pd.read_excel(path_total+choice_date+'.xlsx')\n",
    "df = df['name']\n",
    "name = df.to_list()\n",
    "\n",
    "#name=['hrs','손오공']\n",
    "\n",
    "pure_df = pd.DataFrame()\n",
    "df2 = pd.DataFrame()\n",
    "cci_df = pd.DataFrame()\n",
    "for i in name:\n",
    "    #print(i)\n",
    "    df=select_stock(i,'2010-01-01')\n",
    "    cci_df[['open','high','low','volume','close']] = df[['Open','High','Low','Volume','Close']].astype(float) #  TA-Lib로 평균을 구하려면 실수로 만들어야 함\n",
    "    period = 120\n",
    "    cci_df['cci'] = ta.CCI(cci_df, timeperiod=period)\n",
    "    df['cci'] = cci_df['cci']\n",
    "    cci_ma2(df,'cci','ma60','ma120')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ab.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from mod1 import * \n",
    "\n",
    "def close_ma(df,select1,select2):\n",
    "    ma(df)\n",
    "\n",
    "    source = MinMaxScaler()\n",
    "    data = source.fit_transform(df[['close',select1,select2]].values)\n",
    "    df1 = pd.DataFrame(data)\n",
    "    df1.columns=['close',select1,select2]\n",
    "    df1 = df1.set_index(df['date'])\n",
    "    df1.plot(figsize=(16,4))\n",
    "    plt.title(df['name'][0])\n",
    "    plt.show()\n",
    "    \n",
    "#df = df_ab['name_x']\n",
    "#name = df.to_list()\n",
    "name=['hrs','디엔에프','푸드나무','에스퓨얼셀','에어부산','HDC아이콘트롤스','유니슨','엔시트론','데일리블록체인']\n",
    "\n",
    "for i in name:\n",
    "    df = select_stock(i, '2015-01-01')\n",
    "    close_ma(df,'ma60','ma120')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 일별 관리종목 추출\n",
    "\n",
    "from  datetime import datetime\n",
    "import pandas as pd\n",
    "import xlsxwriter\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "today = datetime.now()\n",
    "today = today.strftime(\"%Y-%m-%d\")\n",
    "#today=input('입력')\n",
    "#url = 'http://finance.naver.com/sise/investorDealTrendDay.nhn?bizdate=2020601&sosok=&page=1'\n",
    "url = 'https://finance.naver.com/sise/management.nhn'\n",
    "source = urlopen(url).read()   # 지정한 페이지에서 코드 읽기\n",
    "source = BeautifulSoup(source, 'lxml')   # 뷰티풀 스프로 태그별로 코드 분류\n",
    "data = []\n",
    "\n",
    "path = 'd:\\\\stockdata\\\\관리종목\\\\'+today+'.xlsx'\n",
    "body = source.find('body')\n",
    "trs = body.find_all('tr')\n",
    "name = []\n",
    "for tr in trs:\n",
    "    tds = tr.find_all('a',{'class':\"tltle\"})\n",
    "    for td in tds:\n",
    "        name.append(td.text.strip())\n",
    "\n",
    "df = pd.DataFrame(name)\n",
    "df['Date']=str(today)\n",
    "df = df.set_index('Date')\n",
    "df.columns=['Name']\n",
    "df.to_excel(path)\n",
    "df = pd.read_excel(path)\n",
    "\n",
    "df.to_sql(name='badstock', con=engine, if_exists='append', index = False)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mod1 import *\n",
    "\n",
    "df = select_stock('hrs','2017-10-01')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mod1 import *\n",
    "\n",
    "df = select_stock('hrs','2010-10-01')\n",
    "df.columns=df.columns.str.lower()\n",
    "df[['volume','close']] = df[['volume','close']].astype(float) #  TA-Lib로 평균을 구하려면 실수로 만들어야 함\n",
    "\n",
    "# ta-lib로 5기간 종가 이동평균 계산\n",
    "talib_ma120 = ta.MA(df, timeperiod=120)\n",
    "df['ma120'] = talib_ma120\n",
    "# pandas 기능을 이용하여 5기간 이동평균 계산\n",
    "pandas_ma120 = df.close.rolling(window=120).mean() \n",
    "\n",
    "talib_ma120.equals(pandas_ma120)\n",
    "# True / 결과는 같음  \n",
    "\n",
    "vol_ma120 = df.volume.rolling(window=120).mean() \n",
    "df['vol_ma120'] = vol_ma120\n",
    "\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.scatter(df['vol_ma120'],df['ma120'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "plt.scatter(df['Volume'],df['Close'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1e7*16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mod1 import *\n",
    "#import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "#from pandas.core.common import SettingWithCopyWarning\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
    "\n",
    "path = 'd:\\\\test\\\\close_ma120_'\n",
    "path_total = 'd:\\\\test\\\\total_'\n",
    "path_total_a = 'd:\\\\test\\\\total_a_'\n",
    "path_total_b = 'd:\\\\test\\\\total_b_'\n",
    "path_total_c = 'd:\\\\test\\\\total_c_'\n",
    "path_total_f = 'd:\\\\test\\\\total_filter_'\n",
    "\n",
    "#df = all_stock('2019-10-10')\n",
    "#df = df['Name']\n",
    "#name = df.to_list()\n",
    "    \n",
    "name = ['hrs','디엔에프','푸드나무','화성밸브','미래생명자원','웹케시']\n",
    "\n",
    "select_start_a = '2019-01-01'\n",
    "select_start_b = '2008-01-01'\n",
    "\n",
    "select_query = \"select distinct name from market \"\n",
    "df3 = pd.read_sql(select_query, engine)\n",
    "\n",
    "df3.to_excel('d:\\\\market_name.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 기존에 액면분할시 가격조정 안된 기존 data가 있을때\n",
    "## insert mysql 개별 주식\n",
    "\n",
    "Code = input('주식 Code를 입력하세요')\n",
    "Name = input('주식이름을 입력하세요')\n",
    "\n",
    "query = \"delete from  market where Code = \"+\"'\"+Code+\"'\"\n",
    "\n",
    "curs.execute(query)\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "df = fdr.DataReader(Code, '1995')\n",
    "df.to_excel('d:\\\\'+Code+'.xlsx', encoding='UTF-8')\n",
    "\n",
    "df = pd.read_excel('d:\\\\'+Code+'.xlsx')\n",
    "df['Code']= Code\n",
    "df['Name']= Name\n",
    "\n",
    "df = df[['Date','Code','Name','Open', 'High', 'Low', 'Volume','Close']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "###  선물크롤링하여 맨처음 DB에 future table생성할때\n",
    "\n",
    "# 2019-09-11 수정  mysql future table에서 최종 날짜를 확인해서 그뒤날부터 insert \n",
    "# 기존 daum 주식 사이트 : ajax 방식으로 변경으로 인해 이를 반영한 코드를 수정.\n",
    "# pip install fake-useragent 설치 후 실행 가능\n",
    "\n",
    "import io\n",
    "import json\n",
    "import sys\n",
    "import pandas as pd\n",
    "import sqlalchemy \n",
    "import urllib.request as req\n",
    "from datetime import datetime\n",
    "from fake_useragent import UserAgent\n",
    "\n",
    "engine = sqlalchemy.create_engine('mysql+pymysql://kkang:leaf2027@localhost/stock?charset=utf8',encoding='utf-8')\n",
    "\n",
    "\n",
    "# Fake Header 정보\n",
    "ua = UserAgent()\n",
    "\n",
    "# 헤더 선언\n",
    "headers = {\n",
    "    'User-Agent': ua.ie,\n",
    "    'referer': 'http://finance.daum.net/domestic/futures'\n",
    "}\n",
    "\n",
    "\n",
    "url = \"http://finance.daum.net/api/future/KR4101Q30005/days?pagination=true&page=1\"\n",
    "res = req.urlopen(req.Request(url, headers=headers)).read().decode('utf-8')\n",
    "\n",
    "df1 = pd.DataFrame()\n",
    "for i in range(1,7):\n",
    "    # 다음 주식 요청 URL\n",
    "    url = \"http://finance.daum.net/api/future/KR4101Q30005/days?pagination=true&page=\"+str(i)\n",
    "\n",
    "    res = req.urlopen(req.Request(url, headers=headers)).read().decode('utf-8')\n",
    "    \n",
    "    rank_json = json.loads(res)['data']\n",
    "    \n",
    "    df = pd.DataFrame(rank_json)\n",
    "    df1 = df1.append(df,ignore_index=True)\n",
    "    \n",
    "df2 = df1[['date','tradePrice','change', 'changePrice','changeRate','unsettledVolume','foreignSettlement', 'institutionSettlement', 'privateSettlement']]\n",
    "df2.columns=('Date','Future','change','가격변동','등락률','미결제약정','외국인','기관','개인')\n",
    "df2['Date'] = pd.to_datetime(df2['Date']).dt.date\n",
    "#df2['Date'] = pd.to_datetime(df2['Date']).apply(lambda x: x.date())\n",
    "#df2['Date'] = pd.to_datetime(df2['Date'], format = '%Y-%m-%d') # yyyy-mm-dd hh:mm:ss -> yyyy-mm-dd (속성은그대로 보여주는 형식만 변경)\n",
    "df2 =df2[['Date','Future','미결제약정','외국인','기관','개인']]\n",
    "#df2 = df2[df2.Date > until_date]\n",
    "df2.to_sql(name='future', con=engine, if_exists='append', index = False)\n",
    "df2 = df2.set_index('Date')\n",
    "df2.to_excel('d:\\\\future.xlsx',encoding='utf-8')\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mod1 import *\n",
    "\n",
    "## 선물  베이시스 graph ( One_graph)\n",
    "## def future_trend_graph():\n",
    "   \n",
    "\n",
    "#query = \"select * from future where Date > '2019-06-13'\"+\"'\"+date+\"'\"\n",
    "query = \"select * from basis where Date > '2019-12-11'\"\n",
    "\n",
    "\n",
    "name=['kpi200','Future']\n",
    "#name=['미결제약정']\n",
    "\n",
    "tuple_name=tuple(name)\n",
    "df1 = pd.DataFrame()\n",
    "    \n",
    "df = pd.read_sql(query ,engine)\n",
    "\n",
    "#df.columns=['Date','kpi200','Close']\n",
    "df = df.set_index('Date')\n",
    "df1=df[name]\n",
    "\n",
    "plt.figure(figsize=(16,4))    \n",
    "for i in range(len(name)):\n",
    "    plt.plot(df1[name[i]]/df1[name[i]].loc[df.index[0]]*100, label=name[i])\n",
    "        \n",
    "#plt.legend(loc=0)\n",
    "plt.legend(loc=0)\n",
    "plt.grid(True,color='0.7',linestyle=':',linewidth=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mod1 import *\n",
    "\n",
    "df = select_stock('hrs','2010-01-01')\n",
    "    \n",
    "df.to_csv('d:\\\\hrs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "37810821*1155"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fix_yahoo_finance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
