{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Crawling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import FinanceDataReader as fdr\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime as dt\n",
    "from datetime import datetime,timedelta\n",
    "from urllib.request import urlopen\n",
    "import sqlalchemy \n",
    "import pymysql\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "from matplotlib import font_manager, rc\n",
    "font_name = font_manager.FontProperties(fname=\"c:/Windows/Fonts/malgun.ttf\").get_name()\n",
    "rc('font', family=font_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MoneyTrend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_money_trend():\n",
    "    \n",
    "    url = 'http://finance.naver.com/sise/sise_deposit.nhn?&page='\n",
    "\n",
    "    source = urlopen(url).read()   # 지정한 페이지에서 코드 읽기\n",
    "    source = BeautifulSoup(source, 'lxml')   # 뷰티풀 스프로 태그별로 코드 분류\n",
    "\n",
    "    last = source.find('td',class_='pgRR').find('a')['href']\n",
    "    last = last.split('&')[1]\n",
    "    last = last.split('=')[1]\n",
    "    last = int(last)\n",
    "\n",
    "    # 사용자의 PC내 폴더 주소를 입력하시면 됩니다.\n",
    "    path = 'd:\\\\moneytrend.xlsx'   \n",
    "    \n",
    "    # 날짜를 받을 리스트\n",
    "    date_list = []\n",
    "\n",
    "    # 값을 받을 사전\n",
    "    dictionary = {'고객예탁금': [],'신용잔고': [],'주식형 펀드': [],'혼합형 펀드': [],'채권형 펀드': []}\n",
    "\n",
    "    # dictionary key 인덱싱을 위한 리스트\n",
    "    name_list = ['고객예탁금','신용잔고','주식형 펀드','혼합형 펀드','채권형 펀드']\n",
    "\n",
    "\n",
    "    # count mask\n",
    "    mask = [1,3,5,7,9]\n",
    "    \n",
    "    for i in range(1,last+1):\n",
    "        \n",
    "        source = urlopen(url+ str(i)).read()\n",
    "        source = BeautifulSoup(source,'lxml')\n",
    "\n",
    "        #tbody = source.find('div',{'id':'wrap'}).find('div',{'class':'box_type_m'})\n",
    "        #trs = tbody.find_all('tr')\n",
    "\n",
    "        body = source.find('body')\n",
    "        trs = body.find_all('tr')\n",
    "\n",
    "        for tr in trs:\n",
    "            tds = tr.find_all('td',{'class':['date','rate_down','rate_up']})\n",
    "            count = 0\n",
    "    \n",
    "            for td in tds:\n",
    "                if count == 0:\n",
    "                    date_ = td.text.strip().replace('.','-')\n",
    "                    date_list.append(date_)\n",
    "                        \n",
    "                      \n",
    "                elif count in mask:\n",
    "                    temp = int((count-1)/2)\n",
    "                    dictionary[name_list[temp]].append(td.text.strip().replace(',',''))\n",
    "        \n",
    "                count += 1\n",
    "            if len(dictionary['고객예탁금']) != len(dictionary['채권형 펀드']):\n",
    "                print(str(i)+ '번째 페이지에서 누락된 값 발생')\n",
    "                print('누락된 데이터를 제거합니다')\n",
    "                    \n",
    "                date_list.pop(-1)\n",
    "                dictionary['고객예탁금'].pop(-1)\n",
    "                dictionary['신용잔고'].pop(-1)\n",
    "                dictionary['주식형 펀드'].pop(-1)\n",
    "                dictionary['혼합형 펀드'].pop(-1)\n",
    "                \n",
    "    # 개별 list 요소 갯수 파악 \n",
    "    #print(len(date_list))\n",
    "    #print(len(dictionary['고객예탁금']))\n",
    "    #print(len(dictionary['신용잔고']))\n",
    "    #print(len(dictionary['주식형 펀드']))\n",
    "    #print(len(dictionary['혼합형 펀드']))\n",
    "    #print(len(dictionary['채권형 펀드']))\n",
    "    print(str(i) + '번째 페이지 크롤링 완료')\n",
    "    df = pd.DataFrame(dictionary,index = date_list)\n",
    "    df = df.sort_index()\n",
    "    df.to_excel(path, encoding='utf-8')\n",
    "    print(df)\n",
    "\n",
    "\n",
    "get_money_trend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "날짜를 입력하세요 sample: '2019-01-10': 2019-07-01\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>고객예탁금</th>\n",
       "      <th>신용잔고</th>\n",
       "      <th>주식형 펀드</th>\n",
       "      <th>혼합형 펀드</th>\n",
       "      <th>채권형 펀드</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19-07-02</th>\n",
       "      <td>249327</td>\n",
       "      <td>102014</td>\n",
       "      <td>810117</td>\n",
       "      <td>267668</td>\n",
       "      <td>1187303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-07-03</th>\n",
       "      <td>245303</td>\n",
       "      <td>101285</td>\n",
       "      <td>806478</td>\n",
       "      <td>267931</td>\n",
       "      <td>1189882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-07-04</th>\n",
       "      <td>246573</td>\n",
       "      <td>101509</td>\n",
       "      <td>806966</td>\n",
       "      <td>267577</td>\n",
       "      <td>1191866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-07-05</th>\n",
       "      <td>244098</td>\n",
       "      <td>101908</td>\n",
       "      <td>806254</td>\n",
       "      <td>267246</td>\n",
       "      <td>1191666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-07-08</th>\n",
       "      <td>249578</td>\n",
       "      <td>101685</td>\n",
       "      <td>801271</td>\n",
       "      <td>267835</td>\n",
       "      <td>1193273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-07-09</th>\n",
       "      <td>245999</td>\n",
       "      <td>101470</td>\n",
       "      <td>800163</td>\n",
       "      <td>267431</td>\n",
       "      <td>1196568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-07-10</th>\n",
       "      <td>243732</td>\n",
       "      <td>100741</td>\n",
       "      <td>799399</td>\n",
       "      <td>267512</td>\n",
       "      <td>1195346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-07-11</th>\n",
       "      <td>241386</td>\n",
       "      <td>98951</td>\n",
       "      <td>802245</td>\n",
       "      <td>267814</td>\n",
       "      <td>1197854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-07-12</th>\n",
       "      <td>242357</td>\n",
       "      <td>98681</td>\n",
       "      <td>803167</td>\n",
       "      <td>267776</td>\n",
       "      <td>1199725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-07-15</th>\n",
       "      <td>249210</td>\n",
       "      <td>98777</td>\n",
       "      <td>804104</td>\n",
       "      <td>267627</td>\n",
       "      <td>1200156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-07-16</th>\n",
       "      <td>238733</td>\n",
       "      <td>99272</td>\n",
       "      <td>805791</td>\n",
       "      <td>267646</td>\n",
       "      <td>1202023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-07-17</th>\n",
       "      <td>239065</td>\n",
       "      <td>99648</td>\n",
       "      <td>802964</td>\n",
       "      <td>267828</td>\n",
       "      <td>1203694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-07-18</th>\n",
       "      <td>244744</td>\n",
       "      <td>99827</td>\n",
       "      <td>801783</td>\n",
       "      <td>267729</td>\n",
       "      <td>1205610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-07-19</th>\n",
       "      <td>244479</td>\n",
       "      <td>99833</td>\n",
       "      <td>806933</td>\n",
       "      <td>267574</td>\n",
       "      <td>1206755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-07-22</th>\n",
       "      <td>241833</td>\n",
       "      <td>99736</td>\n",
       "      <td>805981</td>\n",
       "      <td>268322</td>\n",
       "      <td>1204910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-07-23</th>\n",
       "      <td>242129</td>\n",
       "      <td>99451</td>\n",
       "      <td>807415</td>\n",
       "      <td>272576</td>\n",
       "      <td>1206357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-07-24</th>\n",
       "      <td>241131</td>\n",
       "      <td>99822</td>\n",
       "      <td>804661</td>\n",
       "      <td>272530</td>\n",
       "      <td>1207924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-07-25</th>\n",
       "      <td>244278</td>\n",
       "      <td>99805</td>\n",
       "      <td>803018</td>\n",
       "      <td>272481</td>\n",
       "      <td>1210819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-07-26</th>\n",
       "      <td>248585</td>\n",
       "      <td>98998</td>\n",
       "      <td>802480</td>\n",
       "      <td>272205</td>\n",
       "      <td>1211688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-07-29</th>\n",
       "      <td>245195</td>\n",
       "      <td>97742</td>\n",
       "      <td>795191</td>\n",
       "      <td>272078</td>\n",
       "      <td>1213904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-07-30</th>\n",
       "      <td>242994</td>\n",
       "      <td>96489</td>\n",
       "      <td>795857</td>\n",
       "      <td>272006</td>\n",
       "      <td>1211852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-07-31</th>\n",
       "      <td>241078</td>\n",
       "      <td>94518</td>\n",
       "      <td>793464</td>\n",
       "      <td>266559</td>\n",
       "      <td>1213679</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           고객예탁금    신용잔고  주식형 펀드  혼합형 펀드   채권형 펀드\n",
       "19-07-02  249327  102014  810117  267668  1187303\n",
       "19-07-03  245303  101285  806478  267931  1189882\n",
       "19-07-04  246573  101509  806966  267577  1191866\n",
       "19-07-05  244098  101908  806254  267246  1191666\n",
       "19-07-08  249578  101685  801271  267835  1193273\n",
       "19-07-09  245999  101470  800163  267431  1196568\n",
       "19-07-10  243732  100741  799399  267512  1195346\n",
       "19-07-11  241386   98951  802245  267814  1197854\n",
       "19-07-12  242357   98681  803167  267776  1199725\n",
       "19-07-15  249210   98777  804104  267627  1200156\n",
       "19-07-16  238733   99272  805791  267646  1202023\n",
       "19-07-17  239065   99648  802964  267828  1203694\n",
       "19-07-18  244744   99827  801783  267729  1205610\n",
       "19-07-19  244479   99833  806933  267574  1206755\n",
       "19-07-22  241833   99736  805981  268322  1204910\n",
       "19-07-23  242129   99451  807415  272576  1206357\n",
       "19-07-24  241131   99822  804661  272530  1207924\n",
       "19-07-25  244278   99805  803018  272481  1210819\n",
       "19-07-26  248585   98998  802480  272205  1211688\n",
       "19-07-29  245195   97742  795191  272078  1213904\n",
       "19-07-30  242994   96489  795857  272006  1211852\n",
       "19-07-31  241078   94518  793464  266559  1213679"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_money_trend_date():\n",
    "    url = 'http://finance.naver.com/sise/sise_deposit.nhn?&page='\n",
    "\n",
    "    source = urlopen(url).read()   # 지정한 페이지에서 코드 읽기\n",
    "    source = BeautifulSoup(source, 'lxml')   # 뷰티풀 스프로 태그별로 코드 분류\n",
    "\n",
    "    last = source.find('td',class_='pgRR').find('a')['href']\n",
    "    last = last.split('&')[1]\n",
    "    last = last.split('=')[1]\n",
    "    last = int(last)\n",
    "\n",
    "    # 사용자의 PC내 폴더 주소를 입력하시면 됩니다.\n",
    "    path = 'd:\\\\money_trend.xlsx'\n",
    "\n",
    "    \n",
    "    until_date = input(\"날짜를 입력하세요 sample: '2019-01-10': \")\n",
    "    \n",
    "    year = until_date.split('-')[0]\n",
    "    mm = until_date.split('-')[1]\n",
    "    dd = until_date.split('-')[2]\n",
    "    year=year[2:]\n",
    "    until_date = year+'-'+mm+'-'+dd\n",
    "    \n",
    "    #df = DataFrame(columns = ['고객예탁금', '신용잔고','주식형 펀드','혼합형 펀드','채권형 펀드'])\n",
    "\n",
    "    # 날짜를 받을 리스트\n",
    "    date_list = []\n",
    "\n",
    "    \n",
    "    # 값을 받을 사전\n",
    "    dictionary = {'고객예탁금': [],\n",
    "                  '신용잔고': [],\n",
    "                  '주식형 펀드': [],\n",
    "                  '혼합형 펀드': [],\n",
    "                  '채권형 펀드': []\n",
    "                  }\n",
    "\n",
    "    # dictionary key 인덱싱을 위한 리스트\n",
    "    name_list = ['고객예탁금','신용잔고','주식형 펀드','혼합형 펀드','채권형 펀드']\n",
    "\n",
    "\n",
    "    # count mask\n",
    "    mask = [1,3,5,7,9]\n",
    "    \n",
    "    for i in range(1,last+1):\n",
    "        \n",
    "        source = urlopen(url+ str(i)).read()\n",
    "        source = BeautifulSoup(source,'lxml')\n",
    "\n",
    "        #tbody = source.find('div',{'id':'wrap'}).find('div',{'class':'box_type_m'})\n",
    "        #trs = tbody.find_all('tr')\n",
    "\n",
    "        body = source.find('body')\n",
    "        trs = body.find_all('tr')\n",
    "\n",
    "        for tr in trs:\n",
    "            tds = tr.find_all('td',{'class':['date','rate_down','rate_up']})\n",
    "            count = 0\n",
    "    \n",
    "            for td in tds:\n",
    "                if count == 0:\n",
    "                    date_ = td.text.strip().replace('.','-')\n",
    "                    if date_ <=  until_date :\n",
    "                    #if date_ <=  '19-03-05' :\n",
    "                        df = pd.DataFrame(dictionary,index = date_list)\n",
    "                        df = df.sort_index()\n",
    "                        df.to_excel(path, encoding='utf-8')\n",
    "                        return df\n",
    "                    date_list.append(date_)\n",
    "                    \n",
    "                elif count in mask:\n",
    "                    temp = int((count-1)/2)\n",
    "                    dictionary[name_list[temp]].append(td.text.strip().replace(',',''))\n",
    "                \n",
    "       \n",
    "                count += 1\n",
    "\n",
    "get_money_trend_date()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KPI200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kpi200():\n",
    "    \n",
    "    url = 'https://finance.naver.com/sise/sise_index_day.nhn?code=KPI200&page='\n",
    "\n",
    "    source = urlopen(url).read()   # 지정한 페이지에서 코드 읽기\n",
    "    source = BeautifulSoup(source, 'lxml')   # 뷰티풀 스프로 태그별로 코드 분류\n",
    "\n",
    "    last = source.find('td',class_='pgRR').find('a')['href']\n",
    "    last = last.split('page')[1]\n",
    "    last = last.split('=')[1]\n",
    "    last = int(last)\n",
    "    print(last)\n",
    "\n",
    "    # 사용자의 PC내 폴더 주소를 입력하시면 됩니다.\n",
    "    path = 'd:\\\\kpi200.xlsx'\n",
    "    \n",
    "    # 날짜를 받을 리스트\n",
    "    date_list = []\n",
    "\n",
    "    # 값을 받을 사전\n",
    "    dictionary = {'KPI200': [],'거래량': []}\n",
    "\n",
    "    # dictionary key 인덱싱을 위한 리스트\n",
    "    name_list = ['KPI200','거래량']\n",
    "\n",
    "\n",
    "    # count mask\n",
    "    mask = [1,3]\n",
    "    \n",
    "    for i in range(1,last+1):\n",
    "        \n",
    "        source = urlopen(url+ str(i)).read()\n",
    "        source = BeautifulSoup(source,'lxml')\n",
    "\n",
    "        #tbody = source.find('div',{'id':'wrap'}).find('div',{'class':'box_type_m'})\n",
    "        #trs = tbody.find_all('tr')\n",
    "\n",
    "        body = source.find('body')\n",
    "        trs = body.find_all('tr')\n",
    "\n",
    "        for tr in trs:\n",
    "            tds = tr.find_all('td',{'class':['date','number_1']})\n",
    "            count = 0\n",
    "    \n",
    "            for td in tds:\n",
    "                if count == 0:\n",
    "                    date_ = td.text.strip().replace('.','-')\n",
    "                    date_list.append(date_)\n",
    "                        \n",
    "                      \n",
    "                elif count in mask:\n",
    "                    temp = int(count/3)\n",
    "                    dictionary[name_list[temp]].append(td.text.strip().replace(',',''))\n",
    "        \n",
    "                count += 1\n",
    "            if len(date_list) != len(dictionary['KPI200']):\n",
    "                print(str(i)+ '번째 페이지에서 누락된 값 발생')\n",
    "                print('누락된 데이터를 제거합니다')\n",
    "                    \n",
    "                date_list.pop(-1)\n",
    "                #dictionary['KPI200'].pop(-1)\n",
    "                dictionary['거래량'].pop(-1)\n",
    "                \n",
    "    # 개별 list 요소 갯수 파악 \n",
    "    #print(len(date_list))\n",
    "    #print(len(dictionary['개인']))\n",
    "    #print(len(dictionary['외국인']))\n",
    "    #print(len(dictionary['기관']))\n",
    "\n",
    "    print(str(i) + '번째 페이지 크롤링 완료')\n",
    "    df = pd.DataFrame(dictionary,index = date_list)\n",
    "    df = df.sort_index()\n",
    "    df.to_excel(path, encoding='utf-8')\n",
    "    print(df)\n",
    "\n",
    "get_kpi200()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kpi200_date():\n",
    "    \n",
    "    url = 'https://finance.naver.com/sise/sise_index_day.nhn?code=KPI200&page='\n",
    "\n",
    "    source = urlopen(url).read()   # 지정한 페이지에서 코드 읽기\n",
    "    source = BeautifulSoup(source, 'lxml')   # 뷰티풀 스프로 태그별로 코드 분류\n",
    "\n",
    "    last = source.find('td',class_='pgRR').find('a')['href']\n",
    "    last = last.split('page')[1]\n",
    "    last = last.split('=')[1]\n",
    "    last = int(last)\n",
    "    print(last)\n",
    "\n",
    "    # 사용자의 PC내 폴더 주소를 입력하시면 됩니다.\n",
    "    path = 'd:\\\\kpi200.xlsx'\n",
    "\n",
    "    until_date = input(\"날짜를 입력하세요 sample: '2019-01-10': \")\n",
    "    \n",
    "    year = until_date.split('-')[0]\n",
    "    mm = until_date.split('-')[1]\n",
    "    dd = until_date.split('-')[2]\n",
    "    #year=year[2:]\n",
    "    until_date = year+'-'+mm+'-'+dd\n",
    "    \n",
    "    # 날짜를 받을 리스트\n",
    "    date_list = []\n",
    "\n",
    "    # 값을 받을 사전\n",
    "    dictionary = {'KPI200': [],'거래량': []}\n",
    "\n",
    "    # dictionary key 인덱싱을 위한 리스트\n",
    "    name_list = ['KPI200','거래량']\n",
    "\n",
    "\n",
    "    # count mask\n",
    "    mask = [1,3]\n",
    "    \n",
    "    for i in range(1,last+1):\n",
    "        \n",
    "        source = urlopen(url+ str(i)).read()\n",
    "        source = BeautifulSoup(source,'lxml')\n",
    "\n",
    "        #tbody = source.find('div',{'id':'wrap'}).find('div',{'class':'box_type_m'})\n",
    "        #trs = tbody.find_all('tr')\n",
    "\n",
    "        body = source.find('body')\n",
    "        trs = body.find_all('tr')\n",
    "\n",
    "        for tr in trs:\n",
    "            tds = tr.find_all('td',{'class':['date','number_1']})\n",
    "            count = 0\n",
    "    \n",
    "            for td in tds:\n",
    "                if count == 0:\n",
    "                    date_ = td.text.strip().replace('.','-')\n",
    "                    if date_ <=  until_date :\n",
    "                    #if date_ <=  '19-03-05' :\n",
    "                        df = pd.DataFrame(dictionary,index = date_list)\n",
    "                        df = df.sort_index()\n",
    "                        df.to_excel(path, encoding='utf-8')\n",
    "                        return df   \n",
    "                    date_list.append(date_)\n",
    "                    #print(date_list)\n",
    "                elif count in mask:\n",
    "                    temp = int(count/3)\n",
    "                    dictionary[name_list[temp]].append(td.text.strip().replace(',',''))\n",
    "                    #print(dictionary[name_list[temp]])\n",
    "                count += 1\n",
    "                \n",
    "get_kpi200_date()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investor Trend"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def get_investor_trend():\n",
    "    \n",
    "    url = 'http://finance.naver.com/sise/investorDealTrendDay.nhn?bizdate=2020601&sosok=&page='\n",
    "\n",
    "    source = urlopen(url).read()   # 지정한 페이지에서 코드 읽기\n",
    "    source = BeautifulSoup(source, 'lxml')   # 뷰티풀 스프로 태그별로 코드 분류\n",
    "\n",
    "    last = source.find('td',class_='pgRR').find('a')['href']\n",
    "    last = last.split('page')[1]\n",
    "    last = last.split('=')[1]\n",
    "    last = int(last)\n",
    "    print(last)\n",
    "\n",
    "    # 사용자의 PC내 폴더 주소를 입력하시면 됩니다.\n",
    "    path = 'd:\\\\investortrend.xlsx'\n",
    "    \n",
    "    # 날짜를 받을 리스트\n",
    "    date_list = []\n",
    "\n",
    "    # 값을 받을 사전\n",
    "    dictionary = {'개인': [],'외국인': [],'기관': []}\n",
    "\n",
    "    # dictionary key 인덱싱을 위한 리스트\n",
    "    name_list = ['개인','외국인','기관']\n",
    "\n",
    "\n",
    "    # count mask\n",
    "    mask = [1,2,3]\n",
    "    \n",
    "    for i in range(1,last+1):\n",
    "        \n",
    "        source = urlopen(url+ str(i)).read()\n",
    "        source = BeautifulSoup(source,'lxml')\n",
    "\n",
    "        #tbody = source.find('div',{'id':'wrap'}).find('div',{'class':'box_type_m'})\n",
    "        #trs = tbody.find_all('tr')\n",
    "\n",
    "        body = source.find('body')\n",
    "        trs = body.find_all('tr')\n",
    "\n",
    "        for tr in trs:\n",
    "            tds = tr.find_all('td',{'class':['date2','rate_down3','rate_up3']})\n",
    "            count = 0\n",
    "    \n",
    "            for td in tds:\n",
    "                if count == 0:\n",
    "                    date_ = td.text.strip().replace('.','-')\n",
    "                    date_list.append(date_)\n",
    "                        \n",
    "                      \n",
    "                elif count in mask:\n",
    "                    temp = int(count-1)\n",
    "                    dictionary[name_list[temp]].append(td.text.strip().replace(',',''))\n",
    "        \n",
    "                count += 1\n",
    "            if len(date_list) != len(dictionary['개인']):\n",
    "                print(str(i)+ '번째 페이지에서 누락된 값 발생')\n",
    "                print('누락된 데이터를 제거합니다')\n",
    "                    \n",
    "                date_list.pop(-1)\n",
    "                dictionary['개인'].pop(-1)\n",
    "                dictionary['외국인'].pop(-1)\n",
    "                dictionary['기관'].pop(-1)\n",
    "                \n",
    "    # 개별 list 요소 갯수 파악 \n",
    "    #print(len(date_list))\n",
    "    #print(len(dictionary['개인']))\n",
    "    #print(len(dictionary['외국인']))\n",
    "    #print(len(dictionary['기관']))\n",
    "\n",
    "    print(str(i) + '번째 페이지 크롤링 완료')\n",
    "    df = pd.DataFrame(dictionary,index = date_list)\n",
    "    df = df.sort_index()\n",
    "    df.to_excel(path, encoding='utf-8')\n",
    "    print(df)\n",
    "\n",
    "get_investor_trend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "361\n",
      "날짜를 입력하세요 sample: '2019-01-10': 2019-03-23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>개인</th>\n",
       "      <th>외국인</th>\n",
       "      <th>기관</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19-03-25</th>\n",
       "      <td>2692</td>\n",
       "      <td>-709</td>\n",
       "      <td>-2191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-03-26</th>\n",
       "      <td>1557</td>\n",
       "      <td>374</td>\n",
       "      <td>-1915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-03-27</th>\n",
       "      <td>192</td>\n",
       "      <td>-1561</td>\n",
       "      <td>1202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-03-28</th>\n",
       "      <td>837</td>\n",
       "      <td>-139</td>\n",
       "      <td>-832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-03-29</th>\n",
       "      <td>-1560</td>\n",
       "      <td>890</td>\n",
       "      <td>597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-04-01</th>\n",
       "      <td>-4381</td>\n",
       "      <td>2491</td>\n",
       "      <td>1846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-04-02</th>\n",
       "      <td>-1036</td>\n",
       "      <td>2734</td>\n",
       "      <td>-1506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-04-03</th>\n",
       "      <td>-4644</td>\n",
       "      <td>1431</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-04-04</th>\n",
       "      <td>-3797</td>\n",
       "      <td>2449</td>\n",
       "      <td>1378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-04-05</th>\n",
       "      <td>-1544</td>\n",
       "      <td>996</td>\n",
       "      <td>616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-04-08</th>\n",
       "      <td>-1181</td>\n",
       "      <td>2731</td>\n",
       "      <td>-1566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-04-09</th>\n",
       "      <td>-1740</td>\n",
       "      <td>2090</td>\n",
       "      <td>-332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-04-10</th>\n",
       "      <td>-2280</td>\n",
       "      <td>-33</td>\n",
       "      <td>2335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-04-11</th>\n",
       "      <td>-1512</td>\n",
       "      <td>3208</td>\n",
       "      <td>-1606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-04-12</th>\n",
       "      <td>-1657</td>\n",
       "      <td>2446</td>\n",
       "      <td>-558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-04-15</th>\n",
       "      <td>466</td>\n",
       "      <td>1781</td>\n",
       "      <td>-2189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-04-16</th>\n",
       "      <td>-949</td>\n",
       "      <td>1527</td>\n",
       "      <td>-539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-04-17</th>\n",
       "      <td>-589</td>\n",
       "      <td>756</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-04-18</th>\n",
       "      <td>2959</td>\n",
       "      <td>-1320</td>\n",
       "      <td>-1290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-04-19</th>\n",
       "      <td>178</td>\n",
       "      <td>-567</td>\n",
       "      <td>351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-04-22</th>\n",
       "      <td>702</td>\n",
       "      <td>-186</td>\n",
       "      <td>-503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-04-23</th>\n",
       "      <td>180</td>\n",
       "      <td>407</td>\n",
       "      <td>-708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-04-24</th>\n",
       "      <td>4030</td>\n",
       "      <td>230</td>\n",
       "      <td>-4214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-04-25</th>\n",
       "      <td>629</td>\n",
       "      <td>-165</td>\n",
       "      <td>-446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-04-26</th>\n",
       "      <td>1401</td>\n",
       "      <td>355</td>\n",
       "      <td>-1844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-04-29</th>\n",
       "      <td>-2833</td>\n",
       "      <td>30</td>\n",
       "      <td>2785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-04-30</th>\n",
       "      <td>119</td>\n",
       "      <td>429</td>\n",
       "      <td>-573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-05-02</th>\n",
       "      <td>-1025</td>\n",
       "      <td>681</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-05-03</th>\n",
       "      <td>2417</td>\n",
       "      <td>1521</td>\n",
       "      <td>-4075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-05-07</th>\n",
       "      <td>2823</td>\n",
       "      <td>2026</td>\n",
       "      <td>-4787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-06-24</th>\n",
       "      <td>-728</td>\n",
       "      <td>-992</td>\n",
       "      <td>1637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-06-25</th>\n",
       "      <td>-211</td>\n",
       "      <td>88</td>\n",
       "      <td>-273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-06-26</th>\n",
       "      <td>-736</td>\n",
       "      <td>165</td>\n",
       "      <td>610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-06-27</th>\n",
       "      <td>-4058</td>\n",
       "      <td>1559</td>\n",
       "      <td>2671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-06-28</th>\n",
       "      <td>-1995</td>\n",
       "      <td>3123</td>\n",
       "      <td>-1097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-07-01</th>\n",
       "      <td>-191</td>\n",
       "      <td>1545</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-07-02</th>\n",
       "      <td>240</td>\n",
       "      <td>343</td>\n",
       "      <td>-515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-07-03</th>\n",
       "      <td>1562</td>\n",
       "      <td>-860</td>\n",
       "      <td>-675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-07-04</th>\n",
       "      <td>-238</td>\n",
       "      <td>401</td>\n",
       "      <td>-93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-07-05</th>\n",
       "      <td>-1050</td>\n",
       "      <td>-250</td>\n",
       "      <td>1263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-07-08</th>\n",
       "      <td>499</td>\n",
       "      <td>18</td>\n",
       "      <td>-498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-07-09</th>\n",
       "      <td>826</td>\n",
       "      <td>240</td>\n",
       "      <td>-1149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-07-10</th>\n",
       "      <td>-13</td>\n",
       "      <td>2033</td>\n",
       "      <td>-1882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-07-11</th>\n",
       "      <td>-1993</td>\n",
       "      <td>3649</td>\n",
       "      <td>-1782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-07-12</th>\n",
       "      <td>168</td>\n",
       "      <td>-59</td>\n",
       "      <td>-64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-07-15</th>\n",
       "      <td>-494</td>\n",
       "      <td>143</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-07-16</th>\n",
       "      <td>-2157</td>\n",
       "      <td>2512</td>\n",
       "      <td>-315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-07-17</th>\n",
       "      <td>587</td>\n",
       "      <td>233</td>\n",
       "      <td>-745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-07-18</th>\n",
       "      <td>1002</td>\n",
       "      <td>708</td>\n",
       "      <td>-1729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-07-19</th>\n",
       "      <td>-4632</td>\n",
       "      <td>1306</td>\n",
       "      <td>3381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-07-22</th>\n",
       "      <td>-647</td>\n",
       "      <td>2335</td>\n",
       "      <td>-1686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-07-23</th>\n",
       "      <td>-2833</td>\n",
       "      <td>2857</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-07-24</th>\n",
       "      <td>533</td>\n",
       "      <td>585</td>\n",
       "      <td>-1140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-07-25</th>\n",
       "      <td>457</td>\n",
       "      <td>1124</td>\n",
       "      <td>-1536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-07-26</th>\n",
       "      <td>-221</td>\n",
       "      <td>1184</td>\n",
       "      <td>-1032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-07-29</th>\n",
       "      <td>-767</td>\n",
       "      <td>-625</td>\n",
       "      <td>1350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-07-30</th>\n",
       "      <td>-1469</td>\n",
       "      <td>1410</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-07-31</th>\n",
       "      <td>-774</td>\n",
       "      <td>-496</td>\n",
       "      <td>1209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-08-01</th>\n",
       "      <td>-873</td>\n",
       "      <td>-51</td>\n",
       "      <td>836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-08-02</th>\n",
       "      <td>143</td>\n",
       "      <td>-3979</td>\n",
       "      <td>3626</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>92 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             개인    외국인     기관\n",
       "19-03-25   2692   -709  -2191\n",
       "19-03-26   1557    374  -1915\n",
       "19-03-27    192  -1561   1202\n",
       "19-03-28    837   -139   -832\n",
       "19-03-29  -1560    890    597\n",
       "19-04-01  -4381   2491   1846\n",
       "19-04-02  -1036   2734  -1506\n",
       "19-04-03  -4644   1431   2008\n",
       "19-04-04  -3797   2449   1378\n",
       "19-04-05  -1544    996    616\n",
       "19-04-08  -1181   2731  -1566\n",
       "19-04-09  -1740   2090   -332\n",
       "19-04-10  -2280    -33   2335\n",
       "19-04-11  -1512   3208  -1606\n",
       "19-04-12  -1657   2446   -558\n",
       "19-04-15    466   1781  -2189\n",
       "19-04-16   -949   1527   -539\n",
       "19-04-17   -589    756     14\n",
       "19-04-18   2959  -1320  -1290\n",
       "19-04-19    178   -567    351\n",
       "19-04-22    702   -186   -503\n",
       "19-04-23    180    407   -708\n",
       "19-04-24   4030    230  -4214\n",
       "19-04-25    629   -165   -446\n",
       "19-04-26   1401    355  -1844\n",
       "19-04-29  -2833     30   2785\n",
       "19-04-30    119    429   -573\n",
       "19-05-02  -1025    681    170\n",
       "19-05-03   2417   1521  -4075\n",
       "19-05-07   2823   2026  -4787\n",
       "...         ...    ...    ...\n",
       "19-06-24   -728   -992   1637\n",
       "19-06-25   -211     88   -273\n",
       "19-06-26   -736    165    610\n",
       "19-06-27  -4058   1559   2671\n",
       "19-06-28  -1995   3123  -1097\n",
       "19-07-01   -191   1545     61\n",
       "19-07-02    240    343   -515\n",
       "19-07-03   1562   -860   -675\n",
       "19-07-04   -238    401    -93\n",
       "19-07-05  -1050   -250   1263\n",
       "19-07-08    499     18   -498\n",
       "19-07-09    826    240  -1149\n",
       "19-07-10    -13   2033  -1882\n",
       "19-07-11  -1993   3649  -1782\n",
       "19-07-12    168    -59    -64\n",
       "19-07-15   -494    143    253\n",
       "19-07-16  -2157   2512   -315\n",
       "19-07-17    587    233   -745\n",
       "19-07-18   1002    708  -1729\n",
       "19-07-19  -4632   1306   3381\n",
       "19-07-22   -647   2335  -1686\n",
       "19-07-23  -2833   2857     37\n",
       "19-07-24    533    585  -1140\n",
       "19-07-25    457   1124  -1536\n",
       "19-07-26   -221   1184  -1032\n",
       "19-07-29   -767   -625   1350\n",
       "19-07-30  -1469   1410     39\n",
       "19-07-31   -774   -496   1209\n",
       "19-08-01   -873    -51    836\n",
       "19-08-02    143  -3979   3626\n",
       "\n",
       "[92 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_investor_trend_date():\n",
    "    \n",
    "    url = 'http://finance.naver.com/sise/investorDealTrendDay.nhn?bizdate=2020601&sosok=&page='\n",
    "\n",
    "    source = urlopen(url).read()   # 지정한 페이지에서 코드 읽기\n",
    "    source = BeautifulSoup(source, 'lxml')   # 뷰티풀 스프로 태그별로 코드 분류\n",
    "\n",
    "    last = source.find('td',class_='pgRR').find('a')['href']\n",
    "    last = last.split('page')[1]\n",
    "    last = last.split('=')[1]\n",
    "    last = int(last)\n",
    "    print(last)\n",
    "\n",
    "    # 사용자의 PC내 폴더 주소를 입력하시면 됩니다.\n",
    "    path = 'd:\\\\investortrend.xlsx'\n",
    "\n",
    "    until_date = input(\"날짜를 입력하세요 sample: '2019-01-10': \")\n",
    "    \n",
    "    year = until_date.split('-')[0]\n",
    "    mm = until_date.split('-')[1]\n",
    "    dd = until_date.split('-')[2]\n",
    "    year=year[2:]\n",
    "    until_date = year+'-'+mm+'-'+dd\n",
    "    \n",
    "    # 날짜를 받을 리스트\n",
    "    date_list = []\n",
    "\n",
    "    # 값을 받을 사전\n",
    "    dictionary = {'개인': [],'외국인': [],'기관': []}\n",
    "\n",
    "    # dictionary key 인덱싱을 위한 리스트\n",
    "    name_list = ['개인','외국인','기관']\n",
    "\n",
    "\n",
    "    # count mask\n",
    "    mask = [1,2,3]\n",
    "    \n",
    "    for i in range(1,last+1):\n",
    "        \n",
    "        source = urlopen(url+ str(i)).read()\n",
    "        source = BeautifulSoup(source,'lxml')\n",
    "\n",
    "        #tbody = source.find('div',{'id':'wrap'}).find('div',{'class':'box_type_m'})\n",
    "        #trs = tbody.find_all('tr')\n",
    "\n",
    "        body = source.find('body')\n",
    "        trs = body.find_all('tr')\n",
    "\n",
    "        for tr in trs:\n",
    "            tds = tr.find_all('td',{'class':['date2','rate_down3','rate_up3']})\n",
    "            count = 0\n",
    "    \n",
    "            for td in tds:\n",
    "                if count == 0:\n",
    "                    date_ = td.text.strip().replace('.','-')\n",
    "                    if date_ <=  until_date :\n",
    "                        df = pd.DataFrame(dictionary,index = date_list)\n",
    "                        df = df.sort_index()\n",
    "                        df.to_excel(path, encoding='utf-8')\n",
    "                        return df   \n",
    "                    date_list.append(date_)\n",
    "                    #print(date_list)\n",
    "                elif count in mask:\n",
    "                    temp = int(count-1)\n",
    "                    dictionary[name_list[temp]].append(td.text.strip().replace(',',''))\n",
    "                    \n",
    "                count += 1\n",
    "                \n",
    "get_investor_trend_date()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Program Trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_program_trend():\n",
    "    \n",
    "    url = 'https://finance.naver.com/sise/programDealTrendDay.nhn?bizdate=20200315&sosok=&page='\n",
    "\n",
    "    source = urlopen(url).read()   # 지정한 페이지에서 코드 읽기\n",
    "    source = BeautifulSoup(source, 'lxml')   # 뷰티풀 스프로 태그별로 코드 분류\n",
    "\n",
    "    last = source.find('td',class_='pgRR').find('a')['href']\n",
    "    last = last.split('page')[1]\n",
    "    last = last.split('=')[1]\n",
    "    last = int(last)\n",
    "    print(last)\n",
    "\n",
    "    # 사용자의 PC내 폴더 주소를 입력하시면 됩니다.\n",
    "    path = 'd:\\\\programtrend.xlsx'\n",
    "    \n",
    "    # 날짜를 받을 리스트\n",
    "    date_list = []\n",
    "\n",
    "    # 값을 받을 사전\n",
    "    dictionary = {'차익': [],'비차익': [],'전체': []}\n",
    "\n",
    "    # dictionary key 인덱싱을 위한 리스트\n",
    "    name_list = ['차익','비차익','전체']\n",
    "\n",
    "\n",
    "    # count mask\n",
    "    mask = [3,6,9]\n",
    "    \n",
    "    for i in range(1,last+1):\n",
    "        \n",
    "        source = urlopen(url+ str(i)).read()\n",
    "        source = BeautifulSoup(source,'lxml')\n",
    "\n",
    "        #tbody = source.find('div',{'id':'wrap'}).find('div',{'class':'box_type_m'})\n",
    "        #trs = tbody.find_all('tr')\n",
    "\n",
    "        body = source.find('body')\n",
    "        trs = body.find_all('tr')\n",
    "\n",
    "        for tr in trs:\n",
    "            tds = tr.find_all('td',{'class':['date','rate_down','rate_up']})\n",
    "            count = 0\n",
    "    \n",
    "            for td in tds:\n",
    "                if count == 0:\n",
    "                    date_ = td.text.strip().replace('.','-')\n",
    "                    date_list.append(date_)\n",
    "                        \n",
    "                      \n",
    "                elif count in mask:\n",
    "                    temp = int((count/3)-1)\n",
    "                    dictionary[name_list[temp]].append(td.text.strip().replace(',',''))\n",
    "        \n",
    "                count += 1\n",
    "            if len(date_list) != len(dictionary['전체']):\n",
    "                print(str(i)+ '번째 페이지에서 누락된 값 발생')\n",
    "                print('누락된 데이터를 제거합니다')\n",
    "                    \n",
    "                date_list.pop(-1)\n",
    "                dictionary['차익'].pop(-1)\n",
    "                dictionary['비차익'].pop(-1)\n",
    "                #dictionary['전체'].pop(-1)\n",
    "                \n",
    "    # 개별 list 요소 갯수 파악 \n",
    "    print(len(date_list))\n",
    "    print(len(dictionary['차익']))\n",
    "    print(len(dictionary['비차익']))\n",
    "    print(len(dictionary['전체']))\n",
    "\n",
    "    print(str(i) + '번째 페이지 크롤링 완료')\n",
    "    df = pd.DataFrame(dictionary,index = date_list)\n",
    "    df = df.sort_index()\n",
    "    df.to_excel(path, encoding='utf-8')\n",
    "    print(df)\n",
    "\n",
    "get_program_trend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "361\n",
      "날짜를 입력하세요 sample: '2019-01-10': 2019-08-01\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>차익</th>\n",
       "      <th>비차익</th>\n",
       "      <th>전체</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19-08-02</th>\n",
       "      <td>-11</td>\n",
       "      <td>-1725</td>\n",
       "      <td>-1736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-08-05</th>\n",
       "      <td>777</td>\n",
       "      <td>91</td>\n",
       "      <td>868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-08-06</th>\n",
       "      <td>-35</td>\n",
       "      <td>-1377</td>\n",
       "      <td>-1412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           차익    비차익     전체\n",
       "19-08-02  -11  -1725  -1736\n",
       "19-08-05  777     91    868\n",
       "19-08-06  -35  -1377  -1412"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_program_trend_date():\n",
    "    \n",
    "    url = 'https://finance.naver.com/sise/programDealTrendDay.nhn?bizdate=20200315&sosok=&page='\n",
    "\n",
    "    source = urlopen(url).read()   # 지정한 페이지에서 코드 읽기\n",
    "    source = BeautifulSoup(source, 'lxml')   # 뷰티풀 스프로 태그별로 코드 분류\n",
    "\n",
    "    last = source.find('td',class_='pgRR').find('a')['href']\n",
    "    last = last.split('page')[1]\n",
    "    last = last.split('=')[1]\n",
    "    last = int(last)\n",
    "    print(last)\n",
    "\n",
    "    # 사용자의 PC내 폴더 주소를 입력하시면 됩니다.\n",
    "    path = 'd:\\\\programtrend.xlsx'\n",
    "\n",
    "    until_date = input(\"날짜를 입력하세요 sample: '2019-01-10': \")\n",
    "    \n",
    "    year = until_date.split('-')[0]\n",
    "    mm = until_date.split('-')[1]\n",
    "    dd = until_date.split('-')[2]\n",
    "    year=year[2:]\n",
    "    until_date = year+'-'+mm+'-'+dd\n",
    "    \n",
    "    # 날짜를 받을 리스트\n",
    "    date_list = []\n",
    "\n",
    "    # 값을 받을 사전\n",
    "    dictionary = {'차익': [],'비차익': [],'전체': []}\n",
    "\n",
    "    # dictionary key 인덱싱을 위한 리스트\n",
    "    name_list = ['차익','비차익','전체']\n",
    "\n",
    "\n",
    "    # count mask\n",
    "    mask = [3,6,9]\n",
    "    \n",
    "    for i in range(1,last+1):\n",
    "        \n",
    "        source = urlopen(url+ str(i)).read()\n",
    "        source = BeautifulSoup(source,'lxml')\n",
    "\n",
    "        #tbody = source.find('div',{'id':'wrap'}).find('div',{'class':'box_type_m'})\n",
    "        #trs = tbody.find_all('tr')\n",
    "\n",
    "        body = source.find('body')\n",
    "        trs = body.find_all('tr')\n",
    "\n",
    "        for tr in trs:\n",
    "            tds = tr.find_all('td',{'class':['date','rate_down','rate_up']})\n",
    "            count = 0\n",
    "    \n",
    "            for td in tds:\n",
    "                if count == 0:\n",
    "                    date_ = td.text.strip().replace('.','-')\n",
    "                    if date_ <=  until_date :\n",
    "                        df = pd.DataFrame(dictionary,index = date_list)\n",
    "                        df = df.sort_index()\n",
    "                        df.to_excel(path, encoding='utf-8')\n",
    "                        return df   \n",
    "                    date_list.append(date_)\n",
    "                    #print(date_list)\n",
    "                elif count in mask:\n",
    "                    temp = int((count/3)-1)\n",
    "                    dictionary[name_list[temp]].append(td.text.strip().replace(',',''))\n",
    "                    \n",
    "                count += 1\n",
    "get_program_trend_date()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 선물"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  futures():\n",
    "    \n",
    "    url = 'https://finance.naver.com/sise/sise_index_day.nhn?code=FUT&page='\n",
    "\n",
    "    source = urlopen(url).read()   # 지정한 페이지에서 코드 읽기\n",
    "    source = BeautifulSoup(source, 'lxml')   # 뷰티풀 스프로 태그별로 코드 분류\n",
    "\n",
    "    last = source.find('td',class_='pgRR').find('a')['href']\n",
    "    last = last.split('page')[1]\n",
    "    last = last.split('=')[1]\n",
    "    last = int(last)\n",
    "    print(last)\n",
    "\n",
    "    # 사용자의 PC내 폴더 주소를 입력하시면 됩니다.\n",
    "    path = 'd:\\\\futures.xlsx'\n",
    "    \n",
    "    # 날짜를 받을 리스트\n",
    "    date_list = []\n",
    "\n",
    "    # 값을 받을 사전\n",
    "    dictionary = {'Close': [],'updown': [],'rate': []}\n",
    "\n",
    "    # dictionary key 인덱싱을 위한 리스트\n",
    "    name_list = ['Close','updown','rate']\n",
    "\n",
    "\n",
    "    # count mask\n",
    "    mask = [1,2,3]\n",
    "    \n",
    "    for i in range(1,last+1):\n",
    "        \n",
    "        source = urlopen(url+ str(i)).read()\n",
    "        source = BeautifulSoup(source,'lxml')\n",
    "\n",
    "        #tbody = source.find('div',{'id':'wrap'}).find('div',{'class':'box_type_m'})\n",
    "        #trs = tbody.find_all('tr')\n",
    "\n",
    "        body = source.find('body')\n",
    "        trs = body.find_all('tr')\n",
    "\n",
    "        for tr in trs:\n",
    "            tds = tr.find_all('td',{'class':['date','number_1','rate_down']})\n",
    "            count = 0\n",
    "    \n",
    "            for td in tds:\n",
    "                if count == 0:\n",
    "                    date_ = td.text.strip().replace('.','-')\n",
    "                    date_list.append(date_)\n",
    "                        \n",
    "                      \n",
    "                elif count in mask:\n",
    "                    temp = int(count-1)\n",
    "                    dictionary[name_list[temp]].append(td.text.strip().replace(',',''))\n",
    "        \n",
    "                count += 1\n",
    "            if len(date_list) != len(dictionary['Close']):\n",
    "                print(str(i)+ '번째 페이지에서 누락된 값 발생')\n",
    "                print('누락된 데이터를 제거합니다')\n",
    "                    \n",
    "                date_list.pop(-1)\n",
    "                dictionary['Close'].pop(-1)\n",
    "                dictionary['updown'].pop(-1)\n",
    "                dictionary['rate'].pop(-1)\n",
    "                \n",
    "    # 개별 list 요소 갯수 파악 \n",
    "    #print(len(date_list))\n",
    "    #print(len(dictionary['개인']))\n",
    "    #print(len(dictionary['외국인']))\n",
    "    #print(len(dictionary['기관']))\n",
    "\n",
    "    print(str(i) + '번째 페이지 크롤링 완료')\n",
    "    df = pd.DataFrame(dictionary,index = date_list)\n",
    "    df = df.sort_index()\n",
    "    df.to_excel(path, encoding='utf-8')\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "352\n"
     ]
    }
   ],
   "source": [
    "def get_program_trend():\n",
    "    \n",
    "    url = 'https://finance.naver.com/sise/programDealTrendDay.nhn?bizdate=20190315&sosok=&page=1'\n",
    "\n",
    "    source = urlopen(url).read()   # 지정한 페이지에서 코드 읽기\n",
    "    source = BeautifulSoup(source, 'lxml')   # 뷰티풀 스프로 태그별로 코드 분류\n",
    "\n",
    "    last = source.find('td',class_='pgRR').find('a')['href']\n",
    "    last = last.split('page')[1]\n",
    "    last = last.split('=')[1]\n",
    "    last = int(last)\n",
    "    print(last)\n",
    "get_program_trend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-63d620e94b24>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\gpu\\lib\\json\\__init__.py\u001b[0m in \u001b[0;36mloads\u001b[1;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    352\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[1;32m--> 354\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    355\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m         \u001b[0mcls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\gpu\\lib\\json\\decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m         \"\"\"\n\u001b[1;32m--> 339\u001b[1;33m         \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    340\u001b[0m         \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\gpu\\lib\\json\\decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    355\u001b[0m             \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 357\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Expecting value\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    358\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "url = 'http://finance.daum.net/api/trend/arounds?page=1&perPage=20&fieldName=changeRate&order=desc&'\n",
    "\n",
    "headers = {\n",
    "            'Accept': 'application/json, text/javascript, */*; q=0.01',\n",
    "            'Accept-Encoding': 'gzip, deflate',\n",
    "            'Accept-Language': 'ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7',\n",
    "            'Connection': 'keep-alive',\n",
    "            'Cookie': 'webid=d46440de38044bf09793bcb7b72f6e44; HM_CU=53tOIE3pJAl; PROF=0603012032024076024152UiQPJk7X-6w0mlxoempuua9ZV2cHpAw.yYZCWRveAG66KuZP3z7wEl2bxriNh5SdkQ00LYYSA9A1_cGNLCyhCzrwOpjlf.dyaYOF73J4wVWlUV-s4YfMaxSVtlykILG9ANzoDGNdZmMA6ow0fIauQlo8OTLLnHHY.bHDTw00pCsuaN7PcHxD-1-COJRcrCRKdtGkJTxsMPDn.AARqchjj_-wex3iZx3wLHSw2zOJV.v6jIW4KBMTlbLOnujI-eVINNr9BbQ_KeOzYuEMT_ef42fOXQqNBos4gXyk4bhTSZyZ2Y1KFae9xnaQoQWr5w00; SLEVEL=1; ssab=; AGEN=_mu9pzAMt5sQLPv-ldWVC_IAFijAIG9qARn2QDRvByo; TS=1553412011; HTS=CiiEXdlRFxG7ojGJ9WgV1w00; LSID=f6127be3-d5e5-4032-8c37-628ae599bd181553412011772; _ga=GA1.2.425358004.1553636955; _gid=GA1.2.296667810.1553636955; webid_sync=1553723295574; _gat_gtag_UA_128578811_1=1; TIARA=33ct94Z7b1leKyZ3bC-NI856RU7.OHSANrbu4xUyWnUvsKKAGyYHKdKtFobGx.DrFpAAYU4lBaLcWieRt6trQmWZ_AYwcswz',\n",
    "            'Host': 'finance.daum.net',\n",
    "            'If-None-Match': 'W/\"486e9e8ca2eb9ee4cfa1c386a42117f3\"',\n",
    "            'Referer': 'http://finance.daum.net/domestic/arounds',\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.86 Safari/537.36'\n",
    "            }\n",
    "headers['Referer'] = 'http://finance.daum.net/api/trend/arounds?page=1&perPage=20&fieldName=changeRate&order=desc&'\n",
    "r = requests.get(url, headers = headers)\n",
    "\n",
    "data = json.loads(r.text)\n",
    "df = pd.DataFrame(data['data'])\n",
    "\n",
    "return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def get_price(code, n):\n",
    "    # DATA를 불러오는 부분 입니다.\n",
    "    url = 'http://finance.daum.net/api/charts/A%s/days?limit=%d&adjusted=true'%(code, n)\n",
    "    headers = {\n",
    "                'Accept': 'application/json, text/plain, */*',\n",
    "                'Accept-Encoding': 'gzip, deflate',\n",
    "                'Accept-Language': 'ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7',\n",
    "                'Connection': 'keep-alive',\n",
    "                'Cookie': 'GS_font_Name_no=0; GS_font_size=16; _ga=GA1.3.937989519.1493034297; webid=bb619e03ecbf4672b8d38a3fcedc3f8c; _ga=GA1.2.937989519.1493034297; _gid=GA1.2.215330840.1541556419; KAKAO_STOCK_RECENT=[%22A069500%22]; recentMenus=[{%22destination%22:%22chart%22%2C%22title%22:%22%EC%B0%A8%ED%8A%B8%22}%2C{%22destination%22:%22current%22%2C%22title%22:%22%ED%98%84%EC%9E%AC%EA%B0%80%22}]; TIARA=C-Tax5zAJ3L1CwQFDxYNxe-9yt4xuvAcw3IjfDg6hlCbJ_KXLZZhwEPhrMuSc5Rv1oty5obaYZzBQS5Du9ne5x7XZds-vHVF; webid_sync=1541565778037; _gat_gtag_UA_128578811_1=1; _dfs=VFlXMkVwUGJENlVvc1B3V2NaV1pFdHhpNTVZdnRZTWFZQWZwTzBPYWRxMFNVL3VrODRLY1VlbXI0dHhBZlJzcE03SS9Vblh0U2p2L2V2b3hQbU5mNlE9PS0tcGI2aXQrZ21qY0hFbzJ0S1hkaEhrZz09--6eba3111e6ac36d893bbc58439d2a3e0304c7cf3',\n",
    "                'Host': 'finance.daum.net',\n",
    "                'If-None-Match': 'W/\"23501689faaaf24452ece4a039a904fd\"',\n",
    "                'Referer': 'http://finance.daum.net/quotes/A069500',\n",
    "                'User-Agent':'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'\n",
    "                }\n",
    "    headers['Referer'] = 'http://finance.daum.net/quotes/A%s'%code\n",
    "    r = requests.get(url, headers = headers)\n",
    "    \n",
    "    # DATA를 보기 좋게 편집하는 부분 입니다.\n",
    "    data = json.loads(r.text)\n",
    "    df = pd.DataFrame(data['data'])\n",
    "    df.index = pd.to_datetime(df['candleTime'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>candleAccTradePrice</th>\n",
       "      <th>candleAccTradeVolume</th>\n",
       "      <th>candleTime</th>\n",
       "      <th>change</th>\n",
       "      <th>changePrice</th>\n",
       "      <th>changeRate</th>\n",
       "      <th>date</th>\n",
       "      <th>highPrice</th>\n",
       "      <th>lowPrice</th>\n",
       "      <th>openingPrice</th>\n",
       "      <th>symbolCode</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>tradePrice</th>\n",
       "      <th>tradeTime</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candleTime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-02-28</th>\n",
       "      <td>1262292450</td>\n",
       "      <td>127433</td>\n",
       "      <td>2019-02-28 00:00:00.0</td>\n",
       "      <td>FALL</td>\n",
       "      <td>130.0</td>\n",
       "      <td>0.013092</td>\n",
       "      <td>2019-02-28</td>\n",
       "      <td>9980.0</td>\n",
       "      <td>9720.0</td>\n",
       "      <td>9930.0</td>\n",
       "      <td>A000020</td>\n",
       "      <td>1551345978459</td>\n",
       "      <td>9800.0</td>\n",
       "      <td>153025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-04</th>\n",
       "      <td>858235130</td>\n",
       "      <td>86244</td>\n",
       "      <td>2019-03-04 00:00:00.0</td>\n",
       "      <td>RISE</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>2019-03-04</td>\n",
       "      <td>10050.0</td>\n",
       "      <td>9800.0</td>\n",
       "      <td>9810.0</td>\n",
       "      <td>A000020</td>\n",
       "      <td>1551691539233</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>153021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-05</th>\n",
       "      <td>655114470</td>\n",
       "      <td>65110</td>\n",
       "      <td>2019-03-05 00:00:00.0</td>\n",
       "      <td>RISE</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>2019-03-05</td>\n",
       "      <td>10150.0</td>\n",
       "      <td>9970.0</td>\n",
       "      <td>10050.0</td>\n",
       "      <td>A000020</td>\n",
       "      <td>1551777979504</td>\n",
       "      <td>10100.0</td>\n",
       "      <td>153010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-06</th>\n",
       "      <td>484114800</td>\n",
       "      <td>47791</td>\n",
       "      <td>2019-03-06 00:00:00.0</td>\n",
       "      <td>EVEN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2019-03-06</td>\n",
       "      <td>10250.0</td>\n",
       "      <td>10050.0</td>\n",
       "      <td>10150.0</td>\n",
       "      <td>A000020</td>\n",
       "      <td>1551864371128</td>\n",
       "      <td>10100.0</td>\n",
       "      <td>153030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-07</th>\n",
       "      <td>658441180</td>\n",
       "      <td>65924</td>\n",
       "      <td>2019-03-07 00:00:00.0</td>\n",
       "      <td>FALL</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.010891</td>\n",
       "      <td>2019-03-07</td>\n",
       "      <td>10100.0</td>\n",
       "      <td>9910.0</td>\n",
       "      <td>10050.0</td>\n",
       "      <td>A000020</td>\n",
       "      <td>1551950773359</td>\n",
       "      <td>9990.0</td>\n",
       "      <td>153010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-08</th>\n",
       "      <td>343866720</td>\n",
       "      <td>34591</td>\n",
       "      <td>2019-03-08 00:00:00.0</td>\n",
       "      <td>FALL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.006006</td>\n",
       "      <td>2019-03-08</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>9860.0</td>\n",
       "      <td>9990.0</td>\n",
       "      <td>A000020</td>\n",
       "      <td>1552037163192</td>\n",
       "      <td>9930.0</td>\n",
       "      <td>153005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-11</th>\n",
       "      <td>877700660</td>\n",
       "      <td>89651</td>\n",
       "      <td>2019-03-11 00:00:00.0</td>\n",
       "      <td>FALL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.008056</td>\n",
       "      <td>2019-03-11</td>\n",
       "      <td>9960.0</td>\n",
       "      <td>9700.0</td>\n",
       "      <td>9930.0</td>\n",
       "      <td>A000020</td>\n",
       "      <td>1552296378581</td>\n",
       "      <td>9850.0</td>\n",
       "      <td>153024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-12</th>\n",
       "      <td>502122480</td>\n",
       "      <td>50658</td>\n",
       "      <td>2019-03-12 00:00:00.0</td>\n",
       "      <td>RISE</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.008122</td>\n",
       "      <td>2019-03-12</td>\n",
       "      <td>9960.0</td>\n",
       "      <td>9870.0</td>\n",
       "      <td>9900.0</td>\n",
       "      <td>A000020</td>\n",
       "      <td>1552382772168</td>\n",
       "      <td>9930.0</td>\n",
       "      <td>153030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-13</th>\n",
       "      <td>748344140</td>\n",
       "      <td>74778</td>\n",
       "      <td>2019-03-13 00:00:00.0</td>\n",
       "      <td>RISE</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.012085</td>\n",
       "      <td>2019-03-13</td>\n",
       "      <td>10150.0</td>\n",
       "      <td>9930.0</td>\n",
       "      <td>9950.0</td>\n",
       "      <td>A000020</td>\n",
       "      <td>1552469150813</td>\n",
       "      <td>10050.0</td>\n",
       "      <td>153022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-14</th>\n",
       "      <td>736270070</td>\n",
       "      <td>73439</td>\n",
       "      <td>2019-03-14 00:00:00.0</td>\n",
       "      <td>RISE</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.004975</td>\n",
       "      <td>2019-03-14</td>\n",
       "      <td>10100.0</td>\n",
       "      <td>9990.0</td>\n",
       "      <td>10050.0</td>\n",
       "      <td>A000020</td>\n",
       "      <td>1552555592864</td>\n",
       "      <td>10100.0</td>\n",
       "      <td>153008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-15</th>\n",
       "      <td>595667890</td>\n",
       "      <td>59500</td>\n",
       "      <td>2019-03-15 00:00:00.0</td>\n",
       "      <td>FALL</td>\n",
       "      <td>130.0</td>\n",
       "      <td>0.012871</td>\n",
       "      <td>2019-03-15</td>\n",
       "      <td>10150.0</td>\n",
       "      <td>9970.0</td>\n",
       "      <td>10150.0</td>\n",
       "      <td>A000020</td>\n",
       "      <td>1552641879602</td>\n",
       "      <td>9970.0</td>\n",
       "      <td>153030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-18</th>\n",
       "      <td>378737160</td>\n",
       "      <td>37952</td>\n",
       "      <td>2019-03-18 00:00:00.0</td>\n",
       "      <td>RISE</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.002006</td>\n",
       "      <td>2019-03-18</td>\n",
       "      <td>10050.0</td>\n",
       "      <td>9900.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>A000020</td>\n",
       "      <td>1552901084372</td>\n",
       "      <td>9990.0</td>\n",
       "      <td>153030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-19</th>\n",
       "      <td>784371620</td>\n",
       "      <td>78213</td>\n",
       "      <td>2019-03-19 00:00:00.0</td>\n",
       "      <td>FALL</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>2019-03-19</td>\n",
       "      <td>10100.0</td>\n",
       "      <td>9970.0</td>\n",
       "      <td>9990.0</td>\n",
       "      <td>A000020</td>\n",
       "      <td>1552987502446</td>\n",
       "      <td>9980.0</td>\n",
       "      <td>153022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-20</th>\n",
       "      <td>270691290</td>\n",
       "      <td>27138</td>\n",
       "      <td>2019-03-20 00:00:00.0</td>\n",
       "      <td>RISE</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.002004</td>\n",
       "      <td>2019-03-20</td>\n",
       "      <td>10050.0</td>\n",
       "      <td>9860.0</td>\n",
       "      <td>10050.0</td>\n",
       "      <td>A000020</td>\n",
       "      <td>1553073897914</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>153030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-21</th>\n",
       "      <td>616120910</td>\n",
       "      <td>62361</td>\n",
       "      <td>2019-03-21 00:00:00.0</td>\n",
       "      <td>FALL</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.018000</td>\n",
       "      <td>2019-03-21</td>\n",
       "      <td>10050.0</td>\n",
       "      <td>9790.0</td>\n",
       "      <td>10050.0</td>\n",
       "      <td>A000020</td>\n",
       "      <td>1553160306054</td>\n",
       "      <td>9820.0</td>\n",
       "      <td>153030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-22</th>\n",
       "      <td>1815471070</td>\n",
       "      <td>187248</td>\n",
       "      <td>2019-03-22 00:00:00.0</td>\n",
       "      <td>FALL</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0.014257</td>\n",
       "      <td>2019-03-22</td>\n",
       "      <td>9920.0</td>\n",
       "      <td>9570.0</td>\n",
       "      <td>9820.0</td>\n",
       "      <td>A000020</td>\n",
       "      <td>1553246690004</td>\n",
       "      <td>9680.0</td>\n",
       "      <td>153030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-25</th>\n",
       "      <td>963192930</td>\n",
       "      <td>100403</td>\n",
       "      <td>2019-03-25 00:00:00.0</td>\n",
       "      <td>FALL</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.003099</td>\n",
       "      <td>2019-03-25</td>\n",
       "      <td>9720.0</td>\n",
       "      <td>9510.0</td>\n",
       "      <td>9600.0</td>\n",
       "      <td>A000020</td>\n",
       "      <td>1553505930832</td>\n",
       "      <td>9650.0</td>\n",
       "      <td>153030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-26</th>\n",
       "      <td>318868690</td>\n",
       "      <td>33185</td>\n",
       "      <td>2019-03-26 00:00:00.0</td>\n",
       "      <td>FALL</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.009326</td>\n",
       "      <td>2019-03-26</td>\n",
       "      <td>9680.0</td>\n",
       "      <td>9560.0</td>\n",
       "      <td>9630.0</td>\n",
       "      <td>A000020</td>\n",
       "      <td>1553592292838</td>\n",
       "      <td>9560.0</td>\n",
       "      <td>153007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-27</th>\n",
       "      <td>221336520</td>\n",
       "      <td>23278</td>\n",
       "      <td>2019-03-27 00:00:00.0</td>\n",
       "      <td>FALL</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.009414</td>\n",
       "      <td>2019-03-27</td>\n",
       "      <td>9600.0</td>\n",
       "      <td>9440.0</td>\n",
       "      <td>9600.0</td>\n",
       "      <td>A000020</td>\n",
       "      <td>1553678714899</td>\n",
       "      <td>9470.0</td>\n",
       "      <td>153030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-28</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-03-28 00:00:00.0</td>\n",
       "      <td>EVEN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2019-03-28</td>\n",
       "      <td>9470.0</td>\n",
       "      <td>9470.0</td>\n",
       "      <td>9470.0</td>\n",
       "      <td>A000020</td>\n",
       "      <td>1553723408284</td>\n",
       "      <td>9470.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            candleAccTradePrice  candleAccTradeVolume             candleTime  \\\n",
       "candleTime                                                                     \n",
       "2019-02-28           1262292450                127433  2019-02-28 00:00:00.0   \n",
       "2019-03-04            858235130                 86244  2019-03-04 00:00:00.0   \n",
       "2019-03-05            655114470                 65110  2019-03-05 00:00:00.0   \n",
       "2019-03-06            484114800                 47791  2019-03-06 00:00:00.0   \n",
       "2019-03-07            658441180                 65924  2019-03-07 00:00:00.0   \n",
       "2019-03-08            343866720                 34591  2019-03-08 00:00:00.0   \n",
       "2019-03-11            877700660                 89651  2019-03-11 00:00:00.0   \n",
       "2019-03-12            502122480                 50658  2019-03-12 00:00:00.0   \n",
       "2019-03-13            748344140                 74778  2019-03-13 00:00:00.0   \n",
       "2019-03-14            736270070                 73439  2019-03-14 00:00:00.0   \n",
       "2019-03-15            595667890                 59500  2019-03-15 00:00:00.0   \n",
       "2019-03-18            378737160                 37952  2019-03-18 00:00:00.0   \n",
       "2019-03-19            784371620                 78213  2019-03-19 00:00:00.0   \n",
       "2019-03-20            270691290                 27138  2019-03-20 00:00:00.0   \n",
       "2019-03-21            616120910                 62361  2019-03-21 00:00:00.0   \n",
       "2019-03-22           1815471070                187248  2019-03-22 00:00:00.0   \n",
       "2019-03-25            963192930                100403  2019-03-25 00:00:00.0   \n",
       "2019-03-26            318868690                 33185  2019-03-26 00:00:00.0   \n",
       "2019-03-27            221336520                 23278  2019-03-27 00:00:00.0   \n",
       "2019-03-28                    0                     0  2019-03-28 00:00:00.0   \n",
       "\n",
       "           change  changePrice  changeRate        date  highPrice  lowPrice  \\\n",
       "candleTime                                                                    \n",
       "2019-02-28   FALL        130.0    0.013092  2019-02-28     9980.0    9720.0   \n",
       "2019-03-04   RISE        200.0    0.020408  2019-03-04    10050.0    9800.0   \n",
       "2019-03-05   RISE        100.0    0.010000  2019-03-05    10150.0    9970.0   \n",
       "2019-03-06   EVEN          0.0    0.000000  2019-03-06    10250.0   10050.0   \n",
       "2019-03-07   FALL        110.0    0.010891  2019-03-07    10100.0    9910.0   \n",
       "2019-03-08   FALL         60.0    0.006006  2019-03-08    10000.0    9860.0   \n",
       "2019-03-11   FALL         80.0    0.008056  2019-03-11     9960.0    9700.0   \n",
       "2019-03-12   RISE         80.0    0.008122  2019-03-12     9960.0    9870.0   \n",
       "2019-03-13   RISE        120.0    0.012085  2019-03-13    10150.0    9930.0   \n",
       "2019-03-14   RISE         50.0    0.004975  2019-03-14    10100.0    9990.0   \n",
       "2019-03-15   FALL        130.0    0.012871  2019-03-15    10150.0    9970.0   \n",
       "2019-03-18   RISE         20.0    0.002006  2019-03-18    10050.0    9900.0   \n",
       "2019-03-19   FALL         10.0    0.001001  2019-03-19    10100.0    9970.0   \n",
       "2019-03-20   RISE         20.0    0.002004  2019-03-20    10050.0    9860.0   \n",
       "2019-03-21   FALL        180.0    0.018000  2019-03-21    10050.0    9790.0   \n",
       "2019-03-22   FALL        140.0    0.014257  2019-03-22     9920.0    9570.0   \n",
       "2019-03-25   FALL         30.0    0.003099  2019-03-25     9720.0    9510.0   \n",
       "2019-03-26   FALL         90.0    0.009326  2019-03-26     9680.0    9560.0   \n",
       "2019-03-27   FALL         90.0    0.009414  2019-03-27     9600.0    9440.0   \n",
       "2019-03-28   EVEN          0.0    0.000000  2019-03-28     9470.0    9470.0   \n",
       "\n",
       "            openingPrice symbolCode      timestamp  tradePrice tradeTime  \n",
       "candleTime                                                                \n",
       "2019-02-28        9930.0    A000020  1551345978459      9800.0    153025  \n",
       "2019-03-04        9810.0    A000020  1551691539233     10000.0    153021  \n",
       "2019-03-05       10050.0    A000020  1551777979504     10100.0    153010  \n",
       "2019-03-06       10150.0    A000020  1551864371128     10100.0    153030  \n",
       "2019-03-07       10050.0    A000020  1551950773359      9990.0    153010  \n",
       "2019-03-08        9990.0    A000020  1552037163192      9930.0    153005  \n",
       "2019-03-11        9930.0    A000020  1552296378581      9850.0    153024  \n",
       "2019-03-12        9900.0    A000020  1552382772168      9930.0    153030  \n",
       "2019-03-13        9950.0    A000020  1552469150813     10050.0    153022  \n",
       "2019-03-14       10050.0    A000020  1552555592864     10100.0    153008  \n",
       "2019-03-15       10150.0    A000020  1552641879602      9970.0    153030  \n",
       "2019-03-18       10000.0    A000020  1552901084372      9990.0    153030  \n",
       "2019-03-19        9990.0    A000020  1552987502446      9980.0    153022  \n",
       "2019-03-20       10050.0    A000020  1553073897914     10000.0    153030  \n",
       "2019-03-21       10050.0    A000020  1553160306054      9820.0    153030  \n",
       "2019-03-22        9820.0    A000020  1553246690004      9680.0    153030  \n",
       "2019-03-25        9600.0    A000020  1553505930832      9650.0    153030  \n",
       "2019-03-26        9630.0    A000020  1553592292838      9560.0    153007  \n",
       "2019-03-27        9600.0    A000020  1553678714899      9470.0    153030  \n",
       "2019-03-28        9470.0    A000020  1553723408284      9470.0      None  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_price('000020', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
