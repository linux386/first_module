{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Crawling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import FinanceDataReader as fdr\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime as dt\n",
    "from datetime import datetime,timedelta\n",
    "from urllib.request import urlopen\n",
    "import sqlalchemy \n",
    "import pymysql\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "from matplotlib import font_manager, rc\n",
    "font_name = font_manager.FontProperties(fname=\"c:/Windows/Fonts/malgun.ttf\").get_name()\n",
    "rc('font', family=font_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MoneyTrend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_money_trend():\n",
    "    \n",
    "    url = 'http://finance.naver.com/sise/sise_deposit.nhn?&page='\n",
    "\n",
    "    source = urlopen(url).read()   # 지정한 페이지에서 코드 읽기\n",
    "    source = BeautifulSoup(source, 'lxml')   # 뷰티풀 스프로 태그별로 코드 분류\n",
    "\n",
    "    last = source.find('td',class_='pgRR').find('a')['href']\n",
    "    last = last.split('&')[1]\n",
    "    last = last.split('=')[1]\n",
    "    last = int(last)\n",
    "\n",
    "    # 사용자의 PC내 폴더 주소를 입력하시면 됩니다.\n",
    "    path = 'd:\\\\moneytrend.xlsx'   \n",
    "    \n",
    "    # 날짜를 받을 리스트\n",
    "    date_list = []\n",
    "\n",
    "    # 값을 받을 사전\n",
    "    dictionary = {'고객예탁금': [],'신용잔고': [],'주식형 펀드': [],'혼합형 펀드': [],'채권형 펀드': []}\n",
    "\n",
    "    # dictionary key 인덱싱을 위한 리스트\n",
    "    name_list = ['고객예탁금','신용잔고','주식형 펀드','혼합형 펀드','채권형 펀드']\n",
    "\n",
    "\n",
    "    # count mask\n",
    "    mask = [1,3,5,7,9]\n",
    "    \n",
    "    for i in range(1,last+1):\n",
    "        \n",
    "        source = urlopen(url+ str(i)).read()\n",
    "        source = BeautifulSoup(source,'lxml')\n",
    "\n",
    "        #tbody = source.find('div',{'id':'wrap'}).find('div',{'class':'box_type_m'})\n",
    "        #trs = tbody.find_all('tr')\n",
    "\n",
    "        body = source.find('body')\n",
    "        trs = body.find_all('tr')\n",
    "\n",
    "        for tr in trs:\n",
    "            tds = tr.find_all('td',{'class':['date','rate_down','rate_up']})\n",
    "            count = 0\n",
    "    \n",
    "            for td in tds:\n",
    "                if count == 0:\n",
    "                    date_ = td.text.strip().replace('.','-')\n",
    "                    date_list.append(date_)\n",
    "                        \n",
    "                      \n",
    "                elif count in mask:\n",
    "                    temp = int((count-1)/2)\n",
    "                    dictionary[name_list[temp]].append(td.text.strip().replace(',',''))\n",
    "        \n",
    "                count += 1\n",
    "            if len(dictionary['고객예탁금']) != len(dictionary['채권형 펀드']):\n",
    "                print(str(i)+ '번째 페이지에서 누락된 값 발생')\n",
    "                print('누락된 데이터를 제거합니다')\n",
    "                    \n",
    "                date_list.pop(-1)\n",
    "                dictionary['고객예탁금'].pop(-1)\n",
    "                dictionary['신용잔고'].pop(-1)\n",
    "                dictionary['주식형 펀드'].pop(-1)\n",
    "                dictionary['혼합형 펀드'].pop(-1)\n",
    "                \n",
    "    # 개별 list 요소 갯수 파악 \n",
    "    #print(len(date_list))\n",
    "    #print(len(dictionary['고객예탁금']))\n",
    "    #print(len(dictionary['신용잔고']))\n",
    "    #print(len(dictionary['주식형 펀드']))\n",
    "    #print(len(dictionary['혼합형 펀드']))\n",
    "    #print(len(dictionary['채권형 펀드']))\n",
    "    print(str(i) + '번째 페이지 크롤링 완료')\n",
    "    df = pd.DataFrame(dictionary,index = date_list)\n",
    "    df = df.sort_index()\n",
    "    df.to_excel(path, encoding='utf-8')\n",
    "    print(df)\n",
    "\n",
    "\n",
    "get_money_trend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "날짜를 입력하세요 sample: '2019-01-10': 2019-03-08\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>고객예탁금</th>\n",
       "      <th>신용잔고</th>\n",
       "      <th>주식형 펀드</th>\n",
       "      <th>혼합형 펀드</th>\n",
       "      <th>채권형 펀드</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19-03-11</th>\n",
       "      <td>249,915</td>\n",
       "      <td>103,175</td>\n",
       "      <td>861,947</td>\n",
       "      <td>275,543</td>\n",
       "      <td>1,076,049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-03-12</th>\n",
       "      <td>241,209</td>\n",
       "      <td>103,111</td>\n",
       "      <td>864,535</td>\n",
       "      <td>275,569</td>\n",
       "      <td>1,072,923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-03-13</th>\n",
       "      <td>248,093</td>\n",
       "      <td>103,310</td>\n",
       "      <td>861,124</td>\n",
       "      <td>275,556</td>\n",
       "      <td>1,073,121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            고객예탁금     신용잔고   주식형 펀드   혼합형 펀드     채권형 펀드\n",
       "19-03-11  249,915  103,175  861,947  275,543  1,076,049\n",
       "19-03-12  241,209  103,111  864,535  275,569  1,072,923\n",
       "19-03-13  248,093  103,310  861,124  275,556  1,073,121"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_money_trend_date():\n",
    "    url = 'http://finance.naver.com/sise/sise_deposit.nhn?&page='\n",
    "\n",
    "    source = urlopen(url).read()   # 지정한 페이지에서 코드 읽기\n",
    "    source = BeautifulSoup(source, 'lxml')   # 뷰티풀 스프로 태그별로 코드 분류\n",
    "\n",
    "    last = source.find('td',class_='pgRR').find('a')['href']\n",
    "    last = last.split('&')[1]\n",
    "    last = last.split('=')[1]\n",
    "    last = int(last)\n",
    "\n",
    "    # 사용자의 PC내 폴더 주소를 입력하시면 됩니다.\n",
    "    path = 'd:\\\\money_trend.xlsx'\n",
    "\n",
    "    \n",
    "    until_date = input(\"날짜를 입력하세요 sample: '2019-01-10': \")\n",
    "    \n",
    "    year = until_date.split('-')[0]\n",
    "    mm = until_date.split('-')[1]\n",
    "    dd = until_date.split('-')[2]\n",
    "    year=year[2:]\n",
    "    until_date = year+'-'+mm+'-'+dd\n",
    "    \n",
    "    #df = DataFrame(columns = ['고객예탁금', '신용잔고','주식형 펀드','혼합형 펀드','채권형 펀드'])\n",
    "\n",
    "    # 날짜를 받을 리스트\n",
    "    date_list = []\n",
    "\n",
    "    \n",
    "    # 값을 받을 사전\n",
    "    dictionary = {'고객예탁금': [],\n",
    "                  '신용잔고': [],\n",
    "                  '주식형 펀드': [],\n",
    "                  '혼합형 펀드': [],\n",
    "                  '채권형 펀드': []\n",
    "                  }\n",
    "\n",
    "    # dictionary key 인덱싱을 위한 리스트\n",
    "    name_list = ['고객예탁금','신용잔고','주식형 펀드','혼합형 펀드','채권형 펀드']\n",
    "\n",
    "\n",
    "    # count mask\n",
    "    mask = [1,3,5,7,9]\n",
    "    \n",
    "    for i in range(1,last+1):\n",
    "        \n",
    "        source = urlopen(url+ str(i)).read()\n",
    "        source = BeautifulSoup(source,'lxml')\n",
    "\n",
    "        #tbody = source.find('div',{'id':'wrap'}).find('div',{'class':'box_type_m'})\n",
    "        #trs = tbody.find_all('tr')\n",
    "\n",
    "        body = source.find('body')\n",
    "        trs = body.find_all('tr')\n",
    "\n",
    "        for tr in trs:\n",
    "            tds = tr.find_all('td',{'class':['date','rate_down','rate_up']})\n",
    "            count = 0\n",
    "    \n",
    "            for td in tds:\n",
    "                if count == 0:\n",
    "                    date_ = td.text.strip().replace('.','-')\n",
    "                    if date_ <=  until_date :\n",
    "                    #if date_ <=  '19-03-05' :\n",
    "                        df = pd.DataFrame(dictionary,index = date_list)\n",
    "                        df = df.sort_index()\n",
    "                        df.to_excel(path, encoding='utf-8')\n",
    "                        return df\n",
    "                    date_list.append(date_)\n",
    "                    \n",
    "                elif count in mask:\n",
    "                    temp = int((count-1)/2)\n",
    "                    dictionary[name_list[temp]].append(td.text.strip().replace(',',''))\n",
    "                \n",
    "       \n",
    "                count += 1\n",
    "\n",
    "get_money_trend_date()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KPI200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kpi200():\n",
    "    \n",
    "    url = 'https://finance.naver.com/sise/sise_index_day.nhn?code=KPI200&page='\n",
    "\n",
    "    source = urlopen(url).read()   # 지정한 페이지에서 코드 읽기\n",
    "    source = BeautifulSoup(source, 'lxml')   # 뷰티풀 스프로 태그별로 코드 분류\n",
    "\n",
    "    last = source.find('td',class_='pgRR').find('a')['href']\n",
    "    last = last.split('page')[1]\n",
    "    last = last.split('=')[1]\n",
    "    last = int(last)\n",
    "    print(last)\n",
    "\n",
    "    # 사용자의 PC내 폴더 주소를 입력하시면 됩니다.\n",
    "    path = 'd:\\\\kpi200.xlsx'\n",
    "    \n",
    "    # 날짜를 받을 리스트\n",
    "    date_list = []\n",
    "\n",
    "    # 값을 받을 사전\n",
    "    dictionary = {'KPI200': [],'거래량': []}\n",
    "\n",
    "    # dictionary key 인덱싱을 위한 리스트\n",
    "    name_list = ['KPI200','거래량']\n",
    "\n",
    "\n",
    "    # count mask\n",
    "    mask = [1,3]\n",
    "    \n",
    "    for i in range(1,last+1):\n",
    "        \n",
    "        source = urlopen(url+ str(i)).read()\n",
    "        source = BeautifulSoup(source,'lxml')\n",
    "\n",
    "        #tbody = source.find('div',{'id':'wrap'}).find('div',{'class':'box_type_m'})\n",
    "        #trs = tbody.find_all('tr')\n",
    "\n",
    "        body = source.find('body')\n",
    "        trs = body.find_all('tr')\n",
    "\n",
    "        for tr in trs:\n",
    "            tds = tr.find_all('td',{'class':['date','number_1']})\n",
    "            count = 0\n",
    "    \n",
    "            for td in tds:\n",
    "                if count == 0:\n",
    "                    date_ = td.text.strip().replace('.','-')\n",
    "                    date_list.append(date_)\n",
    "                        \n",
    "                      \n",
    "                elif count in mask:\n",
    "                    temp = int(count/3)\n",
    "                    dictionary[name_list[temp]].append(td.text.strip().replace(',',''))\n",
    "        \n",
    "                count += 1\n",
    "            if len(date_list) != len(dictionary['KPI200']):\n",
    "                print(str(i)+ '번째 페이지에서 누락된 값 발생')\n",
    "                print('누락된 데이터를 제거합니다')\n",
    "                    \n",
    "                date_list.pop(-1)\n",
    "                #dictionary['KPI200'].pop(-1)\n",
    "                dictionary['거래량'].pop(-1)\n",
    "                \n",
    "    # 개별 list 요소 갯수 파악 \n",
    "    #print(len(date_list))\n",
    "    #print(len(dictionary['개인']))\n",
    "    #print(len(dictionary['외국인']))\n",
    "    #print(len(dictionary['기관']))\n",
    "\n",
    "    print(str(i) + '번째 페이지 크롤링 완료')\n",
    "    df = pd.DataFrame(dictionary,index = date_list)\n",
    "    df = df.sort_index()\n",
    "    df.to_excel(path, encoding='utf-8')\n",
    "    print(df)\n",
    "\n",
    "get_kpi200()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kpi200_date():\n",
    "    \n",
    "    url = 'https://finance.naver.com/sise/sise_index_day.nhn?code=KPI200&page='\n",
    "\n",
    "    source = urlopen(url).read()   # 지정한 페이지에서 코드 읽기\n",
    "    source = BeautifulSoup(source, 'lxml')   # 뷰티풀 스프로 태그별로 코드 분류\n",
    "\n",
    "    last = source.find('td',class_='pgRR').find('a')['href']\n",
    "    last = last.split('page')[1]\n",
    "    last = last.split('=')[1]\n",
    "    last = int(last)\n",
    "    print(last)\n",
    "\n",
    "    # 사용자의 PC내 폴더 주소를 입력하시면 됩니다.\n",
    "    path = 'd:\\\\kpi200.xlsx'\n",
    "\n",
    "    until_date = input(\"날짜를 입력하세요 sample: '2019-01-10': \")\n",
    "    \n",
    "    year = until_date.split('-')[0]\n",
    "    mm = until_date.split('-')[1]\n",
    "    dd = until_date.split('-')[2]\n",
    "    #year=year[2:]\n",
    "    until_date = year+'-'+mm+'-'+dd\n",
    "    \n",
    "    # 날짜를 받을 리스트\n",
    "    date_list = []\n",
    "\n",
    "    # 값을 받을 사전\n",
    "    dictionary = {'KPI200': [],'거래량': []}\n",
    "\n",
    "    # dictionary key 인덱싱을 위한 리스트\n",
    "    name_list = ['KPI200','거래량']\n",
    "\n",
    "\n",
    "    # count mask\n",
    "    mask = [1,3]\n",
    "    \n",
    "    for i in range(1,last+1):\n",
    "        \n",
    "        source = urlopen(url+ str(i)).read()\n",
    "        source = BeautifulSoup(source,'lxml')\n",
    "\n",
    "        #tbody = source.find('div',{'id':'wrap'}).find('div',{'class':'box_type_m'})\n",
    "        #trs = tbody.find_all('tr')\n",
    "\n",
    "        body = source.find('body')\n",
    "        trs = body.find_all('tr')\n",
    "\n",
    "        for tr in trs:\n",
    "            tds = tr.find_all('td',{'class':['date','number_1']})\n",
    "            count = 0\n",
    "    \n",
    "            for td in tds:\n",
    "                if count == 0:\n",
    "                    date_ = td.text.strip().replace('.','-')\n",
    "                    if date_ <=  until_date :\n",
    "                    #if date_ <=  '19-03-05' :\n",
    "                        df = pd.DataFrame(dictionary,index = date_list)\n",
    "                        df = df.sort_index()\n",
    "                        df.to_excel(path, encoding='utf-8')\n",
    "                        return df   \n",
    "                    date_list.append(date_)\n",
    "                    #print(date_list)\n",
    "                elif count in mask:\n",
    "                    temp = int(count/3)\n",
    "                    dictionary[name_list[temp]].append(td.text.strip().replace(',',''))\n",
    "                    #print(dictionary[name_list[temp]])\n",
    "                count += 1\n",
    "                \n",
    "get_kpi200_date()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investor Trend"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def get_investor_trend():\n",
    "    \n",
    "    url = 'http://finance.naver.com/sise/investorDealTrendDay.nhn?bizdate=2020601&sosok=&page='\n",
    "\n",
    "    source = urlopen(url).read()   # 지정한 페이지에서 코드 읽기\n",
    "    source = BeautifulSoup(source, 'lxml')   # 뷰티풀 스프로 태그별로 코드 분류\n",
    "\n",
    "    last = source.find('td',class_='pgRR').find('a')['href']\n",
    "    last = last.split('page')[1]\n",
    "    last = last.split('=')[1]\n",
    "    last = int(last)\n",
    "    print(last)\n",
    "\n",
    "    # 사용자의 PC내 폴더 주소를 입력하시면 됩니다.\n",
    "    path = 'd:\\\\investortrend.xlsx'\n",
    "    \n",
    "    # 날짜를 받을 리스트\n",
    "    date_list = []\n",
    "\n",
    "    # 값을 받을 사전\n",
    "    dictionary = {'개인': [],'외국인': [],'기관': []}\n",
    "\n",
    "    # dictionary key 인덱싱을 위한 리스트\n",
    "    name_list = ['개인','외국인','기관']\n",
    "\n",
    "\n",
    "    # count mask\n",
    "    mask = [1,2,3]\n",
    "    \n",
    "    for i in range(1,last+1):\n",
    "        \n",
    "        source = urlopen(url+ str(i)).read()\n",
    "        source = BeautifulSoup(source,'lxml')\n",
    "\n",
    "        #tbody = source.find('div',{'id':'wrap'}).find('div',{'class':'box_type_m'})\n",
    "        #trs = tbody.find_all('tr')\n",
    "\n",
    "        body = source.find('body')\n",
    "        trs = body.find_all('tr')\n",
    "\n",
    "        for tr in trs:\n",
    "            tds = tr.find_all('td',{'class':['date2','rate_down3','rate_up3']})\n",
    "            count = 0\n",
    "    \n",
    "            for td in tds:\n",
    "                if count == 0:\n",
    "                    date_ = td.text.strip().replace('.','-')\n",
    "                    date_list.append(date_)\n",
    "                        \n",
    "                      \n",
    "                elif count in mask:\n",
    "                    temp = int(count-1)\n",
    "                    dictionary[name_list[temp]].append(td.text.strip().replace(',',''))\n",
    "        \n",
    "                count += 1\n",
    "            if len(date_list) != len(dictionary['개인']):\n",
    "                print(str(i)+ '번째 페이지에서 누락된 값 발생')\n",
    "                print('누락된 데이터를 제거합니다')\n",
    "                    \n",
    "                date_list.pop(-1)\n",
    "                dictionary['개인'].pop(-1)\n",
    "                dictionary['외국인'].pop(-1)\n",
    "                dictionary['기관'].pop(-1)\n",
    "                \n",
    "    # 개별 list 요소 갯수 파악 \n",
    "    #print(len(date_list))\n",
    "    #print(len(dictionary['개인']))\n",
    "    #print(len(dictionary['외국인']))\n",
    "    #print(len(dictionary['기관']))\n",
    "\n",
    "    print(str(i) + '번째 페이지 크롤링 완료')\n",
    "    df = pd.DataFrame(dictionary,index = date_list)\n",
    "    df = df.sort_index()\n",
    "    df.to_excel(path, encoding='utf-8')\n",
    "    print(df)\n",
    "\n",
    "get_investor_trend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_investor_trend_date():\n",
    "    \n",
    "    url = 'http://finance.naver.com/sise/investorDealTrendDay.nhn?bizdate=2020601&sosok=&page='\n",
    "\n",
    "    source = urlopen(url).read()   # 지정한 페이지에서 코드 읽기\n",
    "    source = BeautifulSoup(source, 'lxml')   # 뷰티풀 스프로 태그별로 코드 분류\n",
    "\n",
    "    last = source.find('td',class_='pgRR').find('a')['href']\n",
    "    last = last.split('page')[1]\n",
    "    last = last.split('=')[1]\n",
    "    last = int(last)\n",
    "    print(last)\n",
    "\n",
    "    # 사용자의 PC내 폴더 주소를 입력하시면 됩니다.\n",
    "    path = 'd:\\\\investortrend.xlsx'\n",
    "\n",
    "    until_date = input(\"날짜를 입력하세요 sample: '2019-01-10': \")\n",
    "    \n",
    "    year = until_date.split('-')[0]\n",
    "    mm = until_date.split('-')[1]\n",
    "    dd = until_date.split('-')[2]\n",
    "    year=year[2:]\n",
    "    until_date = year+'-'+mm+'-'+dd\n",
    "    \n",
    "    # 날짜를 받을 리스트\n",
    "    date_list = []\n",
    "\n",
    "    # 값을 받을 사전\n",
    "    dictionary = {'개인': [],'외국인': [],'기관': []}\n",
    "\n",
    "    # dictionary key 인덱싱을 위한 리스트\n",
    "    name_list = ['개인','외국인','기관']\n",
    "\n",
    "\n",
    "    # count mask\n",
    "    mask = [1,2,3]\n",
    "    \n",
    "    for i in range(1,last+1):\n",
    "        \n",
    "        source = urlopen(url+ str(i)).read()\n",
    "        source = BeautifulSoup(source,'lxml')\n",
    "\n",
    "        #tbody = source.find('div',{'id':'wrap'}).find('div',{'class':'box_type_m'})\n",
    "        #trs = tbody.find_all('tr')\n",
    "\n",
    "        body = source.find('body')\n",
    "        trs = body.find_all('tr')\n",
    "\n",
    "        for tr in trs:\n",
    "            tds = tr.find_all('td',{'class':['date2','rate_down3','rate_up3']})\n",
    "            count = 0\n",
    "    \n",
    "            for td in tds:\n",
    "                if count == 0:\n",
    "                    date_ = td.text.strip().replace('.','-')\n",
    "                    if date_ <=  until_date :\n",
    "                        df = pd.DataFrame(dictionary,index = date_list)\n",
    "                        df = df.sort_index()\n",
    "                        df.to_excel(path, encoding='utf-8')\n",
    "                        return df   \n",
    "                    date_list.append(date_)\n",
    "                    #print(date_list)\n",
    "                elif count in mask:\n",
    "                    temp = int(count-1)\n",
    "                    dictionary[name_list[temp]].append(td.text.strip().replace(',',''))\n",
    "                    \n",
    "                count += 1\n",
    "get_investor_trend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Program Trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_program_trend():\n",
    "    \n",
    "    url = 'https://finance.naver.com/sise/programDealTrendDay.nhn?bizdate=20190315&sosok=&page='\n",
    "\n",
    "    source = urlopen(url).read()   # 지정한 페이지에서 코드 읽기\n",
    "    source = BeautifulSoup(source, 'lxml')   # 뷰티풀 스프로 태그별로 코드 분류\n",
    "\n",
    "    last = source.find('td',class_='pgRR').find('a')['href']\n",
    "    last = last.split('page')[1]\n",
    "    last = last.split('=')[1]\n",
    "    last = int(last)\n",
    "    print(last)\n",
    "\n",
    "    # 사용자의 PC내 폴더 주소를 입력하시면 됩니다.\n",
    "    path = 'd:\\\\programtrend.xlsx'\n",
    "    \n",
    "    # 날짜를 받을 리스트\n",
    "    date_list = []\n",
    "\n",
    "    # 값을 받을 사전\n",
    "    dictionary = {'차익': [],'비차익': [],'전체': []}\n",
    "\n",
    "    # dictionary key 인덱싱을 위한 리스트\n",
    "    name_list = ['차익','비차익','전체']\n",
    "\n",
    "\n",
    "    # count mask\n",
    "    mask = [3,6,9]\n",
    "    \n",
    "    for i in range(1,last+1):\n",
    "        \n",
    "        source = urlopen(url+ str(i)).read()\n",
    "        source = BeautifulSoup(source,'lxml')\n",
    "\n",
    "        #tbody = source.find('div',{'id':'wrap'}).find('div',{'class':'box_type_m'})\n",
    "        #trs = tbody.find_all('tr')\n",
    "\n",
    "        body = source.find('body')\n",
    "        trs = body.find_all('tr')\n",
    "\n",
    "        for tr in trs:\n",
    "            tds = tr.find_all('td',{'class':['date','rate_down','rate_up']})\n",
    "            count = 0\n",
    "    \n",
    "            for td in tds:\n",
    "                if count == 0:\n",
    "                    date_ = td.text.strip().replace('.','-')\n",
    "                    date_list.append(date_)\n",
    "                        \n",
    "                      \n",
    "                elif count in mask:\n",
    "                    temp = int((count/3)-1)\n",
    "                    dictionary[name_list[temp]].append(td.text.strip().replace(',',''))\n",
    "        \n",
    "                count += 1\n",
    "            if len(date_list) != len(dictionary['전체']):\n",
    "                print(str(i)+ '번째 페이지에서 누락된 값 발생')\n",
    "                print('누락된 데이터를 제거합니다')\n",
    "                    \n",
    "                date_list.pop(-1)\n",
    "                dictionary['차익'].pop(-1)\n",
    "                dictionary['비차익'].pop(-1)\n",
    "                #dictionary['전체'].pop(-1)\n",
    "                \n",
    "    # 개별 list 요소 갯수 파악 \n",
    "    print(len(date_list))\n",
    "    print(len(dictionary['차익']))\n",
    "    print(len(dictionary['비차익']))\n",
    "    print(len(dictionary['전체']))\n",
    "\n",
    "    print(str(i) + '번째 페이지 크롤링 완료')\n",
    "    df = pd.DataFrame(dictionary,index = date_list)\n",
    "    df = df.sort_index()\n",
    "    df.to_excel(path, encoding='utf-8')\n",
    "    print(df)\n",
    "\n",
    "get_program_trend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "352\n",
      "날짜를 입력하세요 sample: '2019-01-10': 2019-03-01\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>차익</th>\n",
       "      <th>비차익</th>\n",
       "      <th>전체</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19-03-04</th>\n",
       "      <td>1168</td>\n",
       "      <td>1453</td>\n",
       "      <td>-285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-03-05</th>\n",
       "      <td>1797</td>\n",
       "      <td>2161</td>\n",
       "      <td>-364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-03-06</th>\n",
       "      <td>1289</td>\n",
       "      <td>1807</td>\n",
       "      <td>-518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-03-07</th>\n",
       "      <td>1450</td>\n",
       "      <td>1698</td>\n",
       "      <td>-248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-03-08</th>\n",
       "      <td>1345</td>\n",
       "      <td>1560</td>\n",
       "      <td>-215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-03-11</th>\n",
       "      <td>1220</td>\n",
       "      <td>1334</td>\n",
       "      <td>-114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-03-12</th>\n",
       "      <td>1188</td>\n",
       "      <td>1327</td>\n",
       "      <td>-139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-03-13</th>\n",
       "      <td>1218</td>\n",
       "      <td>1513</td>\n",
       "      <td>-294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-03-14</th>\n",
       "      <td>2228</td>\n",
       "      <td>3020</td>\n",
       "      <td>-792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-03-15</th>\n",
       "      <td>2176</td>\n",
       "      <td>1756</td>\n",
       "      <td>420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            차익   비차익    전체\n",
       "19-03-04  1168  1453  -285\n",
       "19-03-05  1797  2161  -364\n",
       "19-03-06  1289  1807  -518\n",
       "19-03-07  1450  1698  -248\n",
       "19-03-08  1345  1560  -215\n",
       "19-03-11  1220  1334  -114\n",
       "19-03-12  1188  1327  -139\n",
       "19-03-13  1218  1513  -294\n",
       "19-03-14  2228  3020  -792\n",
       "19-03-15  2176  1756   420"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_program_trend_date():\n",
    "    \n",
    "    url = 'https://finance.naver.com/sise/programDealTrendDay.nhn?bizdate=20190315&sosok=&page='\n",
    "\n",
    "    source = urlopen(url).read()   # 지정한 페이지에서 코드 읽기\n",
    "    source = BeautifulSoup(source, 'lxml')   # 뷰티풀 스프로 태그별로 코드 분류\n",
    "\n",
    "    last = source.find('td',class_='pgRR').find('a')['href']\n",
    "    last = last.split('page')[1]\n",
    "    last = last.split('=')[1]\n",
    "    last = int(last)\n",
    "    print(last)\n",
    "\n",
    "    # 사용자의 PC내 폴더 주소를 입력하시면 됩니다.\n",
    "    path = 'd:\\\\investortrend.xlsx'\n",
    "\n",
    "    until_date = input(\"날짜를 입력하세요 sample: '2019-01-10': \")\n",
    "    \n",
    "    year = until_date.split('-')[0]\n",
    "    mm = until_date.split('-')[1]\n",
    "    dd = until_date.split('-')[2]\n",
    "    year=year[2:]\n",
    "    until_date = year+'-'+mm+'-'+dd\n",
    "    \n",
    "    # 날짜를 받을 리스트\n",
    "    date_list = []\n",
    "\n",
    "    # 값을 받을 사전\n",
    "    dictionary = {'차익': [],'비차익': [],'전체': []}\n",
    "\n",
    "    # dictionary key 인덱싱을 위한 리스트\n",
    "    name_list = ['차익','비차익','전체']\n",
    "\n",
    "\n",
    "    # count mask\n",
    "    mask = [1,2,3]\n",
    "    \n",
    "    for i in range(1,last+1):\n",
    "        \n",
    "        source = urlopen(url+ str(i)).read()\n",
    "        source = BeautifulSoup(source,'lxml')\n",
    "\n",
    "        #tbody = source.find('div',{'id':'wrap'}).find('div',{'class':'box_type_m'})\n",
    "        #trs = tbody.find_all('tr')\n",
    "\n",
    "        body = source.find('body')\n",
    "        trs = body.find_all('tr')\n",
    "\n",
    "        for tr in trs:\n",
    "            tds = tr.find_all('td',{'class':['date','rate_down','rate_up']})\n",
    "            count = 0\n",
    "    \n",
    "            for td in tds:\n",
    "                if count == 0:\n",
    "                    date_ = td.text.strip().replace('.','-')\n",
    "                    if date_ <=  until_date :\n",
    "                        df = pd.DataFrame(dictionary,index = date_list)\n",
    "                        df = df.sort_index()\n",
    "                        df.to_excel(path, encoding='utf-8')\n",
    "                        return df   \n",
    "                    date_list.append(date_)\n",
    "                    #print(date_list)\n",
    "                elif count in mask:\n",
    "                    temp = int(count-1)\n",
    "                    dictionary[name_list[temp]].append(td.text.strip().replace(',',''))\n",
    "                    \n",
    "                count += 1\n",
    "get_program_trend_date()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "352\n"
     ]
    }
   ],
   "source": [
    "def get_program_trend():\n",
    "    \n",
    "    url = 'https://finance.naver.com/sise/programDealTrendDay.nhn?bizdate=20190315&sosok=&page=1'\n",
    "\n",
    "    source = urlopen(url).read()   # 지정한 페이지에서 코드 읽기\n",
    "    source = BeautifulSoup(source, 'lxml')   # 뷰티풀 스프로 태그별로 코드 분류\n",
    "\n",
    "    last = source.find('td',class_='pgRR').find('a')['href']\n",
    "    last = last.split('page')[1]\n",
    "    last = last.split('=')[1]\n",
    "    last = int(last)\n",
    "    print(last)\n",
    "get_program_trend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-63d620e94b24>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\gpu\\lib\\json\\__init__.py\u001b[0m in \u001b[0;36mloads\u001b[1;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    352\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[1;32m--> 354\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    355\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m         \u001b[0mcls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\gpu\\lib\\json\\decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m         \"\"\"\n\u001b[1;32m--> 339\u001b[1;33m         \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    340\u001b[0m         \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\gpu\\lib\\json\\decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    355\u001b[0m             \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 357\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Expecting value\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    358\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "url = 'http://finance.daum.net/api/trend/arounds?page=1&perPage=20&fieldName=changeRate&order=desc&'\n",
    "\n",
    "headers = {\n",
    "            'Accept': 'application/json, text/javascript, */*; q=0.01',\n",
    "            'Accept-Encoding': 'gzip, deflate',\n",
    "            'Accept-Language': 'ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7',\n",
    "            'Connection': 'keep-alive',\n",
    "            'Cookie': 'webid=d46440de38044bf09793bcb7b72f6e44; HM_CU=53tOIE3pJAl; PROF=0603012032024076024152UiQPJk7X-6w0mlxoempuua9ZV2cHpAw.yYZCWRveAG66KuZP3z7wEl2bxriNh5SdkQ00LYYSA9A1_cGNLCyhCzrwOpjlf.dyaYOF73J4wVWlUV-s4YfMaxSVtlykILG9ANzoDGNdZmMA6ow0fIauQlo8OTLLnHHY.bHDTw00pCsuaN7PcHxD-1-COJRcrCRKdtGkJTxsMPDn.AARqchjj_-wex3iZx3wLHSw2zOJV.v6jIW4KBMTlbLOnujI-eVINNr9BbQ_KeOzYuEMT_ef42fOXQqNBos4gXyk4bhTSZyZ2Y1KFae9xnaQoQWr5w00; SLEVEL=1; ssab=; AGEN=_mu9pzAMt5sQLPv-ldWVC_IAFijAIG9qARn2QDRvByo; TS=1553412011; HTS=CiiEXdlRFxG7ojGJ9WgV1w00; LSID=f6127be3-d5e5-4032-8c37-628ae599bd181553412011772; _ga=GA1.2.425358004.1553636955; _gid=GA1.2.296667810.1553636955; webid_sync=1553723295574; _gat_gtag_UA_128578811_1=1; TIARA=33ct94Z7b1leKyZ3bC-NI856RU7.OHSANrbu4xUyWnUvsKKAGyYHKdKtFobGx.DrFpAAYU4lBaLcWieRt6trQmWZ_AYwcswz',\n",
    "            'Host': 'finance.daum.net',\n",
    "            'If-None-Match': 'W/\"486e9e8ca2eb9ee4cfa1c386a42117f3\"',\n",
    "            'Referer': 'http://finance.daum.net/domestic/arounds',\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.86 Safari/537.36'\n",
    "            }\n",
    "headers['Referer'] = 'http://finance.daum.net/api/trend/arounds?page=1&perPage=20&fieldName=changeRate&order=desc&'\n",
    "r = requests.get(url, headers = headers)\n",
    "\n",
    "data = json.loads(r.text)\n",
    "df = pd.DataFrame(data['data'])\n",
    "\n",
    "return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def get_price(code, n):\n",
    "    # DATA를 불러오는 부분 입니다.\n",
    "    url = 'http://finance.daum.net/api/charts/A%s/days?limit=%d&adjusted=true'%(code, n)\n",
    "    headers = {\n",
    "                'Accept': 'application/json, text/plain, */*',\n",
    "                'Accept-Encoding': 'gzip, deflate',\n",
    "                'Accept-Language': 'ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7',\n",
    "                'Connection': 'keep-alive',\n",
    "                'Cookie': 'GS_font_Name_no=0; GS_font_size=16; _ga=GA1.3.937989519.1493034297; webid=bb619e03ecbf4672b8d38a3fcedc3f8c; _ga=GA1.2.937989519.1493034297; _gid=GA1.2.215330840.1541556419; KAKAO_STOCK_RECENT=[%22A069500%22]; recentMenus=[{%22destination%22:%22chart%22%2C%22title%22:%22%EC%B0%A8%ED%8A%B8%22}%2C{%22destination%22:%22current%22%2C%22title%22:%22%ED%98%84%EC%9E%AC%EA%B0%80%22}]; TIARA=C-Tax5zAJ3L1CwQFDxYNxe-9yt4xuvAcw3IjfDg6hlCbJ_KXLZZhwEPhrMuSc5Rv1oty5obaYZzBQS5Du9ne5x7XZds-vHVF; webid_sync=1541565778037; _gat_gtag_UA_128578811_1=1; _dfs=VFlXMkVwUGJENlVvc1B3V2NaV1pFdHhpNTVZdnRZTWFZQWZwTzBPYWRxMFNVL3VrODRLY1VlbXI0dHhBZlJzcE03SS9Vblh0U2p2L2V2b3hQbU5mNlE9PS0tcGI2aXQrZ21qY0hFbzJ0S1hkaEhrZz09--6eba3111e6ac36d893bbc58439d2a3e0304c7cf3',\n",
    "                'Host': 'finance.daum.net',\n",
    "                'If-None-Match': 'W/\"23501689faaaf24452ece4a039a904fd\"',\n",
    "                'Referer': 'http://finance.daum.net/quotes/A069500',\n",
    "                'User-Agent':'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'\n",
    "                }\n",
    "    headers['Referer'] = 'http://finance.daum.net/quotes/A%s'%code\n",
    "    r = requests.get(url, headers = headers)\n",
    "    \n",
    "    # DATA를 보기 좋게 편집하는 부분 입니다.\n",
    "    data = json.loads(r.text)\n",
    "    df = pd.DataFrame(data['data'])\n",
    "    df.index = pd.to_datetime(df['candleTime'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>candleAccTradePrice</th>\n",
       "      <th>candleAccTradeVolume</th>\n",
       "      <th>candleTime</th>\n",
       "      <th>change</th>\n",
       "      <th>changePrice</th>\n",
       "      <th>changeRate</th>\n",
       "      <th>date</th>\n",
       "      <th>highPrice</th>\n",
       "      <th>lowPrice</th>\n",
       "      <th>openingPrice</th>\n",
       "      <th>symbolCode</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>tradePrice</th>\n",
       "      <th>tradeTime</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candleTime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-02-28</th>\n",
       "      <td>1262292450</td>\n",
       "      <td>127433</td>\n",
       "      <td>2019-02-28 00:00:00.0</td>\n",
       "      <td>FALL</td>\n",
       "      <td>130.0</td>\n",
       "      <td>0.013092</td>\n",
       "      <td>2019-02-28</td>\n",
       "      <td>9980.0</td>\n",
       "      <td>9720.0</td>\n",
       "      <td>9930.0</td>\n",
       "      <td>A000020</td>\n",
       "      <td>1551345978459</td>\n",
       "      <td>9800.0</td>\n",
       "      <td>153025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-04</th>\n",
       "      <td>858235130</td>\n",
       "      <td>86244</td>\n",
       "      <td>2019-03-04 00:00:00.0</td>\n",
       "      <td>RISE</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>2019-03-04</td>\n",
       "      <td>10050.0</td>\n",
       "      <td>9800.0</td>\n",
       "      <td>9810.0</td>\n",
       "      <td>A000020</td>\n",
       "      <td>1551691539233</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>153021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-05</th>\n",
       "      <td>655114470</td>\n",
       "      <td>65110</td>\n",
       "      <td>2019-03-05 00:00:00.0</td>\n",
       "      <td>RISE</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>2019-03-05</td>\n",
       "      <td>10150.0</td>\n",
       "      <td>9970.0</td>\n",
       "      <td>10050.0</td>\n",
       "      <td>A000020</td>\n",
       "      <td>1551777979504</td>\n",
       "      <td>10100.0</td>\n",
       "      <td>153010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-06</th>\n",
       "      <td>484114800</td>\n",
       "      <td>47791</td>\n",
       "      <td>2019-03-06 00:00:00.0</td>\n",
       "      <td>EVEN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2019-03-06</td>\n",
       "      <td>10250.0</td>\n",
       "      <td>10050.0</td>\n",
       "      <td>10150.0</td>\n",
       "      <td>A000020</td>\n",
       "      <td>1551864371128</td>\n",
       "      <td>10100.0</td>\n",
       "      <td>153030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-07</th>\n",
       "      <td>658441180</td>\n",
       "      <td>65924</td>\n",
       "      <td>2019-03-07 00:00:00.0</td>\n",
       "      <td>FALL</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.010891</td>\n",
       "      <td>2019-03-07</td>\n",
       "      <td>10100.0</td>\n",
       "      <td>9910.0</td>\n",
       "      <td>10050.0</td>\n",
       "      <td>A000020</td>\n",
       "      <td>1551950773359</td>\n",
       "      <td>9990.0</td>\n",
       "      <td>153010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-08</th>\n",
       "      <td>343866720</td>\n",
       "      <td>34591</td>\n",
       "      <td>2019-03-08 00:00:00.0</td>\n",
       "      <td>FALL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.006006</td>\n",
       "      <td>2019-03-08</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>9860.0</td>\n",
       "      <td>9990.0</td>\n",
       "      <td>A000020</td>\n",
       "      <td>1552037163192</td>\n",
       "      <td>9930.0</td>\n",
       "      <td>153005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-11</th>\n",
       "      <td>877700660</td>\n",
       "      <td>89651</td>\n",
       "      <td>2019-03-11 00:00:00.0</td>\n",
       "      <td>FALL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.008056</td>\n",
       "      <td>2019-03-11</td>\n",
       "      <td>9960.0</td>\n",
       "      <td>9700.0</td>\n",
       "      <td>9930.0</td>\n",
       "      <td>A000020</td>\n",
       "      <td>1552296378581</td>\n",
       "      <td>9850.0</td>\n",
       "      <td>153024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-12</th>\n",
       "      <td>502122480</td>\n",
       "      <td>50658</td>\n",
       "      <td>2019-03-12 00:00:00.0</td>\n",
       "      <td>RISE</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.008122</td>\n",
       "      <td>2019-03-12</td>\n",
       "      <td>9960.0</td>\n",
       "      <td>9870.0</td>\n",
       "      <td>9900.0</td>\n",
       "      <td>A000020</td>\n",
       "      <td>1552382772168</td>\n",
       "      <td>9930.0</td>\n",
       "      <td>153030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-13</th>\n",
       "      <td>748344140</td>\n",
       "      <td>74778</td>\n",
       "      <td>2019-03-13 00:00:00.0</td>\n",
       "      <td>RISE</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.012085</td>\n",
       "      <td>2019-03-13</td>\n",
       "      <td>10150.0</td>\n",
       "      <td>9930.0</td>\n",
       "      <td>9950.0</td>\n",
       "      <td>A000020</td>\n",
       "      <td>1552469150813</td>\n",
       "      <td>10050.0</td>\n",
       "      <td>153022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-14</th>\n",
       "      <td>736270070</td>\n",
       "      <td>73439</td>\n",
       "      <td>2019-03-14 00:00:00.0</td>\n",
       "      <td>RISE</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.004975</td>\n",
       "      <td>2019-03-14</td>\n",
       "      <td>10100.0</td>\n",
       "      <td>9990.0</td>\n",
       "      <td>10050.0</td>\n",
       "      <td>A000020</td>\n",
       "      <td>1552555592864</td>\n",
       "      <td>10100.0</td>\n",
       "      <td>153008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-15</th>\n",
       "      <td>595667890</td>\n",
       "      <td>59500</td>\n",
       "      <td>2019-03-15 00:00:00.0</td>\n",
       "      <td>FALL</td>\n",
       "      <td>130.0</td>\n",
       "      <td>0.012871</td>\n",
       "      <td>2019-03-15</td>\n",
       "      <td>10150.0</td>\n",
       "      <td>9970.0</td>\n",
       "      <td>10150.0</td>\n",
       "      <td>A000020</td>\n",
       "      <td>1552641879602</td>\n",
       "      <td>9970.0</td>\n",
       "      <td>153030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-18</th>\n",
       "      <td>378737160</td>\n",
       "      <td>37952</td>\n",
       "      <td>2019-03-18 00:00:00.0</td>\n",
       "      <td>RISE</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.002006</td>\n",
       "      <td>2019-03-18</td>\n",
       "      <td>10050.0</td>\n",
       "      <td>9900.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>A000020</td>\n",
       "      <td>1552901084372</td>\n",
       "      <td>9990.0</td>\n",
       "      <td>153030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-19</th>\n",
       "      <td>784371620</td>\n",
       "      <td>78213</td>\n",
       "      <td>2019-03-19 00:00:00.0</td>\n",
       "      <td>FALL</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>2019-03-19</td>\n",
       "      <td>10100.0</td>\n",
       "      <td>9970.0</td>\n",
       "      <td>9990.0</td>\n",
       "      <td>A000020</td>\n",
       "      <td>1552987502446</td>\n",
       "      <td>9980.0</td>\n",
       "      <td>153022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-20</th>\n",
       "      <td>270691290</td>\n",
       "      <td>27138</td>\n",
       "      <td>2019-03-20 00:00:00.0</td>\n",
       "      <td>RISE</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.002004</td>\n",
       "      <td>2019-03-20</td>\n",
       "      <td>10050.0</td>\n",
       "      <td>9860.0</td>\n",
       "      <td>10050.0</td>\n",
       "      <td>A000020</td>\n",
       "      <td>1553073897914</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>153030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-21</th>\n",
       "      <td>616120910</td>\n",
       "      <td>62361</td>\n",
       "      <td>2019-03-21 00:00:00.0</td>\n",
       "      <td>FALL</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.018000</td>\n",
       "      <td>2019-03-21</td>\n",
       "      <td>10050.0</td>\n",
       "      <td>9790.0</td>\n",
       "      <td>10050.0</td>\n",
       "      <td>A000020</td>\n",
       "      <td>1553160306054</td>\n",
       "      <td>9820.0</td>\n",
       "      <td>153030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-22</th>\n",
       "      <td>1815471070</td>\n",
       "      <td>187248</td>\n",
       "      <td>2019-03-22 00:00:00.0</td>\n",
       "      <td>FALL</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0.014257</td>\n",
       "      <td>2019-03-22</td>\n",
       "      <td>9920.0</td>\n",
       "      <td>9570.0</td>\n",
       "      <td>9820.0</td>\n",
       "      <td>A000020</td>\n",
       "      <td>1553246690004</td>\n",
       "      <td>9680.0</td>\n",
       "      <td>153030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-25</th>\n",
       "      <td>963192930</td>\n",
       "      <td>100403</td>\n",
       "      <td>2019-03-25 00:00:00.0</td>\n",
       "      <td>FALL</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.003099</td>\n",
       "      <td>2019-03-25</td>\n",
       "      <td>9720.0</td>\n",
       "      <td>9510.0</td>\n",
       "      <td>9600.0</td>\n",
       "      <td>A000020</td>\n",
       "      <td>1553505930832</td>\n",
       "      <td>9650.0</td>\n",
       "      <td>153030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-26</th>\n",
       "      <td>318868690</td>\n",
       "      <td>33185</td>\n",
       "      <td>2019-03-26 00:00:00.0</td>\n",
       "      <td>FALL</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.009326</td>\n",
       "      <td>2019-03-26</td>\n",
       "      <td>9680.0</td>\n",
       "      <td>9560.0</td>\n",
       "      <td>9630.0</td>\n",
       "      <td>A000020</td>\n",
       "      <td>1553592292838</td>\n",
       "      <td>9560.0</td>\n",
       "      <td>153007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-27</th>\n",
       "      <td>221336520</td>\n",
       "      <td>23278</td>\n",
       "      <td>2019-03-27 00:00:00.0</td>\n",
       "      <td>FALL</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.009414</td>\n",
       "      <td>2019-03-27</td>\n",
       "      <td>9600.0</td>\n",
       "      <td>9440.0</td>\n",
       "      <td>9600.0</td>\n",
       "      <td>A000020</td>\n",
       "      <td>1553678714899</td>\n",
       "      <td>9470.0</td>\n",
       "      <td>153030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-28</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-03-28 00:00:00.0</td>\n",
       "      <td>EVEN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2019-03-28</td>\n",
       "      <td>9470.0</td>\n",
       "      <td>9470.0</td>\n",
       "      <td>9470.0</td>\n",
       "      <td>A000020</td>\n",
       "      <td>1553723408284</td>\n",
       "      <td>9470.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            candleAccTradePrice  candleAccTradeVolume             candleTime  \\\n",
       "candleTime                                                                     \n",
       "2019-02-28           1262292450                127433  2019-02-28 00:00:00.0   \n",
       "2019-03-04            858235130                 86244  2019-03-04 00:00:00.0   \n",
       "2019-03-05            655114470                 65110  2019-03-05 00:00:00.0   \n",
       "2019-03-06            484114800                 47791  2019-03-06 00:00:00.0   \n",
       "2019-03-07            658441180                 65924  2019-03-07 00:00:00.0   \n",
       "2019-03-08            343866720                 34591  2019-03-08 00:00:00.0   \n",
       "2019-03-11            877700660                 89651  2019-03-11 00:00:00.0   \n",
       "2019-03-12            502122480                 50658  2019-03-12 00:00:00.0   \n",
       "2019-03-13            748344140                 74778  2019-03-13 00:00:00.0   \n",
       "2019-03-14            736270070                 73439  2019-03-14 00:00:00.0   \n",
       "2019-03-15            595667890                 59500  2019-03-15 00:00:00.0   \n",
       "2019-03-18            378737160                 37952  2019-03-18 00:00:00.0   \n",
       "2019-03-19            784371620                 78213  2019-03-19 00:00:00.0   \n",
       "2019-03-20            270691290                 27138  2019-03-20 00:00:00.0   \n",
       "2019-03-21            616120910                 62361  2019-03-21 00:00:00.0   \n",
       "2019-03-22           1815471070                187248  2019-03-22 00:00:00.0   \n",
       "2019-03-25            963192930                100403  2019-03-25 00:00:00.0   \n",
       "2019-03-26            318868690                 33185  2019-03-26 00:00:00.0   \n",
       "2019-03-27            221336520                 23278  2019-03-27 00:00:00.0   \n",
       "2019-03-28                    0                     0  2019-03-28 00:00:00.0   \n",
       "\n",
       "           change  changePrice  changeRate        date  highPrice  lowPrice  \\\n",
       "candleTime                                                                    \n",
       "2019-02-28   FALL        130.0    0.013092  2019-02-28     9980.0    9720.0   \n",
       "2019-03-04   RISE        200.0    0.020408  2019-03-04    10050.0    9800.0   \n",
       "2019-03-05   RISE        100.0    0.010000  2019-03-05    10150.0    9970.0   \n",
       "2019-03-06   EVEN          0.0    0.000000  2019-03-06    10250.0   10050.0   \n",
       "2019-03-07   FALL        110.0    0.010891  2019-03-07    10100.0    9910.0   \n",
       "2019-03-08   FALL         60.0    0.006006  2019-03-08    10000.0    9860.0   \n",
       "2019-03-11   FALL         80.0    0.008056  2019-03-11     9960.0    9700.0   \n",
       "2019-03-12   RISE         80.0    0.008122  2019-03-12     9960.0    9870.0   \n",
       "2019-03-13   RISE        120.0    0.012085  2019-03-13    10150.0    9930.0   \n",
       "2019-03-14   RISE         50.0    0.004975  2019-03-14    10100.0    9990.0   \n",
       "2019-03-15   FALL        130.0    0.012871  2019-03-15    10150.0    9970.0   \n",
       "2019-03-18   RISE         20.0    0.002006  2019-03-18    10050.0    9900.0   \n",
       "2019-03-19   FALL         10.0    0.001001  2019-03-19    10100.0    9970.0   \n",
       "2019-03-20   RISE         20.0    0.002004  2019-03-20    10050.0    9860.0   \n",
       "2019-03-21   FALL        180.0    0.018000  2019-03-21    10050.0    9790.0   \n",
       "2019-03-22   FALL        140.0    0.014257  2019-03-22     9920.0    9570.0   \n",
       "2019-03-25   FALL         30.0    0.003099  2019-03-25     9720.0    9510.0   \n",
       "2019-03-26   FALL         90.0    0.009326  2019-03-26     9680.0    9560.0   \n",
       "2019-03-27   FALL         90.0    0.009414  2019-03-27     9600.0    9440.0   \n",
       "2019-03-28   EVEN          0.0    0.000000  2019-03-28     9470.0    9470.0   \n",
       "\n",
       "            openingPrice symbolCode      timestamp  tradePrice tradeTime  \n",
       "candleTime                                                                \n",
       "2019-02-28        9930.0    A000020  1551345978459      9800.0    153025  \n",
       "2019-03-04        9810.0    A000020  1551691539233     10000.0    153021  \n",
       "2019-03-05       10050.0    A000020  1551777979504     10100.0    153010  \n",
       "2019-03-06       10150.0    A000020  1551864371128     10100.0    153030  \n",
       "2019-03-07       10050.0    A000020  1551950773359      9990.0    153010  \n",
       "2019-03-08        9990.0    A000020  1552037163192      9930.0    153005  \n",
       "2019-03-11        9930.0    A000020  1552296378581      9850.0    153024  \n",
       "2019-03-12        9900.0    A000020  1552382772168      9930.0    153030  \n",
       "2019-03-13        9950.0    A000020  1552469150813     10050.0    153022  \n",
       "2019-03-14       10050.0    A000020  1552555592864     10100.0    153008  \n",
       "2019-03-15       10150.0    A000020  1552641879602      9970.0    153030  \n",
       "2019-03-18       10000.0    A000020  1552901084372      9990.0    153030  \n",
       "2019-03-19        9990.0    A000020  1552987502446      9980.0    153022  \n",
       "2019-03-20       10050.0    A000020  1553073897914     10000.0    153030  \n",
       "2019-03-21       10050.0    A000020  1553160306054      9820.0    153030  \n",
       "2019-03-22        9820.0    A000020  1553246690004      9680.0    153030  \n",
       "2019-03-25        9600.0    A000020  1553505930832      9650.0    153030  \n",
       "2019-03-26        9630.0    A000020  1553592292838      9560.0    153007  \n",
       "2019-03-27        9600.0    A000020  1553678714899      9470.0    153030  \n",
       "2019-03-28        9470.0    A000020  1553723408284      9470.0      None  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_price('000020', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
